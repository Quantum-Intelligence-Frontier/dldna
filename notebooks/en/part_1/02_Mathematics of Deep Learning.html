<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>mathematics-of-deep-learning – Deep Learning DNA: Surviving Architectures and Essential Principles</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-f507c7d0488cb7630e20aad62ad8c2aa.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script>window.MathJax = {loader: {load: ['[tex]/boldsymbol']},tex: {packages: {'[+]': ['boldsymbol']}}};</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../notebooks/en/part_1/01_The Beginning of Deep Learning.html">part_1</a></li><li class="breadcrumb-item"><a href="../../../notebooks/en/part_1/02_Mathematics of Deep Learning.html">2. Mathematics of Deep Learning</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../../">English</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Language</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index_de.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Deutsch</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index_en.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">English</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index_es.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Español</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">한국어</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index_zh.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">中文</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/en/part_1/00_Introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">part_1</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/en/part_1/01_The Beginning of Deep Learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1. The Beginning of Deep Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/en/part_1/02_Mathematics of Deep Learning.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">2. Mathematics of Deep Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/en/part_1/03_Deep Learning Framework.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3. Deep Learning Framework</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/en/part_1/04_Activation Function.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4. Activation Function</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/en/part_1/05_Optimization and Visualization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5. Optimization and Visualization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/en/part_1/06_Overfitting and Development of Solution Techniques.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">6. Overfitting and Development of Solution Techniques</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/en/part_1/07_Evolution of Convolutional Neural Networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">7. Evolution of Convolutional Neural Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/en/part_1/08_The Birth of Transformer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8. The Birth of Transformer</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/en/part_1/09_The Evolution of Transformers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">9. The Evolution of Transformers</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/en/part_1/10_Multimodal Deep Learning: The Beginning of Multisensory Convergence.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">10. Multimodal Deep Learning: The Beginning of Multisensory Convergence</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/en/part_1/11_Multimodal Deep Learning: Intelligence Beyond Limits.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">11. Multimodal Deep Learning: Intelligence Beyond Limits</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Deep Learning Frontier</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/en/Deep Learning Frontier/01_SLM: Small but Powerful Language Model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1. SLM: Small but Powerful Language Model</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/en/Deep Learning Frontier/02_Autonomous Driving.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2. Autonomous Driving</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#mathematics-of-deep-learning" id="toc-mathematics-of-deep-learning" class="nav-link active" data-scroll-target="#mathematics-of-deep-learning">2. Mathematics of Deep Learning</a>
  <ul class="collapse">
  <li><a href="#basics-of-linear-algebra" id="toc-basics-of-linear-algebra" class="nav-link" data-scroll-target="#basics-of-linear-algebra">2.1 Basics of Linear Algebra</a>
  <ul class="collapse">
  <li><a href="#vectors" id="toc-vectors" class="nav-link" data-scroll-target="#vectors">2.1.1 Vectors</a></li>
  <li><a href="#dimensions-ranks" id="toc-dimensions-ranks" class="nav-link" data-scroll-target="#dimensions-ranks">2.1.2 Dimensions, Ranks</a></li>
  <li><a href="#basics-of-linear-transformations" id="toc-basics-of-linear-transformations" class="nav-link" data-scroll-target="#basics-of-linear-transformations">2.1.3 Basics of Linear Transformations</a></li>
  <li><a href="#tensor-operations" id="toc-tensor-operations" class="nav-link" data-scroll-target="#tensor-operations">2.1.4 Tensor Operations</a></li>
  <li><a href="#singular-value-decomposition-and-principal-component-analysis" id="toc-singular-value-decomposition-and-principal-component-analysis" class="nav-link" data-scroll-target="#singular-value-decomposition-and-principal-component-analysis">2.1.5 Singular Value Decomposition and Principal Component Analysis</a></li>
  </ul></li>
  <li><a href="#calculus-and-optimization" id="toc-calculus-and-optimization" class="nav-link" data-scroll-target="#calculus-and-optimization">2.2 Calculus and Optimization</a>
  <ul class="collapse">
  <li><a href="#chain-rule" id="toc-chain-rule" class="nav-link" data-scroll-target="#chain-rule">2.2.1 Chain Rule</a></li>
  <li><a href="#gradient-and-jacobian" id="toc-gradient-and-jacobian" class="nav-link" data-scroll-target="#gradient-and-jacobian">2.2.2 Gradient and Jacobian</a></li>
  <li><a href="#chain-rule-and-backpropagation-in-neural-networks" id="toc-chain-rule-and-backpropagation-in-neural-networks" class="nav-link" data-scroll-target="#chain-rule-and-backpropagation-in-neural-networks">2.2.3 Chain Rule and Backpropagation in Neural Networks</a></li>
  <li><a href="#gradient-calculation-for-backpropagation" id="toc-gradient-calculation-for-backpropagation" class="nav-link" data-scroll-target="#gradient-calculation-for-backpropagation">2.2.4 Gradient Calculation for Backpropagation</a></li>
  </ul></li>
  <li><a href="#probability-and-statistics" id="toc-probability-and-statistics" class="nav-link" data-scroll-target="#probability-and-statistics">2.3 Probability and Statistics</a>
  <ul class="collapse">
  <li><a href="#probability-distributions-and-expectations" id="toc-probability-distributions-and-expectations" class="nav-link" data-scroll-target="#probability-distributions-and-expectations">2.3.1 Probability Distributions and Expectations</a></li>
  <li><a href="#bayes-theorem-and-maximum-likelihood-estimation" id="toc-bayes-theorem-and-maximum-likelihood-estimation" class="nav-link" data-scroll-target="#bayes-theorem-and-maximum-likelihood-estimation">2.3.2 Bayes’ Theorem and Maximum Likelihood Estimation</a></li>
  <li><a href="#information-theory-basics" id="toc-information-theory-basics" class="nav-link" data-scroll-target="#information-theory-basics">2.3.3 Information Theory Basics</a></li>
  <li><a href="#loss-function" id="toc-loss-function" class="nav-link" data-scroll-target="#loss-function">2.3.4 Loss Function</a></li>
  </ul></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises">Exercises</a>
  <ul class="collapse">
  <li><a href="#linear-algebra" id="toc-linear-algebra" class="nav-link" data-scroll-target="#linear-algebra">1. Linear Algebra</a></li>
  </ul></li>
  <li><a href="#practice-problems" id="toc-practice-problems" class="nav-link" data-scroll-target="#practice-problems">Practice Problems</a>
  <ul class="collapse">
  <li><a href="#probability-and-statistics-1" id="toc-probability-and-statistics-1" class="nav-link" data-scroll-target="#probability-and-statistics-1">3 Probability and Statistics</a></li>
  </ul></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../notebooks/en/part_1/01_The Beginning of Deep Learning.html">part_1</a></li><li class="breadcrumb-item"><a href="../../../notebooks/en/part_1/02_Mathematics of Deep Learning.html">2. Mathematics of Deep Learning</a></li></ol></nav></header>




<p><a href="https://colab.research.google.com/github/Quantum-Intelligence-Frontier/dldna/blob/main/notebooks/en/part_1/02_Mathematics_of_Deep_Learning.ipynb" target="_parent"> <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"> </a></p>
<section id="mathematics-of-deep-learning" class="level1">
<h1>2. Mathematics of Deep Learning</h1>
<blockquote class="blockquote">
<p>“Every number is composed of units, and every number can be divided into units” - Al-Khwarizmi (780-850), Persian mathematician</p>
</blockquote>
<p>This chapter explores the mathematical concepts that form the core of deep learning. Deep learning models are composed of complex mathematical functions. A deep understanding of linear algebra, calculus, probability, and statistics is essential to grasp the principles of model behavior, improve performance, and design new models. For example, understanding matrix operations is crucial for understanding the behavior of Convolutional Neural Networks (CNNs), and differentiation and optimization play a key role in understanding the learning process of models.</p>
<p>If this chapter feels difficult, you can move on to the next one and come back to it later. It’s best to revisit and get familiar with it from time to time.</p>
<section id="basics-of-linear-algebra" class="level2">
<h2 class="anchored" data-anchor-id="basics-of-linear-algebra">2.1 Basics of Linear Algebra</h2>
<p>Linear algebra is the foundation of deep learning. From matrix operations to advanced optimization techniques, linear algebra is an essential tool. This section will cover basic concepts such as vectors, matrices, and tensors, as well as advanced topics like singular value decomposition and principal component analysis.</p>
<section id="vectors" class="level3">
<h3 class="anchored" data-anchor-id="vectors">2.1.1 Vectors</h3>
<p>Vectors and matrices are the most basic operations for representing data and transforming it.</p>
<p><strong>Vector Basics</strong></p>
<p>A vector is a mathematical object that represents a quantity with both magnitude and direction. The mathematical definition is the same, but the perspective varies depending on the field of application.</p>
<ul>
<li>Mathematical perspective: In mathematics, a vector is defined as an abstract object with magnitude and direction, which is closed under addition and scalar multiplication.</li>
<li>Physical perspective: In physics, vectors are mainly used to represent physical quantities such as force, velocity, and acceleration. In this case, the magnitude and direction of the vector have real physical meaning. Physics treats all changes as vectors, and the dimension of the vector is limited. For example, space is 3D, and spacetime is 4D.</li>
<li>Computer science perspective: In computer science, especially in machine learning and deep learning, vectors are mainly used to represent features of data. Here, each element of the vector represents a specific property of the data, and it may not necessarily have physical directionality. The dimension of the vector can range from tens to thousands.</li>
</ul>
<p>Understanding these different perspectives is important when working with vectors in deep learning. In deep learning, vectors are mainly used from a computer science perspective, but mathematical operations and physical intuition are also utilized.</p>
<p>In deep learning, vectors are often used to represent multiple features of data simultaneously. For example, a 5-dimensional vector used in a housing price prediction model can be represented as:</p>
<p><span class="math inline">\(\mathbf{v} = \begin{bmatrix} v_1 \\ v_2 \\ v_3 \\ v_4 \\ v_5 \end{bmatrix}\)</span></p>
<p>Each element of this vector represents different characteristics of the house. <span class="math inline">\(v_1\)</span>: area of the house (square meters), <span class="math inline">\(v_2\)</span>: number of rooms, <span class="math inline">\(v_3\)</span>: age of the house (years), <span class="math inline">\(v_4\)</span>: distance to the nearest school (kilometers), <span class="math inline">\(v_5\)</span>: crime rate (percentage)</p>
<p>Deep learning models can use these multi-dimensional vectors as input to predict housing prices. Vectors are used to effectively represent and process complex real-world data with multiple features.</p>
<p>In NumPy, vectors can be easily created and used.</p>
<div id="cell-2" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install dldna[colab] <span class="co"># in Colab</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip install dldna[all] # in your local</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="cell-3" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Vector creation</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>v <span class="op">=</span> np.array([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>])</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Vector magnitude (L2 norm)</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>magnitude <span class="op">=</span> np.linalg.norm(v)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Vector magnitude: </span><span class="sc">{</span>magnitude<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Vector normalization</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>normalized_v <span class="op">=</span> v <span class="op">/</span> magnitude</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Normalized vector: </span><span class="sc">{</span>normalized_v<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Vector magnitude: 3.7416573867739413
Normalized vector: [0.26726124 0.53452248 0.80178373]</code></pre>
</div>
</div>
<p>A closer look at the concept of vectors reveals distinctions between row vectors and column vectors, as well as covectors and contravariant vectors used in physics and engineering.</p>
<p><strong>Row Vectors and Column Vectors</strong></p>
<p>Vectors are generally represented as column vectors. Row vectors can be considered as the transpose of column vectors. More mathematically accurate, row vectors can also be referred to as dual vectors or covectors.</p>
<p>Column vector: <span class="math inline">\(\mathbf{v} = \begin{bmatrix} v_1 \\ v_2 \\ v_3 \end{bmatrix}\)</span>, Row vector: <span class="math inline">\(\mathbf{v}^T = [v_1 \quad v_2 \quad v_3]\)</span></p>
<p>Row vectors and column vectors have different properties. Row vectors act on column vectors as linear functions to produce scalars, which is represented by the dot product operation.</p>
<p><span class="math display">\[\mathbf{u}^T\mathbf{v} = u_1v_1 + u_2v_2 + u_3v_3\]</span></p>
<p><strong>Covectors and Contravariant Vectors</strong></p>
<p>In physics and engineering, the concepts of covectors (covariant vectors) and contravariant vectors are importantly dealt with. This represents the transformation characteristics of vectors according to coordinate system changes.</p>
<ul>
<li>Contravariant vector: A vector that transforms in the opposite direction of the basis when the coordinate system changes. It is generally denoted with a superscript (e.g., <span class="math inline">\(v^i\)</span>).</li>
<li>Covector: A vector that transforms in the same direction as the basis when the coordinate system changes. It is generally denoted with a subscript (e.g., <span class="math inline">\(v_i\)</span>).</li>
</ul>
<p>This distinction is crucial in tensor notation. For example, <span class="math inline">\(T^i_j\)</span> indicates that the upper index <span class="math inline">\(i\)</span> represents contravariance and the lower index <span class="math inline">\(j\)</span> represents covariance. Notably, in general relativity, these concepts of covariance and contravariance are treated as very important.</p>
<p><strong>Application in Deep Learning</strong></p>
<p>In deep learning, the distinction between covariance and contravariance is often not explicitly emphasized. The reasons for this include:</p>
<ol type="1">
<li>Standardized data representation: Deep learning typically handles data in a standardized form (e.g., column vectors), making the distinction between covariance and contravariance less important.</li>
<li>Euclidean space assumption: Many deep learning models assume that data exists in Euclidean space, where distinctions between covariance and contravariance are not clear.</li>
<li>Simplification of operations: Key deep learning operations (e.g., matrix multiplication, application of activation functions) can be effectively performed without these distinctions.</li>
<li>Automatic differentiation: Modern deep learning frameworks’ automatic differentiation capabilities can accurately compute gradients without considering these subtle distinctions.</li>
</ol>
<p>However, in specific fields, particularly physics-based machine learning or geometric deep learning, these concepts may still be important. For instance, in deep learning models that utilize differential geometry, the distinction between covariance and contravariance can play a critical role in model design and interpretation.</p>
<p>In conclusion, while the basic concept of vectors in deep learning is simplified, more complex mathematical concepts still play significant roles in advanced model design and special applications.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Click to view contents (Deep Dive: Vector Space and Linear Combination)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Click to view contents (Deep Dive: Vector Space and Linear Combination)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<section id="vector-space-and-linear-combination" class="level3 callout-body-container callout-body">
<h3 class="anchored" data-anchor-id="vector-space-and-linear-combination">Vector Space and Linear Combination</h3>
<p>The vector space, a core concept in linear algebra, provides a fundamental framework for representing and transforming data in deep learning. In this deep dive, we’ll explore the rigorous definition of vector spaces and related concepts, along with examples of their applications in deep learning.</p>
<section id="vector-space" class="level4">
<h4 class="anchored" data-anchor-id="vector-space">Vector Space</h4>
<p>A vector space consists of a set <span class="math inline">\(V\)</span> that satisfies eight axioms, along with addition and scalar multiplication operations. Here, elements of <span class="math inline">\(V\)</span> are called vectors, and scalars are real numbers <span class="math inline">\(\mathbb{R}\)</span> or complex numbers <span class="math inline">\(\mathbb{C}\)</span>. (In deep learning, we mainly use real numbers.)</p>
<p><strong>Vector Addition:</strong> For any two elements <span class="math inline">\(\mathbf{u}, \mathbf{v}\)</span> in <span class="math inline">\(V\)</span>, <span class="math inline">\(\mathbf{u} + \mathbf{v}\)</span> is also an element of <span class="math inline">\(V\)</span>. (Closed under addition)</p>
<p><strong>Scalar Multiplication:</strong> For any element <span class="math inline">\(\mathbf{u}\)</span> in <span class="math inline">\(V\)</span> and scalar <span class="math inline">\(c\)</span>, <span class="math inline">\(c\mathbf{u}\)</span> is also an element of <span class="math inline">\(V\)</span>. (Closed under scalar multiplication)</p>
<p><strong>Vector Addition and Scalar Multiplication must satisfy the following eight axioms.</strong> (<span class="math inline">\(\mathbf{u}, \mathbf{v}, \mathbf{w} \in V\)</span>, <span class="math inline">\(c, d\)</span>: scalars)</p>
<ol type="1">
<li><strong>Commutativity of addition:</strong> <span class="math inline">\(\mathbf{u} + \mathbf{v} = \mathbf{v} + \mathbf{u}\)</span></li>
<li><strong>Associativity of addition:</strong> <span class="math inline">\((\mathbf{u} + \mathbf{v}) + \mathbf{w} = \mathbf{u} + (\mathbf{v} + \mathbf{w})\)</span></li>
<li><strong>Additive identity:</strong> For all <span class="math inline">\(\mathbf{u} \in V\)</span>, there exists a <span class="math inline">\(\mathbf{0} \in V\)</span> (zero vector) such that <span class="math inline">\(\mathbf{u} + \mathbf{0} = \mathbf{u}\)</span>.</li>
<li><strong>Additive inverse:</strong> For each <span class="math inline">\(\mathbf{u} \in V\)</span>, there exists a <span class="math inline">\(-\mathbf{u} \in V\)</span> (additive inverse) such that <span class="math inline">\(\mathbf{u} + (-\mathbf{u}) = \mathbf{0}\)</span>.</li>
<li><strong>Distributivity of scalar multiplication with respect to vector addition:</strong> <span class="math inline">\(c(\mathbf{u} + \mathbf{v}) = c\mathbf{u} + c\mathbf{v}\)</span></li>
<li><strong>Distributivity of scalar multiplication with respect to scalar addition:</strong> <span class="math inline">\((c + d)\mathbf{u} = c\mathbf{u} + d\mathbf{u}\)</span></li>
<li><strong>Compatibility of scalar multiplication with scalar multiplication:</strong> <span class="math inline">\(c(d\mathbf{u}) = (cd)\mathbf{u}\)</span></li>
<li><strong>Identity element of scalar multiplication:</strong> <span class="math inline">\(1\mathbf{u} = \mathbf{u}\)</span> (here, 1 is the identity element of scalar multiplication)</li>
</ol>
<p><strong>Example:</strong> * <span class="math inline">\(\mathbb{R}^n\)</span>: <span class="math inline">\(n\)</span>-dimensional real vector space (n-tuples of real numbers) * <span class="math inline">\(\mathbb{C}^n\)</span>: <span class="math inline">\(n\)</span>-dimensional complex vector space * <span class="math inline">\(M_{m \times n}(\mathbb{R})\)</span>: <span class="math inline">\(m \times n\)</span> real matrix space * <span class="math inline">\(P_n\)</span>: space of polynomials with real coefficients of degree at most <span class="math inline">\(n\)</span> * <span class="math inline">\(C[a, b]\)</span>: space of real-valued continuous functions on the interval <span class="math inline">\([a, b]\)</span></p>
</section>
<section id="subspace" class="level4">
<h4 class="anchored" data-anchor-id="subspace">Subspace</h4>
<p>A subset <span class="math inline">\(W\)</span> of a vector space <span class="math inline">\(V\)</span> is called a subspace if it satisfies the following conditions:</p>
<ol type="1">
<li><span class="math inline">\(\mathbf{0} \in W\)</span> (contains the zero vector)</li>
<li>If <span class="math inline">\(\mathbf{u}, \mathbf{v} \in W\)</span>, then <span class="math inline">\(\mathbf{u} + \mathbf{v} \in W\)</span> (closed under addition)</li>
<li>If <span class="math inline">\(\mathbf{u} \in W\)</span> and <span class="math inline">\(c\)</span> is a scalar, then <span class="math inline">\(c\mathbf{u} \in W\)</span> (closed under scalar multiplication)</li>
</ol>
<p>In other words, a subspace is a subset of a vector space that is itself a vector space.</p>
</section>
<section id="linear-combination" class="level4">
<h4 class="anchored" data-anchor-id="linear-combination">Linear Combination</h4>
<p>Given vectors <span class="math inline">\(\mathbf{v}_1, \mathbf{v}_2, ..., \mathbf{v}_k\)</span> in a vector space <span class="math inline">\(V\)</span> and scalars <span class="math inline">\(c_1, c_2, ..., c_k\)</span>, an expression of the form <span class="math inline">\(c_1\mathbf{v}_1 + c_2\mathbf{v}_2 + ... + c_k\mathbf{v}_k\)</span> is called a linear combination.</p>
</section>
<section id="linear-independence-and-linear-dependence" class="level4">
<h4 class="anchored" data-anchor-id="linear-independence-and-linear-dependence">Linear Independence and Linear Dependence</h4>
<p>A set of vectors {<span class="math inline">\(\mathbf{v}_1, \mathbf{v}_2, ..., \mathbf{v}_k\)</span>} is said to be linearly independent if the only way to express the zero vector as a linear combination of these vectors is with all coefficients equal to zero:</p>
<p><span class="math inline">\(c_1\mathbf{v}_1 + c_2\mathbf{v}_2 + ... + c_k\mathbf{v}_k = \mathbf{0}\)</span> implies <span class="math inline">\(c_1 = c_2 = ... = c_k = 0\)</span></p>
<p>If this condition is not satisfied (i.e., there exist non-zero scalars <span class="math inline">\(c_1, ..., c_k\)</span> such that the equation holds), the set of vectors is said to be linearly dependent.</p>
<p><strong>Intuitive meaning:</strong></p>
<ul>
<li><strong>Linear Independence:</strong> Vectors can be thought of as pointing in “different directions”. No vector can be expressed as a linear combination of the others.</li>
<li><strong>Linear Dependence:</strong> Some vectors can be thought of as lying in the “same direction” (or “plane”, “hyperplane”). At least one vector can be expressed as a linear combination of the others.</li>
</ul>
</section>
<section id="basis-and-dimension" class="level4">
<h4 class="anchored" data-anchor-id="basis-and-dimension">Basis and Dimension</h4>
<ul>
<li><strong>Basis:</strong> A basis for a vector space <span class="math inline">\(V\)</span> is a set of vectors that satisfies two conditions:
<ol type="1">
<li>Linear independence.</li>
<li>Spans <span class="math inline">\(V\)</span> (see span below).</li>
</ol></li>
<li><strong>Dimension:</strong> The number of vectors in a basis for a vector space is called the dimension of the space. (dim <span class="math inline">\(V\)</span>)</li>
</ul>
<p><strong>Key point:</strong> While a basis for a given vector space is not unique, all bases have the same number of vectors.</p>
</section>
<section id="span" class="level4">
<h4 class="anchored" data-anchor-id="span">Span</h4>
<p>The span of a set of vectors {<span class="math inline">\(\mathbf{v}_1, \mathbf{v}_2, ..., \mathbf{v}_k\)</span>} is the set of all possible linear combinations of these vectors:</p>
<p>span{<span class="math inline">\(\mathbf{v}_1, \mathbf{v}_2, ..., \mathbf{v}_k\)</span>} = {<span class="math inline">\(c_1\mathbf{v}_1 + c_2\mathbf{v}_2 + ... + c_k\mathbf{v}_k\)</span> | <span class="math inline">\(c_1, c_2, ..., c_k\)</span> are scalars}</p>
<p>In other words, it is the set of all vectors that can be formed using the given vectors. The span is always a subspace. #### Vector Space Examples in Deep Learning</p>
<ul>
<li><strong>Feature Vector:</strong> Input data for deep learning models, such as images, text, and audio, are often represented as high-dimensional vectors. For example, a 28x28 pixel grayscale image can be represented as a 784-dimensional vector. Each dimension represents the brightness value of a specific pixel in the image.</li>
<li><strong>Weight Vector:</strong> Each layer of a neural network consists of a weight matrix and a bias vector. Each row (or column) of the weight matrix can be viewed as a vector representing the weights of a particular neuron.</li>
<li><strong>Embedding Vector:</strong> Used to represent words, users, items, etc. in a low-dimensional vector space. Word2Vec, GloVe, and BERT are representative embedding techniques that represent words as vectors.</li>
<li><strong>Latent Space:</strong> Autoencoders, Variational Autoencoders (VAE), and Generative Adversarial Networks (GAN) learn to map data to a low-dimensional latent space. This latent space can also be viewed as a vector space.</li>
</ul>
</section>
</section>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Click to view contents (Deep Dive: Norum and Street - Deep Learning Perspective)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Click to view contents (Deep Dive: Norum and Street - Deep Learning Perspective)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<section id="norms-and-distances-in-deep-learning" class="level3 callout-body-container callout-body">
<h3 class="anchored" data-anchor-id="norms-and-distances-in-deep-learning">Norms and Distances in Deep Learning</h3>
<p>Measuring the magnitude of vectors or the distance between two vectors is crucial in deep learning. It is utilized in various areas, including loss functions, regularization, and similarity measurements.</p>
<section id="norms" class="level4">
<h4 class="anchored" data-anchor-id="norms">Norms</h4>
<p>The Lp-norm of a vector <span class="math inline">\(\mathbf{x} = [x_1, x_2, ..., x_n]\)</span> is defined as follows (<span class="math inline">\(p \ge 1\)</span>).</p>
<p><span class="math inline">\(||\mathbf{x}||_p = \left( \sum_{i=1}^{n} |x_i|^p \right)^{1/p}\)</span></p>
<ul>
<li><strong>L1-norm (<span class="math inline">\(p=1\)</span>):</strong> <span class="math inline">\(||\mathbf{x}||_1 = \sum_{i=1}^{n} |x_i|\)</span> (Manhattan distance, Taxicab norm)
<ul>
<li><strong>Characteristics:</strong> The sum of the absolute values of each element. Useful when the magnitude of each feature in the vector is important.</li>
<li><strong>Deep Learning Application:</strong> L1 regularization (Lasso regression) is used to create sparse models (some weights are 0) by limiting the sum of the absolute values of the weights.</li>
</ul></li>
<li><strong>L2-norm (<span class="math inline">\(p=2\)</span>):</strong> <span class="math inline">\(||\mathbf{x}||_2 = \sqrt{\sum_{i=1}^{n} x_i^2}\)</span> (Euclidean norm)
<ul>
<li><strong>Characteristics:</strong> The straight-line distance from the origin to the vector coordinates (Pythagorean theorem). The most widely used norm.</li>
<li><strong>Deep Learning Application:</strong> L2 regularization (Ridge regression) is used to prevent overfitting by limiting the sum of the squares of the weights. Also known as weight decay.</li>
</ul></li>
<li><strong>L∞-norm (<span class="math inline">\(p \to \infty\)</span>):</strong> <span class="math inline">\(||\mathbf{x}||_\infty = \max_i |x_i|\)</span>
<ul>
<li><strong>Characteristics:</strong> The maximum absolute value among the vector elements.</li>
<li><strong>Deep Learning Application:</strong> (Less common) Used when you want to limit the value of a specific element from becoming too large.</li>
</ul></li>
</ul>
</section>
<section id="distances" class="level4">
<h4 class="anchored" data-anchor-id="distances">Distances</h4>
<p>The distance between two vectors <span class="math inline">\(\mathbf{x}\)</span> and <span class="math inline">\(\mathbf{y}\)</span> is generally defined as the norm of their difference.</p>
<p><span class="math inline">\(d(\mathbf{x}, \mathbf{y}) = ||\mathbf{x} - \mathbf{y}||\)</span></p>
<ul>
<li><strong>L1 Distance:</strong> <span class="math inline">\(d(\mathbf{x}, \mathbf{y}) = ||\mathbf{x} - \mathbf{y}||_1 = \sum_{i=1}^{n} |x_i - y_i|\)</span></li>
<li><strong>L2 Distance:</strong> <span class="math inline">\(d(\mathbf{x}, \mathbf{y}) = ||\mathbf{x} - \mathbf{y}||_2 = \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2}\)</span></li>
</ul>
<p><strong>Examples of Applications in Deep Learning:</strong></p>
<ul>
<li><strong>Loss Functions:</strong> MSE (L2 Loss), MAE (L1 Loss)</li>
<li><strong>Regularization:</strong> L1 regularization, L2 regularization (weight decay)</li>
<li><strong>Similarity/Distance-based Learning:</strong> k-NN, SVM, Siamese Network, Triplet Network, Contrastive Learning</li>
<li><strong>Embeddings:</strong> Representing words, users, items, etc. in vector space and understanding similarity/relevance through vector distances.</li>
<li><strong>Outlier Detection:</strong> Detecting outliers based on the distance between data points.</li>
</ul>
<p><strong>Note:</strong> In deep learning, it is essential to distinguish between “distance” and “similarity.” A smaller distance indicates higher similarity, while higher similarity means closer proximity. Cosine similarity is one of the commonly used methods for measuring similarity in deep learning.</p>
</section>
</section>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Click to view contents (Deep Dive: Affine Space)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Click to view contents (Deep Dive: Affine Space)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<section id="affine-space" class="level3 callout-body-container callout-body">
<h3 class="anchored" data-anchor-id="affine-space">Affine Space</h3>
<p>Affine space is a generalization of the vector space concept in linear algebra, and it is a useful tool for understanding deep learning models from a geometric perspective. In particular, affine transformations represent a form of linear transformation with bias added, which is frequently used in deep learning.</p>
<section id="definition-of-affine-space" class="level4">
<h4 class="anchored" data-anchor-id="definition-of-affine-space">Definition of Affine Space</h4>
<p>An affine space consists of three elements: a set of points, a vector space, and an operation that adds a point and a vector. More specifically:</p>
<ul>
<li><strong>Set of points (<span class="math inline">\(\mathcal{A}\)</span>):</strong> A collection of geometric objects (points). Unlike vector spaces, <em>there is no fixed origin</em>.</li>
<li><strong>Vector space (<span class="math inline">\(V\)</span>):</strong> A set of vectors representing the displacement or difference between points. It satisfies all properties of a vector space (addition, scalar multiplication, and eight axioms).</li>
<li><strong>Addition of point and vector (<span class="math inline">\(\mathcal{A} \times V \to \mathcal{A}\)</span>):</strong> An operation that adds a point <span class="math inline">\(P \in \mathcal{A}\)</span> and a vector <span class="math inline">\(\mathbf{v} \in V\)</span> to obtain a new point <span class="math inline">\(Q \in \mathcal{A}\)</span>. This is denoted as <span class="math inline">\(Q = P + \mathbf{v}\)</span>.</li>
</ul>
<p>This addition operation must satisfy two properties:</p>
<ol type="1">
<li><strong>For any point <span class="math inline">\(P \in \mathcal{A}\)</span>, <span class="math inline">\(P + \mathbf{0} = P\)</span> (where <span class="math inline">\(\mathbf{0}\)</span> is the zero vector in the vector space <span class="math inline">\(V\)</span>)</strong></li>
<li><strong>For any points <span class="math inline">\(P, Q, R \in \mathcal{A}\)</span>, <span class="math inline">\((P + \mathbf{u}) + \mathbf{v} = P + (\mathbf{u} + \mathbf{v})\)</span> (where <span class="math inline">\(\mathbf{u}, \mathbf{v} \in V\)</span>)</strong></li>
</ol>
<p><strong>Important Characteristics</strong></p>
<ul>
<li>There is <em>no special point called the “origin”</em> in an affine space. All points are equal.</li>
<li>The difference between two points <span class="math inline">\(P, Q \in \mathcal{A}\)</span> can be represented as a vector in the vector space <span class="math inline">\(V\)</span>: <span class="math inline">\(\overrightarrow{PQ} = Q - P \in V\)</span>. However, the sum of two points is not defined.</li>
<li>Using point and vector addition, it is possible to move from one point to another.</li>
</ul>
</section>
<section id="affine-combination" class="level4">
<h4 class="anchored" data-anchor-id="affine-combination">Affine Combination</h4>
<p>Given points <span class="math inline">\(P_1, P_2, ..., P_k\)</span> in an affine space <span class="math inline">\(\mathcal{A}\)</span> and scalars <span class="math inline">\(c_1, c_2, ..., c_k\)</span>, the following expression is called an affine combination:</p>
<p><span class="math inline">\(c_1P_1 + c_2P_2 + ... + c_kP_k\)</span> (provided that <span class="math inline">\(c_1 + c_2 + ... + c_k = 1\)</span>)</p>
<p><strong>Important:</strong> Unlike linear combinations, affine combinations require that <em>the sum of the coefficients is 1</em>. This condition reflects the property of affine spaces that there is no “origin”.</p>
</section>
<section id="affine-transformation" class="level4">
<h4 class="anchored" data-anchor-id="affine-transformation">Affine Transformation</h4>
<p>An affine transformation is a function from one affine space to another, expressed as a combination of a linear transformation and a translation. That is, an affine transformation includes both a <em>linear transformation</em> and a <em>bias</em>:</p>
<p><span class="math inline">\(f(P) = T(P) + \mathbf{b}\)</span></p>
<ul>
<li><span class="math inline">\(T\)</span>: Linear transformation (from vector space <span class="math inline">\(V\)</span> to <span class="math inline">\(V\)</span>)</li>
<li><span class="math inline">\(\mathbf{b}\)</span>: Translation vector (an element of vector space <span class="math inline">\(V\)</span>)</li>
</ul>
<p><strong>Matrix Representation:</strong></p>
<p>Affine transformations can be represented using augmented matrices. In an <span class="math inline">\(n\)</span>-dimensional affine space, using <span class="math inline">\((n+1)\)</span>-dimensional vectors allows the representation of affine transformations as <span class="math inline">\((n+1) \times (n+1)\)</span> matrices. <span class="math inline">\(\begin{bmatrix} \mathbf{y} \\ 1 \end{bmatrix} = \begin{bmatrix} \mathbf{A} &amp; \mathbf{b} \\ \mathbf{0}^T &amp; 1 \end{bmatrix} \begin{bmatrix} \mathbf{x} \\ 1 \end{bmatrix}\)</span></p>
<ul>
<li><span class="math inline">\(\mathbf{A}\)</span>: <span class="math inline">\(n \times n\)</span> linear transformation matrix</li>
<li><span class="math inline">\(\mathbf{b}\)</span>: <span class="math inline">\(n\)</span>-dimensional translation vector</li>
<li><span class="math inline">\(\mathbf{x}\)</span>: <span class="math inline">\(n\)</span>-dimensional input vector (point in affine space)</li>
<li><span class="math inline">\(\mathbf{y}\)</span>: <span class="math inline">\(n\)</span>-dimensional output vector (point in affine space)</li>
</ul>
</section>
<section id="affine-space-and-affine-transformation-in-deep-learning" class="level4">
<h4 class="anchored" data-anchor-id="affine-space-and-affine-transformation-in-deep-learning">Affine Space and Affine Transformation in Deep Learning</h4>
<ul>
<li><strong>Fully Connected Layer:</strong> The fully connected layer (dense layer) in deep learning performs an affine transformation. In <span class="math inline">\(\mathbf{y} = \mathbf{W}\mathbf{x} + \mathbf{b}\)</span>, <span class="math inline">\(\mathbf{W}\mathbf{x}\)</span> represents the linear transformation and <span class="math inline">\(\mathbf{b}\)</span> represents the bias (translation).</li>
<li><strong>Input Space:</strong> Input data in deep learning models is often represented as high-dimensional vectors, but can be considered as points in an affine space without an origin. For example, image data is represented as a vector with pixel brightness values as elements, but this vector space does not have a special origin.</li>
<li><strong>Feature Space:</strong> Each layer of the neural network transforms the input into a new feature space. This transformation is often a combination of affine transformations (linear transformation + bias) and non-linear activation functions.</li>
<li><strong>Data Augmentation:</strong> Operations such as rotation, translation, and scaling on image data can be represented as affine transformations.</li>
<li><strong>Affine Layer</strong>: Unlike linear transformations, it considers bias.</li>
</ul>
</section>
<section id="deep-learning-models-without-bias" class="level4">
<h4 class="anchored" data-anchor-id="deep-learning-models-without-bias">Deep Learning Models Without Bias</h4>
<p>Recently, some deep learning research has proposed models that remove the bias term for computational efficiency, model interpretability, or specific theoretical backgrounds.</p>
<ul>
<li><strong>DeepMind’s MuZero (2020):</strong> The reinforcement learning model MuZero does not use bias in its policy network and value network. The paper mentions that removing bias helps with representation learning.</li>
<li><strong>OpenAI’s GPT (Generative Pre-trained Transformer) series:</strong> In some studies and implementations, the bias term is removed for computational efficiency. However, not all GPT series models do not use bias. Large models like GPT-3 often still use bias.</li>
<li><strong>No-Bias Networks:</strong> Some research systematically analyzes the effect of removing bias on the model’s generalization performance.</li>
</ul>
<p><strong>Reasons for Removing Bias</strong></p>
<ul>
<li><strong>Computational Efficiency:</strong> Removing the bias term reduces the number of model parameters, resulting in decreased computational and memory usage. This effect can be more significant in large models.</li>
<li><strong>Representation Learning:</strong> In certain problems, the bias term may be unnecessary or even hinder representation learning. For example, MuZero believes that bias-free representations can learn more abstract and generalized representations.</li>
<li><strong>Theoretical/Mathematical Grounds:</strong> Some models (e.g., certain types of generative models) may have a form without bias that is mathematically more natural or suitable for specific theoretical analyses.</li>
<li><strong>Regularization Effect</strong>: There is also research suggesting that the absence of bias can have a regularization effect, allowing the weight matrix to carry more important information. <strong>Note:</strong> Removing bias does not <em>always</em> guarantee improved performance. The impact of bias on performance may vary depending on the characteristics of the problem, the structure of the model, and the amount of data.</li>
</ul>
<p>The concept of affine space and affine transformation can be used for geometric interpretation of deep learning models, analysis of generalization performance, and design of new architectures.</p>
</section>
</section>
</div>
</div>
</section>
<section id="dimensions-ranks" class="level3">
<h3 class="anchored" data-anchor-id="dimensions-ranks">2.1.2 Dimensions, Ranks</h3>
<p>Terms related to tensors, vectors, and matrices are used slightly differently in mathematics, physics, and computer science, which can cause confusion. To avoid this confusion, let’s clarify the key concepts. First, we’ll look at the rank and dimensions of a tensor. The rank of a tensor refers to the number of indices it has. For example, a scalar is a rank 0 tensor, a vector is a rank 1 tensor, and a matrix is a rank 2 tensor. Tensors with three or more dimensions are generally just called tensors.</p>
<p>The term “dimension” can have two different meanings, so caution is needed. First, it can be used to mean the same as the rank of a tensor. In this case, a vector would be called a one-dimensional tensor and a matrix would be called a two-dimensional tensor. Second, it can be used to refer to the length or size of an array. For example, the dimension of a vector <span class="math inline">\(\mathbf{a} = [1, 2, 3, 4]\)</span> would be said to be 4.</p>
<p>It’s also important to know the differences in terminology between fields. In physics, the number of elements has physical meaning, so the terms are used more strictly. On the other hand, in computer science, vectors, matrices, and tensors are often treated as arrays of numbers, and the term “dimension” is used interchangeably to refer to both the number of data elements and the number of indices.</p>
<p>To avoid confusion due to these differences in terminology, several things need to be kept in mind. The meaning of a term can vary depending on the context, so careful interpretation is necessary. It’s necessary to clearly distinguish what is meant by “dimension” in papers or books. In particular, in the field of deep learning, both the rank of a tensor and the size of an array are often referred to as “dimensions”, so consistent interpretation is important.</p>
<p>In deep learning frameworks, the term ‘dimension’ or ‘axis’ is used to represent the shape of a tensor. For example, in PyTorch, you can check the size of each dimension of a tensor using <code>tensor.shape</code> or <code>tensor.size()</code>. In this book, we will use ‘dimension’ to refer to the rank of a tensor and the length/size of an array as the value of each element in the shape or dimension.</p>
</section>
<section id="basics-of-linear-transformations" class="level3">
<h3 class="anchored" data-anchor-id="basics-of-linear-transformations">2.1.3 Basics of Linear Transformations</h3>
<p>Let’s take a look at the math needed for deep learning training. The linear transformation, which is the core operation of neural networks, is expressed very simply in forward calculations. In this section, we will focus on the basic linear operations before passing through the activation function.</p>
<p>The basic form of forward operations is as follows.</p>
<p><span class="math display">\[\boldsymbol y = \boldsymbol x \boldsymbol W + \boldsymbol b\]</span></p>
<p>Here, <span class="math inline">\(\boldsymbol x\)</span> represents the input, <span class="math inline">\(\boldsymbol W\)</span> represents the weight, <span class="math inline">\(\boldsymbol b\)</span> represents the bias, and <span class="math inline">\(\boldsymbol y\)</span> represents the output. In neural network mathematics, inputs and outputs are often represented as vectors, and weights are represented as matrices. Bias (<span class="math inline">\(\boldsymbol b\)</span>) is sometimes expressed as a scalar value, but it should be accurately represented as a vector of the same form as the output.</p>
<p><strong>Matrices and Linear Transformations</strong></p>
<p>Matrices are powerful tools for expressing linear transformations. Linear transformations are processes that map a point in vector space to another point, which can be seen as a transformation of the entire space. For materials that help visualize these concepts, I recommend 3Blue1Brown’s video “Linear transformations and matrices”[1]. This video intuitively explains basic concepts of linear algebra and clearly shows how matrices transform spaces.</p>
<p>When input data <span class="math inline">\(\boldsymbol x\)</span> is represented as a vector, it means a single data point, and the length of the vector becomes the number of features. However, in actual training processes, multiple data are usually processed at once. In this case, the input becomes a matrix <span class="math inline">\(\boldsymbol X\)</span> of the form (n, m), where n represents the number of data and m represents the number of features.</p>
<p>In actual deep learning models, input data can take the form of tensors with dimensions higher than 2D matrices.</p>
<ul>
<li>Image data: 4D tensor of the form (batch size, height, width, channel)</li>
<li>Video data: 5D tensor of the form (batch size, frame number, height, width, channel)</li>
</ul>
<p>To handle such high-dimensional data, neural networks use various forms of linear and nonlinear transformations. In the reverse propagation process of linear transformations, gradients are calculated and transmitted in reverse order to each layer to update parameters. This process can be complex, but it is efficiently performed using automatic differentiation tools. Linear transformation is a basic component of deep learning models, but the actual performance of models is achieved through combinations with nonlinear activation functions. In the next section, we will look at how this nonlinearity increases the expressive power of models.</p>
<div id="cell-10" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># if in Colab, plase don't run this and below code. just see the result video bleow the following cell.</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="co">#from manim import *  </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="cell-11" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>manim <span class="op">-</span>qh <span class="op">-</span>v WARNING LinearTransformations  </span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> manim <span class="im">import</span> <span class="op">*</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> manim <span class="im">import</span> config</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LinearTransformations(ThreeDScene):</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> construct(<span class="va">self</span>):</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.set_camera_orientation(phi<span class="op">=</span><span class="dv">75</span> <span class="op">*</span> DEGREES, theta<span class="op">=-</span><span class="dv">45</span> <span class="op">*</span> DEGREES)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>        axes <span class="op">=</span> ThreeDAxes(x_range<span class="op">=</span>[<span class="op">-</span><span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">1</span>], y_range<span class="op">=</span>[<span class="op">-</span><span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">1</span>], z_range<span class="op">=</span>[<span class="op">-</span><span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">1</span>], x_length<span class="op">=</span><span class="dv">10</span>, y_length<span class="op">=</span><span class="dv">10</span>, z_length<span class="op">=</span><span class="dv">10</span>).set_color(GRAY)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.add(axes)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># --- 3D Linear Transformation (Rotation and Shear) ---</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>        title <span class="op">=</span> Text(<span class="st">"3D Linear Transformations"</span>, color<span class="op">=</span>BLACK).to_edge(UP)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.play(Write(title))</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.wait(<span class="dv">1</span>)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 1. Rotation around Z-axis</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>        text_rotation <span class="op">=</span> Text(<span class="st">"Rotation around Z-axis"</span>, color<span class="op">=</span>BLUE).scale(<span class="fl">0.7</span>).next_to(title, DOWN, buff<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.play(Write(text_rotation))</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>        cube <span class="op">=</span> Cube(side_length<span class="op">=</span><span class="dv">2</span>, fill_color<span class="op">=</span>BLUE, fill_opacity<span class="op">=</span><span class="fl">0.5</span>, stroke_color<span class="op">=</span>WHITE, stroke_width<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.play(Create(cube))</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.play(Rotate(cube, angle<span class="op">=</span>PI<span class="op">/</span><span class="dv">2</span>, axis<span class="op">=</span>OUT, about_point<span class="op">=</span>ORIGIN), run_time<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.wait(<span class="dv">1</span>)</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.play(FadeOut(text_rotation))</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 2. Shear</span></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>        text_shear <span class="op">=</span> Text(<span class="st">"Shear Transformation"</span>, color<span class="op">=</span>GREEN).scale(<span class="fl">0.7</span>).next_to(title, DOWN, buff<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.play(Write(text_shear))</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Define the shear transformation matrix.  This shears in x relative to y, and in y relative to x.</span></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>        shear_matrix <span class="op">=</span> np.array([</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>            [<span class="dv">1</span>, <span class="fl">0.5</span>, <span class="dv">0</span>],</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>            [<span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">0</span>],</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>            [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>]</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.play(</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>            cube.animate.apply_matrix(shear_matrix),</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>            run_time<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.wait(<span class="dv">1</span>)</span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add transformed axes to visualize the shear</span></span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>        transformed_axes <span class="op">=</span> axes.copy().apply_matrix(shear_matrix)</span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.play(Create(transformed_axes), run_time<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.wait(<span class="dv">1</span>)</span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.play(FadeOut(cube), FadeOut(transformed_axes), FadeOut(text_shear))</span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>        <span class="co"># --- 2D to 3D Transformation (Paraboloid) ---</span></span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>        text_2d_to_3d <span class="op">=</span> Text(<span class="st">"2D to 3D: Paraboloid"</span>, color<span class="op">=</span>MAROON).scale(<span class="fl">0.7</span>).next_to(title, DOWN, buff<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.play(Write(text_2d_to_3d))</span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a>        square <span class="op">=</span> Square(side_length<span class="op">=</span><span class="dv">4</span>, fill_color<span class="op">=</span>MAROON, fill_opacity<span class="op">=</span><span class="fl">0.5</span>, stroke_color<span class="op">=</span>WHITE, stroke_width<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.play(Create(square))</span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a>        <span class="kw">def</span> paraboloid(point):  <span class="co"># Function for the transformation</span></span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a>            x, y, _ <span class="op">=</span> point</span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> [x, y, <span class="fl">0.2</span> <span class="op">*</span> (x<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> y<span class="op">**</span><span class="dv">2</span>)]  <span class="co"># Adjust scaling factor (0.2) as needed</span></span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a>        paraboloid_surface <span class="op">=</span> always_redraw(<span class="kw">lambda</span>: Surface(</span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a>            <span class="kw">lambda</span> u, v: axes.c2p(<span class="op">*</span>paraboloid(axes.p2c(np.array([u,v,<span class="dv">0</span>])))),</span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a>            u_range<span class="op">=</span>[<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>],</span>
<span id="cb5-63"><a href="#cb5-63" aria-hidden="true" tabindex="-1"></a>            v_range<span class="op">=</span>[<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>],</span>
<span id="cb5-64"><a href="#cb5-64" aria-hidden="true" tabindex="-1"></a>            resolution<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">15</span>), <span class="co"># Added for smoothness</span></span>
<span id="cb5-65"><a href="#cb5-65" aria-hidden="true" tabindex="-1"></a>            fill_color<span class="op">=</span>MAROON,</span>
<span id="cb5-66"><a href="#cb5-66" aria-hidden="true" tabindex="-1"></a>            fill_opacity<span class="op">=</span><span class="fl">0.7</span>,</span>
<span id="cb5-67"><a href="#cb5-67" aria-hidden="true" tabindex="-1"></a>            stroke_color<span class="op">=</span>WHITE,</span>
<span id="cb5-68"><a href="#cb5-68" aria-hidden="true" tabindex="-1"></a>            stroke_width<span class="op">=</span><span class="fl">0.5</span></span>
<span id="cb5-69"><a href="#cb5-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-70"><a href="#cb5-70" aria-hidden="true" tabindex="-1"></a>        ).set_shade_in_3d(<span class="va">True</span>))</span>
<span id="cb5-71"><a href="#cb5-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-72"><a href="#cb5-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-73"><a href="#cb5-73" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.play(</span>
<span id="cb5-74"><a href="#cb5-74" aria-hidden="true" tabindex="-1"></a>            Transform(square, paraboloid_surface),</span>
<span id="cb5-75"><a href="#cb5-75" aria-hidden="true" tabindex="-1"></a>            run_time<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb5-76"><a href="#cb5-76" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb5-77"><a href="#cb5-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-78"><a href="#cb5-78" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.wait(<span class="dv">2</span>)</span>
<span id="cb5-79"><a href="#cb5-79" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.play(FadeOut(square), FadeOut(text_2d_to_3d))</span>
<span id="cb5-80"><a href="#cb5-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-81"><a href="#cb5-81" aria-hidden="true" tabindex="-1"></a>        <span class="co"># --- 3D to 2D Transformation (Projection) ---</span></span>
<span id="cb5-82"><a href="#cb5-82" aria-hidden="true" tabindex="-1"></a>        text_3d_to_2d <span class="op">=</span> Text(<span class="st">"3D to 2D: Projection"</span>, color<span class="op">=</span>PURPLE).scale(<span class="fl">0.7</span>).next_to(title, DOWN, buff<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb5-83"><a href="#cb5-83" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.play(Write(text_3d_to_2d))</span>
<span id="cb5-84"><a href="#cb5-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-85"><a href="#cb5-85" aria-hidden="true" tabindex="-1"></a>        sphere <span class="op">=</span> Sphere(radius<span class="op">=</span><span class="fl">1.5</span>, fill_color<span class="op">=</span>PURPLE, fill_opacity<span class="op">=</span><span class="fl">0.7</span>, stroke_color<span class="op">=</span>WHITE, stroke_width<span class="op">=</span><span class="dv">1</span>, resolution<span class="op">=</span>(<span class="dv">20</span>,<span class="dv">20</span>)).set_shade_in_3d(<span class="va">True</span>)</span>
<span id="cb5-86"><a href="#cb5-86" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.play(Create(sphere))</span>
<span id="cb5-87"><a href="#cb5-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-88"><a href="#cb5-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-89"><a href="#cb5-89" aria-hidden="true" tabindex="-1"></a>        <span class="kw">def</span> project_to_2d(mob, alpha):</span>
<span id="cb5-90"><a href="#cb5-90" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> p <span class="kw">in</span> mob.points:</span>
<span id="cb5-91"><a href="#cb5-91" aria-hidden="true" tabindex="-1"></a>                p[<span class="dv">2</span>] <span class="op">*=</span> (<span class="dv">1</span><span class="op">-</span>alpha)</span>
<span id="cb5-92"><a href="#cb5-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-93"><a href="#cb5-93" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.play(</span>
<span id="cb5-94"><a href="#cb5-94" aria-hidden="true" tabindex="-1"></a>            UpdateFromAlphaFunc(sphere, project_to_2d),</span>
<span id="cb5-95"><a href="#cb5-95" aria-hidden="true" tabindex="-1"></a>            run_time<span class="op">=</span><span class="dv">2</span></span>
<span id="cb5-96"><a href="#cb5-96" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb5-97"><a href="#cb5-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-98"><a href="#cb5-98" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.wait(<span class="dv">1</span>)</span>
<span id="cb5-99"><a href="#cb5-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-100"><a href="#cb5-100" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Show a circle representing the final projection </span></span>
<span id="cb5-101"><a href="#cb5-101" aria-hidden="true" tabindex="-1"></a>        circle <span class="op">=</span> Circle(radius<span class="op">=</span><span class="fl">1.5</span>, color<span class="op">=</span>PURPLE, fill_opacity<span class="op">=</span><span class="fl">0.7</span>, stroke_color <span class="op">=</span> WHITE, stroke_width<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb5-102"><a href="#cb5-102" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.add(circle)</span>
<span id="cb5-103"><a href="#cb5-103" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.wait(<span class="dv">1</span>)</span>
<span id="cb5-104"><a href="#cb5-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-105"><a href="#cb5-105" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.play(FadeOut(sphere), FadeOut(text_3d_to_2d), FadeOut(circle), FadeOut(title))</span>
<span id="cb5-106"><a href="#cb5-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-107"><a href="#cb5-107" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.wait(<span class="dv">1</span>)</span>
<span id="cb5-108"><a href="#cb5-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-109"><a href="#cb5-109" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> logging</span>
<span id="cb5-110"><a href="#cb5-110" aria-hidden="true" tabindex="-1"></a>logging.getLogger(<span class="st">"manim"</span>).setLevel(logging.WARNING)</span>
<span id="cb5-111"><a href="#cb5-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-112"><a href="#cb5-112" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">"__main__"</span>:</span>
<span id="cb5-113"><a href="#cb5-113" aria-hidden="true" tabindex="-1"></a>    config.video_dir <span class="op">=</span> <span class="st">"./"</span></span>
<span id="cb5-114"><a href="#cb5-114" aria-hidden="true" tabindex="-1"></a>    scene <span class="op">=</span> LinearTransformations()</span>
<span id="cb5-115"><a href="#cb5-115" aria-hidden="true" tabindex="-1"></a>    scene.render()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<video width="640" height="480" controls="">
<source src="../../../assets/videos/LinearTransformations.mp4" type="video/mp4">
<p>Your browser does not support the video tag. </p>
<p>A linear transformation is a function that maps one vector space to another while preserving the structure of the vector space. These transformations can be represented by matrix operations, which play a crucial role in deep learning. The animation above visualizes a linear transformation.</p>
<p>Understanding linear transformations is important for understanding how neural networks work. For example, an overfitted model can distort the input space too much, whereas a well-generalized model can perform a smoother transformation. Geometric intuition can be very useful when designing and optimizing deep learning models.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Click to view contents (Deep Dive: Rigorous definition of linear transformation and additional properties)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Click to view contents (Deep Dive: Rigorous definition of linear transformation and additional properties)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<section id="strict-definition-and-additional-properties-of-linear-transformations" class="level3 callout-body-container callout-body">
<h3 class="anchored" data-anchor-id="strict-definition-and-additional-properties-of-linear-transformations">Strict Definition and Additional Properties of Linear Transformations</h3>
<p>A linear transformation is a function between vector spaces that preserves the linear structure (addition and scalar multiplication) of the vector space. In deep learning, a fully connected layer is a representative example of a linear transformation.</p>
<section id="strict-definition-of-linear-transformation" class="level4">
<h4 class="anchored" data-anchor-id="strict-definition-of-linear-transformation">Strict Definition of Linear Transformation</h4>
<p>Given vector spaces <span class="math inline">\(V\)</span> and <span class="math inline">\(W\)</span>, a function <span class="math inline">\(T: V \to W\)</span> that satisfies the following two conditions is called a <em>linear transformation</em>:</p>
<ol type="1">
<li><strong>Addition Preservation:</strong> For any <span class="math inline">\(\mathbf{u}, \mathbf{v} \in V\)</span>, <span class="math inline">\(T(\mathbf{u} + \mathbf{v}) = T(\mathbf{u}) + T(\mathbf{v})\)</span></li>
<li><strong>Scalar Multiplication Preservation:</strong> For any <span class="math inline">\(\mathbf{u} \in V\)</span> and scalar <span class="math inline">\(c\)</span>, <span class="math inline">\(T(c\mathbf{u}) = cT(\mathbf{u})\)</span></li>
</ol>
<p>Only functions that satisfy these two conditions can be called linear transformations.</p>
</section>
<section id="example-of-linear-transformation-in-deep-learning-fully-connected-layer" class="level4">
<h4 class="anchored" data-anchor-id="example-of-linear-transformation-in-deep-learning-fully-connected-layer">Example of Linear Transformation in Deep Learning: Fully Connected Layer</h4>
<p>The fully connected layer (dense layer) in deep learning is a representative example of a linear transformation. For an input vector <span class="math inline">\(\mathbf{x} \in \mathbb{R}^m\)</span>, weight matrix <span class="math inline">\(\mathbf{W} \in \mathbb{R}^{n \times m}\)</span>, and bias vector <span class="math inline">\(\mathbf{b} \in \mathbb{R}^n\)</span>, the operation of a fully connected layer can be expressed as follows:</p>
<p><span class="math inline">\(\mathbf{y} = \mathbf{W}\mathbf{x} + \mathbf{b}\)</span></p>
<p>where <span class="math inline">\(\mathbf{y} \in \mathbb{R}^n\)</span> is the output vector. The <span class="math inline">\(\mathbf{W}\mathbf{x}\)</span> part corresponds to a linear transformation, and <span class="math inline">\(\mathbf{b}\)</span> represents a translation (parallel shift) for an affine transformation. (Strictly speaking, if bias is included, it’s an <em>affine transformation</em>, but in deep learning, it’s often referred to as a <em>linear transformation</em>.)</p>
</section>
<section id="kernel-and-range" class="level4">
<h4 class="anchored" data-anchor-id="kernel-and-range">Kernel and Range</h4>
<p>For a linear transformation <span class="math inline">\(T: V \to W\)</span>,</p>
<ul>
<li><strong>Kernel (or Null Space):</strong> The set of all vectors in <span class="math inline">\(V\)</span> that are mapped to <span class="math inline">\(\mathbf{0}_W\)</span> (the zero vector in <span class="math inline">\(W\)</span>).
<ul>
<li><span class="math inline">\(\text{ker}(T) = \{\mathbf{v} \in V | T(\mathbf{v}) = \mathbf{0}_W \}\)</span></li>
<li><span class="math inline">\(\text{ker}(T)\)</span> is a subspace of <span class="math inline">\(V\)</span>.</li>
</ul></li>
<li><strong>Range (or Image):</strong> The subset of <span class="math inline">\(W\)</span> that consists of the images of all vectors in <span class="math inline">\(V\)</span> under <span class="math inline">\(T\)</span>.
<ul>
<li><span class="math inline">\(\text{range}(T) = \{T(\mathbf{v}) | \mathbf{v} \in V \}\)</span></li>
<li><span class="math inline">\(\text{range}(T)\)</span> is a subspace of <span class="math inline">\(W\)</span>.</li>
</ul></li>
</ul>
</section>
<section id="rank-nullity-theorem-dimension-theorem" class="level4">
<h4 class="anchored" data-anchor-id="rank-nullity-theorem-dimension-theorem">Rank-Nullity Theorem (Dimension Theorem)</h4>
<p>For a linear transformation <span class="math inline">\(T: V \to W\)</span>, where <span class="math inline">\(V\)</span> is a finite-dimensional vector space, the following holds:</p>
<p><span class="math inline">\(\text{dim}(\text{ker}(T)) + \text{dim}(\text{range}(T)) = \text{dim}(V)\)</span></p>
<ul>
<li><span class="math inline">\(\text{dim}(\text{ker}(T))\)</span>: The <em>nullity</em> of <span class="math inline">\(T\)</span></li>
<li><span class="math inline">\(\text{dim}(\text{range}(T))\)</span>: The <em>rank</em> of <span class="math inline">\(T\)</span></li>
</ul>
<p>That is, the dimension of the input space is equal to the sum of the dimensions of the kernel (nullity) and the range (rank).</p>
</section>
<section id="matrix-representation-of-linear-transformations" class="level4">
<h4 class="anchored" data-anchor-id="matrix-representation-of-linear-transformations">Matrix Representation of Linear Transformations</h4>
<p>A linear transformation between finite-dimensional vector spaces can always be represented by a matrix. Given a basis {<span class="math inline">\(\mathbf{v}_1, \mathbf{v}_2, ..., \mathbf{v}_m\)</span>} of <span class="math inline">\(V\)</span> and a basis {<span class="math inline">\(\mathbf{w}_1, \mathbf{w}_2, ..., \mathbf{w}_n\)</span>} of <span class="math inline">\(W\)</span>, a linear transformation <span class="math inline">\(T: V \to W\)</span> can be represented by an <span class="math inline">\(n \times m\)</span> matrix <span class="math inline">\(\mathbf{A}\)</span> as follows:</p>
<p><span class="math inline">\(T(\mathbf{v}_j) = \sum_{i=1}^{n} a_{ij}\mathbf{w}_i\)</span> (for <span class="math inline">\(j = 1, 2, ..., m\)</span>)</p>
<p>where <span class="math inline">\(a_{ij}\)</span> is the element in the <span class="math inline">\(i\)</span>th row and <span class="math inline">\(j\)</span>th column of matrix <span class="math inline">\(\mathbf{A}\)</span>. In other words, the <span class="math inline">\(j\)</span>th column of matrix <span class="math inline">\(\mathbf{A}\)</span> consists of the coefficients when <span class="math inline">\(T(\mathbf{v}_j)\)</span> is expressed in terms of the basis of <span class="math inline">\(W\)</span>.</p>
<p>If a vector <span class="math inline">\(\mathbf{v} \in V\)</span> can be expressed as a linear combination of the basis {<span class="math inline">\(\mathbf{v}_1, \mathbf{v}_2, ..., \mathbf{v}_m\)</span>}, i.e., <span class="math inline">\(\mathbf{v} = c_1\mathbf{v}_1 + c_2\mathbf{v}_2 + ... + c_m\mathbf{v}_m\)</span>, then the coordinates of this vector can be represented by a column vector <span class="math inline">\(\begin{bmatrix} c_1 \\ c_2 \\ \vdots \\ c_m \end{bmatrix}\)</span>. Then,</p>
<p><span class="math inline">\(T(\mathbf{v}) = \mathbf{A} \begin{bmatrix} c_1 \\ c_2 \\ \vdots \\ c_m \end{bmatrix}\)</span></p>
<p><strong>Matrix Representation in Deep Learning:</strong> The operation of a fully connected layer in deep learning, <span class="math inline">\(\mathbf{y} = \mathbf{W}\mathbf{x}\)</span>, exactly matches the matrix representation of a linear transformation.</p>
</section>
</section>
</div>
</div>
</video></section>
<section id="tensor-operations" class="level3">
<h3 class="anchored" data-anchor-id="tensor-operations">2.1.4 Tensor Operations</h3>
<blockquote class="blockquote">
<p><strong>Challenge:</strong> How can we efficiently represent and operate on multidimensional data?</p>
<p><strong>Researcher’s Dilemma:</strong> In the early days of deep learning, researchers had to deal with various forms of data such as images, text, and audio. This data was difficult to express using simple vectors or matrices, and a method to effectively process complex data structures was needed. Additionally, efficient operation methods for processing large amounts of data quickly were also important tasks.</p>
</blockquote>
<p>Tensors are the fundamental mathematical objects used to represent data and model parameters in deep learning. They can be thought of as multidimensional arrays, generalizing scalars, vectors, and matrices. Tensors are classified according to their dimension (dimension, rank) as follows:</p>
<ul>
<li>0-dimensional tensor: scalar (e.g., 3.14)</li>
<li>1-dimensional tensor: vector (e.g., [1, 2, 3])</li>
<li>2-dimensional tensor: matrix (e.g., [[1, 2], [3, 4]])</li>
<li>3-dimensional or higher: high-dimensional tensor</li>
</ul>
<p>In deep learning, we mainly deal with the following types of tensors:</p>
<ul>
<li><strong>Input Data:</strong>
<ul>
<li><strong>General:</strong> (batch size, number of features)</li>
<li><strong>Time series/Text:</strong> (batch size, sequence length, number of features/embedding dimension)</li>
<li><strong>Image:</strong> (batch size, height, width, channels)</li>
</ul></li>
<li><strong>Weights:</strong>
<ul>
<li><strong>Fully-connected:</strong> (number of input features, number of output features)</li>
<li><strong>Convolutional:</strong> (number of output channels, number of input channels, kernel height, kernel width)</li>
</ul></li>
<li><strong>Output Data (Output/Prediction):</strong>
<ul>
<li><strong>Classification:</strong> (batch size, number of classes)</li>
<li><strong>Regression:</strong> (batch size, output dimension)</li>
</ul></li>
<li><strong>Bias:</strong>
<ul>
<li><strong>Fully connected:</strong> (number of output features,)</li>
<li><strong>Convolutional:</strong> (number of output channels,)</li>
</ul></li>
<li><strong>Feature maps (Outputs of Convolutional layers):</strong> (batch size, number of output channels, height, width)</li>
</ul>
<p>The basic linear transformation of a neural network is as follows:</p>
<p><span class="math inline">\(y_j = \sum\limits_{i} x_i w_{ij} + b_j\)</span></p>
<p>where <span class="math inline">\(i\)</span> is the index of the input and <span class="math inline">\(j\)</span> is the index of the output. This can be expressed in vector and matrix form as follows:</p>
<p><span class="math inline">\(\boldsymbol x = \begin{bmatrix}x_{1} &amp; x_{2} &amp; \cdots &amp; x_{i} \end{bmatrix}\)</span></p>
<p><span class="math inline">\(\boldsymbol W = \begin{bmatrix}
w_{11} &amp; \cdots &amp; w_{1j} \
\vdots &amp; \ddots &amp; \vdots \
w_{i1} &amp; \cdots &amp; w_{ij}
\end{bmatrix}\)</span></p>
<p><span class="math inline">\(\boldsymbol b = \begin{bmatrix}b_{1} &amp; b_{2} &amp; \cdots &amp; b_{j} \end{bmatrix}\)</span></p>
<p><span class="math inline">\(\boldsymbol y = \boldsymbol x \boldsymbol W + \boldsymbol b\)</span></p>
<p>The main features of tensor operations are as follows:</p>
<ol type="1">
<li><p>Broadcasting: enables operations between tensors of different sizes.</p></li>
<li><p>Dimension reduction: reduces specific dimensions of a tensor using operations such as sum() and mean().</p></li>
<li><p>Reshaping: changes the shape of a tensor to transform it into a tensor with different dimensions.</p></li>
</ol>
<p>One of the most important operations in neural network learning is gradient calculation. The main gradient calculations are as follows:</p>
<ol type="1">
<li><p>Gradient with respect to input: <span class="math inline">\(\frac{\partial \boldsymbol y}{\partial \boldsymbol{x}}\)</span></p></li>
<li><p>Gradient with respect to weights: <span class="math inline">\(\frac{\partial \boldsymbol y}{\partial \boldsymbol W}\)</span></p></li>
</ol>
<p>These gradients represent the change in output with respect to changes in input and weights, and are the core of backpropagation algorithms. Tensor operations form the basis of modern deep learning, enabling efficient learning and inference of large models through highly parallel processing using GPUs. Additionally, automatic differentiation of tensor operations enables efficient gradient computation, which has become a major breakthrough in modern deep learning research. This goes beyond simple numerical computations, making the structure and learning process of models themselves programmable targets. We will look at practical examples of tensor operations in more detail in Chapter 3 on PyTorch.</p>
</section>
<section id="singular-value-decomposition-and-principal-component-analysis" class="level3">
<h3 class="anchored" data-anchor-id="singular-value-decomposition-and-principal-component-analysis">2.1.5 Singular Value Decomposition and Principal Component Analysis</h3>
<p>Singular Value Decomposition (SVD) and Principal Component Analysis (PCA) are powerful mathematical tools used to reduce the dimensionality of high-dimensional data and extract the main features inherent in the data.</p>
<section id="singular-value-decomposition-svd" class="level4">
<h4 class="anchored" data-anchor-id="singular-value-decomposition-svd">Singular Value Decomposition (SVD)</h4>
<p>SVD is a method of decomposing any <span class="math inline">\(m \times n\)</span> matrix <span class="math inline">\(\mathbf{A}\)</span> into the product of three matrices as follows:</p>
<p><span class="math inline">\(\mathbf{A} = \mathbf{U\Sigma V^T}\)</span></p>
<p>where,</p>
<ul>
<li><span class="math inline">\(\mathbf{U}\)</span>: an <span class="math inline">\(m \times m\)</span> orthogonal matrix (left singular vectors)</li>
<li><span class="math inline">\(\mathbf{\Sigma}\)</span>: an <span class="math inline">\(m \times n\)</span> diagonal matrix (singular values)</li>
<li><span class="math inline">\(\mathbf{V}\)</span>: an <span class="math inline">\(n \times n\)</span> orthogonal matrix (right singular vectors)</li>
</ul>
<p><strong>Key Idea:</strong></p>
<ul>
<li><strong>Singular Values:</strong> The diagonal elements of <span class="math inline">\(\mathbf{\Sigma}\)</span> (<span class="math inline">\(\sigma_1 \ge \sigma_2 \ge \dots \ge \sigma_r &gt; 0\)</span>) are the singular values of matrix <span class="math inline">\(\mathbf{A}\)</span>, representing the degree of data variation in the corresponding direction. Large singular values represent important features of the data, while small singular values represent noise or less important information.</li>
<li><strong>Dimensionality Reduction:</strong> By using only the <span class="math inline">\(k\)</span> largest singular values and their corresponding singular vectors to approximate matrix <span class="math inline">\(\mathbf{A}\)</span> (<span class="math inline">\(\mathbf{A} \approx \mathbf{U}_k \mathbf{\Sigma}_k \mathbf{V}_k^T\)</span>), we can reduce the dimensionality from <span class="math inline">\(m \times n\)</span> to <span class="math inline">\(k\)</span> while preserving the main features of the original data.</li>
</ul>
<p><strong>Application in Deep Learning:</strong></p>
<ul>
<li><strong>Model Compression:</strong> Applying SVD to the weight matrix of a neural network and approximating it with a low-dimensional matrix can reduce the model size and improve inference speed. This is particularly effective for reducing the embedding matrix size in Transformer-based language models (e.g., BERT).</li>
<li><strong>Recommendation System:</strong> SVD can be used to extract latent factors between users and items.
<ul>
<li><strong>Latent Factors:</strong> By decomposing user and item matrices using SVD, we can represent users and items in a low-dimensional space.
<ul>
<li>User’s latent factor: represents the user’s hidden preferences (e.g., movie enthusiast, likes action movies, likes romantic comedies, etc.).</li>
<li>Item’s latent factor: represents the item’s hidden features (e.g., blockbuster movie, starring actor A, happy ending, etc.).</li>
</ul></li>
<li><strong>Low-Dimensional Representation:</strong> SVD allows us to approximate the originally large user-item matrix with a low-dimensional matrix product.</li>
<li><strong>Recommendation:</strong> We can calculate the similarity between users and items in the low-dimensional space or predict the probability that a user will prefer a particular item by computing the inner product.</li>
</ul></li>
</ul>
</section>
<section id="principal-component-analysis-pca" class="level4">
<h4 class="anchored" data-anchor-id="principal-component-analysis-pca">Principal Component Analysis (PCA)</h4>
<p>PCA is a method of finding the direction (principal component) that maximizes the variance of the data and projecting the data onto a lower-dimensional space. It is closely related to SVD and finds the principal components through eigenvalue decomposition of the data’s covariance matrix.</p>
<p><strong>PCA Steps:</strong> 1. <strong>Data Centering:</strong> Makes the average of each feature 0. 2. <strong>Covariance Matrix Calculation:</strong> Calculates the covariance matrix that represents the correlation between features. 3. <strong>Eigenvalue Decomposition:</strong> Calculates the eigenvalues and eigenvectors of the covariance matrix. * Eigenvector: Direction of the principal component * Eigenvalue: Size of the variance in the direction of the principal component 4. <strong>Principal Component Selection:</strong> Selects <span class="math inline">\(k\)</span> eigenvectors corresponding to the largest eigenvalues. (Reduces data to <span class="math inline">\(k\)</span>-dimension) 5. <strong>Data Projection:</strong> Projects data onto the selected <span class="math inline">\(k\)</span> principal components to reduce dimensions.</p>
<p><strong>Application in Deep Learning:</strong></p>
<ul>
<li><strong>Data Preprocessing:</strong> By projecting high-dimensional data such as images and text into a low-dimensional space, it can be used as input for deep learning models, reducing computational cost and preventing overfitting. Especially in image classification problems, representing high-resolution images in low dimensions through PCA can speed up model training.</li>
<li><strong>Feature Extraction</strong>: The principal components extracted by PCA can be interpreted as new features that are uncorrelated with each other and preserve the maximum variance of the data.</li>
</ul>
<p><strong>SVD vs.&nbsp;PCA</strong></p>
<ul>
<li>SVD is a <em>matrix</em> decomposition technique, while PCA is a <em>data</em> dimensionality reduction technique.</li>
<li>PCA can be implemented using SVD. (The SVD of the data matrix is related to the eigendecomposition of the covariance matrix)</li>
<li>PCA requires a preprocessing step to center the data mean at 0, but SVD can be applied directly without this process.</li>
</ul>
<p>SVD and PCA are mathematical tools that play an important role in efficiently representing data and improving model performance in deep learning.</p>
<div id="cell-16" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_02.pca <span class="im">import</span> visualize_pca</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>visualize_pca()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="02_Mathematics of Deep Learning_files/figure-html/cell-6-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Explained variance ratio: 0.5705</code></pre>
</div>
</div>
<p>This example demonstrates the ability of PCA to project complex 2D structures into 1D. For spiral data, a single principal component cannot capture all variability, but it can capture the major trend of the data. The explained variance ratio can be used to evaluate how well this 1D representation preserves the structure of the original data.</p>
<p>These techniques are powerful tools for extracting important patterns from complex data.</p>
<ol type="1">
<li>Data preprocessing: dimensionality reduction of input data</li>
<li>Model compression: efficient approximation of weight matrices</li>
<li>Feature extraction: identification and selection of important features</li>
</ol>
<p>SVD and PCA are powerful tools for extracting important patterns from high-dimensional data and simplifying complex data structures.</p>
</section>
</section>
</section>
<section id="calculus-and-optimization" class="level2">
<h2 class="anchored" data-anchor-id="calculus-and-optimization">2.2 Calculus and Optimization</h2>
<section id="chain-rule" class="level3">
<h3 class="anchored" data-anchor-id="chain-rule">2.2.1 Chain Rule</h3>
<blockquote class="blockquote">
<p><strong>Challenge:</strong> How can we efficiently compute the derivative of a complex nested function?</p>
<p><strong>Researcher’s Concern:</strong> Early deep learning researchers had to use backpropagation algorithms to update neural network weights. However, since neural networks are structures with multiple layers of functions connected in a complicated way, calculating the derivative of the loss function for each weight was a very difficult problem. In particular, as the layers deepened, the amount of computation increased exponentially, making learning inefficient.</p>
</blockquote>
<p>The most important calculus rule used in deep learning is the chain rule. The chain rule is a powerful and elegant rule that allows us to express the derivative of a composite function as the product of the derivatives of the constituent functions. Visualizing the chain rule can make it easier to understand. For example, let’s assume that <span class="math inline">\(z\)</span> is a function of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, and <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> are functions of <span class="math inline">\(s\)</span> and <span class="math inline">\(t\)</span>, respectively. This relationship can be represented as a tree diagram.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../../assets/images/02_01.chain_rule.png" class="img-fluid figure-img"></p>
<figcaption>Chain Rule</figcaption>
</figure>
</div>
<p>In this diagram, the partial derivative of <span class="math inline">\(z\)</span> with respect to <span class="math inline">\(s\)</span>, <span class="math inline">\(\frac{\partial z}{\partial s}\)</span>, is the sum of the products of the partial derivatives along all paths from <span class="math inline">\(z\)</span> to <span class="math inline">\(s\)</span>.</p>
<p><span class="math inline">\(\frac{\partial z}{\partial s} = \frac{\partial z}{\partial x} \frac{\partial x}{\partial s} + \frac{\partial z}{\partial y} \frac{\partial y}{\partial s}\)</span></p>
<p>In this formula,</p>
<ul>
<li><span class="math inline">\(\frac{\partial z}{\partial x}\)</span> and <span class="math inline">\(\frac{\partial z}{\partial y}\)</span> represent how <span class="math inline">\(z\)</span> changes with respect to <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>.</li>
<li><span class="math inline">\(\frac{\partial x}{\partial s}\)</span> and <span class="math inline">\(\frac{\partial y}{\partial s}\)</span> represent how <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> change with respect to <span class="math inline">\(s\)</span>.</li>
</ul>
<p>Let’s consider another case where the chain rule is used to express a total derivative. Suppose <span class="math inline">\(z\)</span> is a function of mutually independent variables. In this case, the chain rule simplifies to the form of a total derivative. For example, if <span class="math inline">\(z = f(x, y)\)</span> and <span class="math inline">\(x = g(s)\)</span> and <span class="math inline">\(y = h(t)\)</span>, and <span class="math inline">\(s\)</span> and <span class="math inline">\(t\)</span> are independent, then the total derivative of <span class="math inline">\(z\)</span> can be expressed as follows.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../../assets/images/02_02_chain_rule.png" class="img-fluid figure-img"></p>
<figcaption>Chain Rule</figcaption>
</figure>
</div>
<p><span class="math inline">\(dz = \frac{\partial z}{\partial x}dx + \frac{\partial z}{\partial y}dy\)</span></p>
<p>Here, <span class="math inline">\(dx = \frac{\partial x}{\partial s}ds\)</span> and <span class="math inline">\(dy = \frac{\partial y}{\partial t}dt\)</span>, so we finally get the following form.</p>
<p><span class="math inline">\(dz = \frac{\partial z}{\partial x}\frac{\partial x}{\partial s}ds + \frac{\partial z}{\partial y}\frac{\partial y}{\partial t}dt\)</span></p>
<p>This equation looks similar to the chain rule, but it actually represents a total derivative. The important point here is that since <span class="math inline">\(s\)</span> and <span class="math inline">\(t\)</span> are independent, <span class="math inline">\(\frac{\partial x}{\partial t}\)</span> and <span class="math inline">\(\frac{\partial y}{\partial s}\)</span> are 0. This form is a total derivative. A total derivative represents the total effect of changes in all independent variables on the function value and can be expressed as the sum of partial derivatives for each variable. The chain rule’s structure allows the derivative of a complex function to be broken down into simpler components. This is especially important in deep learning, where neural networks are composed of multiple layers of functions. Using tree diagrams, the chain rule can be applied even in more complicated situations by finding all paths from the dependent variable to the independent variables, multiplying the partial derivatives along each path, and then summing these products.</p>
<p>The chain rule is the mathematical foundation for backpropagation algorithms in deep learning, enabling efficient updates of weights in complex neural network models.</p>
</section>
<section id="gradient-and-jacobian" class="level3">
<h3 class="anchored">2.2.2 Gradient and Jacobian</h3>
<blockquote class="blockquote">
<p><strong>Challenge</strong>: How can we generalize the derivative for functions with various forms of input and output?</p>
<p><strong>Researcher’s Concerns</strong>: Early deep learning primarily dealt with scalar functions, but it gradually had to handle functions with vectors, matrices, and other forms of input and output. Expressing and calculating the derivatives of these functions in a unified manner was an essential task for developing deep learning frameworks.</p>
</blockquote>
<p>In deep learning, we deal with functions that have various forms of input (scalars, vectors, matrices, tensors) and output (scalars, vectors, matrices, tensors). Accordingly, the expression of the function’s derivative also changes. The key is to consistently express these various cases of derivatives and apply the chain rule to calculate them efficiently.</p>
<section id="key-concepts" class="level4">
<h4 class="anchored" data-anchor-id="key-concepts">Key Concepts</h4>
<ul>
<li><strong>Gradient</strong>: An expression used when differentiating a scalar function with respect to a vector. It is a column vector containing the partial derivatives of the function with respect to each element of the input vector, representing the direction of the steepest ascent.</li>
<li><strong>Jacobian Matrix</strong>: An expression used when differentiating a vector function with respect to a vector. It is a matrix whose elements are the partial derivatives of each element of the output vector with respect to each element of the input vector.</li>
</ul>
</section>
<section id="derivative-expressions-for-various-input-and-output-forms" class="level4">
<h4 class="anchored" data-anchor-id="derivative-expressions-for-various-input-and-output-forms">Derivative Expressions for Various Input and Output Forms</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 14%">
<col style="width: 12%">
<col style="width: 57%">
<col style="width: 15%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Input Form</th>
<th style="text-align: left;">Output Form</th>
<th style="text-align: left;">Derivative Expression</th>
<th style="text-align: left;">Dimension</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Vector (<span class="math inline">\(\mathbf{x}\)</span>)</td>
<td style="text-align: left;">Vector (<span class="math inline">\(\mathbf{f}\)</span>)</td>
<td style="text-align: left;">Jacobian Matrix (<span class="math inline">\(\mathbf{J} = \frac{\partial \mathbf{f}}{\partial \mathbf{x}}\)</span>)</td>
<td style="text-align: left;"><span class="math inline">\(n \times m\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Matrix (<span class="math inline">\(\mathbf{X}\)</span>)</td>
<td style="text-align: left;">Vector (<span class="math inline">\(\mathbf{f}\)</span>)</td>
<td style="text-align: left;">3D Tensor (generally not well-handled)</td>
<td style="text-align: left;">-</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Vector (<span class="math inline">\(\mathbf{x}\)</span>)</td>
<td style="text-align: left;">Matrix (<span class="math inline">\(\mathbf{F}\)</span>)</td>
<td style="text-align: left;">3D Tensor (generally not well-handled)</td>
<td style="text-align: left;">-</td>
</tr>
<tr class="even">
<td style="text-align: left;">Scalar (<span class="math inline">\(x\)</span>)</td>
<td style="text-align: left;">Vector (<span class="math inline">\(\mathbf{f}\)</span>)</td>
<td style="text-align: left;">Column Vector (<span class="math inline">\(\frac{\partial \mathbf{f}}{\partial x}\)</span>)</td>
<td style="text-align: left;"><span class="math inline">\(n \times 1\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Vector (<span class="math inline">\(\mathbf{x}\)</span>)</td>
<td style="text-align: left;">Scalar (<span class="math inline">\(f\)</span>)</td>
<td style="text-align: left;">Gradient (<span class="math inline">\(\nabla f = \frac{\partial f}{\partial \mathbf{x}}\)</span>)</td>
<td style="text-align: left;"><span class="math inline">\(m \times 1\)</span> (column vector)</td>
</tr>
<tr class="even">
<td style="text-align: left;">Matrix (<span class="math inline">\(\mathbf{X}\)</span>)</td>
<td style="text-align: left;">Scalar (<span class="math inline">\(f\)</span>)</td>
<td style="text-align: left;">Matrix (<span class="math inline">\(\frac{\partial f}{\partial \mathbf{X}}\)</span>)</td>
<td style="text-align: left;"><span class="math inline">\(m \times n\)</span></td>
</tr>
</tbody>
</table>
<p><strong>Note:</strong></p>
<ul>
<li><span class="math inline">\(m\)</span>: Dimension of the input vector/matrix, <span class="math inline">\(n\)</span>: Dimension of the output vector/matrix, <span class="math inline">\(p, q\)</span>: Number of rows/columns in a matrix</li>
<li>In the case of matrix input and vector/matrix output, the derivative becomes a 3D tensor. Deep learning frameworks efficiently handle such high-dimensional tensor operations internally, but generally, Jacobian/gradient calculations for vector/matrix inputs and outputs are predominant.</li>
</ul>
</section>
<section id="application-in-deep-learning" class="level4">
<h4 class="anchored">Application in Deep Learning</h4>
<ul>
<li><strong>Backpropagation Algorithm:</strong> The Jacobian matrix and gradient play a crucial role when implementing the backpropagation algorithm in deep learning. As the neural network passes through each layer, it applies the chain rule to calculate the gradient of the loss function with respect to the weights, and updates the weights accordingly.</li>
<li><strong>Automatic Differentiation:</strong> Modern deep learning frameworks (TensorFlow, PyTorch, etc.) provide automatic differentiation features that automatically handle these complex differentiation calculations. Users do not need to implement complex differentiation formulas directly; they only need to define the model structure and loss function.</li>
</ul>
<p>Thus, the concepts of gradients and Jacobian matrices are essential tools for generalizing derivatives of various forms of functions in deep learning and efficiently training models through backpropagation.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Click to view contents (Deep Dive: Hessian Matrix)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Click to view contents (Deep Dive: Hessian Matrix)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<section id="hessian-matrix" class="level2 callout-body-container callout-body">
<h2 class="anchored" data-anchor-id="hessian-matrix">Hessian Matrix</h2>
<section id="definition-and-meaning-of-the-hessian-matrix" class="level3">
<h3 class="anchored" data-anchor-id="definition-and-meaning-of-the-hessian-matrix">1. Definition and Meaning of the Hessian Matrix</h3>
<ul>
<li><p><strong>Definition:</strong> The Hessian matrix is a square matrix of second partial derivatives of a scalar-valued function. Given a function <span class="math inline">\(f(x_1, x_2, ..., x_n)\)</span>, the Hessian matrix <span class="math inline">\(H\)</span> is defined as follows:</p>
<p><span class="math display">\[
H = \begin{bmatrix}
\frac{\partial^2 f}{\partial x_1^2} &amp; \frac{\partial^2 f}{\partial x_1 \partial x_2} &amp; \cdots &amp; \frac{\partial^2 f}{\partial x_1 \partial x_n} \\
\frac{\partial^2 f}{\partial x_2 \partial x_1} &amp; \frac{\partial^2 f}{\partial x_2^2} &amp; \cdots &amp; \frac{\partial^2 f}{\partial x_2 \partial x_n} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\frac{\partial^2 f}{\partial x_n \partial x_1} &amp; \frac{\partial^2 f}{\partial x_n \partial x_2} &amp; \cdots &amp; \frac{\partial^2 f}{\partial x_n^2}
\end{bmatrix}
\]</span></p>
<ul>
<li>Each element represents the second partial derivative of the function with respect to each variable.</li>
<li><strong>Symmetric Matrix:</strong> If the function has continuous second partial derivatives, the Hessian matrix is symmetric because the order of partial differentiation can be swapped (Schwarz’s theorem). (<span class="math inline">\(\frac{\partial^2 f}{\partial x_i \partial x_j} = \frac{\partial^2 f}{\partial x_j \partial x_i}\)</span>)</li>
</ul></li>
<li><p><strong>Meaning:</strong></p>
<ul>
<li><strong>Curvature:</strong> The Hessian matrix contains local curvature information about the function. It describes how much the graph of the function is curved at a specific point.</li>
<li><strong>Rate of Change of the Rate of Change:</strong> While the first derivative (gradient) represents the rate of change of the function, the Hessian matrix represents how quickly this rate of change changes.</li>
</ul></li>
</ul>
</section>
<section id="hessian-matrix-and-critical-point-determination" class="level3">
<h3 class="anchored" data-anchor-id="hessian-matrix-and-critical-point-determination">2. Hessian Matrix and Critical Point Determination</h3>
<ul>
<li><strong>Critical Point:</strong> A point where the gradient of the function is zero. In other words, it’s a point where all first partial derivatives with respect to each variable are zero. (<span class="math inline">\(\nabla f = 0\)</span>)</li>
<li><strong>Determination of Extrema:</strong>
<ul>
<li>The Hessian matrix is used at critical points to determine whether the function has a local maximum, minimum, or saddle point.</li>
<li><strong>Local Minimum:</strong> If the Hessian matrix is positive definite (all eigenvalues are positive), then the critical point is a local minimum.</li>
<li><strong>Local Maximum:</strong> If the Hessian matrix is negative definite (all eigenvalues are negative), then the critical point is a local maximum.</li>
<li><strong>Saddle Point:</strong> If the Hessian matrix is indefinite (has both positive and negative eigenvalues), then the critical point is a saddle point.</li>
<li><strong>Semi-definite:</strong> If the Hessian is positive or negative semi-definite, additional information is needed to determine the type of extremum, as an eigenvalue is zero.</li>
</ul></li>
</ul>
</section>
<section id="application-of-the-hessian-matrix-in-deep-learning" class="level3">
<h3 class="anchored" data-anchor-id="application-of-the-hessian-matrix-in-deep-learning">3. Application of the Hessian Matrix in Deep Learning</h3>
<ul>
<li><strong>Newton’s Method:</strong>
<ul>
<li>It is one of the optimization algorithms for finding the extreme value of a function.</li>
<li>While the gradient descent method uses the first derivative (gradient), Newton’s method uses the second derivative (Hessian) to converge faster.</li>
<li>Update rule: <span class="math inline">\(x_{k+1} = x_k - H^{-1}(x_k) \nabla f(x_k)\)</span> (H is the Hessian matrix)</li>
</ul></li>
<li><strong>Curvature Matrix:</strong>
<ul>
<li>The Hessian matrix can be used as a curvature matrix representing the curvature of the loss function.</li>
<li>It utilizes curvature information to adjust the learning rate or improve the performance of optimization algorithms. (e.g., Natural Gradient Descent)</li>
</ul></li>
</ul>
</section>
</section>
</div>
</div>
</section>
</section>
<section id="chain-rule-and-backpropagation-in-neural-networks" class="level3">
<h3 class="anchored" data-anchor-id="chain-rule-and-backpropagation-in-neural-networks">2.2.3 Chain Rule and Backpropagation in Neural Networks</h3>
<p>The core of neural network learning is the backpropagation algorithm. Backpropagation is an efficient method that updates the weights and biases of each layer by propagating errors from the output layer to the input layer. In this process, the chain rule allows for the calculation of complex composite functions by expressing their derivatives as products of simpler derivatives.</p>
<section id="applying-the-chain-rule-in-neural-networks" class="level4">
<h4 class="anchored" data-anchor-id="applying-the-chain-rule-in-neural-networks">Applying the Chain Rule in Neural Networks</h4>
<p>A neural network can be seen as a composition of multiple layers of functions. For example, a two-layer neural network can be expressed as follows:</p>
<p><span class="math inline">\(\mathbf{z} = f_1(\mathbf{x}; \mathbf{W_1}, \mathbf{b_1})\)</span> <span class="math inline">\(\mathbf{y} = f_2(\mathbf{z}; \mathbf{W_2}, \mathbf{b_2})\)</span></p>
<p>Here, <span class="math inline">\(\mathbf{x}\)</span> is the input, <span class="math inline">\(\mathbf{z}\)</span> is the output of the first layer (input to the second layer), <span class="math inline">\(\mathbf{y}\)</span> is the final output, and <span class="math inline">\(\mathbf{W_1}\)</span>, <span class="math inline">\(\mathbf{b_1}\)</span> are the weights and biases of the first layer, while <span class="math inline">\(\mathbf{W_2}\)</span>, <span class="math inline">\(\mathbf{b_2}\)</span> are those of the second layer.</p>
<p>During backpropagation, we need to calculate the gradients of the loss function <span class="math inline">\(E\)</span> with respect to each parameter (<span class="math inline">\(\frac{\partial E}{\partial \mathbf{W_1}}\)</span>, <span class="math inline">\(\frac{\partial E}{\partial \mathbf{b_1}}\)</span>, <span class="math inline">\(\frac{\partial E}{\partial \mathbf{W_2}}\)</span>, <span class="math inline">\(\frac{\partial E}{\partial \mathbf{b_2}}\)</span>). Applying the chain rule, we can compute these as follows:</p>
<p><span class="math inline">\(\frac{\partial E}{\partial \mathbf{W_2}} = \frac{\partial E}{\partial \mathbf{y}} \frac{\partial \mathbf{y}}{\partial \mathbf{W_2}}\)</span> <span class="math inline">\(\frac{\partial E}{\partial \mathbf{b_2}} = \frac{\partial E}{\partial \mathbf{y}} \frac{\partial \mathbf{y}}{\partial \mathbf{b_2}}\)</span> <span class="math inline">\(\frac{\partial E}{\partial \mathbf{W_1}} = \frac{\partial E}{\partial \mathbf{y}} \frac{\partial \mathbf{y}}{\partial \mathbf{z}} \frac{\partial \mathbf{z}}{\partial \mathbf{W_1}}\)</span> <span class="math inline">\(\frac{\partial E}{\partial \mathbf{b_1}} = \frac{\partial E}{\partial \mathbf{y}} \frac{\partial \mathbf{y}}{\partial \mathbf{z}} \frac{\partial \mathbf{z}}{\partial \mathbf{b_1}}\)</span></p>
<p>By using the chain rule, we can efficiently calculate the gradients of each parameter in a complex neural network as products of sequential derivatives. Section 2.2.4 provides a detailed theoretical dive into this process.</p>
</section>
<section id="gradients-and-directional-derivatives" class="level4">
<h4 class="anchored" data-anchor-id="gradients-and-directional-derivatives">Gradients and Directional Derivatives</h4>
<ul>
<li><strong>Gradient:</strong> A vector composed of the partial derivatives of a multivariable function with respect to each variable. It represents the direction of the steepest ascent.</li>
<li><strong>Directional Derivative:</strong> Represents the rate of change of a function in a specific direction. It can be calculated as the dot product of the gradient and the direction vector.</li>
</ul>
</section>
<section id="notes-on-gradient-representation" class="level4">
<h4 class="anchored" data-anchor-id="notes-on-gradient-representation">Notes on Gradient Representation</h4>
<ul>
<li><strong>Column Vector vs.&nbsp;Row Vector:</strong> Typically, vectors are expressed as column vectors by convention, but in deep learning, they can be expressed as row vectors depending on the context. Consistency is important. (This book uses the numerator notation.)</li>
<li><strong>Jacobian Matrix:</strong> For a function (vector function) with multiple input variables and multiple output variables, it is a matrix containing all partial derivative values. It is used for backpropagation calculations in deep learning.</li>
</ul>
<p>Based on these concepts, the next section will take a closer look at the method of calculating gradients in the backpropagation process with specific examples.</p>
</section>
</section>
<section id="gradient-calculation-for-backpropagation" class="level3">
<h3 class="anchored" data-anchor-id="gradient-calculation-for-backpropagation">2.2.4 Gradient Calculation for Backpropagation</h3>
<p>The core of backpropagation is to calculate the gradient of the loss function and update the weights. Let’s take a simple linear transformation (<span class="math inline">\(\mathbf{y} = \mathbf{xW} + \mathbf{b}\)</span>) as an example to illustrate the backpropagation process.</p>
<section id="core-idea-of-backpropagation" class="level4">
<h4 class="anchored" data-anchor-id="core-idea-of-backpropagation">1. Core Idea of Backpropagation</h4>
<p>Backpropagation is an algorithm that updates the weights by propagating the error calculated in the output layer towards the input layer, adjusting each weight according to its contribution to the error. The key step in this process is calculating the gradient of the loss function with respect to each weight.</p>
</section>
<section id="gradient-of-the-loss-function" class="level4">
<h4 class="anchored" data-anchor-id="gradient-of-the-loss-function">2. Gradient of the Loss Function</h4>
<p>If we use the mean squared error (MSE) as the loss function, the gradient of the loss function <span class="math inline">\(E\)</span> with respect to the output <span class="math inline">\(\mathbf{y}\)</span> is as follows:</p>
<p><span class="math inline">\(E = \frac{1}{M} \sum_{i=1}^{M} (y_i - \hat{y}_i)^2\)</span></p>
<p><span class="math inline">\(\frac{\partial E}{\partial \mathbf{y}} = \frac{2}{M}(\mathbf{y} - \hat{\mathbf{y}})\)</span></p>
<p>Here, <span class="math inline">\(y_i\)</span> is the actual value, <span class="math inline">\(\hat{y}_i\)</span> is the predicted value of the model, and <span class="math inline">\(M\)</span> is the number of data points.</p>
</section>
<section id="gradient-with-respect-to-weights" class="level4">
<h4 class="anchored" data-anchor-id="gradient-with-respect-to-weights">3. Gradient with Respect to Weights</h4>
<p>We can calculate the gradient of the loss function <span class="math inline">\(E\)</span> with respect to the weights <span class="math inline">\(\mathbf{W}\)</span> by applying the chain rule.</p>
<p><span class="math inline">\(\frac{\partial E}{\partial \mathbf{W}} = \frac{\partial E}{\partial \mathbf{y}} \frac{\partial \mathbf{y}}{\partial \mathbf{W}}\)</span></p>
<p>Since <span class="math inline">\(\mathbf{y} = \mathbf{xW} + \mathbf{b}\)</span>, we have <span class="math inline">\(\frac{\partial \mathbf{y}}{\partial \mathbf{W}} = \mathbf{x}^T\)</span>.</p>
<p>Ultimately, the gradient with respect to the weights is expressed as:</p>
<p><span class="math inline">\(\frac{\partial E}{\partial \mathbf{W}} = \mathbf{x}^T \frac{\partial E}{\partial \mathbf{y}}\)</span></p>
</section>
<section id="gradient-with-respect-to-input" class="level4">
<h4 class="anchored" data-anchor-id="gradient-with-respect-to-input">4. Gradient with Respect to Input</h4>
<p>The gradient of the loss function <span class="math inline">\(E\)</span> with respect to the input <span class="math inline">\(\mathbf{x}\)</span> is used to propagate the error to the previous layer.</p>
<p><span class="math inline">\(\frac{\partial E}{\partial \mathbf{x}} = \frac{\partial E}{\partial \mathbf{y}} \frac{\partial \mathbf{y}}{\partial \mathbf{x}}\)</span></p>
<p>Since <span class="math inline">\(\mathbf{y} = \mathbf{xW} + \mathbf{b}\)</span>, we have <span class="math inline">\(\frac{\partial \mathbf{y}}{\partial \mathbf{x}} = \mathbf{W}^T\)</span>.</p>
<p>Therefore, the gradient with respect to the input is:</p>
<p><span class="math inline">\(\frac{\partial E}{\partial \mathbf{x}} = \frac{\partial E}{\partial \mathbf{y}} \mathbf{W}^T\)</span></p>
</section>
<section id="summary" class="level4">
<h4 class="anchored" data-anchor-id="summary">5. Summary</h4>
<p>Backpropagation is carried out through the following key steps. 1. <strong>Forward Propagation:</strong> Input data <span class="math inline">\(\mathbf{x}\)</span> is passed through the neural network to calculate the predicted value <span class="math inline">\(\hat{\mathbf{y}}\)</span>. 2. <strong>Loss Function Calculation:</strong> The predicted value <span class="math inline">\(\hat{\mathbf{y}}\)</span> and actual value <span class="math inline">\(\mathbf{y}\)</span> are compared to calculate the loss <span class="math inline">\(E\)</span>. 3. <strong>Backward Propagation:</strong> * The gradient of the loss function with respect to the output <span class="math inline">\(\frac{\partial E}{\partial \mathbf{y}}\)</span> is calculated in the output layer. * Using the chain rule, the gradient of the loss with respect to the weights <span class="math inline">\(\frac{\partial E}{\partial \mathbf{W}} = \mathbf{x}^T \frac{\partial E}{\partial \mathbf{y}}\)</span> is calculated. * The gradient with respect to the input <span class="math inline">\(\frac{\partial E}{\partial \mathbf{x}} = \frac{\partial E}{\partial \mathbf{y}} \mathbf{W}^T\)</span> is calculated, propagating the error to the previous layer. 4. <strong>Weight Update:</strong> The computed gradients are used to update the weights using optimization algorithms such as gradient descent.</p>
<p>The backpropagation algorithm is the core of deep learning model training, allowing for effective approximation of complex nonlinear functions.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Click to view the content (Deep Dive: Gradient Calculation for Backpropagation)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Click to view the content (Deep Dive: Gradient Calculation for Backpropagation)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The core of backpropagation is to calculate the gradient of the loss function and update the weights. Let’s take a simple linear transformation (<span class="math inline">\(\mathbf{y} = \mathbf{xW} + \mathbf{b}\)</span>) as an example to illustrate the backpropagation process. Here, we will explain the calculation process in detail.</p>
<section id="gradient-of-the-loss-function-1" class="level4">
<h4 class="anchored" data-anchor-id="gradient-of-the-loss-function-1">Gradient of the Loss Function</h4>
<p>The goal of neural network learning is to minimize the loss function <span class="math inline">\(E\)</span>. If we use the mean squared error (MSE) as the loss function, it can be expressed as follows:</p>
<p><span class="math inline">\(E = f(\mathbf{y}) = \frac{1}{M} \sum_{i=1}^{M} (y_i - \hat{y}_i)^2\)</span></p>
<p>where <span class="math inline">\(y_i\)</span> is the actual value, <span class="math inline">\(\hat{y}_i\)</span> is the predicted value, and <span class="math inline">\(M\)</span> is the number of data (or the dimension of the output vector).</p>
<p>The derivative of <span class="math inline">\(E\)</span> with respect to <span class="math inline">\(\mathbf{y}\)</span> is as follows:</p>
<p><span class="math inline">\(\frac{\partial E}{\partial \mathbf{y}} = \frac{2}{M} (\mathbf{y} - \hat{\mathbf{y}})\)</span></p>
<p>where <span class="math inline">\(\mathbf{y}\)</span> is the output vector of the neural network, and <span class="math inline">\(\hat{\mathbf{y}}\)</span> is the actual value (target) vector. Since <span class="math inline">\(y_i\)</span> is a constant (each element of the target), only the partial derivative with respect to <span class="math inline">\(\mathbf{y}\)</span> remains.</p>
<p><strong>Note:</strong> In the example code in Chapter 1, we used the term <span class="math inline">\(-\frac{2}{M}\)</span>, which included a negative sign (-) in the definition of the loss function. Here, we use the general definition of MSE, so we use the positive term <span class="math inline">\(\frac{2}{M}\)</span>. In actual learning, the absolute size of this constant is not important because it is multiplied by the learning rate.</p>
</section>
<section id="gradient-of-the-loss-function-with-respect-to-weights" class="level4">
<h4 class="anchored" data-anchor-id="gradient-of-the-loss-function-with-respect-to-weights">Gradient of the Loss Function with Respect to Weights</h4>
<p>Now, let’s calculate the gradient of the loss function <span class="math inline">\(E\)</span> with respect to the weights <span class="math inline">\(\mathbf{W}\)</span>. <span class="math inline">\(E = f(\mathbf{y})\)</span> and <span class="math inline">\(\mathbf{y} = \mathbf{xW} + \mathbf{b}\)</span>. <span class="math inline">\(\mathbf{x}\)</span> is the input vector, <span class="math inline">\(\mathbf{W}\)</span> is the weight matrix, and <span class="math inline">\(\mathbf{b}\)</span> is the bias vector.</p>
<p><strong>Computational Graph:</strong></p>
<p>To visually represent the backpropagation process, we can use a computational graph. (Insert computational graph figure)</p>
<p><span class="math inline">\(E\)</span> is a scalar value, and for each <span class="math inline">\(w_{ij}\)</span> (each element of the weight matrix <span class="math inline">\(\mathbf{W}\)</span>), we need to find the partial derivative of <span class="math inline">\(E\)</span>. <span class="math inline">\(\mathbf{W}\)</span> is a matrix of size (input dimension) x (output dimension). For example, if the input is 3-dimensional (<span class="math inline">\(x_1, x_2, x_3\)</span>) and the output is 2-dimensional (<span class="math inline">\(y_1, y_2\)</span>), then <span class="math inline">\(\mathbf{W}\)</span> is a 3x2 matrix.</p>
<p><span class="math inline">\(\frac{\partial E}{\partial \mathbf{W}} = \begin{bmatrix}
\frac{\partial E}{\partial w_{11}} &amp; \frac{\partial E}{\partial w_{12}} \\
\frac{\partial E}{\partial w_{21}} &amp; \frac{\partial E}{\partial w_{22}} \\
\frac{\partial E}{\partial w_{31}} &amp; \frac{\partial E}{\partial w_{32}}
\end{bmatrix}\)</span></p>
<p>The derivative of <span class="math inline">\(E\)</span> with respect to <span class="math inline">\(\mathbf{y}\)</span> can be expressed as a row vector: <span class="math inline">\(\frac{\partial E}{\partial \mathbf{y}} = \begin{bmatrix} \frac{\partial E}{\partial y_1} &amp; \frac{\partial E}{\partial y_2} \end{bmatrix}\)</span>. (Using numerator notation). Strictly speaking, the gradient should be expressed as a column vector, but here we use a row vector for convenience of calculation.</p>
<p>By the chain rule, <span class="math inline">\(\frac{\partial E}{\partial \mathbf{W}} = \frac{\partial E}{\partial \mathbf{y}} \frac{\partial \mathbf{y}}{\partial \mathbf{W}}\)</span></p>
<p><span class="math inline">\(\frac{\partial E}{\partial w_{ij}} = \sum_k \frac{\partial E}{\partial y_k} \frac{\partial y_k}{\partial w_{ij}}\)</span> (here <span class="math inline">\(k\)</span> is the index of the output vector <span class="math inline">\(\mathbf{y}\)</span>)</p>
<p>Expanding the equation,</p>
<p><span class="math inline">\(\frac{\partial E}{\partial \mathbf{W}} = \frac{\partial E}{\partial y_1} \frac{\partial y_1}{\partial \mathbf{W}} + \frac{\partial E}{\partial y_2} \frac{\partial y_2}{\partial \mathbf{W}}\)</span></p>
<p>Now, we need to calculate <span class="math inline">\(\frac{\partial y_k}{\partial w_{ij}}\)</span>. Since <span class="math inline">\(\mathbf{y} = \mathbf{xW} + \mathbf{b}\)</span>,</p>
<p><span class="math inline">\(y_1 = x_1w_{11} + x_2w_{21} + x_3w_{31} + b_1\)</span> <span class="math inline">\(y_2 = x_1w_{12} + x_2w_{22} + x_3w_{32} + b_2\)</span></p>
<p><span class="math inline">\(\frac{\partial y_1}{\partial w_{ij}} = \begin{bmatrix}
\frac{\partial y_1}{\partial w_{11}} &amp; \frac{\partial y_1}{\partial w_{12}} \\
\frac{\partial y_1}{\partial w_{21}} &amp; \frac{\partial y_1}{\partial w_{22}} \\
\frac{\partial y_1}{\partial w_{31}} &amp; \frac{\partial y_1}{\partial w_{32}}
\end{bmatrix} =
\begin{bmatrix}
x_1 &amp; 0 \\
x_2 &amp; 0 \\
x_3 &amp; 0
\end{bmatrix}\)</span></p>
<p><span class="math inline">\(\frac{\partial y_2}{\partial w_{ij}} = \begin{bmatrix}
0 &amp; x_1 \\
0 &amp; x_2 \\
0 &amp; x_3
\end{bmatrix}\)</span></p>
<p>Therefore,</p>
<p><span class="math inline">\(\frac{\partial E}{\partial \mathbf{W}} = \frac{\partial E}{\partial y_1} \begin{bmatrix}
x_1 &amp; 0 \\
x_2 &amp; 0 \\
x_3 &amp; 0
\end{bmatrix} + \frac{\partial E}{\partial y_2} \begin{bmatrix}
0 &amp; x_1 \\
0 &amp; x_2 \\
0 &amp; x_3
\end{bmatrix} = \begin{bmatrix}
\frac{\partial E}{\partial y_1}x_1 &amp; \frac{\partial E}{\partial y_2}x_1 \\
\frac{\partial E}{\partial y_1}x_2 &amp; \frac{\partial E}{\partial y_2}x_2 \\
\frac{\partial E}{\partial y_1}x_3 &amp; \frac{\partial E}{\partial y_2}x_3
\end{bmatrix} = \begin{bmatrix} x_1 \\ x_2 \\ x_3 \end{bmatrix} \begin{bmatrix} \frac{\partial E}{\partial y_1} &amp; \frac{\partial E}{\partial y_2} \end{bmatrix} = \mathbf{x}^T \frac{\partial E}{\partial \mathbf{y}}\)</span></p>
<p><strong>Generalization:</strong></p>
<p>If the input is a <span class="math inline">\(1 \times m\)</span> row vector <span class="math inline">\(\mathbf{x}\)</span> and the output is a <span class="math inline">\(1 \times n\)</span> row vector <span class="math inline">\(\mathbf{y}\)</span>, then the weight <span class="math inline">\(\mathbf{W}\)</span> becomes an <span class="math inline">\(m \times n\)</span> matrix. In this case, <span class="math inline">\(\frac{\partial E}{\partial \mathbf{W}} = \mathbf{x}^T \frac{\partial E}{\partial \mathbf{y}}\)</span></p>
</section>
<section id="gradient-of-the-loss-function-with-respect-to-input" class="level4">
<h4 class="anchored" data-anchor-id="gradient-of-the-loss-function-with-respect-to-input">Gradient of the Loss Function with Respect to Input</h4>
<p>The gradient of the loss function <span class="math inline">\(E\)</span> with respect to the input <span class="math inline">\(\mathbf{x}\)</span> can also be calculated using the chain rule.</p>
<p><span class="math inline">\(\frac{\partial E}{\partial \mathbf{x}} = \frac{\partial E}{\partial \mathbf{y}} \frac{\partial \mathbf{y}}{\partial \mathbf{x}}\)</span></p>
<p>Since <span class="math inline">\(\mathbf{y} = \mathbf{xW} + \mathbf{b}\)</span>, we have <span class="math inline">\(\frac{\partial \mathbf{y}}{\partial \mathbf{x}} = \mathbf{W}^T\)</span>.</p>
<p>Therefore,</p>
<p><span class="math inline">\(\frac{\partial E}{\partial \mathbf{x}} = \frac{\partial E}{\partial \mathbf{y}} \mathbf{W}^T\)</span></p>
</section>
<section id="gradient-with-respect-to-bias" class="level4">
<h4 class="anchored" data-anchor-id="gradient-with-respect-to-bias">Gradient with Respect to Bias</h4>
<p>The gradient of the loss function with respect to the bias <span class="math inline">\(\mathbf{b}\)</span> is as follows.</p>
<p><span class="math inline">\(\frac{\partial E}{\partial \mathbf{b}} = \frac{\partial E}{\partial \mathbf{y}} \frac{\partial \mathbf{y}}{\partial \mathbf{b}}\)</span></p>
<p>Since <span class="math inline">\(\mathbf{y} = \mathbf{xW} + \mathbf{b}\)</span>, we have <span class="math inline">\(\frac{\partial \mathbf{y}}{\partial \mathbf{b}} = \begin{bmatrix} 1 &amp; 1 &amp; \dots &amp; 1\end{bmatrix}\)</span> (a <span class="math inline">\(1 \times n\)</span> row vector of all ones)</p>
<p><span class="math inline">\(\frac{\partial E}{\partial \mathbf{b}} = \frac{\partial E}{\partial \mathbf{y}}\)</span></p>
</section>
<section id="summary-and-additional-explanation" class="level4">
<h4 class="anchored" data-anchor-id="summary-and-additional-explanation">Summary and Additional Explanation</h4>
<ol type="1">
<li><strong>Gradient with Respect to Weights:</strong> <span class="math inline">\(\frac{\partial E}{\partial \mathbf{W}} = \mathbf{x}^T \frac{\partial E}{\partial \mathbf{y}}\)</span>
<ul>
<li>Calculated as the matrix product of the transpose of the input vector <span class="math inline">\(\mathbf{x}\)</span> and the gradient of the loss function with respect to the output (<span class="math inline">\(\frac{\partial E}{\partial \mathbf{y}}\)</span>, represented here as a row vector).</li>
</ul></li>
<li><strong>Gradient with Respect to Input:</strong> <span class="math inline">\(\frac{\partial E}{\partial \mathbf{x}} = \frac{\partial E}{\partial \mathbf{y}} \mathbf{W}^T\)</span>
<ul>
<li>Calculated as the matrix product of the gradient of the loss function with respect to the output (<span class="math inline">\(\frac{\partial E}{\partial \mathbf{y}}\)</span>) and the transpose of the weight matrix <span class="math inline">\(\mathbf{W}\)</span>. This result is backpropagated to the previous layer and used for updating the weights of that layer.</li>
</ul></li>
<li><strong>Gradient with Respect to Bias</strong>: <span class="math inline">\(\frac{\partial E}{\partial \mathbf{b}} = \frac{\partial E}{\partial \mathbf{y}}\)</span></li>
</ol>
<ul>
<li>Equal to the gradient of the loss function with respect to the output.</li>
</ul>
<ol start="4" type="1">
<li><strong>Utilization of Gradients:</strong> These calculated gradients are used in optimization algorithms like Gradient Descent to update the weights and biases. Each parameter is updated in the direction opposite to its gradient, minimizing the loss function.</li>
<li><strong>Notation:</strong> In the above description, we used the numerator layout to calculate the gradient. We could also use the denominator layout, but we would eventually get the same update rule. What is important is to use a consistent notation. This book uses the numerator layout.</li>
</ol>
<p>Through such mathematical processes, deep learning models can learn complex nonlinear transformations from input data to output data.</p>
</section>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="probability-and-statistics" class="level2">
<h2 class="anchored" data-anchor-id="probability-and-statistics">2.3 Probability and Statistics</h2>
<p>Deep learning is deeply rooted in probability and statistical theory to handle the uncertainty of data. In this chapter, we will explore core concepts such as probability distributions, expectations, Bayes’ theorem, and maximum likelihood estimation. These concepts are essential for understanding the learning and inference processes of models.</p>
<section id="probability-distributions-and-expectations" class="level3">
<h3 class="anchored" data-anchor-id="probability-distributions-and-expectations">2.3.1 Probability Distributions and Expectations</h3>
<blockquote class="blockquote">
<p><strong>Challenge</strong>: How can we mathematically model the uncertainty of real data?</p>
<p><strong>Researcher’s Concern</strong>: Early machine learning researchers recognized that real-world data cannot be explained by deterministic rules. Data contains measurement errors, noise, and unpredictable variability. Mathematical tools were needed to quantify this uncertainty and reflect it in models.</p>
</blockquote>
<p>A probability distribution represents all possible outcomes and their occurrence probabilities. It can be divided into discrete and continuous probability distributions.</p>
<section id="discrete-probability-distributions" class="level4">
<h4 class="anchored" data-anchor-id="discrete-probability-distributions">Discrete Probability Distributions</h4>
<p>Discrete probability distributions deal with cases where the values that a random variable can take are finite or countable. The characteristic is that a clear probability can be assigned to each possible outcome.</p>
<p>Mathematically, a discrete probability distribution is represented by a probability mass function (PMF).</p>
<p><span class="math display">\[P(X = x) = p(x)\]</span></p>
<p>where <span class="math inline">\(p(x)\)</span> is the probability that <span class="math inline">\(X\)</span> takes the value <span class="math inline">\(x\)</span>. The main properties are as follows:</p>
<ol type="1">
<li>For all <span class="math inline">\(x\)</span>, <span class="math inline">\(0 ≤ p(x) ≤ 1\)</span></li>
<li><span class="math inline">\(\sum_{x} p(x) = 1\)</span></li>
</ol>
<p>Representative examples include the Bernoulli distribution, binomial distribution, and Poisson distribution.</p>
<p>The probability mass function for rolling a die is as follows:</p>
<p><span class="math display">\[P(X = x) = \begin{cases}
\frac{1}{6} &amp; \text{if } x \in \{1, 2, 3, 4, 5, 6\} \
0 &amp; \text{otherwise}
\end{cases}\]</span></p>
<p>Discrete probability distributions are used in various fields such as classification problems, reinforcement learning, and natural language processing in machine learning and deep learning. The following is the result of simulating a die roll.</p>
<div id="cell-25" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_02.statistics <span class="im">import</span> simulate_dice_roll</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>simulate_dice_roll()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="02_Mathematics of Deep Learning_files/figure-html/cell-7-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="continuous-probability-distribution" class="level4">
<h4 class="anchored" data-anchor-id="continuous-probability-distribution">Continuous Probability Distribution</h4>
<p>A continuous probability distribution deals with the case where the random variable can take on continuous values. Unlike discrete probability distributions, the probability at a specific point is 0, and we deal with probabilities of intervals. Mathematically, a continuous probability distribution is represented by a probability density function (PDF).</p>
<p><span class="math display">\[f(x) = \lim_{\Delta x \to 0} \frac{P(x &lt; X \leq x + \Delta x)}{\Delta x}\]</span></p>
<p>Here, f(x) represents the probability density near x. The main properties are as follows:</p>
<ol type="1">
<li>For all x, f(x) ≥ 0</li>
<li><span class="math inline">\(\int_{-\infty}^{\infty} f(x) dx = 1\)</span></li>
</ol>
<p>Representative examples include the normal distribution, exponential distribution, and gamma distribution.</p>
<p>The probability density function of the normal distribution is as follows.</p>
<p><span class="math display">\[f(x) = \frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}\]</span></p>
<p>Here, μ is the mean and σ is the standard deviation.</p>
<p>Continuous probability distributions are importantly used in various machine learning and deep learning application fields such as regression problems, signal processing, and time series analysis.</p>
<div id="cell-27" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_02.statistics <span class="im">import</span> plot_normal_distribution</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>plot_normal_distribution()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="02_Mathematics of Deep Learning_files/figure-html/cell-8-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="expected-value" class="level4">
<h4 class="anchored" data-anchor-id="expected-value">Expected Value</h4>
<p>The expected value is an important concept that represents the central tendency of a probability distribution. It can be interpreted as the weighted average of all possible values of a random variable. For discrete probability distributions, the expected value is calculated as follows:</p>
<p><span class="math display">\[E[X] = \sum_{i} x_i P(X = x_i)\]</span></p>
<p>where <span class="math inline">\(x_i\)</span> is a possible value of the random variable X, and <span class="math inline">\(P(X = x_i)\)</span> is the probability of that value. For continuous probability distributions, the expected value is calculated through integration.</p>
<p><span class="math display">\[E[X] = \int_{-\infty}^{\infty} x f(x) dx\]</span></p>
<p>where <span class="math inline">\(f(x)\)</span> is the probability density function. The expected value has the following important properties:</p>
<ol type="1">
<li>Linearity: <span class="math inline">\(E[aX + b] = aE[X] + b\)</span></li>
<li>Expectation of the product of independent random variables: <span class="math inline">\(E[XY] = E[X]E[Y]\)</span> (when X and Y are independent)</li>
</ol>
<p>In deep learning, the expected value is crucial for minimizing loss functions or estimating model parameters. For example, the mean squared error (MSE) is defined as:</p>
<p><span class="math display">\[MSE = E[(Y - \hat{Y})^2]\]</span></p>
<p>where <span class="math inline">\(Y\)</span> is the actual value, and <span class="math inline">\(\hat{Y}\)</span> is the predicted value.</p>
<p>The concept of expected value provides a theoretical basis for optimization algorithms such as stochastic gradient descent and is also essential for estimating value functions in reinforcement learning.</p>
<div id="cell-29" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_02.statistics <span class="im">import</span> calculate_dice_expected_value</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>calculate_dice_expected_value()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Expected value of dice roll: 3.5</code></pre>
</div>
</div>
<p>These fundamental concepts of probability and statistics play a crucial role in the design, learning, and evaluation process of deep learning models. In the next section, we will look at Bayes’ theorem and maximum likelihood estimation based on this.</p>
</section>
</section>
<section id="bayes-theorem-and-maximum-likelihood-estimation" class="level3">
<h3 class="anchored">2.3.2 Bayes’ Theorem and Maximum Likelihood Estimation</h3>
<blockquote class="blockquote">
<p><strong>Challenge:</strong> How can we best estimate a model’s parameters with limited data?</p>
<p><strong>Researcher’s Dilemma:</strong> Early statisticians and machine learning researchers often faced the challenge of creating models with limited data. Accurately estimating a model’s parameters with insufficient data was a daunting task. Instead of relying solely on the data, they needed a method to incorporate prior knowledge or beliefs to improve the accuracy of their estimates.</p>
</blockquote>
<p>Bayes’ theorem and maximum likelihood estimation are core concepts in probability theory and statistics, widely applied in deep learning for model training and inference.</p>
<section id="bayes-theorem" class="level4">
<h4 class="anchored" data-anchor-id="bayes-theorem">Bayes’ Theorem</h4>
<p>Bayes’ theorem provides a way to calculate conditional probabilities. It is used to update the probability of a hypothesis when new evidence is given. The mathematical expression of Bayes’ theorem is as follows:</p>
<p><span class="math display">\[P(A|B) = \frac{P(B|A)P(A)}{P(B)}\]</span></p>
<p>where: - <span class="math inline">\(P(A|B)\)</span> is the probability of A given B (posterior probability) - <span class="math inline">\(P(B|A)\)</span> is the probability of B given A (likelihood) - <span class="math inline">\(P(A)\)</span> is the probability of A (prior probability) - <span class="math inline">\(P(B)\)</span> is the probability of B (evidence)</p>
<p>Bayes’ theorem is utilized in machine learning as follows:</p>
<ol type="1">
<li>Classification problems: calculating the probability of belonging to a specific class in naive Bayes classifiers.</li>
<li>Parameter estimation: calculating the posterior distribution of model parameters.</li>
<li>Decision theory: making optimal decisions under uncertainty.</li>
</ol>
</section>
<section id="maximum-likelihood-estimation" class="level4">
<h4 class="anchored">Maximum Likelihood Estimation</h4>
<p>Maximum likelihood estimation (MLE) is a method for finding the model parameters that best explain the given data. In the context of deep learning, this means finding the weights and biases of a neural network that best describe the observed data. In other words, MLE finds the parameters that maximize the probability of the model generating the training data, which is directly related to the learning process of the model.</p>
<p>Mathematically, given data <span class="math inline">\(X = (x_1, ..., x_n)\)</span>, the likelihood function for parameter <span class="math inline">\(\theta\)</span> is defined as:</p>
<p><span class="math display">\[L(\theta|X) = P(X|\theta) = \prod_{i=1}^n P(x_i|\theta)\]</span></p>
<p>The maximum likelihood estimate <span class="math inline">\(\hat{\theta}_{MLE}\)</span> is found by:</p>
<p><span class="math display">\[\hat{\theta}_{MLE} = \operatorname{argmax}_{\theta} L(\theta|X)\]</span></p>
<p>In practice, it is more convenient to maximize the log-likelihood:</p>
<p><span class="math display">\[\hat{\theta}_{MLE} = \operatorname{argmax}_{\theta} \log L(\theta|X) = \operatorname{argmax}_{\theta} \sum_{i=1}^n \log P(x_i|\theta)\]</span></p>
<p>Using log-likelihood has several important mathematical advantages:</p>
<ol type="1">
<li>Conversion of multiplication to addition: due to the property of logarithms, <span class="math inline">\(\log(ab) = \log(a) + \log(b)\)</span>, the product of probabilities can be converted into a sum of log-probabilities, simplifying calculations and improving numerical stability.</li>
<li>Improved numerical stability: when dealing with very small probability values, multiplication can lead to underflow. Using logs avoids this problem.</li>
<li>Simplification of differentiation: in optimization processes where derivatives are calculated, using log functions simplifies the computations, especially for exponential distributions.</li>
<li>Monotonic increase: the log function is monotonically increasing, meaning that maximizing the likelihood and maximizing the log-likelihood yield the same result.</li>
</ol>
<p>For these reasons, many machine learning algorithms, including those in deep learning, use log-likelihood for optimization.</p>
<p>Maximum likelihood estimation is applied in deep learning as follows:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>Application</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1. <strong>Parameter Estimation</strong></td>
<td>MLE is used to estimate model parameters by maximizing the likelihood of observing the training data given these parameters.</td>
</tr>
<tr class="even">
<td>2. <strong>Model Selection</strong></td>
<td>By comparing the log-likelihood values of different models on a test set, one can select the best model for the data, balancing model complexity and fit to the data.</td>
</tr>
<tr class="odd">
<td>3. <strong>Density Estimation</strong></td>
<td>MLE is used in density estimation techniques such as Gaussian Mixture Models (GMMs) to estimate the parameters of the underlying distributions that generate the observed data.</td>
</tr>
</tbody>
</table>
<ol type="1">
<li>Model learning: The process of minimizing the loss function when learning the weights of a neural network is essentially the same as maximum likelihood estimation.</li>
<li>Probabilistic modeling: It is used to estimate the distribution of data in generative models.</li>
<li>Hyperparameter tuning: It can be used to select the hyperparameters of a model.</li>
</ol>
<p>Bayes’ theorem and maximum likelihood estimation are closely related. In Bayes estimation, if the prior probability is a uniform distribution, the maximum a posteriori (MAP) estimation is equivalent to maximum likelihood estimation. Mathematically, when <span class="math inline">\(P(\theta)\)</span> is constant in <span class="math inline">\(P(\theta|X) \propto P(X|\theta)P(\theta)\)</span>, <span class="math inline">\(\operatorname{argmax}_{\theta} P(\theta|X) = \operatorname{argmax}_{\theta} P(X|\theta)P(\theta)\)</span> holds. This means that when the prior probability does not provide additional information about the parameter, the estimate based on data only (MLE) is consistent with Bayes estimation (MAP).</p>
<p>These concepts are essential for understanding and optimizing the learning and inference processes of deep learning models. In the next section, we will explore the basics of information theory.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Deep Dive: In-Depth Analysis of Bayes' Theorem">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Deep Dive: In-Depth Analysis of Bayes’ Theorem
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<section id="bayes-theorem---in-depth-analysis" class="level2 callout-body-container callout-body">
<h2 class="anchored" data-anchor-id="bayes-theorem---in-depth-analysis">Bayes’ Theorem - In-Depth Analysis</h2>
<section id="rigorous-derivation-of-bayes-theorem-and-probability-space" class="level3">
<h3 class="anchored" data-anchor-id="rigorous-derivation-of-bayes-theorem-and-probability-space">1. Rigorous Derivation of Bayes’ Theorem and Probability Space</h3>
<ul>
<li><strong>Probability Space:</strong> Bayes’ theorem is defined on a probability space <span class="math inline">\((\Omega, \mathcal{F}, P)\)</span>.
<ul>
<li><span class="math inline">\(\Omega\)</span>: Sample space (set of all possible outcomes)</li>
<li><span class="math inline">\(\mathcal{F}\)</span>: Event space (set of subsets of the sample space, <span class="math inline">\(\sigma\)</span>-algebra)</li>
<li><span class="math inline">\(P\)</span>: Probability measure (function assigning probability to each event in the event space)</li>
</ul></li>
<li><strong>Rigorous Definition of Conditional Probability:</strong>
<ul>
<li>For an event <span class="math inline">\(B \in \mathcal{F}\)</span> with <span class="math inline">\(P(B) &gt; 0\)</span>, the conditional probability of an event <span class="math inline">\(A \in \mathcal{F}\)</span> given <span class="math inline">\(B\)</span> is defined as: <span class="math inline">\(P(A|B) = \frac{P(A \cap B)}{P(B)}\)</span></li>
</ul></li>
<li><strong>Joint Probability:</strong>
<ul>
<li>The joint probability of two events <span class="math inline">\(A, B \in \mathcal{F}\)</span>, denoted by <span class="math inline">\(P(A \cap B)\)</span>, represents the probability that both events occur simultaneously.</li>
<li>Using the definition of conditional probability, it can be expressed as:
<ul>
<li><span class="math inline">\(P(A \cap B) = P(A|B)P(B)\)</span></li>
<li><span class="math inline">\(P(A \cap B) = P(B|A)P(A)\)</span></li>
</ul></li>
</ul></li>
<li><strong>Derivation of Bayes’ Theorem:</strong>
<ol type="1">
<li><span class="math inline">\(P(A|B)P(B) = P(B|A)P(A)\)</span> (two expressions for joint probability)</li>
<li><span class="math inline">\(P(A|B) = \frac{P(B|A)P(A)}{P(B)}\)</span> (dividing both sides by <span class="math inline">\(P(B)\)</span>, given <span class="math inline">\(P(B) &gt; 0\)</span>)</li>
</ol></li>
</ul>
</section>
<section id="in-depth-meaning-and-statistical-interpretation-of-each-term-in-bayes-theorem" class="level3">
<h3 class="anchored" data-anchor-id="in-depth-meaning-and-statistical-interpretation-of-each-term-in-bayes-theorem">2. In-Depth Meaning and Statistical Interpretation of Each Term in Bayes’ Theorem</h3>
<ul>
<li><strong><span class="math inline">\(P(A|B)\)</span>: Posterior Probability</strong>
<ul>
<li><strong>Interpretation:</strong> The updated probability distribution of hypothesis <span class="math inline">\(A\)</span> after observing data <span class="math inline">\(B\)</span>. It represents the result of inference based on the data.</li>
<li><strong>Bayesian Perspective:</strong> The posterior probability quantifies uncertainty by combining prior and likelihood, providing a basis for decision-making.</li>
</ul></li>
<li><strong><span class="math inline">\(P(B|A)\)</span>: Likelihood</strong>
<ul>
<li><strong>Interpretation:</strong> The probability of observing data <span class="math inline">\(B\)</span> given that hypothesis <span class="math inline">\(A\)</span> is true. It measures how well hypothesis <span class="math inline">\(A\)</span> explains the data.</li>
<li><strong>Frequentist vs.&nbsp;Bayesian Perspective:</strong>
<ul>
<li><strong>Frequentist:</strong> Likelihood is a function of fixed parameters, explaining the distribution of the data.</li>
<li><strong>Bayesian:</strong> Likelihood is a function providing information about the parameter given the data.</li>
</ul></li>
</ul></li>
<li><strong><span class="math inline">\(P(A)\)</span>: Prior Probability</strong>
<ul>
<li><strong>Interpretation:</strong> The probability distribution representing prior belief in hypothesis <span class="math inline">\(A\)</span> before observing data <span class="math inline">\(B\)</span>.</li>
<li><strong>Subjective vs.&nbsp;Objective Prior:</strong>
<ul>
<li><strong>Subjective:</strong> Set based on expert knowledge, previous experience, etc.</li>
<li><strong>Objective:</strong> Uses a uniform distribution or non-informative prior, containing minimal information.</li>
</ul></li>
</ul></li>
<li><strong><span class="math inline">\(P(B)\)</span>: Evidence or Marginal Likelihood</strong></li>
<li><strong>Interpretation:</strong> The probability of observing the data <span class="math inline">\(B\)</span> under all possible hypotheses. It serves as a normalizing constant to make <span class="math inline">\(P(A|B)\)</span> a probability distribution.</li>
<li><strong>Calculation:</strong> <span class="math inline">\(P(B) = \sum_{A'} P(B|A')P(A')\)</span> (discrete random variable) <span class="math inline">\(P(B) = \int P(B|A)p(A) dA\)</span> (continuous random variable, where <span class="math inline">\(p(A)\)</span> is the probability density function)</li>
<li><strong>Model Comparison:</strong> Used to compare evidence of different models, such as calculating Bayes factors.</li>
</ul>
</section>
<section id="bayes-theorem-and-bayesian-inference" class="level3">
<h3 class="anchored" data-anchor-id="bayes-theorem-and-bayesian-inference">3. Bayes’ Theorem and Bayesian Inference</h3>
<ul>
<li><strong>Core:</strong> Bayes’ theorem is the core principle of Bayesian inference, which infers the probability distribution of a parameter or hypothesis given data.</li>
<li><strong>Process:</strong>
<ol type="1">
<li><strong>Prior:</strong> Set the prior distribution <span class="math inline">\(p(\theta)\)</span> for the parameter <span class="math inline">\(\theta\)</span>.</li>
<li><strong>Likelihood:</strong> Define the likelihood function <span class="math inline">\(p(x|\theta)\)</span>, which is the probability of observing data <span class="math inline">\(x\)</span> given the parameter <span class="math inline">\(\theta\)</span>.</li>
<li><strong>Posterior:</strong> Calculate the posterior distribution <span class="math inline">\(p(\theta|x)\)</span> using Bayes’ theorem. <span class="math inline">\(p(\theta|x) = \frac{p(x|\theta)p(\theta)}{p(x)} = \frac{p(x|\theta)p(\theta)}{\int p(x|\theta')p(\theta') d\theta'}\)</span></li>
<li><strong>Inference:</strong> Perform estimation, interval estimation, and hypothesis testing based on the posterior distribution.</li>
</ol></li>
<li><strong>Iterative Update:</strong> It is possible to update beliefs continuously by using the previous posterior distribution as the new prior distribution when new data arrives. (Sequential Bayesian updating)</li>
</ul>
</section>
<section id="extensions-and-applications-of-bayes-theorem" class="level3">
<h3 class="anchored" data-anchor-id="extensions-and-applications-of-bayes-theorem">4. Extensions and Applications of Bayes’ Theorem</h3>
<ul>
<li><strong>Continuous Random Variables:</strong> Bayes’ theorem using probability density functions</li>
<li><strong>Conjugate Prior:</strong>
<ul>
<li>A prior distribution that makes the posterior distribution belong to the same family of distributions as the prior. It is widely used due to its computational convenience. (e.g., beta distribution - Bernoulli distribution, gamma distribution - Poisson distribution)</li>
</ul></li>
<li><strong>Variational Bayes:</strong>
<ul>
<li>A method for approximating complex posterior distributions.</li>
<li>Find a manageable distribution similar to the posterior distribution and minimize the Kullback-Leibler divergence between the two distributions.</li>
</ul></li>
<li><strong>Markov Chain Monte Carlo (MCMC):</strong>
<ul>
<li>A method for estimating the characteristics of a posterior distribution by sampling from it.</li>
<li>Algorithms such as Metropolis-Hastings and Gibbs sampling.</li>
</ul></li>
<li><strong>Applications in Deep Learning:</strong>
<ul>
<li><strong>Bayesian Neural Networks:</strong> Treat neural network weights as random variables to quantify the uncertainty of predictions.</li>
<li><strong>Gaussian Processes:</strong> Define a prior distribution on the function space using kernels and calculate the predictive distribution using Bayes’ theorem.</li>
</ul></li>
</ul>
</section>
</section>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Deep Dive: In-Depth Analysis of Maximum Likelihood Estimation (MLE) and Comparison with MAP (Master's and Above)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Deep Dive: In-Depth Analysis of Maximum Likelihood Estimation (MLE) and Comparison with MAP (Master’s and Above)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<section id="maximum-likelihood-estimation-mle---in-depth-analysis-and-comparison-with-map" class="level2 callout-body-container callout-body">
<h2 class="anchored" data-anchor-id="maximum-likelihood-estimation-mle---in-depth-analysis-and-comparison-with-map">Maximum Likelihood Estimation (MLE) - In-Depth Analysis and Comparison with MAP</h2>
<section id="specific-example-of-mle-calculation" class="level3">
<h3 class="anchored" data-anchor-id="specific-example-of-mle-calculation">1. Specific Example of MLE Calculation</h3>
<p>MLE is a method for finding the parameter that best explains the given data. It finds the parameter value that maximizes the likelihood of the observed data.</p>
<ul>
<li><p><strong>Likelihood Function:</strong></p>
<ul>
<li>When the data <span class="math inline">\(x_1, x_2, ..., x_n\)</span> are assumed to be independently and identically distributed (i.i.d), the likelihood function is defined as follows. <span class="math display">\[L(\theta; x_1, ..., x_n) = \prod_{i=1}^{n} p(x_i | \theta)\]</span>
<ul>
<li><span class="math inline">\(\theta\)</span>: parameter</li>
<li><span class="math inline">\(p(x_i | \theta)\)</span>: probability (or probability density) of data <span class="math inline">\(x_i\)</span> given parameter <span class="math inline">\(\theta\)</span></li>
</ul></li>
</ul></li>
<li><p><strong>Log-Likelihood Function:</strong></p>
<ul>
<li>For convenience of calculation, the log-likelihood function is used, which is the logarithm of the likelihood function. <span class="math display">\[l(\theta; x_1, ..., x_n) = \log L(\theta; x_1, ..., x_n) = \sum_{i=1}^{n} \log p(x_i | \theta)\]</span></li>
<li>Since taking the logarithm does not change the location of the maximum, we can also find the parameter that maximizes the log-likelihood.</li>
</ul></li>
<li><p><strong>MLE Calculation Procedure:</strong></p>
<ol type="1">
<li>Define the likelihood function for the given data and probability distribution model.</li>
<li>Take the logarithm of the likelihood function to obtain the log-likelihood function.</li>
<li>Differentiate the log-likelihood function with respect to parameter <span class="math inline">\(\theta\)</span>.</li>
<li>Find the value of <span class="math inline">\(\theta\)</span> where the derivative is 0 (if necessary, use the second derivative to determine whether it is a maximum or minimum).</li>
<li>The found <span class="math inline">\(\theta\)</span> value is the MLE estimate.</li>
</ol></li>
<li><p><strong>Specific Example:</strong></p>
<ul>
<li><strong>Normal Distribution:</strong>
<ul>
<li>Assume that the data <span class="math inline">\(x_1, ..., x_n\)</span> follow a normal distribution with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>.</li>
<li>Log-likelihood function: <span class="math display">\[l(\mu, \sigma^2; x_1, ..., x_n) = -\frac{n}{2}\log(2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^{n}(x_i - \mu)^2\]</span></li>
<li>By partially differentiating with respect to <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span> and finding the point where it becomes 0, the MLE estimates are as follows.
<ul>
<li><span class="math inline">\(\hat{\mu}_{MLE} = \frac{1}{n}\sum_{i=1}^{n} x_i\)</span> (sample mean)</li>
<li><span class="math inline">\(\hat{\sigma}^2_{MLE} = \frac{1}{n}\sum_{i=1}^{n} (x_i - \hat{\mu}_{MLE})^2\)</span> (sample variance)</li>
</ul></li>
</ul></li>
<li><strong>Bernoulli Distribution:</strong>
<ul>
<li>Assume that the data <span class="math inline">\(x_1, ..., x_n\)</span> follow a Bernoulli distribution with success probability <span class="math inline">\(p\)</span>. (<span class="math inline">\(x_i = 1\)</span> (success), <span class="math inline">\(x_i = 0\)</span> (failure))</li>
<li>Log-likelihood function: <span class="math display">\[ l(p; x_1, ..., x_n) = \sum_{i=1}^n [x_i \log p + (1-x_i) \log (1-p)] \]</span></li>
<li>By differentiating with respect to <span class="math inline">\(p\)</span> and finding the point where it becomes 0, the MLE estimate is as follows.
<ul>
<li><span class="math inline">\(\hat{p}_{MLE} = \frac{1}{n}\sum_{i=1}^{n} x_i\)</span> (number of successes / total number of trials)</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="advantages-and-disadvantages-of-mle" class="level3">
<h3 class="anchored" data-anchor-id="advantages-and-disadvantages-of-mle">2. Advantages and Disadvantages of MLE</h3>
<ul>
<li><strong>Advantages:</strong>
<ul>
<li><strong>Ease of calculation:</strong> Parameter estimation is possible with relatively simple calculations. (Especially for exponential family distributions)</li>
<li><strong>Asymptotic properties:</strong> (Described in more detail below)
<ul>
<li><strong>Consistency:</strong> As the sample size increases, the MLE estimator converges to the actual parameter.</li>
<li><strong>Asymptotic normality:</strong> As the sample size increases, the MLE estimator approaches a normal distribution.</li>
<li><strong>Efficiency:</strong> It is an unbiased estimator with the smallest variance asymptotically (Cramér–Rao lower bound).</li>
</ul></li>
</ul></li>
<li><strong>Disadvantages:</strong>
<ul>
<li><strong>Overfitting possibility:</strong> Especially when the sample size is small, it may be overfitted to the data and have poor generalization performance.</li>
<li><strong>Sensitive to outliers:</strong> If there are outliers, the MLE estimate can be greatly distorted.</li>
<li><strong>Not applicable to all distributions:</strong> MLE requires a probabilistic model to be given (not applicable to non-parametric methods).</li>
<li><strong>Possibility of bias:</strong> In some cases, the MLE estimator may be biased (e.g., variance estimation of a normal distribution).</li>
</ul></li>
</ul>
</section>
<section id="comparison-with-maximum-a-posteriori-map-estimation" class="level3">
<h3 class="anchored" data-anchor-id="comparison-with-maximum-a-posteriori-map-estimation">3. Comparison with Maximum A Posteriori (MAP) Estimation</h3>
<ul>
<li><p><strong>MAP:</strong> Based on Bayes’ theorem, it finds the parameter that maximizes the posterior probability by combining the prior probability and likelihood.</p></li>
<li><p><strong>MAP estimation:</strong> <span class="math display">\[
  \hat{\theta}_{MAP} = \arg\max_{\theta} p(\theta|x) = \arg\max_{\theta} \frac{p(x|\theta)p(\theta)}{p(x)} = \arg\max_{\theta} p(x|\theta)p(\theta)
  \]</span></p>
<ul>
<li><span class="math inline">\(p(\theta|x)\)</span>: Posterior probability</li>
<li><span class="math inline">\(p(x|\theta)\)</span>: Likelihood</li>
<li><span class="math inline">\(p(\theta)\)</span>: Prior probability</li>
<li><span class="math inline">\(p(x)\)</span>: Evidence (constant, so can be ignored)</li>
</ul></li>
<li><p><strong>MLE vs.&nbsp;MAP:</strong> | Feature | MLE | MAP | | —————– | ——————————————————————– | ———————————————————————- | | <strong>Basis</strong> | Frequentist | Bayesian | | <strong>Goal</strong> | Maximum likelihood | Maximum a posteriori probability | | <strong>Prior Probability</strong> | Not considered | Considered | | <strong>Result</strong> | Point estimate | Point estimate (generally) or distribution estimate (in Bayesian inference) | | <strong>Overfitting</strong> | High risk of overfitting | Can prevent overfitting through prior probability (e.g., regularization effect) | | <strong>Computational Complexity</strong> | Generally low | Complexity may increase depending on the prior probability (especially when not conjugate prior distribution) |</p></li>
<li><p><strong>Influence of Prior Probability:</strong></p>
<ul>
<li><strong>Non-informative Prior Distribution:</strong> When the prior probability follows a uniform distribution, such as <span class="math inline">\(p(\theta) \propto 1\)</span> (constant), MAP estimation is equivalent to MLE estimation.</li>
<li><strong>Informative Prior Distribution:</strong> When the prior probability follows a specific distribution (e.g., normal distribution, beta distribution), MAP estimation is affected by the prior probability and differs from MLE estimation. The stronger the prior belief represented by the prior distribution, the closer the posterior is to the prior.</li>
</ul></li>
</ul>
</section>
<section id="asymptotic-property-of-mle" class="level3">
<h3 class="anchored" data-anchor-id="asymptotic-property-of-mle">4. Asymptotic Property of MLE</h3>
<ul>
<li><strong>Consistency:</strong>
<ul>
<li>As the sample size <span class="math inline">\(n\)</span> approaches infinity, the MLE estimator <span class="math inline">\(\hat{\theta}_{MLE}\)</span> converges in probability to the true parameter <span class="math inline">\(\theta_0\)</span>. <span class="math display">\[\hat{\theta}_{MLE} \xrightarrow{p} \theta_0 \text{ as } n \rightarrow \infty\]</span></li>
</ul></li>
<li><strong>Asymptotic Normality:</strong>
<ul>
<li>When the sample size <span class="math inline">\(n\)</span> is sufficiently large, the distribution of the MLE estimator <span class="math inline">\(\hat{\theta}_{MLE}\)</span> approximates the following normal distribution. <span class="math display">\[\sqrt{n}(\hat{\theta}_{MLE} - \theta_0) \xrightarrow{d} N(0, I(\theta_0)^{-1})\]</span>
<ul>
<li><span class="math inline">\(I(\theta_0)\)</span>: Fisher Information Matrix (FIM)
<ul>
<li><span class="math inline">\(I(\theta) = -E[\frac{\partial^2}{\partial \theta^2} l(\theta; x_1, ...,x_n)]\)</span> (in the case of a single parameter)</li>
<li>FIM represents the curvature of the log-likelihood function and means the amount of information about the parameter.</li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Efficiency:</strong>
<ul>
<li>MLE is an efficient estimator that asymptotically achieves the Cramér–Rao lower bound (CRLB). It has the smallest variance asymptotically compared to other unbiased estimators.</li>
</ul></li>
</ul>
</section>
</section>
</div>
</div>
</section>
</section>
<section id="information-theory-basics" class="level3">
<h3 class="anchored">2.3.3 Information Theory Basics</h3>
<blockquote class="blockquote">
<p><strong>Challenge:</strong> How can we measure the amount of information and quantify uncertainty?</p>
<p><strong>Researcher’s Dilemma:</strong> Claude Shannon faced fundamental questions about the efficient transmission and compression of information in communication systems. He needed a theoretical basis for quantifying information, determining how much data could be compressed without losing information, and how much information could be reliably transmitted through noisy channels.</p>
</blockquote>
<p>Information theory is a mathematical theory concerning the compression, transmission, and storage of data, playing a crucial role in evaluating and optimizing model performance in deep learning. In this section, we will explore the core concepts of information theory: entropy, mutual information, and KL divergence.</p>
<section id="entropy" class="level4">
<h4 class="anchored" data-anchor-id="entropy">Entropy</h4>
<p>Entropy is a measure of the uncertainty of information. The entropy <span class="math inline">\(H(P)\)</span> of a probability distribution <span class="math inline">\(P\)</span> is defined as:</p>
<p><span class="math display">\[H(P) = -\sum_{x} P(x) \log P(x)\]</span></p>
<p>where <span class="math inline">\(x\)</span> represents all possible events. The main properties of entropy are:</p>
<ol type="1">
<li>Non-negativity: <span class="math inline">\(H(P) ≥ 0\)</span></li>
<li>Maximum for uniform distribution: Entropy is maximum when all events have equal probabilities.</li>
<li>Zero entropy for certain events: <span class="math inline">\(H(P) = 0\)</span> when <span class="math inline">\(P(x) = 1\)</span></li>
</ol>
<p>In deep learning, entropy is primarily used as the basis for cross-entropy, a loss function commonly used in classification problems. The following example calculates the entropy of various probability distributions and visualizes the entropy of a binary distribution.</p>
<div id="cell-35" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_02.information_theory <span class="im">import</span> calculate_entropy</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>calculate_entropy()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Entropy of fair coin: 0.69
Entropy of biased coin: 0.33
Entropy of fair die: 1.39</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="02_Mathematics of Deep Learning_files/figure-html/cell-10-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="mutual-information" class="level4">
<h4 class="anchored" data-anchor-id="mutual-information">Mutual Information</h4>
<p>Mutual Information measures the mutual dependence between two probability variables X and Y. It is defined mathematically as follows.</p>
<p><span class="math display">\[I(X;Y) = \sum_{x}\sum_{y} P(x,y) \log \frac{P(x,y)}{P(x)P(y)}\]</span></p>
<p>The main characteristics of Mutual Information are as follows.</p>
<ol type="1">
<li>Non-negativity: <span class="math inline">\(I(X;Y) \ge 0\)</span></li>
<li>Symmetry: <span class="math inline">\(I(X;Y) = I(Y;X)\)</span></li>
<li>Zero when X and Y are independent: If X and Y are independent, <span class="math inline">\(I(X;Y) = 0\)</span></li>
</ol>
<p>Mutual Information is used in various machine learning tasks such as feature selection and dimension reduction. The following example calculates and visualizes the Mutual Information for a simple joint probability distribution.</p>
<div id="cell-37" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_02.information_theory <span class="im">import</span> mutual_information_example</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>mutual_information_example()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Mutual Information: 0.0058</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="02_Mathematics of Deep Learning_files/figure-html/cell-11-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="kl-divergence" class="level4">
<h4 class="anchored">KL Divergence</h4>
<p>KL (Kullback-Leibler) divergence is a method for measuring the difference between two probability distributions P and Q. The KL divergence of Q from P is defined as follows.</p>
<p><span class="math display">\[D_{KL}(P||Q) = \sum_{x} P(x) \log \frac{P(x)}{Q(x)}\]</span></p>
<p>The main properties of KL divergence are as follows.</p>
<ol type="1">
<li>Non-negativity: <span class="math inline">\(D_{KL}(P||Q) \ge 0\)</span></li>
<li>Zero if and only if P = Q: <span class="math inline">\(D_{KL}(P||Q) = 0\)</span> if and only if <span class="math inline">\(P = Q\)</span></li>
<li>Asymmetry: In general, <span class="math inline">\(D_{KL}(P||Q) \ne D_{KL}(Q||P)\)</span></li>
</ol>
<p>KL divergence is used in deep learning as follows.</p>
<ol type="1">
<li>Variational inference: It is used to minimize the difference between an approximate distribution and the actual distribution.</li>
<li>Model compression: It is used for knowledge distillation in teacher-student networks.</li>
<li>Anomaly detection: It is used to measure the difference from a normal data distribution.</li>
</ol>
<p>The concepts of information theory are closely related to each other. For example, mutual information can be expressed as the difference between entropy and conditional entropy.</p>
<p><span class="math inline">\(I(X;Y) = H(X) - H(X|Y)\)</span></p>
<p>Additionally, KL divergence can be represented as the difference between cross-entropy and entropy.</p>
<p><span class="math inline">\(D_{KL}(P||Q) = H(P,Q) - H(P)\)</span></p>
<p>Here, <span class="math inline">\(H(P,Q)\)</span> is the cross-entropy of <span class="math inline">\(P\)</span> and <span class="math inline">\(Q\)</span>. The following calculates the KL divergence between two probability distributions and visualizes the distribution.</p>
<div id="cell-39" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_02.information_theory <span class="im">import</span> kl_divergence_example</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>kl_divergence_example()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>KL(P||Q): 0.0823
KL(Q||P): 0.0872</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="02_Mathematics of Deep Learning_files/figure-html/cell-12-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>These concepts of information theory are widely applied to the design and optimization of deep learning models. For example, they are used in various ways, such as using a combination of reconstruction error and KL divergence as the loss function for autoencoders, or using KL divergence as a constraint for policy optimization in reinforcement learning.</p>
<p>In the next chapter, we will look at how these concepts of probability, statistics, and information theory are applied in actual deep learning models.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Deep Dive: Core Concepts of Information Theory">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Deep Dive: Core Concepts of Information Theory
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse">
<section id="core-concepts-of-information-theory---information-content-cross-entropy-kl-divergence-mutual-information" class="level2 callout-body-container callout-body">
<h2 class="anchored" data-anchor-id="core-concepts-of-information-theory---information-content-cross-entropy-kl-divergence-mutual-information">Core Concepts of Information Theory - Information Content, Cross Entropy, KL-Divergence, Mutual Information</h2>
<section id="information-content-self-information" class="level3">
<h3 class="anchored" data-anchor-id="information-content-self-information">1. Information Content (Self-information)</h3>
<ul>
<li><p><strong>Definition:</strong> The information content (self-information) represents the amount of information that can be obtained when a specific event occurs. Events that occur less frequently have higher information content.</p></li>
<li><p><strong>Formula:</strong> <span class="math display">\[I(x) = -\log(P(x))\]</span></p>
<ul>
<li><span class="math inline">\(x\)</span>: Event</li>
<li><span class="math inline">\(P(x)\)</span>: Probability of event <span class="math inline">\(x\)</span> occurring</li>
<li><span class="math inline">\(\log\)</span>: The base of the logarithm can be 2 (unit: bits), <span class="math inline">\(e\)</span> (unit: nats), or 10, among others. In deep learning, the natural logarithm (<span class="math inline">\(e\)</span>) is commonly used.</li>
</ul></li>
<li><p><strong>Intuitive Explanation:</strong></p>
<ul>
<li><strong>Rarity:</strong> Events with lower probabilities (rare events) have higher information content. For example, “The sun rises in the east” is a certain fact and has almost no information content, while “I won the lottery today” is a very rare event and thus has high information content.</li>
<li><strong>Reduction of Uncertainty:</strong> Information content can be interpreted as a measure of how much uncertainty is reduced after an event occurs.</li>
</ul></li>
<li><p><strong>Properties:</strong></p>
<ul>
<li>Since <span class="math inline">\(0 \le P(x) \le 1\)</span>, we have <span class="math inline">\(I(x) \ge 0\)</span>.</li>
<li>If <span class="math inline">\(P(x) = 1\)</span> (a certain event), then <span class="math inline">\(I(x) = 0\)</span>.</li>
<li>The smaller <span class="math inline">\(P(x)\)</span> is, the larger <span class="math inline">\(I(x)\)</span> becomes.</li>
<li>For two independent events <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, we have <span class="math inline">\(I(x, y) = I(x) + I(y)\)</span> (additivity of information content).</li>
</ul></li>
</ul>
</section>
<section id="cross-entropy" class="level3">
<h3 class="anchored" data-anchor-id="cross-entropy">2. Cross Entropy</h3>
<ul>
<li><p><strong>Definition:</strong> The cross entropy measures how different two probability distributions <span class="math inline">\(P\)</span> and <span class="math inline">\(Q\)</span> are. Considering <span class="math inline">\(P\)</span> as the true distribution and <span class="math inline">\(Q\)</span> as the estimated distribution, it represents the average number of bits needed to represent <span class="math inline">\(P\)</span> using <span class="math inline">\(Q\)</span>.</p></li>
<li><p><strong>Derivation:</strong></p>
<ol type="1">
<li><strong>Information Content:</strong> The information content of an event <span class="math inline">\(x\)</span> following the true distribution <span class="math inline">\(P\)</span>: <span class="math inline">\(I(x) = -\log P(x)\)</span></li>
<li><strong>Average Information (Entropy):</strong> The average information (entropy) of the true distribution <span class="math inline">\(P\)</span>: <span class="math inline">\(H(P) = -\sum_{x} P(x) \log P(x)\)</span></li>
<li><strong>Using Estimated Distribution:</strong> When using the estimated distribution <span class="math inline">\(Q\)</span> to represent the true distribution <span class="math inline">\(P\)</span>, the information content for each event <span class="math inline">\(x\)</span>: <span class="math inline">\(-\log Q(x)\)</span></li>
<li><strong>Cross Entropy:</strong> The average information when representing the true distribution <span class="math inline">\(P\)</span> using the estimated distribution <span class="math inline">\(Q\)</span>: <span class="math display">\[H(P, Q) = -\sum_{x} P(x) \log Q(x)\]</span></li>
</ol></li>
<li><p><strong>Intuitive Explanation:</strong></p>
<ul>
<li>The more similar <span class="math inline">\(P\)</span> and <span class="math inline">\(Q\)</span> are, the smaller the cross entropy becomes.</li>
<li>When <span class="math inline">\(P = Q\)</span>, the cross entropy reaches its minimum value (the entropy <span class="math inline">\(H(P)\)</span>).</li>
<li>The more different <span class="math inline">\(P\)</span> and <span class="math inline">\(Q\)</span> are, the larger the cross entropy becomes. This means that as the estimated distribution fails to reflect the actual distribution, information loss occurs.</li>
</ul></li>
<li><p><strong>Binary Cross Entropy (BCE):</strong></p>
<ul>
<li>Used for binary classification problems with two classes (0 or 1).</li>
<li><span class="math inline">\(P = [p, 1-p]\)</span> (true class probability distribution, where <span class="math inline">\(p\)</span> is the probability of class 1)</li>
<li><span class="math inline">\(Q = [q, 1-q]\)</span> (predicted class probability distribution, where <span class="math inline">\(q\)</span> is the predicted probability of class 1)</li>
<li><span class="math display">\[H(P, Q) = -[p \log q + (1-p) \log (1-q)]\]</span></li>
</ul></li>
<li><p><strong>Categorical Cross Entropy (CCE):</strong></p>
<ul>
<li>Used in multi-class classification problems with multiple classes.</li>
<li><span class="math inline">\(P = [p_1, p_2, ..., p_k]\)</span> (actual class probability distribution, <span class="math inline">\(p_i\)</span> is the probability of the <span class="math inline">\(i\)</span>th class, one-hot encoding)</li>
<li><span class="math inline">\(Q = [q_1, q_2, ..., q_k]\)</span> (predicted class probability distribution, <span class="math inline">\(q_i\)</span> is the probability of predicting the <span class="math inline">\(i\)</span>th class, softmax)</li>
<li><span class="math display">\[H(P, Q) = -\sum_{i=1}^{k} p_i \log q_i\]</span></li>
</ul></li>
</ul>
</section>
<section id="cross-entropy-and-likelihood" class="level3">
<h3 class="anchored" data-anchor-id="cross-entropy-and-likelihood">3. Cross Entropy and Likelihood</h3>
<ul>
<li><strong>Likelihood:</strong> The probability that given data occurs in a specific model (parameter).</li>
<li><strong>Negative Log-Likelihood (NLL):</strong> The value obtained by taking the logarithm of the likelihood and multiplying it by -1.</li>
<li><strong>Relationship between Cross Entropy and NLL:</strong>
<ul>
<li>In classification problems, when the model’s output (predicted probability distribution) is <span class="math inline">\(Q\)</span> and the actual label (one-hot encoding) is <span class="math inline">\(P\)</span>, Cross Entropy is equal to Negative Log-Likelihood.</li>
<li>Minimizing Cross Entropy is equivalent to maximizing Likelihood (Maximum Likelihood Estimation, MLE).</li>
</ul></li>
<li><strong>Application in Deep Learning:</strong>
<ul>
<li>Using Cross Entropy as a loss function for classification problems in deep learning is equivalent to training the model so that its output follows the actual label distribution (from the perspective of MLE).</li>
</ul></li>
</ul>
</section>
<section id="relationship-between-kl-divergence-and-cross-entropy" class="level3">
<h3 class="anchored" data-anchor-id="relationship-between-kl-divergence-and-cross-entropy">4. Relationship between KL-Divergence and Cross Entropy</h3>
<ul>
<li><p><strong>KL-Divergence (Kullback-Leibler Divergence):</strong></p>
<ul>
<li>Another method for measuring the difference between two probability distributions <span class="math inline">\(P\)</span> and <span class="math inline">\(Q\)</span> (not a distance concept, asymmetric).</li>
<li>The KL-Divergence from <span class="math inline">\(P\)</span> to <span class="math inline">\(Q\)</span> represents the additional amount of information required to express <span class="math inline">\(P\)</span> using <span class="math inline">\(Q\)</span>.</li>
<li><span class="math display">\[D_{KL}(P||Q) = \sum_{x} P(x) \log \frac{P(x)}{Q(x)} = \sum_{x} P(x)[\log P(x) - \log Q(x)]\]</span></li>
</ul></li>
<li><p><strong>Relationship between KL-Divergence and Cross Entropy:</strong></p>
<p><span class="math display">\[D_{KL}(P||Q) = \sum_{x} P(x) \log P(x) - \sum_{x} P(x) \log Q(x) =  -\sum_{x} P(x) \log Q(x)  - (-\sum_{x} P(x) \log P(x))\]</span> <span class="math display">\[D_{KL}(P||Q) = H(P, Q) - H(P)\]</span></p>
<ul>
<li><p><span class="math inline">\(H(P,Q)\)</span>: Cross Entropy</p></li>
<li><p><span class="math inline">\(H(P)\)</span>: Entropy</p></li>
<li><p>KL-Divergence is the value obtained by subtracting the entropy of <span class="math inline">\(P\)</span> from the Cross Entropy.</p></li>
<li><p>When <span class="math inline">\(P\)</span> is fixed, minimizing Cross Entropy is equivalent to minimizing KL-Divergence.</p></li>
</ul></li>
</ul>
</section>
<section id="relationship-between-mutual-information-and-conditional-entropy" class="level3">
<h3 class="anchored" data-anchor-id="relationship-between-mutual-information-and-conditional-entropy">5. Relationship between Mutual Information and Conditional Entropy</h3>
<ul>
<li><p><strong>Mutual Information:</strong></p>
<ul>
<li>A measure of how much information two random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> share with each other.</li>
<li>Represents the amount by which the uncertainty of <span class="math inline">\(Y\)</span> decreases when <span class="math inline">\(X\)</span> is known (or vice versa).</li>
<li><span class="math display">\[I(X;Y) = \sum_{x, y} P(x, y) \log \frac{P(x, y)}{P(x)P(y)}\]</span></li>
<li><span class="math inline">\(P(x,y)\)</span>: Joint Probability Distribution</li>
<li><span class="math inline">\(P(x)\)</span>, <span class="math inline">\(P(y)\)</span>: Marginal Probability Distribution</li>
</ul></li>
<li><p><strong>Conditional Entropy:</strong></p>
<ul>
<li>Represents the uncertainty of a random variable <span class="math inline">\(X\)</span> given a random variable <span class="math inline">\(Y\)</span>. <span class="math display">\[H(X|Y) = -\sum_{y} P(y) \sum_{x} P(x|y) \log P(x|y) =  -\sum_{x,y} P(x,y) \log P(x|y)\]</span></li>
</ul></li>
<li><p><strong>Relationship between Mutual Information and Conditional Entropy</strong>: <span class="math display">\[I(X;Y) = H(X) - H(X|Y) = H(Y) - H(Y|X)\]</span></p>
<ul>
<li>The mutual information of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is equal to the entropy of <span class="math inline">\(X\)</span> minus the conditional entropy of <span class="math inline">\(X\)</span> given <span class="math inline">\(Y\)</span>.</li>
<li>Represents the degree to which the uncertainty of <span class="math inline">\(X\)</span> decreases when <span class="math inline">\(Y\)</span> is known.</li>
</ul></li>
</ul>
</section>
<section id="jensenshannon-divergence" class="level3">
<h3 class="anchored" data-anchor-id="jensenshannon-divergence">6. Jensen–Shannon Divergence</h3>
<ul>
<li><strong>Jensen–Shannon Divergence (JSD):</strong>
<ul>
<li>Another way to measure the distance between two probability distributions <span class="math inline">\(P\)</span> and <span class="math inline">\(Q\)</span>. Unlike KL-Divergence, it is symmetric and bounded (between 0 and 1).</li>
<li><span class="math display">\[JSD(P||Q) = \frac{1}{2}D_{KL}(P||M) + \frac{1}{2}D_{KL}(Q||M)\]</span>
<ul>
<li><span class="math inline">\(M = \frac{1}{2}(P + Q)\)</span>: the average distribution of <span class="math inline">\(P\)</span> and <span class="math inline">\(Q\)</span></li>
</ul></li>
</ul></li>
<li><strong>Characteristics:</strong>
<ul>
<li>Symmetry: <span class="math inline">\(JSD(P||Q) = JSD(Q||P)\)</span></li>
<li>Boundedness: <span class="math inline">\(0 \le JSD(P||Q) \le 1\)</span> (when using log base 2)</li>
<li>The square root of JSD satisfies the conditions of a distance function (metric).</li>
</ul></li>
</ul>
</section>
</section>
</div>
</div>
</section>
</section>
<section id="loss-function" class="level3">
<h3 class="anchored" data-anchor-id="loss-function">2.3.4 Loss Function</h3>
<p>The loss function measures how different the prediction of a machine learning model is from the actual value. The goal of model training is to find the parameters (weights and biases) that minimize the value of this loss function. Choosing an appropriate loss function has a significant impact on the performance of the model, so it should be selected carefully based on the type of problem and the characteristics of the data.</p>
<section id="definition-of-loss-function" class="level4">
<h4 class="anchored" data-anchor-id="definition-of-loss-function">Definition of Loss Function</h4>
<p>In general, the loss function <span class="math inline">\(L\)</span> can be expressed as follows when the model’s parameters are <span class="math inline">\(\theta\)</span> and the data point is <span class="math inline">\((x_i, y_i)\)</span> (where <span class="math inline">\(y_i\)</span> is the actual value and <span class="math inline">\(f(x_i; \theta)\)</span> is the model’s predicted value):</p>
<p><span class="math inline">\(L(\theta) = \frac{1}{N} \sum_{i=1}^{N} l(y_i, f(x_i; \theta))\)</span></p>
<p><span class="math inline">\(N\)</span> is the number of data points, and <span class="math inline">\(l\)</span> is a function representing the loss for each individual data point.</p>
</section>
<section id="main-loss-functions" class="level4">
<h4 class="anchored" data-anchor-id="main-loss-functions">Main Loss Functions</h4>
<p>The following are loss functions commonly used in machine learning and deep learning:</p>
<section id="mean-squared-error-mse" class="level5">
<h5 class="anchored" data-anchor-id="mean-squared-error-mse">1. Mean Squared Error (MSE)</h5>
<ul>
<li><strong>Formula:</strong> <span class="math inline">\(MSE = \frac{1}{N} \sum_{i=1}^N (y_i - \hat{y}_i)^2\)</span> (<span class="math inline">\(y_i\)</span>: actual value, <span class="math inline">\(\hat{y}_i\)</span>: predicted value)</li>
<li><strong>Characteristics:</strong>
<ul>
<li>Sensitive to outliers because the error is squared.</li>
<li>Differentiable and a convex function, making it easy to find the optimal solution using gradient descent.</li>
</ul></li>
<li><strong>Usage:</strong> Mainly used for regression problems.</li>
</ul>
</section>
<section id="mean-absolute-error-mae" class="level5">
<h5 class="anchored" data-anchor-id="mean-absolute-error-mae">2. Mean Absolute Error (MAE)</h5>
<ul>
<li><strong>Formula:</strong> <span class="math inline">\(MAE = \frac{1}{N} \sum_{i=1}^N |y_i - \hat{y}_i|\)</span></li>
<li><strong>Characteristics:</strong>
<ul>
<li>Less sensitive to outliers compared to MSE.</li>
<li>Not differentiable at <span class="math inline">\(x=0\)</span>, but can be handled by automatic differentiation in deep learning frameworks.</li>
</ul></li>
<li><strong>Usage:</strong> Used for regression problems.</li>
</ul>
</section>
<section id="cross-entropy-loss" class="level5">
<h5 class="anchored" data-anchor-id="cross-entropy-loss">3. Cross-Entropy Loss</h5>
<ul>
<li><strong>Formula:</strong>
<ul>
<li><strong>Binary Classification:</strong> <span class="math inline">\(L = -\frac{1}{N} \sum_{i=1}^N [y_i \log(\hat{y}_i) + (1-y_i) \log(1-\hat{y}_i)]\)</span></li>
<li><strong>Multi-class Classification:</strong> <span class="math inline">\(L = -\frac{1}{N} \sum_{i=1}^N \sum_{j=1}^C y_{ij} \log(\hat{y}_{ij})\)</span> (<span class="math inline">\(C\)</span>: number of classes)</li>
</ul></li>
<li><strong>Characteristics:</strong>
<ul>
<li>Measures the difference between the predicted probability distribution and the actual distribution.</li>
<li>Tends to converge faster than MSE in classification problems.</li>
<li>Used with the softmax activation function in the output layer.</li>
</ul></li>
<li><strong>Usage:</strong> Classification problems (binary classification, multi-class classification).</li>
</ul>
</section>
<section id="hinge-loss" class="level5">
<h5 class="anchored" data-anchor-id="hinge-loss">4. Hinge Loss</h5>
<ul>
<li><strong>Formula:</strong> <span class="math inline">\(L = \max(0, 1 - y \cdot f(x))\)</span> (<span class="math inline">\(y\)</span>: actual class <span class="math inline">\(\in\)</span> {-1, 1}, <span class="math inline">\(f(x)\)</span>: model’s predicted value)</li>
<li><strong>Characteristics:</strong>
<ul>
<li>Maximizes the margin between “correct” and “incorrect” classes.</li>
<li>Not differentiable at <span class="math inline">\(x=1\)</span>.</li>
</ul></li>
<li><strong>Usage:</strong> Mainly used for binary classification problems, such as in Support Vector Machines (SVM).</li>
</ul>
</section>
</section>
<section id="criteria-for-selecting-a-loss-function" class="level4">
<h4 class="anchored" data-anchor-id="criteria-for-selecting-a-loss-function">Criteria for Selecting a Loss Function</h4>
<ul>
<li><strong>Problem Type:</strong> The appropriate loss function differs depending on whether it’s a regression or classification problem.</li>
<li><strong>Data Characteristics:</strong> The presence of outliers, class imbalance, and other factors should be considered when selecting a loss function.</li>
<li><strong>Model:</strong> The choice of loss function may depend on the specific model being used.</li>
</ul>
</section>
<section id="additional-loss-functions" class="level4">
<h4 class="anchored">Additional Loss Functions</h4>
<ul>
<li><strong>Kullback-Leibler Divergence (KLD):</strong> Measures the difference between two probability distributions P and Q. Mainly used in generative models such as Variational Autoencoders (VAEs).</li>
<li><strong>Focal Loss:</strong> A loss function that adjusts Cross-Entropy to work well with imbalanced data, primarily used in object detection tasks.</li>
<li><strong>Huber Loss:</strong> Combines MSE and MAE, providing robustness to outliers while being differentiable.</li>
<li><strong>Log-Cosh Loss:</strong> Similar to Huber Loss but has the advantage of being twice differentiable at all points.</li>
<li><strong>Contrastive Loss:</strong> Used in Siamese Networks to learn embeddings where similar sample pairs are close and dissimilar pairs are far apart.</li>
<li><strong>Triplet Loss:</strong> Uses three samples (Anchor, Positive, Negative) to learn embeddings such that the distance between Anchor and Positive is minimized, and the distance between Anchor and Negative is maximized.</li>
<li><strong>CTC Loss:</strong> A loss function used in speech recognition, handwriting recognition, etc., when the input sequence and output sequence have different lengths.</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled" title="Click to view content (Deep Dive: Loss Function In-Depth Analysis)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-10-contents" aria-controls="callout-10" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Click to view content (Deep Dive: Loss Function In-Depth Analysis)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-10" class="callout-10-contents callout-collapse collapse">
<section id="in-depth-analysis-of-loss-functions" class="level3 callout-body-container callout-body">
<h3 class="anchored" data-anchor-id="in-depth-analysis-of-loss-functions">In-Depth Analysis of Loss Functions</h3>
<section id="loss-function-and-maximum-likelihood-estimation-mle" class="level4">
<h4 class="anchored" data-anchor-id="loss-function-and-maximum-likelihood-estimation-mle">Loss Function and Maximum Likelihood Estimation (MLE)</h4>
<p>The learning process of many machine learning models can be explained from the perspective of maximum likelihood estimation (MLE). MLE is a method for finding the model parameters that best explain the given data. Assuming that the data are independent and identically distributed (i.i.d), the likelihood function is defined as follows:</p>
<p><span class="math inline">\(L(\theta) = P(D|\theta) = \prod_{i=1}^{N} P(y_i | x_i; \theta)\)</span></p>
<p>where <span class="math inline">\(D = \{(x_1, y_1), (x_2, y_2), ..., (x_N, y_N)\}\)</span> is the training data and <span class="math inline">\(\theta\)</span> is the model parameter. <span class="math inline">\(P(y_i | x_i; \theta)\)</span> is the probability (or probability density) that the model outputs <span class="math inline">\(y_i\)</span> when given <span class="math inline">\(x_i\)</span> as input.</p>
<p>The goal of MLE is to find the parameter <span class="math inline">\(\theta\)</span> that maximizes the likelihood function <span class="math inline">\(L(\theta)\)</span>. In practice, it is more convenient to maximize the log-likelihood function:</p>
<p><span class="math inline">\(\log L(\theta) = \sum_{i=1}^{N} \log P(y_i | x_i; \theta)\)</span></p>
<ul>
<li><p><strong>MSE and MLE:</strong> In linear regression models, if the error follows a normal distribution with a mean of 0 and a variance of <span class="math inline">\(\sigma^2\)</span>, MLE is equivalent to minimizing MSE.</p>
<p><span class="math inline">\(P(y_i | x_i; \theta) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(y_i - f(x_i; \theta))^2}{2\sigma^2}\right)\)</span></p>
<p>The log-likelihood function is: <span class="math inline">\(\log L(\theta) = -\frac{N}{2}\log(2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^{N}(y_i - f(x_i;\theta))^2\)</span></p>
<p>Except for constants, and assuming <span class="math inline">\(\sigma^2\)</span> is constant, maximizing the log-likelihood function is equivalent to <em>minimizing</em> MSE.</p></li>
<li><p><strong>Cross-Entropy and MLE:</strong> In classification problems, the output <span class="math inline">\(\hat{y}_i\)</span> can be interpreted as a parameter of the Bernoulli distribution (binary classification) or the multinomial distribution (multi-class classification). In this case, MLE is equivalent to minimizing Cross-Entropy Loss.</p>
<ul>
<li><p><strong>Binary Classification (Bernoulli Distribution):</strong> If <span class="math inline">\(\hat{y_i}\)</span> is the probability that <span class="math inline">\(y_i=1\)</span> as predicted by the model, <span class="math inline">\(P(y_i|x_i;\theta) = \hat{y_i}^{y_i} (1 - \hat{y_i})^{(1-y_i)}\)</span> Log-likelihood: <span class="math inline">\(\log L(\theta) = \sum_{i=1}^{N} [y_i \log(\hat{y}_i) + (1 - y_i)\log(1 - \hat{y}_i)]\)</span></p></li>
<li><p><strong>Multi-Class Classification (Categorical/Multinoulli Distribution):</strong> <span class="math inline">\(P(y_i | x_i; \theta) = \prod_{j=1}^{C} \hat{y}_{ij}^{y_{ij}}\)</span> (one-hot encoding) Log-likelihood: <span class="math inline">\(\log L(\theta) = \sum_{i=1}^N \sum_{j=1}^C y_{ij} \log(\hat{y}_{ij})\)</span></p></li>
</ul>
<p>Therefore, minimizing Cross-Entropy Loss is the same process as finding the parameters that best model the data distribution using MLE.</p></li>
</ul>
</section>
<section id="additional-loss-functions-kld-focal-loss" class="level4">
<h4 class="anchored" data-anchor-id="additional-loss-functions-kld-focal-loss">Additional Loss Functions (KLD, Focal Loss)</h4>
<ul>
<li><p><strong>Kullback-Leibler Divergence (KLD):</strong></p></li>
<li><p><strong>Description:</strong> Measures the difference between two probability distributions P and Q. P represents the actual data distribution, and Q represents the estimated distribution by the model.</p></li>
<li><p><strong>Formula:</strong> <span class="math inline">\(D_{KL}(P||Q) = \sum_{x} P(x) \log \frac{P(x)}{Q(x)}\)</span></p></li>
<li><p><strong>Characteristics:</strong></p>
<ul>
<li>Asymmetric: <span class="math inline">\(D_{KL}(P||Q) \neq D_{KL}(Q||P)\)</span></li>
<li>Always non-negative: <span class="math inline">\(D_{KL}(P||Q) \ge 0\)</span>, with <span class="math inline">\(D_{KL}(P||Q) = 0\)</span> only when <span class="math inline">\(P=Q\)</span></li>
<li>Undefined where <span class="math inline">\(P(x) = 0\)</span></li>
</ul></li>
<li><p><strong>Relationship to VAE:</strong></p>
<ul>
<li>In Variational Autoencoders (VAE), KL Divergence is used to make the posterior distribution of latent variables closer to a prior distribution, such as a normal distribution.</li>
<li>The loss function of VAE consists of reconstruction loss and KL Divergence terms.</li>
</ul></li>
<li><p><strong>Focal Loss:</strong></p>
<ul>
<li><strong>Description:</strong> Proposed to address class imbalance problems by modifying Cross-Entropy Loss, particularly the imbalance between “easy” and “hard” examples.</li>
<li><strong>Formula:</strong> <span class="math inline">\(FL(p_t) = -\alpha_t (1 - p_t)^\gamma \log(p_t)\)</span>
<ul>
<li><span class="math inline">\(p_t\)</span>: probability of the predicted correct class by the model</li>
<li><span class="math inline">\(\gamma\)</span>: focusing parameter (<span class="math inline">\(\gamma \ge 0\)</span>, typically 2)</li>
<li><span class="math inline">\(\alpha_t\)</span>: class-wise weights (optional)</li>
</ul></li>
<li><strong>Characteristics:</strong>
<ul>
<li>When <span class="math inline">\(\gamma = 0\)</span>, it becomes the standard Cross-Entropy Loss.</li>
<li>When <span class="math inline">\(\gamma &gt; 0\)</span>, it reduces the loss for well-classified samples (<span class="math inline">\(p_t\)</span> is large) and relatively keeps the loss large for poorly classified samples (<span class="math inline">\(p_t\)</span> is small), focusing more on hard examples.</li>
<li>Class-wise weights can be adjusted using <span class="math inline">\(\alpha_t\)</span> (e.g., giving more weight to classes with fewer instances).</li>
</ul></li>
<li><strong>Application in Object Detection:</strong></li>
<li>Object detection problems suffer from severe class imbalance because the background (negative) area far exceeds the object (positive) area.</li>
<li>Focal Loss mitigates this imbalance, guiding the object detection model to focus more on actual objects rather than the background.</li>
</ul></li>
</ul>
</section>
<section id="various-loss-functions-advanced" class="level4">
<h4 class="anchored" data-anchor-id="various-loss-functions-advanced">Various Loss Functions (Advanced)</h4>
<ul>
<li><p><strong>Huber Loss:</strong> A loss function that combines the advantages of MSE and MAE. For errors less than a certain value (<span class="math inline">\(\delta\)</span>), it uses squared error like MSE; for larger errors, it uses absolute error like MAE. It is robust to outliers and differentiable.</p>
<p><span class="math inline">\(L_\delta(y, \hat{y}) = \begin{cases}
\frac{1}{2}(y - \hat{y})^2 &amp; \text{if } |y - \hat{y}| \le \delta \\
\delta(|y - \hat{y}| - \frac{1}{2}\delta) &amp; \text{otherwise}
\end{cases}\)</span></p></li>
<li><p><strong>Log-Cosh Loss:</strong> Defined as <span class="math inline">\(\log(\cosh(y - \hat{y}))\)</span>. Similar to Huber Loss, it is robust to outliers and has the advantage of being twice differentiable at all points.</p></li>
<li><p><strong>Quantile Loss:</strong> Used to minimize the prediction error at a specific quantile.</p></li>
<li><p><strong>Contrastive Loss, Triplet Loss:</strong> These are used in Siamese Network, Triplet Network, etc., and are used to adjust the distance between similar sample pairs/triplets. (For details, refer to relevant papers)</p></li>
<li><p><strong>Connectionist Temporal Classification (CTC) Loss</strong>: This is used when the alignment between the input sequence and output sequence is not clear, such as in speech recognition and handwriting recognition.</p></li>
</ul>
</section>
<section id="loss-function-selection-guidelines-advanced" class="level4">
<h4 class="anchored" data-anchor-id="loss-function-selection-guidelines-advanced">Loss Function Selection Guidelines (Advanced)</h4>
<ul>
<li><strong>Outlier handling:</strong> If there are many outliers and robustness to outliers is required, MAE, Huber Loss, Quantile Loss, etc. can be considered.</li>
<li><strong>Differentiability:</strong> For gradient-based optimization, a differentiable loss function is needed. However, even for non-differentiable cases like Hinge Loss and MAE, subgradients (subdifferentials) can be used or automatic differentiation in deep learning frameworks can be utilized.</li>
<li><strong>Probabilistic modeling:</strong> If the model output is to be interpreted as a probability distribution, Cross-Entropy Loss is suitable.</li>
<li><strong>Class imbalance:</strong> In cases of severe class imbalance, Focal Loss, Weighted Cross-Entropy, etc. can be considered.</li>
<li><strong>Multiple outputs</strong>: When there are multiple outputs and correlations exist between them, loss functions for each output can be combined.</li>
</ul>
<p>The loss function is one of the key factors determining the performance of a deep learning model. The ability to select an appropriate loss function considering the problem characteristics, data distribution, and model structure, and to design new loss functions if necessary, is required for deep learning engineers.</p>
</section>
</section>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Click to view content (Deep Dive: Designing a New Loss Function)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-11-contents" aria-controls="callout-11" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Click to view content (Deep Dive: Designing a New Loss Function)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-11" class="callout-11-contents callout-collapse collapse">
<section id="designing-new-loss-functions" class="level3 callout-body-container callout-body">
<h3 class="anchored" data-anchor-id="designing-new-loss-functions">Designing New Loss Functions</h3>
<p>Existing loss functions (MSE, Cross-Entropy, etc.) are not always the optimal choice. Depending on the specific requirements of the problem, data distribution, and model architecture, it may be necessary to design new loss functions. Designing new loss functions is an important part of deep learning research and has the potential to significantly improve model performance.</p>
<section id="when-new-loss-functions-are-needed" class="level4">
<h4 class="anchored" data-anchor-id="when-new-loss-functions-are-needed">When New Loss Functions Are Needed</h4>
<ul>
<li><strong>Special structure of data:</strong> When the data does not follow a common distribution (Gaussian, Bernoulli, etc.) or has a special structure (e.g., ranking, sparsity, hierarchical, graph structure).</li>
<li><strong>Specific constraints of the problem:</strong> When specific constraints (e.g., monotonicity, sparsity, fairness, robustness) are desired to be imposed on the model’s predictions.</li>
<li><strong>Limitations of existing loss functions:</strong> When existing loss functions do not work well for a particular problem (e.g., sensitive to outliers, class imbalance) or do not sufficiently reflect the desired goals. When specific metrics need to be directly optimized.</li>
<li><strong>Multi-objective optimization:</strong> When multiple loss functions need to be combined and optimized simultaneously (e.g., balancing prediction accuracy and model complexity).</li>
<li><strong>Generative models:</strong> Generative models aim to learn the distribution of data, so they require different loss functions than typical classification or regression problems.</li>
</ul>
</section>
<section id="principles-for-designing-new-loss-functions" class="level4">
<h4 class="anchored" data-anchor-id="principles-for-designing-new-loss-functions">Principles for Designing New Loss Functions</h4>
<p>When designing new loss functions, the following principles should be considered:</p>
<ol type="1">
<li><strong>Problem definition and objectives:</strong> Clearly define the problem to be solved and the ultimate goals of the model. The loss function is a key element in defining what the model should learn. (e.g., simply increasing classification accuracy, doing better on specific classes, adjusting False Positive/False Negative ratios, etc.)</li>
<li><strong>Mathematical validity:</strong>
<ul>
<li><strong>Differentiability:</strong> For gradient-based optimization, the loss function should be differentiable at almost all points. If there are non-differentiable points, it should be possible to use subgradients (subdifferentials).</li>
<li><strong>Convexity:</strong> If the loss function is convex, it guarantees finding the global minimum. Even for non-convex functions, the design should aim to find good local minima.</li>
<li><strong>Preventing Gradient Vanishing/Exploding:</strong> Very large or very small gradients make learning unstable. Care should be taken to avoid situations where gradients become 0 or very small, such as the “dying ReLU” problem or vanishing gradients in sigmoid/tanh.</li>
<li><strong>Scale Invariance:</strong> The loss function’s value should not change significantly with the scale of input data or parameters.</li>
</ul></li>
<li><strong>Interpretability:</strong> If the meaning of the loss function can be intuitively understood, it helps analyze and debug the model’s learning process. Each term should have a clear role and meaning, including the interpretation of hyperparameters and their influence.</li>
<li><strong>Computational Efficiency:</strong> Since the loss function is computed at each iteration and for all (or mini-batch) data points, high computational costs can slow down training.</li>
</ol>
</section>
<section id="methodology-for-designing-new-loss-functions" class="level4">
<h4 class="anchored" data-anchor-id="methodology-for-designing-new-loss-functions">Methodology for Designing New Loss Functions</h4>
<ol type="1">
<li><strong>Existing loss function modification/combination:</strong>
<ul>
<li><strong>Weight addition:</strong> Assigns greater weights to specific data points, classes, or outputs (e.g., Weighted Cross-Entropy, Focal Loss).</li>
<li><strong>Regularization term addition:</strong> Adds a regularization term to limit the model’s complexity or encourage certain properties (e.g., L1 regularization, L2 regularization, Elastic Net). Regularization terms can also be added for output smoothness.</li>
<li><strong>Combination of multiple loss functions:</strong> Combines multiple existing loss functions through linear combination (weighted sum) or other methods (e.g., Multi-task learning).</li>
<li><strong>Soft/Hard Label Smoothing:</strong> Prevents the model from being too confident in its predictions using Label Smoothing Regularization.</li>
</ul></li>
<li><strong>Probabilistic modeling-based design:</strong>
<ul>
<li><strong>Maximum likelihood estimation (MLE):</strong> Designs loss functions by assuming a data distribution and estimating its parameters (e.g., MSE is MLE under Gaussian distribution assumption, Cross-Entropy is MLE under Bernoulli/multinomial distribution assumption).</li>
<li><strong>Variational Inference:</strong> Uses variational inference methods to design loss functions that approximate intractable posterior distributions (e.g., ELBO, Evidence Lower Bound) (e.g., Variational Autoencoder).</li>
<li><strong>Implicit Likelihood:</strong> Uses likelihood-free methods (e.g., GAN) when explicitly calculating the likelihood is difficult in generative models.</li>
</ul></li>
<li><strong>Problem-specific loss function design:</strong>
<ul>
<li><strong>Ranking Loss:</strong> Designs loss functions suitable for ranking problems (e.g., pairwise ranking loss, listwise ranking loss, margin ranking loss).</li>
<li><strong>Object Detection Loss:</strong> Designs loss functions that consider both bounding box regression and class classification in object detection problems (e.g., YOLO, SSD, Faster R-CNN’s loss function).</li>
<li><strong>Segmentation Loss:</strong> Designs loss functions that predict each pixel’s class and minimize the difference with the ground truth segmentation map in image segmentation problems (e.g., Dice Loss, IoU Loss, Tversky Loss).</li>
<li><strong>Generative Model Loss:</strong> Uses loss functions for generators and discriminators in generative models like GAN and VAE (e.g., Wasserstein distance, Adversarial Loss).</li>
<li><strong>Metric Learning Loss:</strong> Includes Contrastive Loss, Triplet Loss, N-pair Loss, etc.</li>
<li><strong>Sequence Loss:</strong> Includes CTC Loss, sequence-to-sequence model’s Cross-Entropy, etc.</li>
<li><strong>Graph Data Loss:</strong> Uses loss functions in Graph Neural Networks (e.g., node classification, link prediction, graph classification, etc.)</li>
</ul></li>
</ol>
</section>
<section id="precautions-when-designing-new-loss-functions" class="level4">
<h4 class="anchored" data-anchor-id="precautions-when-designing-new-loss-functions">Precautions when designing new loss functions</h4>
<ul>
<li><strong>Excessive complexity:</strong> A loss function that is too complex can make learning difficult and cause overfitting. It’s best to start with a simple loss function and gradually increase the complexity.</li>
<li><strong>Hyperparameter tuning:</strong> New loss functions often include additional hyperparameters (e.g., <span class="math inline">\(\gamma\)</span> in Focal Loss, weights when combining weights). It’s crucial to tune these hyperparameters properly and find the optimal values through methods like cross-validation.</li>
<li><strong>Theoretical/empirical justification:</strong> When proposing a new loss function, it’s essential to provide theoretical justification (e.g., mathematical characteristics of a specific problem, relationship with MLE) or empirical evidence (e.g., experimental results) explaining why this loss function works well.</li>
</ul>
<p>Designing a new loss function is a creative process, but it also requires a careful approach. It’s vital to deeply understand the essence of the problem, design based on mathematical/statistical principles, and thoroughly verify performance through experiments.</p>
</section>
</section>
</div>
</div>
<p>This chapter has examined the mathematical foundations of deep learning. It explored how concepts from various fields such as linear algebra, calculus, probability and statistics, and information theory are used in the design, training, and analysis of deep learning models. These mathematical tools are essential for understanding complex neural network structures, developing efficient learning algorithms, evaluating and improving model performance, and also play a crucial role in finding new breakthroughs at the forefront of deep learning research.</p>
</section>
</section>
</section>
<section id="exercises" class="level2">
<h2 class="anchored" data-anchor-id="exercises">Exercises</h2>
<section id="linear-algebra" class="level3">
<h3 class="anchored">1. Linear Algebra</h3>
<section id="basic" class="level4">
<h4 class="anchored" data-anchor-id="basic">Basic</h4>
<ol type="1">
<li><p>Calculate the dot product of two vectors <span class="math inline">\(\mathbf{a} = \begin{bmatrix} 1 \\ 2 \end{bmatrix}\)</span> and <span class="math inline">\(\mathbf{b} = \begin{bmatrix} 3 \\ 4 \end{bmatrix}\)</span>.</p></li>
<li><p>Calculate the product <span class="math inline">\(\mathbf{Ab}\)</span> of matrix <span class="math inline">\(\mathbf{A} = \begin{bmatrix} 1 &amp; 2 \\ 3 &amp; 4 \end{bmatrix}\)</span> and vector <span class="math inline">\(\mathbf{b} = \begin{bmatrix} 5 \\ 6 \end{bmatrix}\)</span>.</p></li>
<li><p>Create a 2x2 identity matrix.</p></li>
<li><p>Write the definition of L1 norm and L2 norm of a vector, and calculate the L1 norm and L2 norm of vector <span class="math inline">\(\mathbf{v} = \begin{bmatrix} 3 \\ -4 \end{bmatrix}\)</span>.</p></li>
</ol>
</section>
<section id="application" class="level4">
<h4 class="anchored" data-anchor-id="application">Application</h4>
<ol type="1">
<li><p>Find the eigenvalue and eigenvector of matrix <span class="math inline">\(\mathbf{A} = \begin{bmatrix} 2 &amp; 1 \\ 1 &amp; 2 \end{bmatrix}\)</span>.</p></li>
<li><p>Determine if the inverse of the given matrix exists, and if it does, calculate the inverse. <span class="math inline">\(\mathbf{A} = \begin{bmatrix} 1 &amp; 2 \\ 3 &amp; 4 \end{bmatrix}\)</span></p></li>
<li><p>Given a linear transformation <span class="math inline">\(T(\mathbf{x}) = \mathbf{Ax}\)</span>, explain how the basis vectors <span class="math inline">\(\mathbf{e_1} = \begin{bmatrix} 1 \\ 0 \end{bmatrix}\)</span> and <span class="math inline">\(\mathbf{e_2} = \begin{bmatrix} 0 \\ 1 \end{bmatrix}\)</span> are transformed, and visualize the result. (Assume <span class="math inline">\(\mathbf{A} = \begin{bmatrix} 2 &amp; -1 \\ 1 &amp; 1 \end{bmatrix}\)</span>)</p></li>
<li><p>Calculate the rank of the following matrix. <span class="math inline">\(\mathbf{A} = \begin{bmatrix} 1 &amp; 2 &amp; 3 \\ 4 &amp; 5 &amp; 6 \\ 7 &amp; 8 &amp; 9 \end{bmatrix}\)</span></p></li>
</ol>
</section>
<section id="advanced" class="level4">
<h4 class="anchored">Advanced</h4>
<ol type="1">
<li><p>Write the definition of Singular Value Decomposition (SVD) and decompose the given matrix <span class="math inline">\(\mathbf{A}\)</span> using SVD. <span class="math inline">\(\mathbf{A} = \begin{bmatrix} 1 &amp; 2 \\ 3 &amp; 4 \\ 5 &amp; 6 \end{bmatrix}\)</span></p></li>
<li><p>Explain the purpose and process of Principal Component Analysis (PCA), and perform PCA on the given dataset to reduce its dimension to 1.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">2</span>], [<span class="dv">2</span>, <span class="dv">3</span>], [<span class="dv">3</span>, <span class="dv">4</span>], [<span class="dv">4</span>, <span class="dv">5</span>], [<span class="dv">5</span>, <span class="dv">6</span>]])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p>Find the basis of the null space and column space of the following matrix. <span class="math inline">\(\mathbf{A} = \begin{bmatrix} 1 &amp; 2 &amp; 3 \\ 4 &amp; 5 &amp; 6 \\ 7 &amp; 8 &amp; 9 \end{bmatrix}\)</span></p></li>
<li><p>Write the definition of QR decomposition and perform QR decomposition on the given matrix <span class="math inline">\(\mathbf{A}\)</span>. (QR decomposition is a numerically stable method used to solve linear equations or eigenvalue problems.) <span class="math inline">\(\mathbf{A} = \begin{bmatrix} 1 &amp; 2 \\ 3 &amp; 4 \end{bmatrix}\)</span></p></li>
</ol>
<div class="callout callout-style-default callout-note callout-titled" title="Click to view contents (answer)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-12-contents" aria-controls="callout-12" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Click to view contents (answer)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-12" class="callout-12-contents callout-collapse collapse">
<section id="exercise-answers" class="level2 callout-body-container callout-body">
<h2 class="anchored" data-anchor-id="exercise-answers">Exercise Answers</h2>
<section id="linear-algebra-1" class="level3">
<h3 class="anchored" data-anchor-id="linear-algebra-1">1. Linear Algebra</h3>
<section id="basic-1" class="level4">
<h4 class="anchored" data-anchor-id="basic-1">Basic</h4>
<ol type="1">
<li><p><strong>Dot Product Calculation:</strong> <span class="math inline">\(\mathbf{a} \cdot \mathbf{b} = (1)(3) + (2)(4) = 3 + 8 = 11\)</span></p></li>
<li><p><strong>Matrix-Vector Multiplication:</strong> <span class="math inline">\(\mathbf{Ab} = \begin{bmatrix} 1 &amp; 2 \\ 3 &amp; 4 \end{bmatrix} \begin{bmatrix} 5 \\ 6 \end{bmatrix} = \begin{bmatrix} (1)(5) + (2)(6) \\ (3)(5) + (4)(6) \end{bmatrix} = \begin{bmatrix} 17 \\ 39 \end{bmatrix}\)</span></p></li>
<li><p><strong>2x2 Identity Matrix:</strong> <span class="math inline">\(\mathbf{I} = \begin{bmatrix} 1 &amp; 0 \\ 0 &amp; 1 \end{bmatrix}\)</span></p></li>
<li><p><strong>L1, L2 Norm:</strong></p>
<ul>
<li>L1 Norm (Manhattan Distance): <span class="math inline">\(||\mathbf{v}||_1 = \sum_{i} |v_i|\)</span></li>
<li>L2 Norm (Euclidean Distance): <span class="math inline">\(||\mathbf{v}||_2 = \sqrt{\sum_{i} v_i^2}\)</span></li>
</ul>
<p><span class="math inline">\(\mathbf{v} = \begin{bmatrix} 3 \\ -4 \end{bmatrix}\)</span> <span class="math inline">\(||\mathbf{v}||_1 = |3| + |-4| = 3 + 4 = 7\)</span> <span class="math inline">\(||\mathbf{v}||_2 = \sqrt{(3)^2 + (-4)^2} = \sqrt{9 + 16} = \sqrt{25} = 5\)</span></p></li>
</ol>
</section>
<section id="application-1" class="level4">
<h4 class="anchored" data-anchor-id="application-1">Application</h4>
<ol type="1">
<li><p><strong>Eigenvalue, Eigenvector:</strong> <span class="math inline">\(\mathbf{A} = \begin{bmatrix} 2 &amp; 1 \\ 1 &amp; 2 \end{bmatrix}\)</span></p>
<ul>
<li><p><strong>Characteristic Equation:</strong> <span class="math inline">\(\det(\mathbf{A} - \lambda\mathbf{I}) = 0\)</span> <span class="math inline">\((2-\lambda)^2 - (1)(1) = 0\)</span> <span class="math inline">\(\lambda^2 - 4\lambda + 3 = 0\)</span> <span class="math inline">\((\lambda - 3)(\lambda - 1) = 0\)</span> <span class="math inline">\(\lambda_1 = 3\)</span>, <span class="math inline">\(\lambda_2 = 1\)</span></p></li>
<li><p><strong>Eigenvector (λ = 3):</strong> <span class="math inline">\((\mathbf{A} - 3\mathbf{I})\mathbf{v} = 0\)</span> <span class="math inline">\(\begin{bmatrix} -1 &amp; 1 \\ 1 &amp; -1 \end{bmatrix} \begin{bmatrix} x \\ y \end{bmatrix} = \begin{bmatrix} 0 \\ 0 \end{bmatrix}\)</span> <span class="math inline">\(x = y\)</span>, <span class="math inline">\(\mathbf{v_1} = \begin{bmatrix} 1 \\ 1 \end{bmatrix}\)</span> (or any scalar multiple)</p></li>
<li><p><strong>Eigenvector (λ = 1):</strong> <span class="math inline">\((\mathbf{A} - \mathbf{I})\mathbf{v} = 0\)</span> <span class="math inline">\(\begin{bmatrix} 1 &amp; 1 \\ 1 &amp; 1 \end{bmatrix} \begin{bmatrix} x \\ y \end{bmatrix} = \begin{bmatrix} 0 \\ 0 \end{bmatrix}\)</span> <span class="math inline">\(x = -y\)</span>, <span class="math inline">\(\mathbf{v_2} = \begin{bmatrix} -1 \\ 1 \end{bmatrix}\)</span> (or any scalar multiple)</p></li>
</ul></li>
<li><p><strong>Inverse Matrix:</strong> <span class="math inline">\(\mathbf{A} = \begin{bmatrix} 1 &amp; 2 \\ 3 &amp; 4 \end{bmatrix}\)</span></p></li>
</ol>
<ul>
<li><strong>Existence of Inverse:</strong> <span class="math inline">\(\det(\mathbf{A}) = (1)(4) - (2)(3) = 4 - 6 = -2 \neq 0\)</span>. The inverse exists.</li>
<li><strong>Inverse Calculation:</strong> <span class="math inline">\(\mathbf{A}^{-1} = \frac{1}{\det(\mathbf{A})} \begin{bmatrix} 4 &amp; -2 \\ -3 &amp; 1 \end{bmatrix} = \frac{1}{-2} \begin{bmatrix} 4 &amp; -2 \\ -3 &amp; 1 \end{bmatrix} = \begin{bmatrix} -2 &amp; 1 \\ 1.5 &amp; -0.5 \end{bmatrix}\)</span></li>
</ul>
<ol start="3" type="1">
<li><strong>Linear Transformation Visualization:</strong>
<ul>
<li><span class="math inline">\(T(\mathbf{e_1}) = \mathbf{A}\mathbf{e_1} = \begin{bmatrix} 2 &amp; -1 \\ 1 &amp; 1 \end{bmatrix} \begin{bmatrix} 1 \\ 0 \end{bmatrix} = \begin{bmatrix} 2 \\ 1 \end{bmatrix}\)</span></li>
<li><span class="math inline">\(T(\mathbf{e_2}) = \mathbf{A}\mathbf{e_2} = \begin{bmatrix} 2 &amp; -1 \\ 1 &amp; 1 \end{bmatrix} \begin{bmatrix} 0 \\ 1 \end{bmatrix} = \begin{bmatrix} -1 \\ 1 \end{bmatrix}\)</span></li>
<li>Visualization: The original basis vectors <span class="math inline">\(\mathbf{e_1}\)</span>, <span class="math inline">\(\mathbf{e_2}\)</span> are transformed into <span class="math inline">\(\begin{bmatrix} 2 \\ 1 \end{bmatrix}\)</span>, <span class="math inline">\(\begin{bmatrix} -1 \\ 1 \end{bmatrix}\)</span>, respectively, which is plotted on the coordinate plane.</li>
</ul></li>
<li><strong>Rank Calculation:</strong> <span class="math inline">\(\mathbf{A} = \begin{bmatrix} 1 &amp; 2 &amp; 3 \\ 4 &amp; 5 &amp; 6 \\ 7 &amp; 8 &amp; 9 \end{bmatrix}\)</span> When transformed into row echelon form, two rows have non-zero values, so the rank is 2. (The third row can be expressed as a linear combination of the first and second rows.)</li>
</ol>
</section>
<section id="advanced-1" class="level4">
<h4 class="anchored" data-anchor-id="advanced-1">Advanced</h4>
<ol type="1">
<li><p><strong>SVD:</strong> <span class="math inline">\(\mathbf{A} = \mathbf{U\Sigma V^T}\)</span></p>
<ul>
<li><span class="math inline">\(\mathbf{U}\)</span>: An orthogonal matrix with columns being the eigenvectors of <span class="math inline">\(\mathbf{A}\mathbf{A}^T\)</span></li>
<li><span class="math inline">\(\mathbf{\Sigma}\)</span>: A diagonal matrix with singular values (square roots of the eigenvalues of <span class="math inline">\(\mathbf{A}\mathbf{A}^T\)</span>) as its diagonal elements</li>
<li><span class="math inline">\(\mathbf{V}\)</span>: An orthogonal matrix with columns being the eigenvectors of <span class="math inline">\(\mathbf{A}^T\mathbf{A}\)</span></li>
</ul>
<p>(The calculation process is omitted. It can be calculated using libraries like NumPy: <code>U, S, V = np.linalg.svd(A)</code>)</p></li>
<li><p><strong>PCA:</strong></p>
<div class="sourceCode" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">2</span>], [<span class="dv">2</span>, <span class="dv">3</span>], [<span class="dv">3</span>, <span class="dv">4</span>], [<span class="dv">4</span>, <span class="dv">5</span>], [<span class="dv">5</span>, <span class="dv">6</span>]])</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Data centralization (subtracting the mean)</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>mean <span class="op">=</span> np.mean(data, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>centered_data <span class="op">=</span> data <span class="op">-</span> mean</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Covariance matrix calculation</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>covariance_matrix <span class="op">=</span> np.cov(centered_data.T)</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Eigenvalue and eigenvector calculation</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>eigenvalues, eigenvectors <span class="op">=</span> np.linalg.eig(covariance_matrix)</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Principal component selection (eigenvector corresponding to the largest eigenvalue)</span></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a><span class="co">#    Sort the eigenvalues in descending order and select the eigenvector corresponding to the largest eigenvalue</span></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>sorted_indices <span class="op">=</span> np.argsort(eigenvalues)[::<span class="op">-</span><span class="dv">1</span>]  <span class="co"># Indices of descending order</span></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>largest_eigenvector <span class="op">=</span> eigenvectors[:, sorted_indices[<span class="dv">0</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<h1 id="projection-onto-one-dimension">5. Projection onto one dimension</h1>
<p>projected_data = centered_data.dot(largest_eigenvector)</p></li>
</ol>
<p>print(projected_data)</p>
<pre><code>
3.  **Null Space and Column Space Basis:**
    $\mathbf{A} = \begin{bmatrix} 1 &amp; 2 &amp; 3 \\ 4 &amp; 5 &amp; 6 \\ 7 &amp; 8 &amp; 9 \end{bmatrix}$

    *   **Null Space:** Finding $\mathbf{x}$ that satisfies $\mathbf{Ax} = 0$.
        By transforming into row echelon form and solving, 
        $\mathbf{x} = t\begin{bmatrix} 1 \\ -2 \\ 1 \end{bmatrix}$ (where $t$ is an arbitrary constant) form.
        Therefore, the basis for the null space is $\begin{bmatrix} 1 \\ -2 \\ 1 \end{bmatrix}$

    *   **Column Space:** The space generated by linear combinations of column vectors of matrix $\mathbf{A}$.
        In row echelon form, the original column vectors corresponding to pivot columns become the basis.
         $\begin{bmatrix} 1 \\ 4 \\ 7 \end{bmatrix}$, $\begin{bmatrix} 2 \\ 5 \\ 8 \end{bmatrix}$

4.  **QR Decomposition:**
    $\mathbf{A} = \mathbf{QR}$
    *   $\mathbf{Q}$: A matrix with orthonormal column vectors
    *   $\mathbf{R}$: An upper triangular matrix

    (The calculation process uses the Gram-Schmidt orthogonalization process or calculates using libraries like NumPy: `Q, R = np.linalg.qr(A)`)
:::

## Practice Problems

### 2 Calculus and Optimization

#### Basic

1.  Find the derivative $f'(x)$ of the function $f(x) = x^3 - 6x^2 + 9x + 1$.

2.  Find the partial derivatives $\frac{\partial f}{\partial x}$ and $\frac{\partial f}{\partial y}$ of the function $f(x, y) = x^2y + 2xy^2$.

3.  Find the derivative $f'(x)$ of the function $f(x) = \sin(x^2)$ using the chain rule.

#### Application

1.  Find the gradient $\nabla f$ of the function $f(x, y) = e^{x^2 + y^2}$ and calculate its value at the point (1, 1).

2.  Find all critical points of the function $f(x) = x^4 - 4x^3 + 4x^2$, and determine whether each critical point is a maximum, minimum, or saddle point.

3.  Find the Jacobian matrix of the function $f(x, y) = \begin{bmatrix} x^2 + y^2 \\ 2xy \end{bmatrix}$.

#### Advanced

1.  Use the Lagrange multiplier method to find the maximum and minimum values of the function $f(x, y) = xy$ subject to the constraint $g(x, y) = x^2 + y^2 - 1 = 0$.

2.  Use Gradient Descent to find the minimum value of the function $f(x) = x^4 - 4x^3 + 4x^2$, with initial value $x_0 = 3$, learning rate $\alpha = 0.01$, and 100 iterations.

3.  Express the gradient $\nabla f$ of the function $f(\mathbf{x}) = \mathbf{x}^T \mathbf{A} \mathbf{x}$ in terms of $\mathbf{A}$ and $\mathbf{x}$, where $\mathbf{A}$ is a symmetric matrix.

4.  Use Newton's method to find a root of the equation $x^3 - 2x - 5 = 0$.

::: {.callout-note collapse="true" title="Click to view contents (answer)"}
## Exercise Solutions

### 2 Calculus and Optimization

#### Basic

1.  **Derivative:**
    $f(x) = x^3 - 6x^2 + 9x + 1$
    $f'(x) = 3x^2 - 12x + 9$

2.  **Partial Derivative:**
    $f(x, y) = x^2y + 2xy^2$
    $\frac{\partial f}{\partial x} = 2xy + 2y^2$
    $\frac{\partial f}{\partial y} = x^2 + 4xy$

3.  **Chain Rule:**
    $f(x) = \sin(x^2)$
    $f'(x) = \cos(x^2) \cdot (2x) = 2x\cos(x^2)$

#### Applied

1.  **Gradient:**
    $f(x, y) = e^{x^2 + y^2}$
    $\nabla f = \begin{bmatrix} \frac{\partial f}{\partial x} \\ \frac{\partial f}{\partial y} \end{bmatrix} = \begin{bmatrix} 2xe^{x^2 + y^2} \\ 2ye^{x^2 + y^2} \end{bmatrix}$
    $\nabla f(1, 1) = \begin{bmatrix} 2e^2 \\ 2e^2 \end{bmatrix}$

2.  **Critical Point, Extremum Test:**
    $f(x) = x^4 - 4x^3 + 4x^2$
    $f'(x) = 4x^3 - 12x^2 + 8x = 4x(x-1)(x-2)$
    Critical points: $x = 0, 1, 2$

    $f''(x) = 12x^2 - 24x + 8$
    *   $f''(0) = 8 &gt; 0$: Local minimum
    *   $f''(1) = -4 &lt; 0$: Local maximum
    *   $f''(2) = 8 &gt; 0$: Local minimum

3.  **Jacobian Matrix:**
    $f(x, y) = \begin{bmatrix} x^2 + y^2 \\ 2xy \end{bmatrix}$
    $\mathbf{J} = \begin{bmatrix} \frac{\partial f_1}{\partial x} &amp; \frac{\partial f_1}{\partial y} \\ \frac{\partial f_2}{\partial x} &amp; \frac{\partial f_2}{\partial y} \end{bmatrix} = \begin{bmatrix} 2x &amp; 2y \\ 2y &amp; 2x \end{bmatrix}$

#### Advanced

1.  **Lagrange Multiplier Method:**
    $L(x, y, \lambda) = xy - \lambda(x^2 + y^2 - 1)$
    $\frac{\partial L}{\partial x} = y - 2\lambda x = 0$
    $\frac{\partial L}{\partial y} = x - 2\lambda y = 0$
    $\frac{\partial L}{\partial \lambda} = x^2 + y^2 - 1 = 0$

    *   $x = \pm \frac{1}{\sqrt{2}}$, $y = \pm \frac{1}{\sqrt{2}}$, $\lambda = \pm \frac{1}{2}$
    *   Maximum: $f(\frac{1}{\sqrt{2}}, \frac{1}{\sqrt{2}}) = f(-\frac{1}{\sqrt{2}}, -\frac{1}{\sqrt{2}}) = \frac{1}{2}$
    *   Minimum: $f(\frac{1}{\sqrt{2}}, -\frac{1}{\sqrt{2}}) = f(-\frac{1}{\sqrt{2}}, \frac{1}{\sqrt{2}}) = -\frac{1}{2}$

2.  **Gradient Descent:**

    ```python
def gradient_descent(f, df, x0, alpha, iterations):
    x = x0
    for i in range(iterations):
        x = x - alpha * df(x)
    return x</code></pre>
<p>f = lambda x: x**4 - 4*x**3 + 4*x**2 df = lambda x: 4*x**3 - 12*x**2 + 8*x</p>
<p>x_min = gradient_descent(f, df, 3, 0.01, 100) print(x_min) # approximately converges to 2</p>
<ol start="3" type="1">
<li><p><strong>Gradient (matrix form):</strong> <span class="math inline">\(f(\mathbf{x}) = \mathbf{x}^T \mathbf{A} \mathbf{x}\)</span> <span class="math inline">\(\nabla f = (\mathbf{A} + \mathbf{A}^T)\mathbf{x}\)</span>. Since <span class="math inline">\(\mathbf{A}\)</span> is a symmetric matrix, <span class="math inline">\(\nabla f = 2\mathbf{A}\mathbf{x}\)</span></p></li>
<li><p><strong>Newton’s Method:</strong> <span class="math inline">\(f(x) = x^3 - 2x - 5\)</span> <span class="math inline">\(f'(x) = 3x^2 - 2\)</span> <span class="math inline">\(x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)}\)</span></p>
<div class="sourceCode" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> newton_method(f, df, x0, iterations):</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>  x <span class="op">=</span> x0</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(iterations):</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>      x <span class="op">=</span> x <span class="op">-</span> f(x) <span class="op">/</span> df(x)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> x</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> <span class="kw">lambda</span> x: x<span class="op">**</span><span class="dv">3</span> <span class="op">-</span> <span class="dv">2</span><span class="op">*</span>x <span class="op">-</span> <span class="dv">5</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> <span class="kw">lambda</span> x: <span class="dv">3</span><span class="op">*</span>x<span class="op">**</span><span class="dv">2</span> <span class="op">-</span> <span class="dv">2</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>root <span class="op">=</span> newton_method(f, df, <span class="dv">2</span>, <span class="dv">5</span>) <span class="co"># initial value x0 = 2, 5 iterations</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(root)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ol>
</section>
</section>
</section>
</div>
</div>
</section>
</section>
</section>
<section id="practice-problems" class="level2">
<h2 class="anchored" data-anchor-id="practice-problems">Practice Problems</h2>
<section id="probability-and-statistics-1" class="level3">
<h3 class="anchored">3 Probability and Statistics</h3>
<section id="basic-2" class="level4">
<h4 class="anchored" data-anchor-id="basic-2">Basic</h4>
<ol type="1">
<li><p>Calculate the probability of getting heads twice when a coin is flipped three times.</p></li>
<li><p>Calculate the probability of getting an even number when rolling a die.</p></li>
<li><p>Write down the probability density function (PDF) of a normal distribution and explain the meaning of its mean and variance.</p></li>
</ol>
</section>
<section id="application-2" class="level4">
<h4 class="anchored" data-anchor-id="application-2">Application</h4>
<ol type="1">
<li><p>Explain Bayes’ theorem and apply it to the following problem:</p>
<ul>
<li>A certain disease has a prevalence of 1% and a diagnostic test for this disease has an accuracy (sensitivity and specificity) of 99%. What is the probability that a person actually has the disease when the test result comes out positive?</li>
</ul></li>
<li><p>Explain the concept of Maximum Likelihood Estimation (MLE) and calculate the MLE of the probability of getting heads in a coin flip, given that the coin was flipped five times and got heads three times.</p></li>
<li><p>Write down the definition of expectation and the formulas for calculating expectations of discrete and continuous random variables, respectively.</p></li>
</ol>
</section>
<section id="advanced-2" class="level4">
<h4 class="anchored">Advanced</h4>
<ol type="1">
<li><p>Write down the definition of entropy and calculate the entropy of the following probability distribution:</p>
<ul>
<li>P(X=1) = 0.5, P(X=2) = 0.25, P(X=3) = 0.25</li>
</ul></li>
<li><p>Given the joint probability distribution of two random variables X and Y as follows, calculate the mutual information I(X;Y):</p>
<pre><code>P(X=0, Y=0) = 0.1, P(X=0, Y=1) = 0.2
P(X=1, Y=0) = 0.3, P(X=1, Y=1) = 0.4</code></pre></li>
<li><p>Given two probability distributions P and Q as follows, calculate the Kullback-Leibler divergence <span class="math inline">\(D_{KL}(P||Q)\)</span>:</p>
<ul>
<li>P(X=1) = 0.6, P(X=2) = 0.4</li>
<li>Q(X=1) = 0.8, Q(X=2) = 0.2</li>
</ul></li>
<li><p>Write down the probability mass function (PMF) of a Poisson distribution and explain with an example when it is used.</p></li>
</ol>
<div class="callout callout-style-default callout-note callout-titled" title="Click to view contents (answer)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-13-contents" aria-controls="callout-13" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Click to view contents (answer)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-13" class="callout-13-contents callout-collapse collapse">
<section id="exercise-solutions" class="level2 callout-body-container callout-body">
<h2 class="anchored" data-anchor-id="exercise-solutions">Exercise Solutions</h2>
<section id="probability-and-statistics-2" class="level3">
<h3 class="anchored" data-anchor-id="probability-and-statistics-2">3 Probability and Statistics</h3>
<section id="basic-3" class="level4">
<h4 class="anchored" data-anchor-id="basic-3">Basic</h4>
<ol type="1">
<li><p><strong>Coin Tossing:</strong> Probability = (number of cases where the front appears twice in three times) * (front probability)^2 * (back probability)^1 = 3C2 * (1/2)^2 * (1/2)^1 = 3 * (1/4) * (1/2) = 3/8</p></li>
<li><p><strong>Dice Rolling:</strong> Probability = (number of cases where an even number appears) / (total number of cases) = 3 / 6 = 1/2</p></li>
<li><p><strong>Normal Distribution:</strong> <span class="math inline">\(f(x) = \frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}\)</span></p>
<ul>
<li><span class="math inline">\(\mu\)</span>: average (center of distribution)</li>
<li><span class="math inline">\(\sigma\)</span>: standard deviation (degree of dispersion of distribution)</li>
</ul></li>
</ol>
</section>
<section id="application-3" class="level4">
<h4 class="anchored" data-anchor-id="application-3">Application</h4>
<ol type="1">
<li><p><strong>Bayes’ Theorem:</strong> <span class="math inline">\(P(A|B) = \frac{P(B|A)P(A)}{P(B)}\)</span></p>
<ul>
<li><span class="math inline">\(P(A)\)</span>: probability of having a disease (prior probability) = 0.01</li>
<li><span class="math inline">\(P(B|A)\)</span>: probability that the test result is positive when the disease is present (sensitivity) = 0.99</li>
<li><span class="math inline">\(P(B|\neg A)\)</span>: probability that the test result is positive when the disease is not present (1 - specificity) = 0.01 (assuming a specificity of 0.99)</li>
<li><span class="math inline">\(P(B)\)</span>: probability of a positive test result = <span class="math inline">\(P(B|A)P(A) + P(B|\neg A)P(\neg A) = (0.99)(0.01) + (0.01)(0.99) = 0.0198\)</span></li>
</ul>
<p><span class="math inline">\(P(A|B) = \frac{(0.99)(0.01)}{0.0198} = 0.5\)</span> (50%)</p></li>
<li><p><strong>Maximum Likelihood Estimation (MLE):</strong></p></li>
</ol>
<ul>
<li>likelihood function: <span class="math inline">\(L(p) = p^3 (1-p)^2\)</span> (p is the probability of the coin landing on its front)</li>
<li>log-likelihood function: <span class="math inline">\(\log L(p) = 3\log p + 2\log(1-p)\)</span></li>
<li><span class="math inline">\(\frac{d}{dp} \log L(p) = \frac{3}{p} - \frac{2}{1-p} = 0\)</span></li>
<li><span class="math inline">\(3(1-p) - 2p = 0\)</span></li>
<li><span class="math inline">\(3 - 5p = 0\)</span></li>
<li><span class="math inline">\(p = \frac{3}{5} = 0.6\)</span></li>
</ul>
<ol start="3" type="1">
<li><strong>Expectation:</strong>
<ul>
<li><strong>Definition:</strong> weighted average of possible values of a random variable (weighted by probability)</li>
<li><span class="math inline">\(E(X) = \sum xP(x)\)</span></li>
</ul></li>
</ol>
</section>
<section id="advanced-3" class="level4">
<h4 class="anchored" data-anchor-id="advanced-3">Advanced</h4>
<ol type="1">
<li><p><strong>Entropy:</strong> <span class="math inline">\(H(P) = -\sum P(x)\log P(x)\)</span> (using base-2 logarithm) <span class="math inline">\(H(P) \approx 1.5\)</span> bits</p></li>
<li><p><strong>Mutual Information:</strong> <span class="math inline">\(I(X;Y) = \sum_{x}\sum_{y} P(x,y) \log \frac{P(x,y)}{P(x)P(y)}\)</span></p>
<ul>
<li><span class="math inline">\(P(X=0) = 0.1 + 0.2 = 0.3\)</span></li>
<li><span class="math inline">\(P(X=1) = 0.3 + 0.4 = 0.7\)</span></li>
<li><span class="math inline">\(P(Y=0) = 0.1 + 0.3 = 0.4\)</span></li>
<li><span class="math inline">\(P(Y=1) = 0.2 + 0.4 = 0.6\)</span></li>
</ul>
<p><span class="math inline">\(I(X;Y) = (0.1)\log\frac{0.1}{(0.3)(0.4)} + (0.2)\log\frac{0.2}{(0.3)(0.6)} + (0.3)\log\frac{0.3}{(0.7)(0.4)} + (0.4)\log\frac{0.4}{(0.7)(0.6)}\)</span> <span class="math inline">\(I(X;Y) \approx 0.0867\)</span> (using base-2 logarithm)</p></li>
<li><p><strong>KL Divergence:</strong> <span class="math inline">\(D_{KL}(P||Q) = \sum_{x} P(x) \log \frac{P(x)}{Q(x)}\)</span> <span class="math inline">\(D_{KL}(P||Q) = 0.6 \log \frac{0.6}{0.8} + 0.4 \log \frac{0.4}{0.2} \approx 0.083\)</span></p></li>
<li><p><strong>Poisson Distribution:</strong></p>
<ul>
<li><strong>Probability Mass Function (PMF):</strong> <span class="math inline">\(P(X=k) = \frac{\lambda^k e^{-\lambda}}{k!}\)</span> (<span class="math inline">\(k\)</span> is the number of occurrences, <span class="math inline">\(\lambda\)</span> is the average number of occurrences per unit time/space)</li>
<li><strong>Example Use Cases</strong>:
<ul>
<li>The number of calls to a call center during a certain period</li>
<li>The number of traffic accidents in a specific area</li>
<li>The number of typos in a book</li>
<li>The number of visitors to a website</li>
<li>Radioactive decay, genetic mutations</li>
</ul></li>
</ul></li>
</ol>
</section>
</section>
</section>
</div>
</div>
</section>
</section>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<section id="essential-references" class="level4">
<h4 class="anchored" data-anchor-id="essential-references">Essential References</h4>
<ol type="1">
<li><strong>Linear Algebra and Its Applications (Gilbert Strang, 4th Edition)</strong>:
<ul>
<li>This textbook covers the basic concepts and applications of linear algebra. It clearly explains the core content necessary for deep learning.</li>
<li><a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/">Gilbert Strang’s Linear Algebra Course (MIT OCW)</a></li>
</ul></li>
<li><strong>Calculus (James Stewart, 8th Edition)</strong>:
<ul>
<li>This textbook provides a detailed explanation of the fundamental principles of calculus. It offers background knowledge necessary for understanding optimization algorithms in deep learning.</li>
</ul></li>
<li><strong>Probability and Statistics for Engineering and the Sciences (Jay L. Devore, 9th Edition)</strong>:
<ul>
<li>This textbook explains basic probability and statistics concepts along with engineering applications. It helps with understanding probabilistic modeling and uncertainty inference in deep learning.</li>
</ul></li>
<li><strong>Pattern Recognition and Machine Learning (Christopher Bishop)</strong>:
<ul>
<li>This is a classic textbook on pattern recognition and machine learning. It covers theoretical backgrounds of deep learning, including probabilistic modeling, Bayesian inference, and information theory, in depth.</li>
</ul></li>
<li><strong>The Elements of Statistical Learning (Trevor Hastie, Robert Tibshirani, Jerome Friedman)</strong>:
<ul>
<li>This textbook clearly explains core concepts of statistical learning theory. It is useful for understanding the generalization performance and overfitting issues of deep learning models.</li>
<li><a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://hastie.su.domains/ElemStatLearn/">The Elements of Statistical Learning (Free PDF)</a></li>
</ul></li>
<li><strong>Deep Learning (Ian Goodfellow, Yoshua Bengio, Aaron Courville)</strong>:
<ul>
<li>This textbook comprehensively covers the basic concepts and latest technologies of deep learning. It briefly introduces the mathematical foundations necessary for deep learning.</li>
<li><a href="https://www.deeplearningbook.org/">Deep Learning Book (Free PDF)</a></li>
</ul></li>
<li><strong>Understanding Machine Learning: From Theory to Algorithms (Shai Shalev-Shwartz, Shai Ben-David)</strong>:
<ul>
<li>This textbook provides a solid foundation for the theoretical aspects of machine learning. It explains important concepts such as PAC learning theory, VC dimension, and bias-variance tradeoff that are crucial for understanding the generalization performance of deep learning models.</li>
</ul></li>
<li><strong>Information Theory, Inference, and Learning Algorithms (David J.C. MacKay)</strong>:
<ul>
<li>This textbook explains the principles of machine learning centered around information theory and Bayesian inference. It helps with understanding probabilistic interpretations and generative models in deep learning.</li>
<li><a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=http://www.inference.org.uk/itprnn/book.pdf">Information Theory, Inference, and Learning Algorithms (Free PDF)</a></li>
</ul></li>
<li><strong>Mathematics for Machine Learning (Marc Peter Deisenroth, A. Aldo Faisal, and Cheng Soon Ong)</strong>
<ul>
<li>This textbook broadly covers the mathematical background knowledge necessary for machine learning.</li>
</ul></li>
<li><strong>Matrix Computations (Gene H. Golub, Charles F. Van Loan, 4th Edition)</strong>:
<ul>
<li>This textbook provides an in-depth treatment of numerical methods related to matrix computations. It offers knowledge necessary for implementing and improving optimization algorithms in deep learning.</li>
</ul></li>
<li><strong>Linear Algebra and Its Applications (Gilbert Strang, 4th Edition)</strong>:
<ul>
<li>This textbook covers the basic concepts and applications of linear algebra, clearly explaining the core content necessary for deep learning. - <a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/">Gilbert Strang’s Linear Algebra Course (MIT OCW)</a></li>
</ul></li>
<li><strong>Calculus (James Stewart, 8th Edition)</strong>:
<ul>
<li>This textbook provides a detailed explanation of the basic principles of calculus, offering background knowledge necessary for understanding optimization algorithms in deep learning.</li>
</ul></li>
<li><strong>Probability and Statistics for Engineering and the Sciences (Jay L. Devore, 9th Edition)</strong>:
<ul>
<li>This textbook explains the basic concepts of probability and statistics along with their engineering applications, helping to understand probabilistic modeling and uncertainty inference in deep learning.</li>
</ul></li>
<li><strong>Pattern Recognition and Machine Learning (Christopher Bishop)</strong>:
<ul>
<li>This is a classic textbook on pattern recognition and machine learning, covering the theoretical background of deep learning, including probabilistic modeling, Bayesian inference, and information theory.</li>
</ul></li>
<li><strong>The Elements of Statistical Learning (Trevor Hastie, Robert Tibshirani, Jerome Friedman)</strong>:
<ul>
<li>This textbook clearly explains the core concepts of statistical learning theory, which is useful for understanding the generalization performance and overfitting issues of deep learning models. - <a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://hastie.su.domains/ElemStatLearn/">The Elements of Statistical Learning (Free PDF)</a></li>
</ul></li>
<li><strong>Deep Learning (Ian Goodfellow, Yoshua Bengio, Aaron Courville)</strong>:
<ul>
<li>This textbook comprehensively covers the basic concepts and latest technologies of deep learning, briefly introducing the necessary mathematical foundations. - <a href="https://www.deeplearningbook.org/">Deep Learning Book (Free PDF)</a></li>
</ul></li>
<li><strong>Understanding Machine Learning: From Theory to Algorithms (Shai Shalev-Shwartz, Shai Ben-David)</strong>:
<ul>
<li>This textbook provides a solid foundation for the theoretical aspects of machine learning, explaining important concepts such as PAC learning theory, VC dimension, and bias-variance tradeoff that are crucial for understanding the generalization performance of deep learning models.</li>
</ul></li>
<li><strong>Information Theory, Inference, and Learning Algorithms (David J.C. MacKay)</strong>:
<ul>
<li>This textbook explains the principles of machine learning centered around information theory and Bayesian inference, helping to understand probabilistic interpretations and generative models in deep learning. - <a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=http://www.inference.org.uk/itprnn/book.pdf">Information Theory, Inference, and Learning Algorithms (Free PDF)</a></li>
</ul></li>
<li><strong>Mathematics for Machine Learning (Marc Peter Deisenroth, A. Aldo Faisal, and Cheng Soon Ong)</strong>
<ul>
<li>This textbook broadly covers the mathematical background knowledge necessary for machine learning. Matrix Computations (Gene H. Golub, Charles F. Van Loan, 4th Edition): - A textbook that deals in depth with numerical methods related to matrix operations. It provides the knowledge necessary for implementing optimization algorithms and improving performance in deep learning.</li>
</ul></li>
</ol>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>