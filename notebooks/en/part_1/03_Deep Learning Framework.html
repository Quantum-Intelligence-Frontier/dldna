<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>deep-learning-framework – Deep Learning DNA: Surviving Architectures and Essential Principles</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-f507c7d0488cb7630e20aad62ad8c2aa.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>
<script>window.MathJax = {loader: {load: ['[tex]/boldsymbol']},tex: {packages: {'[+]': ['boldsymbol']}}};</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../notebooks/en/part_1/01_The Beginning of Deep Learning.html">part_1</a></li><li class="breadcrumb-item"><a href="../../../notebooks/en/part_1/03_Deep Learning Framework.html">3. Deep Learning Framework</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../../">English</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Language</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index_de.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Deutsch</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index_en.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">English</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index_es.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Español</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">한국어</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index_zh.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">中文</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/en/part_1/00_Introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">part_1</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/en/part_1/01_The Beginning of Deep Learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1. The Beginning of Deep Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/en/part_1/02_Mathematics of Deep Learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2. Mathematics of Deep Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/en/part_1/03_Deep Learning Framework.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">3. Deep Learning Framework</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/en/part_1/04_Activation Function.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4. Activation Function</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/en/part_1/05_Optimization and Visualization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5. Optimization and Visualization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/en/part_1/06_Overfitting and Development of Solution Techniques.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">6. Overfitting and Development of Solution Techniques</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/en/part_1/07_Evolution of Convolutional Neural Networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">7. Evolution of Convolutional Neural Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/en/part_1/08_The Birth of Transformer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8. The Birth of Transformer</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/en/part_1/09_The Evolution of Transformers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">9. The Evolution of Transformers</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/en/part_1/10_Multimodal Deep Learning: The Beginning of Multisensory Convergence.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">10. Multimodal Deep Learning: The Beginning of Multisensory Convergence</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/en/part_1/11_Multimodal Deep Learning: Intelligence Beyond Limits.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">11. Multimodal Deep Learning: Intelligence Beyond Limits</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Deep Learning Frontier</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/en/Deep Learning Frontier/01_SLM: Small but Powerful Language Model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1. SLM: Small but Powerful Language Model</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/en/Deep Learning Frontier/02_Autonomous Driving.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2. Autonomous Driving</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#deep-learning-frameworks" id="toc-deep-learning-frameworks" class="nav-link active" data-scroll-target="#deep-learning-frameworks">3. Deep Learning Frameworks</a>
  <ul class="collapse">
  <li><a href="#pytorch" id="toc-pytorch" class="nav-link" data-scroll-target="#pytorch">3.1 PyTorch</a>
  <ul class="collapse">
  <li><a href="#tensor-objects" id="toc-tensor-objects" class="nav-link" data-scroll-target="#tensor-objects">3.1.1 Tensor Objects</a></li>
  <li><a href="#operation" id="toc-operation" class="nav-link" data-scroll-target="#operation">3.1.2 Operation</a></li>
  <li><a href="#computational-graph-for-gradient-operations" id="toc-computational-graph-for-gradient-operations" class="nav-link" data-scroll-target="#computational-graph-for-gradient-operations">3.1.3 Computational Graph for Gradient Operations</a></li>
  <li><a href="#data-loading" id="toc-data-loading" class="nav-link" data-scroll-target="#data-loading">3.1.4 Data Loading</a></li>
  <li><a href="#data-transform" id="toc-data-transform" class="nav-link" data-scroll-target="#data-transform">3.1.5 Data Transform</a></li>
  <li><a href="#model" id="toc-model" class="nav-link" data-scroll-target="#model">3.1.6 Model</a></li>
  <li><a href="#training" id="toc-training" class="nav-link" data-scroll-target="#training">3.1.7 Training</a></li>
  <li><a href="#model-saving-and-loading" id="toc-model-saving-and-loading" class="nav-link" data-scroll-target="#model-saving-and-loading">3.1.8 Model Saving and Loading</a></li>
  </ul></li>
  <li><a href="#tensorboard" id="toc-tensorboard" class="nav-link" data-scroll-target="#tensorboard">3.2 TensorBoard</a>
  <ul class="collapse">
  <li><a href="#basic-usage-of-tensorboard" id="toc-basic-usage-of-tensorboard" class="nav-link" data-scroll-target="#basic-usage-of-tensorboard">3.2.1 Basic Usage of TensorBoard</a></li>
  <li><a href="#tensorboards-major-visualization-features" id="toc-tensorboards-major-visualization-features" class="nav-link" data-scroll-target="#tensorboards-major-visualization-features">3.2.2 TensorBoard’s Major Visualization Features</a></li>
  <li><a href="#tensorboard-example" id="toc-tensorboard-example" class="nav-link" data-scroll-target="#tensorboard-example">3.2.3 TensorBoard Example</a></li>
  </ul></li>
  <li><a href="#hugging-face-transformers" id="toc-hugging-face-transformers" class="nav-link" data-scroll-target="#hugging-face-transformers">3.3 Hugging Face Transformers</a>
  <ul class="collapse">
  <li><a href="#introduction-to-the-transformers-library" id="toc-introduction-to-the-transformers-library" class="nav-link" data-scroll-target="#introduction-to-the-transformers-library">3.3.1 Introduction to the Transformers Library</a></li>
  <li><a href="#key-use-cases" id="toc-key-use-cases" class="nav-link" data-scroll-target="#key-use-cases">3.3.2 Key Use Cases</a></li>
  </ul></li>
  <li><a href="#practice-problems" id="toc-practice-problems" class="nav-link" data-scroll-target="#practice-problems">Practice Problems</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../notebooks/en/part_1/01_The Beginning of Deep Learning.html">part_1</a></li><li class="breadcrumb-item"><a href="../../../notebooks/en/part_1/03_Deep Learning Framework.html">3. Deep Learning Framework</a></li></ol></nav></header>




<p><a href="https://colab.research.google.com/github/Quantum-Intelligence-Frontier/dldna/blob/main/notebooks/en/part_1/03_DeepLearningFramework.ipynb" target="_parent"> <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"> </a></p>
<section id="deep-learning-frameworks" class="level1">
<h1>3. Deep Learning Frameworks</h1>
<blockquote class="blockquote">
<p>“A tool is only as good as the person using it.” - <em>Anonymous, often attributed to John von Neumann</em></p>
</blockquote>
<p>The development of frameworks in the history of deep learning has been crucial. After AlexNet’s success in 2012, various frameworks emerged. Through Caffe, Theano, Torch7, and now PyTorch and TensorFlow have become mainstream.</p>
<p>In the early 2010s, deep learning began to show remarkable results in areas such as image recognition and speech recognition, surpassing existing technologies. However, training and deploying deep learning models was still a difficult task. This was because one had to implement neural network configurations, gradient calculations, GPU acceleration, and more directly. Such complexity raised the barrier to entry for deep learning research and slowed down the pace of research. To solve these problems, deep learning frameworks emerged. Deep learning frameworks provided high-level APIs and tools for building, training, and deploying neural network models, simplifying and accelerating the development process. Initially, frameworks like Theano, Caffe, and Torch appeared and were widely used in academia and industry.</p>
<p>In 2015, Google released TensorFlow as an open source, bringing significant changes to the deep learning framework ecosystem. TensorFlow quickly gained popularity due to its flexible architecture, powerful visualization tools, and support for large-scale distributed learning. In 2017, Facebook released PyTorch, setting another important milestone. PyTorch provided dynamic computation graphs, intuitive interfaces, and excellent debugging capabilities, rapidly spreading among researchers.</p>
<p>Currently, deep learning frameworks have established themselves as core infrastructure for deep learning research and development, beyond simple tools. They provide key features such as automatic differentiation, GPU acceleration, model parallelization, and distributed learning, accelerating the development of new models and algorithms. Additionally, competition and cooperation between frameworks are further advancing the deep learning ecosystem.</p>
<section id="pytorch" class="level2">
<h2 class="anchored" data-anchor-id="pytorch">3.1 PyTorch</h2>
<p>PyTorch is an open-source machine learning framework based on the Torch library, used for applications such as computer vision and natural language processing. It was developed in 2016 by Facebook’s AI Research lab (FAIR) as a reimplementation of Torch7 in Python. Thanks to its dynamic computation graphs and intuitive debugging features, PyTorch quickly gained popularity among researchers. Besides PyTorch, other frameworks like TensorFlow, JAX, and Caffe exist, but PyTorch has become the de facto standard in research. Many new models are often released with PyTorch implementations.</p>
<p>After becoming proficient in one framework, leveraging the strengths of another can be a good strategy. For example, you can use TensorFlow’s data preprocessing pipelines or JAX’s functional transformation capabilities alongside PyTorch.</p>
<div id="cell-2" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install dldna[colab] <span class="co"># in Colab</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip install dldna[all] # in your local</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="cell-3" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Print PyTorch version</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"PyTorch version: </span><span class="sc">{</span>torch<span class="sc">.</span>__version__<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the random seed for reproducibility</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">7</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>PyTorch version: 2.6.0+cu124</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="1">
<pre><code>&lt;torch._C.Generator at 0x7352f02b33f0&gt;</code></pre>
</div>
</div>
<p>When generating random numbers, setting the initial seed value allows you to get the same random number every time. This is commonly used in research to ensure consistent results in repetitive training.</p>
<section id="tensor-objects" class="level3">
<h3 class="anchored" data-anchor-id="tensor-objects">3.1.1 Tensor Objects</h3>
<blockquote class="blockquote">
<p><strong>Challenge</strong>: How can large-scale matrix operations be performed efficiently using a GPU?</p>
<p><strong>Researcher’s Concern</strong>: As deep learning models grew in size, it took too much time to train and infer using only the CPU. While GPUs were suitable for deep learning due to their specialization in parallel computing, GPU programming was complex and difficult. A tool was needed to abstract and automate GPU operations so that deep learning researchers could easily utilize GPUs.</p>
</blockquote>
<p>Tensors are the basic data structure in PyTorch. Since the introduction of CUDA in 2006, GPU operations have become central to deep learning, and tensors were designed to perform these operations efficiently. Tensors are multi-dimensional arrays that generalize scalars, vectors, and matrices. In deep learning, the dimensionality of data (tensor rank) is highly varied. For example, images are represented as 4D tensors (batch, channel, height, width), while natural language is represented as 3D tensors (batch, sequence length, embedding dimension). As seen in Chapter 2, it is crucial to freely transform and process these dimensions.</p>
<p>Tensors can be declared as follows:</p>
<div id="cell-6" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a 3x2x4 tensor with random values</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.Tensor(<span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">4</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[[ 1.1210e-44,  0.0000e+00,  0.0000e+00,  4.1369e-41],
         [ 1.8796e-17,  0.0000e+00,  2.8026e-45,  0.0000e+00]],

        [[ 0.0000e+00,  0.0000e+00,         nan,         nan],
         [ 6.3058e-44,  4.7424e+30,  1.4013e-45,  1.3563e-19]],

        [[ 1.0089e-43,  0.0000e+00,  1.1210e-44,  0.0000e+00],
         [-8.8105e+09,  4.1369e-41,  1.8796e-17,  0.0000e+00]]])</code></pre>
</div>
</div>
<p>Tensors can also be initialized from existing data.</p>
<div id="cell-8" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># From a Python list</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> [[<span class="dv">1</span>, <span class="dv">2</span>], [<span class="dv">3</span>, <span class="dv">4</span>]]</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Type of d: </span><span class="sc">{</span><span class="bu">type</span>(d)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.Tensor(d)  <span class="co"># Creates a *copy*</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Tensor a:</span><span class="ch">\n</span><span class="sc">{</span>a<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Type of a: </span><span class="sc">{</span><span class="bu">type</span>(a)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="co"># From a NumPy array</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>d_np <span class="op">=</span> np.array(d)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Type of d_np: </span><span class="sc">{</span><span class="bu">type</span>(d_np)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.from_numpy(d_np) <span class="co"># Shares memory with d_np (zero-copy)</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Tensor b (from_numpy):</span><span class="ch">\n</span><span class="sc">{</span>b<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> torch.Tensor(d_np)  <span class="co"># Creates a *copy*</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Tensor c (from np array using torch.Tensor):</span><span class="ch">\n</span><span class="sc">{</span>c<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Example of memory sharing with torch.from_numpy</span></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>d_np[<span class="dv">0</span>, <span class="dv">0</span>] <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Modified d_np:</span><span class="ch">\n</span><span class="sc">{</span>d_np<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Tensor b (from_numpy) after modifying d_np:</span><span class="ch">\n</span><span class="sc">{</span>b<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Tensor c (copy) after modifying d_np:</span><span class="ch">\n</span><span class="sc">{</span>c<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Type of d: &lt;class 'list'&gt;
Tensor a:
tensor([[1., 2.],
        [3., 4.]])
Type of a: &lt;class 'torch.Tensor'&gt;
Type of d_np: &lt;class 'numpy.ndarray'&gt;
Tensor b (from_numpy):
tensor([[1, 2],
        [3, 4]])
Tensor c (from np array using torch.Tensor):
tensor([[1., 2.],
        [3., 4.]])
Modified d_np:
[[100   2]
 [  3   4]]
Tensor b (from_numpy) after modifying d_np:
tensor([[100,   2],
        [  3,   4]])
Tensor c (copy) after modifying d_np:
tensor([[1., 2.],
        [3., 4.]])</code></pre>
</div>
</div>
<p>Just because they look the same when outputted does not mean they are the same object. <code>d</code> is a Python list object, and tensors can be created from various data structures. In particular, interactions with NumPy arrays are very efficient. However, since list objects and NumPy arrays do not support GPUs, conversion to tensors is essential for large operations. The <em>important</em> point is to understand the difference between <code>torch.Tensor(data)</code> and <code>torch.from_numpy(data)</code>. The former always creates a copy, while the latter creates a <em>view</em> that shares memory with the original NumPy array (if possible - zero-copy). If you modify the NumPy array, the tensor created by <code>from_numpy</code> will also change, and vice versa.</p>
<p>There are many ways to initialize tensors. Since Hinton’s 2006 paper, the importance of initialization methods has been highlighted, and various initialization strategies have been developed. The most basic initialization functions are as follows.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>Function</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>torch.zeros</code></td>
<td>Initializes with 0.</td>
</tr>
<tr class="even">
<td><code>torch.ones</code></td>
<td>Initializes with 1.</td>
</tr>
<tr class="odd">
<td><code>torch.rand</code></td>
<td>Initializes with random numbers from a uniform distribution between 0 and 1.</td>
</tr>
<tr class="even">
<td><code>torch.randn</code></td>
<td>Initializes with random numbers from a standard normal distribution (mean 0, variance 1).</td>
</tr>
<tr class="odd">
<td><code>torch.arange</code></td>
<td>Initializes sequentially, such as n, n+1, n+2, … .</td>
</tr>
</tbody>
</table>
<div id="cell-10" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>shape <span class="op">=</span> (<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>rand_t <span class="op">=</span> torch.rand(shape)     <span class="co"># Uniform distribution [0, 1)</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>randn_t <span class="op">=</span> torch.randn(shape)   <span class="co"># Standard normal distribution</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>ones_t <span class="op">=</span> torch.ones(shape)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>zeros_t <span class="op">=</span> torch.zeros(shape)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Random tensor (uniform):</span><span class="ch">\n</span><span class="sc">{</span>rand_t<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Random tensor (normal):</span><span class="ch">\n</span><span class="sc">{</span>randn_t<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Ones tensor:</span><span class="ch">\n</span><span class="sc">{</span>ones_t<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Zeros tensor:</span><span class="ch">\n</span><span class="sc">{</span>zeros_t<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Random tensor (uniform):
tensor([[0.5349, 0.1988, 0.6592],
        [0.6569, 0.2328, 0.4251]])
Random tensor (normal):
tensor([[-1.2514, -1.8841,  0.4457],
        [-0.7068, -1.5750, -0.6318]])
Ones tensor:
tensor([[1., 1., 1.],
        [1., 1., 1.]])
Zeros tensor:
tensor([[0., 0., 0.],
        [0., 0., 0.]])</code></pre>
</div>
</div>
<p>PyTorch supports over 100 tensor operations, all of which can be run on the GPU. Tensors are created on the CPU by default, so to use the GPU, you must explicitly move them using the <code>to()</code> function. Moving large tensors across CPU and GPU is costly, so careful memory management is essential. In real deep learning training, the memory bandwidth of the GPU has a decisive impact on performance. For example, when training transformer models, the larger the GPU memory, the larger the batch size that can be used, which increases training efficiency. However, high-bandwidth memory is very expensive to produce and accounts for a significant portion of the cost of GPUs. The performance difference between CPU and GPU tensor operations is particularly noticeable in operations that can be parallelized, such as matrix multiplication. For this reason, dedicated accelerators like GPUs, TPUs, and NPUs are essential in modern deep learning.</p>
<div id="cell-12" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Device setting</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> torch.cuda.is_available():</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    tensor <span class="op">=</span> zeros_t.to(<span class="st">"cuda"</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> <span class="st">"cuda:0"</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> <span class="st">"cpu"</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'GPU not available'</span>)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="co"># CPU/GPU performance comparison</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a><span class="co"># CPU operation</span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.rand(<span class="dv">10000</span>, <span class="dv">10000</span>)</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time.time()</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>torch.matmul(x, x)</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>cpu_time <span class="op">=</span> time.time() <span class="op">-</span> start</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"CPU computation time = </span><span class="sc">{</span>cpu_time<span class="sc">:3.2f}</span><span class="ss"> seconds"</span>)</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a><span class="co"># GPU operation</span></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> device <span class="op">!=</span> <span class="st">"cpu"</span>:</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> x.to(device)</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>    start <span class="op">=</span> torch.cuda.Event(enable_timing<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>    end <span class="op">=</span> torch.cuda.Event(enable_timing<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>    start.record()</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>    torch.matmul(x, x)</span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>    end.record()</span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>    torch.cuda.synchronize()  <span class="co"># Wait for all operations to complete</span></span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>    gpu_time <span class="op">=</span> start.elapsed_time(end) <span class="op">/</span> <span class="dv">1000</span>  <span class="co"># Convert milliseconds to seconds</span></span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"GPU computation time = </span><span class="sc">{</span>gpu_time<span class="sc">:3.2f}</span><span class="ss"> seconds"</span>)</span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"GPU is </span><span class="sc">{</span>cpu_time <span class="op">/</span> gpu_time<span class="sc">:3.1f}</span><span class="ss"> times faster."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>CPU computation time = 2.34 seconds
GPU computation time = 0.14 seconds
GPU is 16.2 times faster.</code></pre>
</div>
</div>
<p>The conversion between NumPy and tensors is implemented very efficiently, especially as seen above, using <code>torch.from_numpy()</code>, memory is shared without memory copy.</p>
<div id="cell-14" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>np_a <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">1</span>], [<span class="dv">2</span>, <span class="dv">3</span>]])</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>tensor_a <span class="op">=</span> torch.from_numpy(np_a)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>np_b <span class="op">=</span> tensor_a.numpy() <span class="co"># Shares memory.  If tensor_a is on CPU.</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"NumPy array: </span><span class="sc">{</span>np_a<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Tensor: </span><span class="sc">{</span>tensor_a<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"NumPy array from Tensor: </span><span class="sc">{</span>np_b<span class="sc">}</span><span class="ss">"</span>) <span class="co">#if tensor_a is on CPU.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>NumPy array: [[1 1]
 [2 3]]
Tensor: tensor([[1, 1],
        [2, 3]])
NumPy array from Tensor: [[1 1]
 [2 3]]</code></pre>
</div>
</div>
<p>When converting a tensor to NumPy, the tensor must be on the CPU. Tensors on the GPU must first be moved to the CPU using <code>.cpu()</code>. The basic properties of a tensor are <code>shape</code>, <code>dtype</code>, <code>device</code>, which can be used to check the shape and storage location of the tensor.</p>
<div id="cell-16" class="cell" data-execution_count="18">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.rand(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Shape = </span><span class="sc">{</span>a<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Data type = </span><span class="sc">{</span>a<span class="sc">.</span>dtype<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Device = </span><span class="sc">{</span>a<span class="sc">.</span>device<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Shape = torch.Size([2, 3])
Data type = torch.float32
Device = cpu</code></pre>
</div>
</div>
<p>Indexing and slicing use the same syntax as NumPy.</p>
<div id="cell-18" class="cell" data-execution_count="19">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.rand(<span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Tensor a:</span><span class="ch">\n</span><span class="sc">{</span>a<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"First row: </span><span class="sc">{</span>a[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"First column: </span><span class="sc">{</span>a[:, <span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Last column: </span><span class="sc">{</span>a[..., <span class="op">-</span><span class="dv">1</span>]<span class="sc">}</span><span class="ss">"</span>)  <span class="co"># Equivalent to a[:, -1]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Tensor a:
tensor([[0.2069, 0.8296, 0.4973],
        [0.9265, 0.8386, 0.6611],
        [0.5329, 0.7822, 0.0975]])
First row: tensor([0.2069, 0.8296, 0.4973])
First column: tensor([0.2069, 0.9265, 0.5329])
Last column: tensor([0.4973, 0.6611, 0.0975])</code></pre>
</div>
</div>
</section>
<section id="operation" class="level3">
<h3 class="anchored">3.1.2 Operation</h3>
<p>PyTorch supports almost all operations of NumPy. The tradition of multidimensional array operations that started from the APL language in 1964 has been passed down to PyTorch through NumPy. You can check the list of all supported operations on the official PyTorch documentation (<a href="https://pytorch.org/docs/stable/tensors.html">PyTorch documentation</a>).</p>
<p>Changing the shape of a tensor is one of the most frequently used operations in neural networks. The <code>view()</code> function can change the dimension of a tensor, and at this time, the total number of elements must be maintained. The <code>permute()</code> function rearranges the order of dimensions.</p>
<div id="cell-20" class="cell" data-execution_count="20">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.arange(<span class="dv">12</span>)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"a: </span><span class="sc">{</span>a<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> a.view(<span class="dv">3</span>, <span class="dv">4</span>)  <span class="co"># Reshape to 3x4</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"x: </span><span class="sc">{</span>x<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> x.permute(<span class="dv">1</span>, <span class="dv">0</span>)  <span class="co"># Swap dimensions 0 and 1</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"y: </span><span class="sc">{</span>y<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.randn(<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">5</span>)</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"b shape: </span><span class="sc">{</span>b<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> b.permute(<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>)  <span class="co"># Change dimension order to (2, 0, 1)</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"z shape: </span><span class="sc">{</span>z<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>a: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])
x: tensor([[ 0,  1,  2,  3],
        [ 4,  5,  6,  7],
        [ 8,  9, 10, 11]])
y: tensor([[ 0,  4,  8],
        [ 1,  5,  9],
        [ 2,  6, 10],
        [ 3,  7, 11]])
b shape: torch.Size([2, 3, 5])
z shape: torch.Size([5, 2, 3])</code></pre>
</div>
</div>
<p>Matrix operations are the core of deep learning, and PyTorch provides various matrix operation functions.</p>
<ol type="1">
<li><code>torch.matmul</code>: Performs general matrix operations, which behave as follows depending on the dimensions:
<ul>
<li>1D × 1D: dot product</li>
<li>2D × 2D: matrix product</li>
<li>1D × 2D: matrix product after adding a dimension of size one to the first tensor</li>
<li>N-D × M-D: matrix product after broadcasting</li>
</ul></li>
<li><code>torch.mm</code>: Pure matrix multiplication operation (no broadcasting support)</li>
<li><code>torch.bmm</code>: Batch matrix multiplication ((b, i, k) × (b, k, j) → (b, i, j))</li>
<li><code>torch.einsum</code>: Tensor operations using Einstein summation notation, allowing for concise expression of complex tensor operations. (See “Theory Deep Dive” for details)
<ul>
<li><code>torch.einsum('ij,jk-&gt;ik', a, b)</code>: Product of matrices a and b</li>
</ul></li>
</ol>
<div id="cell-22" class="cell" data-execution_count="21">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.arange(<span class="dv">6</span>)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.arange(<span class="dv">12</span>)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> a.view(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> b.view(<span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"X: </span><span class="sc">{</span>X<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Y: </span><span class="sc">{</span>Y<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="co"># matmul (2,3) X (3,4) -&gt; (2, 4)</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"X @ Y = </span><span class="sc">{</span>torch<span class="sc">.</span>matmul(X, Y)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Using torch.einsum for matrix multiplication</span></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>einsum_result <span class="op">=</span> torch.einsum(<span class="st">'ij,jk-&gt;ik'</span>, X, Y)</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"X @ Y (using einsum) = </span><span class="sc">{</span>einsum_result<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.arange(<span class="dv">2</span>)</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.arange(<span class="dv">2</span>)</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"a: </span><span class="sc">{</span>a<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"b: </span><span class="sc">{</span>b<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Vector x Vector operation</span></span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"a @ b = </span><span class="sc">{</span>torch<span class="sc">.</span>matmul(a, b)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a><span class="co"># 1D tensor (vector), 2D tensor (matrix) operation</span></span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a><span class="co"># (2) x (2,2) is treated as (1,2) x (2,2) for matrix multiplication.</span></span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Result: (1,2) x (2,2) -&gt; (1,2)</span></span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.arange(<span class="dv">4</span>)</span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a>B <span class="op">=</span> b.view(<span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"a: </span><span class="sc">{</span>a<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"B: </span><span class="sc">{</span>B<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"a @ B = </span><span class="sc">{</span>torch<span class="sc">.</span>matmul(a, B)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Matrix x Vector operation</span></span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.randn(<span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb21-36"><a href="#cb21-36" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.randn(<span class="dv">4</span>)</span>
<span id="cb21-37"><a href="#cb21-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"X @ b shape = </span><span class="sc">{</span>torch<span class="sc">.</span>matmul(X, b)<span class="sc">.</span>size()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-38"><a href="#cb21-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-39"><a href="#cb21-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Batched matrix x Batched matrix</span></span>
<span id="cb21-40"><a href="#cb21-40" aria-hidden="true" tabindex="-1"></a><span class="co"># The leading batch dimension is maintained.</span></span>
<span id="cb21-41"><a href="#cb21-41" aria-hidden="true" tabindex="-1"></a><span class="co"># The 2nd and 3rd dimensions are treated as matrices for multiplication.</span></span>
<span id="cb21-42"><a href="#cb21-42" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.arange(<span class="dv">18</span>).view(<span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb21-43"><a href="#cb21-43" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> torch.arange(<span class="dv">18</span>).view(<span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">2</span>)</span>
<span id="cb21-44"><a href="#cb21-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"X: </span><span class="sc">{</span>X<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-45"><a href="#cb21-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Y: </span><span class="sc">{</span>Y<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-46"><a href="#cb21-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Batch dimension remains the same, and (2,3)x(3,2) -&gt; (2,2)</span></span>
<span id="cb21-47"><a href="#cb21-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"X @ Y shape: </span><span class="sc">{</span>torch<span class="sc">.</span>matmul(X, Y)<span class="sc">.</span>size()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-48"><a href="#cb21-48" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"X @ Y: </span><span class="sc">{</span>torch<span class="sc">.</span>matmul(X, Y)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-49"><a href="#cb21-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-50"><a href="#cb21-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Batched matrix x Broadcasted matrix</span></span>
<span id="cb21-51"><a href="#cb21-51" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.arange(<span class="dv">18</span>).view(<span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb21-52"><a href="#cb21-52" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> torch.arange(<span class="dv">6</span>).view(<span class="dv">3</span>, <span class="dv">2</span>)</span>
<span id="cb21-53"><a href="#cb21-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"X: </span><span class="sc">{</span>X<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-54"><a href="#cb21-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Y: </span><span class="sc">{</span>Y<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-55"><a href="#cb21-55" aria-hidden="true" tabindex="-1"></a><span class="co"># The second matrix lacks a batch dimension.</span></span>
<span id="cb21-56"><a href="#cb21-56" aria-hidden="true" tabindex="-1"></a><span class="co"># It's broadcasted to match the batch dimension of the first matrix (repeated 3 times).</span></span>
<span id="cb21-57"><a href="#cb21-57" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"X @ Y shape: </span><span class="sc">{</span>torch<span class="sc">.</span>matmul(X, Y)<span class="sc">.</span>size()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-58"><a href="#cb21-58" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"X @ Y: </span><span class="sc">{</span>torch<span class="sc">.</span>matmul(X, Y)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-59"><a href="#cb21-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-60"><a href="#cb21-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-61"><a href="#cb21-61" aria-hidden="true" tabindex="-1"></a><span class="co"># Using torch.einsum for matrix multiplication</span></span>
<span id="cb21-62"><a href="#cb21-62" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.arange(<span class="dv">6</span>).view(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb21-63"><a href="#cb21-63" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> torch.arange(<span class="dv">12</span>).view(<span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb21-64"><a href="#cb21-64" aria-hidden="true" tabindex="-1"></a>einsum_result <span class="op">=</span> torch.einsum(<span class="st">'ij,jk-&gt;ik'</span>, X, Y)  <span class="co"># Equivalent to torch.matmul(X, Y)</span></span>
<span id="cb21-65"><a href="#cb21-65" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"X @ Y (using einsum) = </span><span class="sc">{</span>einsum_result<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>X: tensor([[0, 1, 2],
        [3, 4, 5]])
Y: tensor([[ 0,  1,  2,  3],
        [ 4,  5,  6,  7],
        [ 8,  9, 10, 11]])
X @ Y = tensor([[20, 23, 26, 29],
        [56, 68, 80, 92]])
X @ Y (using einsum) = tensor([[20, 23, 26, 29],
        [56, 68, 80, 92]])
a: tensor([0, 1])
b: tensor([0, 1])
a @ b = 1
a: tensor([0, 1])
B: tensor([[0, 1],
        [2, 3]])
a @ B = tensor([2, 3])
X @ b shape = torch.Size([3])
X: tensor([[[ 0,  1,  2],
         [ 3,  4,  5]],

        [[ 6,  7,  8],
         [ 9, 10, 11]],

        [[12, 13, 14],
         [15, 16, 17]]])
Y: tensor([[[ 0,  1],
         [ 2,  3],
         [ 4,  5]],

        [[ 6,  7],
         [ 8,  9],
         [10, 11]],

        [[12, 13],
         [14, 15],
         [16, 17]]])
X @ Y shape: torch.Size([3, 2, 2])
X @ Y: tensor([[[ 10,  13],
         [ 28,  40]],

        [[172, 193],
         [244, 274]],

        [[550, 589],
         [676, 724]]])
X: tensor([[[ 0,  1,  2],
         [ 3,  4,  5]],

        [[ 6,  7,  8],
         [ 9, 10, 11]],

        [[12, 13, 14],
         [15, 16, 17]]])
Y: tensor([[0, 1],
        [2, 3],
        [4, 5]])
X @ Y shape: torch.Size([3, 2, 2])
X @ Y: tensor([[[ 10,  13],
         [ 28,  40]],

        [[ 46,  67],
         [ 64,  94]],

        [[ 82, 121],
         [100, 148]]])
X @ Y (using einsum) = tensor([[20, 23, 26, 29],
        [56, 68, 80, 92]])</code></pre>
</div>
</div>
<p>torch.einsum uses Einstein notation to express tensor operations. <code>'ij,jk-&gt;ik'</code> means multiply the <code>(i, j)</code> dimensions of <code>X</code> tensor and <code>(j, k)</code> dimensions of <code>Y</code> tensor to produce <code>(i, k)</code> dimensional result. This is equivalent to matrix multiplication <code>torch.matmul(X, Y)</code>. einsum also supports various operations such as transpose, sum, inner product, outer product, batch matrix multiplication, etc. For more details, please refer to the PyTorch documentation.</p>
<div id="cell-24" class="cell" data-execution_count="22">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Other einsum examples</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Transpose</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.randn(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.einsum(<span class="st">'ij-&gt;ji'</span>, a)  <span class="co"># Swap dimensions</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Sum of all elements</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.randn(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.einsum(<span class="st">'ij-&gt;'</span>, a)  <span class="co"># Sum all elements</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Batch matrix multiplication</span></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.randn(<span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">5</span>)</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.randn(<span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">3</span>)</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> torch.einsum(<span class="st">'bij,bjk-&gt;bik'</span>, a, b) <span class="co"># Batch matrix multiplication</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Click to view contents (Deep Dive: Einstein Notation and torch.einsum)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Click to view contents (Deep Dive: Einstein Notation and torch.einsum)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<section id="einstein-notation-and-torch.einsum" class="level2">
<h2 class="anchored" data-anchor-id="einstein-notation-and-torch.einsum">Einstein Notation and torch.einsum</h2>
<section id="einstein-notation" class="level3">
<h3 class="anchored" data-anchor-id="einstein-notation">Einstein Notation</h3>
<p>Einstein notation, or Einstein summation convention, is a notation introduced by Albert Einstein in 1916 to describe the theory of general relativity. Originally designed to concisely express physical equations, especially those related to relativity, its convenience and expressive power have made it widely used in various fields that deal with tensor operations.</p>
<p><strong>Key Ideas:</strong></p>
<ul>
<li><strong>Repeating indices implies summation:</strong> If an index appears twice in a single term, it implies summation over all possible values of that index. This allows for the omission of explicit summation symbols (<span class="math inline">\(\sum\)</span>), making notation more concise.</li>
<li><strong>Free and dummy indices:</strong>
<ul>
<li><strong>Free index:</strong> An index that appears in the resulting tensor, appearing only once in each term.</li>
<li><strong>Dummy index (or bound index):</strong> An index that is summed over, appearing twice in a single term.</li>
</ul></li>
</ul>
<p><strong>Basic Rules</strong></p>
<ol type="1">
<li><strong>If an index appears twice in a term, it is summed over.</strong></li>
<li><strong>Free indices determine the dimension of the resulting tensor.</strong></li>
<li><strong>Dummy indices are used only for internal calculations and do not appear in the result.</strong></li>
<li><strong>Index letters can be chosen arbitrarily but should be consistent to avoid confusion.</strong> (Conventions often use <span class="math inline">\(i, j, k, l, m, n\)</span>, etc.)</li>
<li><strong>The left side of an arrow (<span class="math inline">\(\rightarrow\)</span>)</strong> represents input tensors, and <strong>the right side</strong> represents output tensors.</li>
</ol>
<p><strong>Examples</strong></p>
<ul>
<li><strong>Dot product:</strong> <span class="math inline">\(a_i b_i\)</span> (equivalent to <span class="math inline">\(\sum_i a_i b_i\)</span>)</li>
<li><strong>Matrix multiplication:</strong> <span class="math inline">\(A_{ij} B_{jk} = C_{ik}\)</span> (equivalent to <span class="math inline">\(\sum_j A_{ij}B_{jk}\)</span>)</li>
<li><strong>Transpose:</strong> <span class="math inline">\(A_{ij} = B_{ji}\)</span> (<span class="math inline">\(B\)</span> is the transpose of <span class="math inline">\(A\)</span>)</li>
<li><strong>Trace:</strong> <span class="math inline">\(A_{ii}\)</span> (equivalent to <span class="math inline">\(\sum_i A_{ii}\)</span>)</li>
<li><strong>Outer product:</strong> <span class="math inline">\(a_i b_j = C_{ij}\)</span></li>
<li><strong>Element-wise multiplication (Hadamard product):</strong> <span class="math inline">\(A_{ij}B_{ij} = C_{ij}\)</span></li>
</ul>
<p><strong>Examples of Use in Deep Learning</strong> * <strong>Batched Matrix Multiplication:</strong> <span class="math inline">\(A\_{bij} B\_{bjk} = C\_{bik}\)</span> (<span class="math inline">\(b\)</span>: batch dimension) * <strong>Attention Mechanism:</strong> <span class="math inline">\(e\_{ij} = Q\_{ik} K\_{jk}\)</span>, <span class="math inline">\(a\_{ij} = \text{softmax}(e\_{ij})\)</span>, <span class="math inline">\(v\_{i} = a\_{ij} V\_{j}\)</span> (<span class="math inline">\(Q\)</span>: query, <span class="math inline">\(K\)</span>: key, <span class="math inline">\(V\)</span>: value) * <strong>Bilinear Transformation:</strong> <span class="math inline">\(x\_i W\_{ijk} y\_j = z\_k\)</span> * <strong>Multi-Dimensional Convolution:</strong> <span class="math inline">\(I\_{b,c,i,j} \* F\_{o,c,k,l} = O\_{b,o,i',j'}\)</span> (<span class="math inline">\(b\)</span>: batch, <span class="math inline">\(c\)</span>: input channel, <span class="math inline">\(o\)</span>: output channel, <span class="math inline">\(i, j\)</span>: input spatial dimension, <span class="math inline">\(k, l\)</span>: filter spatial dimension) * <strong>Batch Normalization:</strong> <span class="math inline">\(\gamma\_c \* \frac{x\_{b,c,h,w} - \mu\_c}{\sigma\_c} + \beta\_c\)</span> (<span class="math inline">\(c\)</span>: channel dimension, <span class="math inline">\(b\)</span>: batch, <span class="math inline">\(h\)</span>: height, <span class="math inline">\(w\)</span>: width) * <strong>RNN Hidden State Update:</strong> <span class="math inline">\(h\_t = \tanh(W\_{ih}x\_t + b\_{ih} + W\_{hh}h\_{t-1} + b\_{hh})\)</span> (<span class="math inline">\(h\)</span>: hidden, <span class="math inline">\(x\)</span>: input, <span class="math inline">\(W\)</span>: weight, <span class="math inline">\(b\)</span>: bias) * <strong>LSTM Cell State Update:</strong> <span class="math inline">\(c\_t = f\_t \* c\_{t-1} + i\_t \* \tilde{c}\_t\)</span> (<span class="math inline">\(c\)</span>: cell state, <span class="math inline">\(f\)</span>: forget gate, <span class="math inline">\(i\)</span>: input gate, <span class="math inline">\(\tilde{c}\_t\)</span>: candidate cell state)</p>
</section>
<section id="torch.einsum" class="level3">
<h3 class="anchored" data-anchor-id="torch.einsum">torch.einsum</h3>
<p><code>torch.einsum</code> is a PyTorch function that performs tensor operations using Einstein notation. <code>einsum</code> is short for “Einstein summation”.</p>
<p><strong>Usage:</strong></p>
<div class="sourceCode" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>torch.einsum(equation, <span class="op">*</span>operands)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li><code>equation</code>: Einstein notation string, e.g., <code>'ij,jk-&gt;ik'</code>.</li>
<li><code>*operands</code>: Tensors participating in the operation (variable number of arguments).</li>
</ul>
<p><strong>Advantages</strong></p>
<ul>
<li><strong>Conciseness:</strong> Complex tensor operations can be expressed in a single line of code.</li>
<li><strong>Readability:</strong> Einstein notation clearly conveys the meaning of tensor operations.</li>
<li><strong>Flexibility:</strong> Various tensor operations can be combined to define new operations easily.</li>
<li><strong>Optimization:</strong> PyTorch automatically optimizes <code>einsum</code> operations for efficient computation. (In some cases) It can be faster than manual implementation by utilizing optimized routines from libraries like BLAS, cuBLAS, or optimizing operation order.</li>
<li><strong>Autograd Support:</strong> Operations defined with <code>einsum</code> are fully compatible with PyTorch’s autograd system.</li>
</ul>
<p><strong>torch.einsum Examples:</strong></p>
<div class="sourceCode" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Matrix Multiplication</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> torch.randn(<span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>B <span class="op">=</span> torch.randn(<span class="dv">4</span>, <span class="dv">5</span>)</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>C <span class="op">=</span> torch.einsum(<span class="st">'ij,jk-&gt;ik'</span>, A, B)  <span class="co"># C = A @ B</span></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Transpose</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> torch.randn(<span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>B <span class="op">=</span> torch.einsum(<span class="st">'ij-&gt;ji'</span>, A)  <span class="co"># B = A.T</span></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Trace</span></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> torch.randn(<span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>trace <span class="op">=</span> torch.einsum(<span class="st">'ii-&gt;'</span>, A)  <span class="co"># trace = torch.trace(A)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="batch-matrix-multiplication" class="level1">
<h1>Batch Matrix Multiplication</h1>
<p>A = torch.randn(2, 3, 4) B = torch.randn(2, 4, 5) C = torch.einsum(‘bij,bjk-&gt;bik’, A, B) # C = torch.bmm(A, B)</p>
</section>
<section id="outer-product" class="level1">
<h1>Outer Product</h1>
<p>a = torch.randn(3) b = torch.randn(4) C = torch.einsum(‘i,j-&gt;ij’, a, b) # C = torch.outer(a, b)</p>
</section>
<section id="element-wise-multiplication" class="level1">
<h1>Element-wise Multiplication</h1>
<p>A = torch.randn(2,3) B = torch.randn(2,3) C = torch.einsum(‘ij,ij-&gt;ij’, A, B) # C = A * B</p>
</section>
<section id="biliner-transformation" class="level1">
<h1>Biliner Transformation</h1>
<p>x = torch.randn(3) W = torch.randn(5, 3, 4) y = torch.randn(4) z = torch.einsum(‘i,ijk,j-&gt;k’, x, W, y) # z_k = sum_i sum_j x_i * W_{ijk} * y_j</p>
</section>
<section id="multidimensional-tensor-contraction" class="level1">
<h1>Multidimensional Tensor Contraction</h1>
<p>tensor = torch.randn(3, 4, 5, 6) result = torch.einsum(‘…ij-&gt;…i’, tensor) # sum over the last two dimensions</p>
<p><strong><code>torch.einsum</code> vs.&nbsp;Other Operations:</strong></p>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 26%">
<col style="width: 47%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Operation</th>
<th style="text-align: left;"><code>torch.einsum</code></th>
<th style="text-align: left;">Other Methods</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Matrix Multiplication</td>
<td style="text-align: left;"><code>'ij,jk-&gt;ik'</code></td>
<td style="text-align: left;"><code>torch.matmul(A, B)</code> or <code>A @ B</code></td>
</tr>
<tr class="even">
<td style="text-align: left;">Transpose</td>
<td style="text-align: left;"><code>'ij-&gt;ji'</code></td>
<td style="text-align: left;"><code>torch.transpose(A, 0, 1)</code> or <code>A.T</code></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Trace</td>
<td style="text-align: left;"><code>'ii-&gt;'</code></td>
<td style="text-align: left;"><code>torch.trace(A)</code></td>
</tr>
<tr class="even">
<td style="text-align: left;">Batch Matrix Multiplication</td>
<td style="text-align: left;"><code>'bij,bjk-&gt;bik'</code></td>
<td style="text-align: left;"><code>torch.bmm(A, B)</code></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Dot Product</td>
<td style="text-align: left;"><code>'i,i-&gt;'</code></td>
<td style="text-align: left;"><code>torch.dot(a, b)</code></td>
</tr>
<tr class="even">
<td style="text-align: left;">Outer Product</td>
<td style="text-align: left;"><code>'i,j-&gt;ij'</code></td>
<td style="text-align: left;"><code>torch.outer(a, b)</code></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Element-wise Multiplication</td>
<td style="text-align: left;"><code>'ij,ij-&gt;ij'</code></td>
<td style="text-align: left;"><code>A * B</code></td>
</tr>
<tr class="even">
<td style="text-align: left;">Tensor Contraction (sum, mean, etc.)</td>
<td style="text-align: left;"><code>'ijk-&gt;i'</code> (example)</td>
<td style="text-align: left;"><code>torch.sum(A, dim=(1, 2))</code></td>
</tr>
</tbody>
</table>
<p><strong>Limitations of <code>torch.einsum</code></strong></p>
<ul>
<li><strong>Initial Learning Curve:</strong> May be difficult for users unfamiliar with Einstein notation at first.</li>
<li><strong>Readability of Complex Operations:</strong> For very complex operations, the <code>einsum</code> string can become long and decrease readability. In such cases, breaking down the operation into multiple steps or using comments is recommended.</li>
<li><strong>Inability to Express All Operations:</strong> Since <code>einsum</code> is based on linear algebra operations, non-linear operations (e.g., <code>max</code>, <code>min</code>, <code>sort</code>) or conditional operations cannot be directly expressed. In such cases, other PyTorch functions must be used in conjunction.</li>
</ul>
<p><strong>Optimizing <code>einsum</code> with <code>torch.compile</code></strong> <code>torch.compile</code> (PyTorch 2.0 and above) can further optimize <code>einsum</code> operations. <code>compile</code> performs various optimizations, such as analyzing code through JIT (Just-In-Time) compilation, merging tensor operations, or optimizing memory access patterns.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Available in PyTorch 2.0 and above</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="at">@torch.compile</span></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> my_einsum_function(a, b):</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> torch.einsum(<span class="st">'ij,jk-&gt;ik'</span>, a, b)</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Compile on the first call, execute optimized code on subsequent calls</span></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> my_einsum_function(torch.randn(<span class="dv">10</span>, <span class="dv">20</span>), torch.randn(<span class="dv">20</span>, <span class="dv">30</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Conclusion:</strong></p>
<p>Einstein notation and <code>torch.einsum</code> are powerful tools for expressing and calculating complex tensor operations in deep learning in a concise and efficient manner. Although they may seem unfamiliar at first, they can greatly improve code readability and efficiency once you get used to them. Especially when dealing with deep learning models that involve complex tensor operations, such as transformer models, they show their value. Using <code>torch.compile</code> together can further enhance performance.</p>
<p><strong>References:</strong></p>
<ol type="1">
<li><strong>Einstein Notation:</strong> https://en.wikipedia.org/wiki/Einstein_notation</li>
<li><strong><code>torch.einsum</code> documentation:</strong> https://pytorch.org/docs/stable/generated/torch.einsum.html</li>
<li><strong>A basic introduction to NumPy’s einsum:</strong> https://ajcr.net/Basic-guide-to-einsum/</li>
<li><strong>Einsum is All You Need - Einstein Summation in Deep Learning:</strong> https://rockt.github.io/2018/04/30/einsum</li>
</ol>
</section>
</div>
</div>
</div>
</section>
<section id="computational-graph-for-gradient-operations" class="level3">
<h3 class="anchored" data-anchor-id="computational-graph-for-gradient-operations">3.1.3 Computational Graph for Gradient Operations</h3>
<p>Automatic Differentiation has been studied since the 1970s, but it has gained significant attention along with the development of deep learning since 2015. PyTorch implements automatic differentiation through a dynamic computation graph, which is an actual implementation of the chain rule discussed in Chapter 2.</p>
<p>PyTorch’s automatic differentiation can track and store gradients at each operation step. To do this, gradient tracking must be explicitly declared for tensors.</p>
<div id="cell-27" class="cell" data-execution_count="23">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.randn((<span class="dv">2</span>,))</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"a.requires_grad (default): </span><span class="sc">{</span>a<span class="sc">.</span>requires_grad<span class="sc">}</span><span class="ss">"</span>)  <span class="co"># False (default)</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>a.requires_grad_(<span class="va">True</span>)  <span class="co"># In-place modification</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"a.requires_grad (after setting to True): </span><span class="sc">{</span>a<span class="sc">.</span>requires_grad<span class="sc">}</span><span class="ss">"</span>)  <span class="co"># True</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Declare during creation</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">2</span>, dtype<span class="op">=</span>torch.float32, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"x.requires_grad (declared at creation): </span><span class="sc">{</span>x<span class="sc">.</span>requires_grad<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>a.requires_grad (default): False
a.requires_grad (after setting to True): True
x.requires_grad (declared at creation): True</code></pre>
</div>
</div>
<p>For example, let’s consider a simple loss function as follows (refer to Figure 3-1, previous version).</p>
<p><span class="math display">\[y = \frac {1}{N}\displaystyle\sum_{i}^{N} \{(x_i - 1)^2 + 4) \}\]</span></p>
<p>The operation for <span class="math inline">\(x_i\)</span> can be expressed sequentially as <span class="math inline">\(a_i = x_i - 1\)</span>, <span class="math inline">\(b_i = a_i^2\)</span>, <span class="math inline">\(c_i = b_i + 4\)</span>, <span class="math inline">\(y = \frac{1}{N}\sum_{i=1}^{N} c_i\)</span>.</p>
<p>Let’s perform forward and backward operations on this equation.</p>
<div id="cell-29" class="cell" data-execution_count="24">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> x <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> a<span class="op">**</span><span class="dv">2</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> b <span class="op">+</span> <span class="dv">4</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> c.mean()</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"y = </span><span class="sc">{</span>y<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform backward operation</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>y.backward()</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the gradient of x (x.grad)</span></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"x.grad = </span><span class="sc">{</span>x<span class="sc">.</span>grad<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>y = 4.5
x.grad = tensor([-1.,  0.])</code></pre>
</div>
</div>
<p>The gradient of each step can be calculated as follows:</p>
<p><span class="math inline">\(\frac{\partial a_i}{\partial x_i} = 1, \frac{\partial b_i}{\partial a_i} = 2 \cdot a_i, \frac{\partial c_i}{\partial b_i} = 1,  \frac{\partial y}{\partial c_i} = \frac{1}{N}\)</span></p>
<p>Therefore, by the chain rule,</p>
<p><span class="math inline">\(\frac{\partial y}{\partial x_i} = \frac{\partial y}{\partial  c_i}\frac{\partial c_i}{\partial b_i}\frac{\partial b_i}{\partial a_i}\frac{\partial a_i}{\partial x_i} =  \frac{1}{N} \cdot 1 \cdot 2 \cdot a_i \cdot 1 = \frac{2}{N}a_i = \frac{2}{N}(x_i - 1)\)</span></p>
<p>Since <span class="math inline">\(x_i\)</span> is in [0, 1] and N=2 (the number of elements in x), <span class="math inline">\(\frac{\partial y}{\partial x_i}\)</span> becomes <span class="math inline">\([-0.5, 0.5]\)</span>. This matches the result of PyTorch’s automatic differentiation.</p>
<p>PyTorch has implemented the concept of automatic differentiation, which has been studied since the 1970s, in a modern way. In particular, the dynamic creation of computation graphs and gradient tracking functions are very useful. However, sometimes it is necessary to disable these automatic differentiation functions.</p>
<div id="cell-31" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn(<span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> torch.randn(<span class="dv">4</span>, <span class="dv">2</span>)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.randn(<span class="dv">2</span>)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="co"># If gradient tracking is needed</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> torch.matmul(x, w) <span class="op">+</span> b</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>z.requires_grad_(<span class="va">True</span>)  <span class="co"># Can also be set using requires_grad_()</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"z.requires_grad: </span><span class="sc">{</span>z<span class="sc">.</span>requires_grad<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Disable gradient tracking method 1: Using 'with' statement</span></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>    z <span class="op">=</span> torch.matmul(x, w) <span class="op">+</span> b</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"z.requires_grad (inside no_grad): </span><span class="sc">{</span>z<span class="sc">.</span>requires_grad<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Disable gradient tracking method 2: Using detach()</span></span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>z_det <span class="op">=</span> z.detach()</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"z_det.requires_grad: </span><span class="sc">{</span>z_det<span class="sc">.</span>requires_grad<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>z.requires_grad: True
z.requires_grad (inside no_grad): False
z_det.requires_grad: False</code></pre>
</div>
</div>
<p>Disabling gradient tracking is particularly useful in the following cases:</p>
<ol type="1">
<li><strong>During inference</strong>: When only the forward pass is needed, it saves memory and computation cost.</li>
<li><strong>Fine-tuning</strong>: When updating specific parameters and keeping the rest fixed.</li>
<li><strong>Performance optimization</strong>: Backpropagation incurs additional memory and computation costs, so disabling it when not necessary.</li>
</ol>
<p>Especially in fine-tuning large language models, where most parameters are typically frozen and only a few are updated, selective activation of gradient tracking is a crucial feature.</p>
</section>
<section id="data-loading" class="level3">
<h3 class="anchored" data-anchor-id="data-loading">3.1.4 Data Loading</h3>
<p>Data loading is a core element of deep learning. Until the early 2000s, each research team used its own data processing method, but with the emergence of large datasets like ImageNet in 2009, the need for standardized data loading systems became prominent.</p>
<p>PyTorch provides two key classes to separate data processing and training logic:</p>
<ol type="1">
<li><code>torch.utils.data.Dataset</code>: Provides a consistent access interface for data and labels. You must implement the <code>__len__</code> and <code>__getitem__</code> methods.</li>
<li><code>torch.utils.data.DataLoader</code>: Offers an efficient data loading mechanism in batch units. It wraps around <code>Dataset</code> to automate mini-batch creation, shuffling, and parallel data loading.</li>
</ol>
<p>The following is an example of generating random data using the Dirichlet distribution.</p>
<div id="cell-34" class="cell" data-execution_count="9">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.utils.data <span class="im">as</span> data</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize with Dirichlet distribution</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> np.random.dirichlet(np.ones(<span class="dv">5</span>), size<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> np.zeros_like(a)</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate label values</span></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> (a <span class="op">==</span> a.<span class="bu">max</span>(axis<span class="op">=</span><span class="dv">1</span>)[:, <span class="va">None</span>]).astype(<span class="bu">int</span>)</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Data (a):</span><span class="ch">\n</span><span class="sc">{</span>a<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Labels (b):</span><span class="ch">\n</span><span class="sc">{</span>b<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a custom Dataset class by inheriting from PyTorch's Dataset.</span></span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> RandomData(data.Dataset):</span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, feature, length):</span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.feature <span class="op">=</span> feature</span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.length <span class="op">=</span> length</span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.generate_data()</span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> generate_data(<span class="va">self</span>):</span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> np.random.dirichlet(np.ones(<span class="va">self</span>.feature), size<span class="op">=</span><span class="va">self</span>.length)</span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a>        y <span class="op">=</span> (x <span class="op">==</span> x.<span class="bu">max</span>(axis<span class="op">=</span><span class="dv">1</span>)[:, <span class="va">None</span>]).astype(<span class="bu">int</span>)  <span class="co"># One-hot encoding</span></span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.data <span class="op">=</span> x  <span class="co"># numpy object</span></span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.label <span class="op">=</span> y</span>
<span id="cb33-28"><a href="#cb33-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-29"><a href="#cb33-29" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb33-30"><a href="#cb33-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.length</span>
<span id="cb33-31"><a href="#cb33-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-32"><a href="#cb33-32" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, index):</span>
<span id="cb33-33"><a href="#cb33-33" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Return data and label as torch tensors</span></span>
<span id="cb33-34"><a href="#cb33-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.tensor(<span class="va">self</span>.data[index], dtype<span class="op">=</span>torch.float32), torch.tensor(<span class="va">self</span>.label[index], dtype<span class="op">=</span>torch.int64)</span>
<span id="cb33-35"><a href="#cb33-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-36"><a href="#cb33-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-37"><a href="#cb33-37" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> RandomData(feature<span class="op">=</span><span class="dv">10</span>, length<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb33-38"><a href="#cb33-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of data samples = </span><span class="sc">{</span><span class="bu">len</span>(dataset)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb33-39"><a href="#cb33-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Data at index 0 = </span><span class="sc">{</span>dataset[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb33-40"><a href="#cb33-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Data type = </span><span class="sc">{</span><span class="bu">type</span>(dataset[<span class="dv">0</span>][<span class="dv">0</span>])<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Data (a):
[[0.46073711 0.01119455 0.28991657 0.11259078 0.12556099]
 [0.07331166 0.43554042 0.1243009  0.13339224 0.23345478]]
Labels (b):
[[1 0 0 0 0]
 [0 1 0 0 0]]
Number of data samples = 100
Data at index 0 = (tensor([1.4867e-01, 1.6088e-01, 1.2207e-02, 3.6049e-02, 1.1054e-04, 8.1160e-02,
        2.9811e-02, 1.9398e-01, 4.9448e-02, 2.8769e-01]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1]))
Data type = &lt;class 'torch.Tensor'&gt;</code></pre>
</div>
</div>
<p><code>DataLoader</code> provides various features for batch processing. The main parameters are as follows.</p>
<ul>
<li><code>batch_size</code>: number of samples per batch</li>
<li><code>shuffle</code>: randomize data order (generally set to <code>True</code> during training)</li>
<li><code>num_workers</code>: number of processes for parallelizing data loading</li>
<li><code>drop_last</code>: whether to drop the last incomplete batch (if <code>True</code>, it is discarded)</li>
</ul>
<p>It reads data from a <code>Dataset</code> using <code>__getitem__</code> and converts the result into tensor objects. In particular, setting <code>num_workers</code> is important when handling large image or video datasets. However, for small datasets, a single process may be more efficient. Setting <code>num_workers</code> too high can lead to overhead, so it’s crucial to find an appropriate value (typically trying the number of cores or twice the number of cores).</p>
<div id="cell-36" class="cell" data-execution_count="10">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>data_loader <span class="op">=</span> data.DataLoader(dataset, batch_size<span class="op">=</span><span class="dv">4</span>, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Read one batch.</span></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>train_x, train_y <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(data_loader))</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"1st batch training data = </span><span class="sc">{</span>train_x<span class="sc">}</span><span class="ss">, </span><span class="ch">\n</span><span class="ss"> Data shape = </span><span class="sc">{</span>train_x<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"1st batch label data = </span><span class="sc">{</span>train_y<span class="sc">}</span><span class="ss">, </span><span class="ch">\n</span><span class="ss"> Data shape = </span><span class="sc">{</span>train_y<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"1st batch label data type = </span><span class="sc">{</span><span class="bu">type</span>(train_y)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>1st batch training data = tensor([[3.3120e-02, 1.4274e-01, 9.7984e-02, 1.9628e-03, 6.8926e-02, 3.4525e-01,
         4.6966e-02, 6.0947e-02, 4.2738e-02, 1.5937e-01],
        [8.0707e-02, 4.9181e-02, 3.1863e-02, 1.4238e-02, 1.6089e-02, 1.7980e-01,
         1.7544e-01, 1.3465e-01, 1.6361e-01, 1.5442e-01],
        [4.2364e-02, 3.3635e-02, 2.0840e-01, 1.6919e-02, 4.5977e-02, 6.5791e-02,
         1.8726e-01, 1.0325e-01, 2.2029e-01, 7.6117e-02],
        [1.4867e-01, 1.6088e-01, 1.2207e-02, 3.6049e-02, 1.1054e-04, 8.1160e-02,
         2.9811e-02, 1.9398e-01, 4.9448e-02, 2.8769e-01]]), 
 Data shape = torch.Size([4, 10])
1st batch label data = tensor([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]), 
 Data shape = torch.Size([4, 10])
1st batch label data type = &lt;class 'torch.Tensor'&gt;</code></pre>
</div>
</div>
<p>PyTorch provides specialized packages for domain-specific data processing. Since 2016, as deep learning has expanded to various fields, the need for specialized data processing for each domain has emerged.</p>
<ul>
<li><code>torchvision</code>: computer vision</li>
<li><code>torchaudio</code>: audio processing</li>
<li><code>torchtext</code>: natural language processing</li>
</ul>
<p>Fashion-MNIST is a dataset released by Zalando Research in 2017, designed to replace MNIST. The composition of the dataset is as follows.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Category</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Training data</td>
<td>60,000</td>
</tr>
<tr class="even">
<td>Test data</td>
<td>10,000</td>
</tr>
<tr class="odd">
<td>Image size</td>
<td>28x28 grayscale</td>
</tr>
</tbody>
</table>
<div id="cell-38" class="cell" data-execution_count="11">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset, DataLoader</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.transforms <span class="im">import</span> ToTensor, Normalize, Compose</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn_image <span class="im">as</span> isns</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt <span class="co"># Added for visualization</span></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to calculate mean and std of the dataset</span></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_mean_std(dataset):</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>    dataloader <span class="op">=</span> DataLoader(dataset, batch_size<span class="op">=</span><span class="bu">len</span>(dataset), shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>    data, _ <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(dataloader))</span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>    mean <span class="op">=</span> data.mean(axis<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">3</span>))  <span class="co"># Calculate mean across channel dimension</span></span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>    std <span class="op">=</span> data.std(axis<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">3</span>))    <span class="co"># Calculate std across channel dimension</span></span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> mean, std</span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Datasets.  Note:  We *don't* apply Normalize here yet.</span></span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> datasets.FashionMNIST(</span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a>    root<span class="op">=</span><span class="st">"data"</span>, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>ToTensor()</span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> datasets.FashionMNIST(</span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a>    root<span class="op">=</span><span class="st">"data"</span>, train<span class="op">=</span><span class="va">False</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>ToTensor()</span>
<span id="cb37-24"><a href="#cb37-24" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb37-25"><a href="#cb37-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-26"><a href="#cb37-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate mean and std for normalization</span></span>
<span id="cb37-27"><a href="#cb37-27" aria-hidden="true" tabindex="-1"></a>train_mean, train_std <span class="op">=</span> calculate_mean_std(train_dataset)</span>
<span id="cb37-28"><a href="#cb37-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Train data mean: </span><span class="sc">{</span>train_mean<span class="sc">}</span><span class="ss">, std: </span><span class="sc">{</span>train_std<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb37-29"><a href="#cb37-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-30"><a href="#cb37-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Now define transforms *with* normalization</span></span>
<span id="cb37-31"><a href="#cb37-31" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> Compose([</span>
<span id="cb37-32"><a href="#cb37-32" aria-hidden="true" tabindex="-1"></a>    ToTensor(),</span>
<span id="cb37-33"><a href="#cb37-33" aria-hidden="true" tabindex="-1"></a>    Normalize(train_mean, train_std)  <span class="co"># Use calculated mean and std</span></span>
<span id="cb37-34"><a href="#cb37-34" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb37-35"><a href="#cb37-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-36"><a href="#cb37-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Re-create datasets with the normalization transform</span></span>
<span id="cb37-37"><a href="#cb37-37" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> datasets.FashionMNIST(</span>
<span id="cb37-38"><a href="#cb37-38" aria-hidden="true" tabindex="-1"></a>    root<span class="op">=</span><span class="st">"data"</span>, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform</span>
<span id="cb37-39"><a href="#cb37-39" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb37-40"><a href="#cb37-40" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> datasets.FashionMNIST(</span>
<span id="cb37-41"><a href="#cb37-41" aria-hidden="true" tabindex="-1"></a>    root<span class="op">=</span><span class="st">"data"</span>, train<span class="op">=</span><span class="va">False</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform</span>
<span id="cb37-42"><a href="#cb37-42" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb37-43"><a href="#cb37-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-44"><a href="#cb37-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-45"><a href="#cb37-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Check one training data sample.</span></span>
<span id="cb37-46"><a href="#cb37-46" aria-hidden="true" tabindex="-1"></a>sample_idx <span class="op">=</span> torch.randint(<span class="bu">len</span>(train_dataset), size<span class="op">=</span>(<span class="dv">1</span>,)).item()</span>
<span id="cb37-47"><a href="#cb37-47" aria-hidden="true" tabindex="-1"></a>img, label <span class="op">=</span> train_dataset[sample_idx]  <span class="co"># Use a random index</span></span>
<span id="cb37-48"><a href="#cb37-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-49"><a href="#cb37-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Label: </span><span class="sc">{</span>label<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb37-50"><a href="#cb37-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-51"><a href="#cb37-51" aria-hidden="true" tabindex="-1"></a><span class="co"># Manually create a label map</span></span>
<span id="cb37-52"><a href="#cb37-52" aria-hidden="true" tabindex="-1"></a>labels_map <span class="op">=</span> {</span>
<span id="cb37-53"><a href="#cb37-53" aria-hidden="true" tabindex="-1"></a>    <span class="dv">0</span>: <span class="st">"T-shirt"</span>,</span>
<span id="cb37-54"><a href="#cb37-54" aria-hidden="true" tabindex="-1"></a>    <span class="dv">1</span>: <span class="st">"Trouser"</span>,</span>
<span id="cb37-55"><a href="#cb37-55" aria-hidden="true" tabindex="-1"></a>    <span class="dv">2</span>: <span class="st">"Pullover"</span>,</span>
<span id="cb37-56"><a href="#cb37-56" aria-hidden="true" tabindex="-1"></a>    <span class="dv">3</span>: <span class="st">"Dress"</span>,</span>
<span id="cb37-57"><a href="#cb37-57" aria-hidden="true" tabindex="-1"></a>    <span class="dv">4</span>: <span class="st">"Coat"</span>,</span>
<span id="cb37-58"><a href="#cb37-58" aria-hidden="true" tabindex="-1"></a>    <span class="dv">5</span>: <span class="st">"Sandal"</span>,</span>
<span id="cb37-59"><a href="#cb37-59" aria-hidden="true" tabindex="-1"></a>    <span class="dv">6</span>: <span class="st">"Shirt"</span>,</span>
<span id="cb37-60"><a href="#cb37-60" aria-hidden="true" tabindex="-1"></a>    <span class="dv">7</span>: <span class="st">"Sneaker"</span>,</span>
<span id="cb37-61"><a href="#cb37-61" aria-hidden="true" tabindex="-1"></a>    <span class="dv">8</span>: <span class="st">"Bag"</span>,</span>
<span id="cb37-62"><a href="#cb37-62" aria-hidden="true" tabindex="-1"></a>    <span class="dv">9</span>: <span class="st">"Ankle Boot"</span>,</span>
<span id="cb37-63"><a href="#cb37-63" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb37-64"><a href="#cb37-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-65"><a href="#cb37-65" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Label map: </span><span class="sc">{</span>labels_map[label]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb37-66"><a href="#cb37-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-67"><a href="#cb37-67" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot using seaborn-image.</span></span>
<span id="cb37-68"><a href="#cb37-68" aria-hidden="true" tabindex="-1"></a>isns.imgplot(img.squeeze())  <span class="co"># Squeeze to remove channel dimension for grayscale</span></span>
<span id="cb37-69"><a href="#cb37-69" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f"Label: </span><span class="sc">{</span>labels_map[label]<span class="sc">}</span><span class="ss">"</span>) <span class="co"># Add title to plot</span></span>
<span id="cb37-70"><a href="#cb37-70" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb37-71"><a href="#cb37-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-72"><a href="#cb37-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-73"><a href="#cb37-73" aria-hidden="true" tabindex="-1"></a><span class="co"># Define data loaders</span></span>
<span id="cb37-74"><a href="#cb37-74" aria-hidden="true" tabindex="-1"></a>train_dataloader <span class="op">=</span> DataLoader(train_dataset, batch_size<span class="op">=</span><span class="dv">32</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb37-75"><a href="#cb37-75" aria-hidden="true" tabindex="-1"></a>test_dataloader <span class="op">=</span> DataLoader(test_dataset, batch_size<span class="op">=</span><span class="dv">32</span>, shuffle<span class="op">=</span><span class="va">False</span>) <span class="co"># No need to shuffle test data</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Train data mean: tensor([0.2860]), std: tensor([0.3530])
Label: 5
Label map: Sandal</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="03_Deep Learning Framework_files/figure-html/cell-19-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="data-transform" class="level3">
<h3 class="anchored" data-anchor-id="data-transform">3.1.5 Data Transform</h3>
<p>Data Transform is a very important preprocessing step in deep learning. After the success of AlexNet in 2012, Data Augmentation became a key factor in improving model performance. PyTorch provides various tools for such transformations. Using <code>transforms.Compose</code>, multiple transformations can be applied sequentially. Additionally, custom transformations can be easily implemented through the <code>Lambda</code> function.</p>
<p>Data transformation is very important for improving the generalization performance of models. Especially in the field of computer vision, data augmentation through various transformations has become a standard practice. The <code>Normalize</code> transformation is an essential step to standardize the data for stable model learning.</p>
<p>To apply the <code>Normalize</code> transformation, you need to know the mean and standard deviation of the dataset. The code to calculate this is as follows.</p>
<div id="cell-40" class="cell" data-execution_count="12">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> transforms</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> PIL</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate mean and std of the dataset</span></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_mean_std(dataset):</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>    dataloader <span class="op">=</span> DataLoader(dataset, batch_size<span class="op">=</span><span class="bu">len</span>(dataset), shuffle<span class="op">=</span><span class="va">False</span>) <span class="co"># Load all data at once</span></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>    data, _ <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(dataloader))</span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># For grayscale images, calculate mean and std over height, width dimensions (0, 2, 3)</span></span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># For RGB images, the calculation would be over (0, 1, 2)</span></span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>    mean <span class="op">=</span> data.mean(dim<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">3</span>))  <span class="co"># Calculate mean across batch and spatial dimensions</span></span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a>    std <span class="op">=</span> data.std(dim<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">3</span>))    <span class="co"># Calculate std across batch and spatial dimensions</span></span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> mean, std</span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Example usage with FashionMNIST ---</span></span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a><span class="co"># 1.  Create dataset *without* normalization first:</span></span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a>train_dataset_for_calc <span class="op">=</span> datasets.FashionMNIST(</span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a>    root<span class="op">=</span><span class="st">"data"</span>, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transforms.ToTensor()  <span class="co"># Only ToTensor</span></span>
<span id="cb39-21"><a href="#cb39-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb39-22"><a href="#cb39-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-23"><a href="#cb39-23" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Calculate mean and std:</span></span>
<span id="cb39-24"><a href="#cb39-24" aria-hidden="true" tabindex="-1"></a>train_mean, train_std <span class="op">=</span> calculate_mean_std(train_dataset_for_calc)</span>
<span id="cb39-25"><a href="#cb39-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Train data mean: </span><span class="sc">{</span>train_mean<span class="sc">}</span><span class="ss">, std: </span><span class="sc">{</span>train_std<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb39-26"><a href="#cb39-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-27"><a href="#cb39-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-28"><a href="#cb39-28" aria-hidden="true" tabindex="-1"></a><span class="co"># 3.  *Now* create the dataset with normalization:</span></span>
<span id="cb39-29"><a href="#cb39-29" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb39-30"><a href="#cb39-30" aria-hidden="true" tabindex="-1"></a>    transforms.ToTensor(),</span>
<span id="cb39-31"><a href="#cb39-31" aria-hidden="true" tabindex="-1"></a>    transforms.Normalize(train_mean, train_std)  <span class="co"># Use calculated mean and std</span></span>
<span id="cb39-32"><a href="#cb39-32" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb39-33"><a href="#cb39-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-34"><a href="#cb39-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Example of defining a custom transform using Lambda</span></span>
<span id="cb39-35"><a href="#cb39-35" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> crop_image(image: PIL.Image.Image) <span class="op">-&gt;</span> PIL.Image.Image:</span>
<span id="cb39-36"><a href="#cb39-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Original image is assumed to be 28x28.</span></span>
<span id="cb39-37"><a href="#cb39-37" aria-hidden="true" tabindex="-1"></a>    left, top, width, height <span class="op">=</span> <span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">18</span>, <span class="dv">18</span> <span class="co"># Example crop parameters</span></span>
<span id="cb39-38"><a href="#cb39-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> transforms.functional.crop(image, top<span class="op">=</span>top, left<span class="op">=</span>left, width<span class="op">=</span>width, height<span class="op">=</span>height)</span>
<span id="cb39-39"><a href="#cb39-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-40"><a href="#cb39-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Compose transforms, including the custom one and normalization.</span></span>
<span id="cb39-41"><a href="#cb39-41" aria-hidden="true" tabindex="-1"></a>transform_with_crop <span class="op">=</span> transforms.Compose([</span>
<span id="cb39-42"><a href="#cb39-42" aria-hidden="true" tabindex="-1"></a>    transforms.Lambda(crop_image), <span class="co"># Custom cropping</span></span>
<span id="cb39-43"><a href="#cb39-43" aria-hidden="true" tabindex="-1"></a>    transforms.ColorJitter(),</span>
<span id="cb39-44"><a href="#cb39-44" aria-hidden="true" tabindex="-1"></a>    transforms.RandomInvert(),</span>
<span id="cb39-45"><a href="#cb39-45" aria-hidden="true" tabindex="-1"></a>    transforms.ToTensor(), <span class="co"># Must be *before* Normalize</span></span>
<span id="cb39-46"><a href="#cb39-46" aria-hidden="true" tabindex="-1"></a>    transforms.Normalize(train_mean, train_std) <span class="co"># Use calculated mean and std</span></span>
<span id="cb39-47"><a href="#cb39-47" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb39-48"><a href="#cb39-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-49"><a href="#cb39-49" aria-hidden="true" tabindex="-1"></a>train_dataset_transformed <span class="op">=</span> datasets.FashionMNIST(root<span class="op">=</span><span class="st">"data"</span>, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform_with_crop)</span>
<span id="cb39-50"><a href="#cb39-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Get one sample to check the transformation.</span></span>
<span id="cb39-51"><a href="#cb39-51" aria-hidden="true" tabindex="-1"></a>sample_img, sample_label <span class="op">=</span> train_dataset_transformed[<span class="dv">0</span>]</span>
<span id="cb39-52"><a href="#cb39-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Transformed image shape: </span><span class="sc">{</span>sample_img<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb39-53"><a href="#cb39-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Transformed image min/max: </span><span class="sc">{</span>sample_img<span class="sc">.</span><span class="bu">min</span>()<span class="sc">}</span><span class="ss">, </span><span class="sc">{</span>sample_img<span class="sc">.</span><span class="bu">max</span>()<span class="sc">}</span><span class="ss">"</span>) <span class="co"># Check normalization</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Train data mean: tensor([0.2860]), std: tensor([0.3530])
Transformed image shape: torch.Size([1, 18, 18])
Transformed image min/max: -0.8102576732635498, 2.022408962249756</code></pre>
</div>
</div>
<p>In the above code, we first create a dataset with only <code>ToTensor()</code> transformation applied and calculate the mean and standard deviation. Then, we define the final transformation including <code>Normalize</code> transformation using the calculated values. The example also includes adding a custom <code>crop_image</code> function to the transformation pipeline using <code>Lambda</code> function. <code>ToTensor()</code> should come before <code>Normalize</code>. <code>ToTensor()</code> converts images in the range of [0, 255] to tensors in the range of [0, 1], and <code>Normalize</code> normalizes this [0, 1] range data to have a mean of 0 and a standard deviation of 1. It is common to apply data augmentation only to the training data and not to the validation/test data.</p>
</section>
<section id="model" class="level3">
<h3 class="anchored" data-anchor-id="model">3.1.6 Model</h3>
<p>The implementation method of neural network models has developed in various ways since the 1980s. PyTorch adopted an object-oriented model implementation method from its release in 2016, which is implemented through <code>nn.Module</code>. This method greatly improved the reusability and extensibility of the model.</p>
<p>The model class is implemented by inheriting <code>nn.Module</code> and generally includes the following methods:</p>
<ul>
<li><code>__init__()</code>: Defines and initializes the components of the neural network (layers, activation functions, etc.).</li>
<li><code>forward()</code>: Receives input data, performs the model’s forward operation, and returns the output (logit or prediction value).</li>
<li>(Optional) <code>training_step()</code>, <code>validation_step()</code>, <code>test_step()</code>: When used with libraries like PyTorch Lightning, defines the actions for each training/validation/test step.</li>
<li>(Optional) Other user-defined methods: Additional methods can be added to perform specific functions of the model.</li>
</ul>
<div id="cell-43" class="cell" data-execution_count="13">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> nn</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SimpleNetwork(nn.Module):</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()  <span class="co"># Or super(SimpleNetwork, self).__init__()</span></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.flatten <span class="op">=</span> nn.Flatten()</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.network_stack <span class="op">=</span> nn.Sequential(</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">28</span> <span class="op">*</span> <span class="dv">28</span>, <span class="dv">512</span>),</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">512</span>, <span class="dv">512</span>),</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">512</span>, <span class="dv">10</span>),</span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.flatten(x)  <span class="co"># Flatten the image data into a 1D array</span></span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> <span class="va">self</span>.network_stack(x)</span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> logits</span>
<span id="cb41-19"><a href="#cb41-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-20"><a href="#cb41-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Move model to the appropriate device (CPU or GPU)</span></span>
<span id="cb41-21"><a href="#cb41-21" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SimpleNetwork().to(device)</span>
<span id="cb41-22"><a href="#cb41-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>SimpleNetwork(
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (network_stack): Sequential(
    (0): Linear(in_features=784, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=10, bias=True)
  )
)</code></pre>
</div>
</div>
<p>Logit has several meanings.</p>
<ul>
<li>Mathematical meaning: a function that converts a probability in the range [0, 1] to a real number in the range [−∞, ∞].</li>
<li>Meaning in deep learning: the raw output value of an unnormalized neural network.</li>
</ul>
<p>In multi-class classification problems, the softmax function is often applied at the end to convert it into a probability value that can be compared with the label. In this case, the logit becomes the input value of the softmax function.</p>
<p>The model is generated from the class and transmitted to the device. If a GPU exists, the model is loaded into GPU memory.</p>
<div id="cell-45" class="cell" data-execution_count="14">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.rand(<span class="dv">1</span>, <span class="dv">28</span>, <span class="dv">28</span>, device<span class="op">=</span>device)</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>logits <span class="op">=</span> model(x)  <span class="co"># Don't call forward() directly!  Call the *model* object.</span></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>prediction <span class="op">=</span> nn.Softmax(dim<span class="op">=</span><span class="dv">1</span>)(logits)  <span class="co"># Convert logits to probabilities</span></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>y_label <span class="op">=</span> prediction.argmax(<span class="dv">1</span>) <span class="co"># Get the predicted class</span></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Logits: </span><span class="sc">{</span>logits<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Prediction probabilities: </span><span class="sc">{</span>prediction<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Predicted class: </span><span class="sc">{</span>y_label<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Logits: tensor([[ 0.0464, -0.0368,  0.0447, -0.0640, -0.0253,  0.0242,  0.0378, -0.1139,
          0.0005,  0.0299]], device='cuda:0', grad_fn=&lt;AddmmBackward0&gt;)
Prediction probabilities: tensor([[0.1052, 0.0968, 0.1050, 0.0942, 0.0979, 0.1029, 0.1043, 0.0896, 0.1005,
         0.1035]], device='cuda:0', grad_fn=&lt;SoftmaxBackward0&gt;)
Predicted class: tensor([0], device='cuda:0')</code></pre>
</div>
</div>
<p>One thing to note is that you should not call the model’s <code>forward()</code> method directly. Instead, when you call the model object like a function (<code>model(x)</code>), it will automatically execute <code>forward()</code> and integrate with PyTorch’s autograd system. The model object’s <code>__call__</code> method calls <code>forward()</code> and performs additional necessary work such as hooks.</p>
</section>
<section id="training" class="level3">
<h3 class="anchored" data-anchor-id="training">3.1.7 Training</h3>
<blockquote class="blockquote">
<p><strong>Challenge</strong>: How can we efficiently train large datasets and complex models?</p>
<p><strong>Researcher’s Concerns</strong>: The performance of deep learning models is greatly affected by the quantity and quality of data, as well as the complexity of the model. However, training large datasets and complex models required a lot of time and computing resources. Stabilizing the training process, preventing overfitting, and finding optimal hyperparameters were also difficult problems. To solve these problems, efficient training algorithms, optimization techniques, and automated training loops were needed.</p>
</blockquote>
<p>After preparing the data and model for training, we perform the actual training. To make the neural network model a good approximator, we need to update the parameters repeatedly. We define a loss function that calculates the difference between labels and predictions and select an optimizer to continuously update the parameters, reducing the error.</p>
<p>The order of training is as follows:</p>
<ol type="1">
<li>Initialize dataset and data loader</li>
<li>Load batch unit data</li>
<li>Calculate prediction values through forward propagation</li>
<li>Calculate errors through loss function</li>
<li>Calculate gradients through backpropagation</li>
<li>Update parameters through optimizer</li>
</ol>
<p>One iteration of the entire dataset is called an epoch, and repeating this process multiple times is called a training loop.</p>
<section id="hyperparameters" class="level5">
<h5 class="anchored" data-anchor-id="hyperparameters">Hyperparameters</h5>
<p>Training requires three key hyperparameters.</p>
<ul>
<li>Number of epochs: determines how many times to repeat the epoch. It’s best to repeat until just before overfitting.</li>
<li>Batch size: the number of training data to pass through the model at once. Passing through all the data is often unrealistic due to GPU memory limits and exponential increases in matrix operation time. We update the model parameters incrementally with some data to approach the optimal value. If the batch size is too small, the change may be too large, making it difficult to approach the minimum value.</li>
<li>Learning rate: adjusts the scale of the updated value. It can be likened to a step size that gradually finds the optimum. Typically, it has a small value. The next chapter explores the relationship between learning rate and optimizer.</li>
</ul>
<div id="cell-48" class="cell" data-execution_count="15">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 3가지 초매개변수</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">32</span></span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">1e-3</span> <span class="co"># 최적화기를 위해 앞서 지정했음.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="training-loop" class="level5">
<h5 class="anchored" data-anchor-id="training-loop">Training Loop</h5>
<p>The training loop proceeds in two stages for each epoch. 1. Training stage: parameter optimization 2. Validation stage: performance evaluation</p>
<p>With the advent of batch normalization in 2015, distinguishing between train() and eval() modes became important. In eval() mode, training-only operations such as batch normalization or dropout are disabled to improve inference speed.</p>
</section>
<section id="loss-function" class="level5">
<h5 class="anchored" data-anchor-id="loss-function">Loss Function</h5>
<p>The loss function is a key element in neural network learning. Since the McCulloch-Pitts neuron model in 1943, various loss functions have been proposed. In particular, the introduction of cross-entropy from information theory in 1989 was an important turning point in the development of deep learning.</p>
</section>
<section id="binary-cross-entropy-bce" class="level5">
<h5 class="anchored" data-anchor-id="binary-cross-entropy-bce">Binary Cross-Entropy (BCE)</h5>
<p>BCE, which is mainly used for binary classification, is defined as follows.</p>
<p><span class="math display">\[\mathcal{L} = - \sum_{i} [y_i \log{x_i} + (1-y_i)\log{(1-x_i)}] \]</span></p>
<p>Here, <span class="math inline">\(y\)</span> is the actual label and <span class="math inline">\(x\)</span> is the model’s prediction value, both of which are in the range [0, 1].</p>
<p>PyTorch provides various loss functions. * <code>nn.MSELoss</code>: for regression problems (Mean Squared Error) * <code>nn.NLLLoss</code>: negative log likelihood * <code>nn.CrossEntropyLoss</code>: a combination of <code>LogSoftmax</code> and <code>NLLLoss</code> * <code>nn.BCEWithLogitsLoss</code>: integrating sigmoid layer and BCE for numerical stability</p>
<p>Notably, <code>nn.BCEWithLogitsLoss</code> integrates the sigmoid layer and BCE for numerical stability. Using the log function has the following advantages (described in more detail in Chapter 2): 1. Mitigating abrupt numerical changes 2. Converting multiplication to addition to improve calculation efficiency</p>
<div id="cell-50" class="cell" data-execution_count="16">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the loss function</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> nn.CrossEntropyLoss()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="optimizer" class="level5">
<h5 class="anchored" data-anchor-id="optimizer">Optimizer</h5>
<p>The optimization algorithm started with the basic gradient descent in the 1950s and made great progress with the emergence of Adam in 2014. <code>torch.optim</code> provides various optimizers, and currently, Adam and AdamW are the mainstream.</p>
<div id="cell-52" class="cell" data-execution_count="17">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Declare the optimizer.</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.SGD(model.parameters(), lr<span class="op">=</span>learning_rate)</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Learning rate scheduler (optional, but often beneficial)</span></span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>scheduler <span class="op">=</span> torch.optim.lr_scheduler.StepLR(optimizer, step_size<span class="op">=</span><span class="dv">30</span>, gamma<span class="op">=</span><span class="fl">0.1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>In the above code, we added a learning rate scheduler using <code>torch.optim.lr_scheduler.StepLR</code>. The learning rate is decreased by multiplying <code>gamma</code> every <code>step_size</code> epoch. Learning rate scheduling can have a big impact on training speed and stability.</p>
</section>
<section id="training-loop-1" class="level5">
<h5 class="anchored" data-anchor-id="training-loop-1">Training Loop</h5>
<p>Let’s construct a training loop that is repeatedly performed for the dataset. One epoch typically consists of two parts: training and validation.</p>
<ol type="1">
<li><strong>Training Loop</strong>: Optimizes parameters using the training dataset.</li>
<li><strong>Validation Loop</strong>: Checks how the model’s performance changes using the test (validation) dataset.</li>
</ol>
<p>During training, the model’s mode can be set to <code>train</code> and <code>eval</code>. This can be thought of as a kind of switch. With the emergence of batch normalization in 2015, the distinction between <code>train()</code> and <code>eval()</code> modes became important. In <code>eval()</code> mode, training-only operations such as batch normalization or dropout are disabled to improve inference speed.</p>
<div id="cell-55" class="cell" data-execution_count="18">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.tensorboard <span class="im">import</span> SummaryWriter</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a><span class="co"># TensorBoard writer setup</span></span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>writer <span class="op">=</span> SummaryWriter(<span class="st">'runs/fashion_mnist_experiment_1'</span>)</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_loop(model, data_loader, loss_fn, optimizer, epoch):  <span class="co"># Added epoch for logging</span></span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a>    model.train()  <span class="co"># Set the model to training mode</span></span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a>    size <span class="op">=</span> <span class="bu">len</span>(data_loader.dataset)  <span class="co"># Total number of data samples</span></span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a>    num_batches <span class="op">=</span> <span class="bu">len</span>(data_loader)</span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a>    total_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch_count, (input_data, label_data) <span class="kw">in</span> <span class="bu">enumerate</span>(data_loader):</span>
<span id="cb48-16"><a href="#cb48-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Move data to the GPU (if available).</span></span>
<span id="cb48-17"><a href="#cb48-17" aria-hidden="true" tabindex="-1"></a>        input_data <span class="op">=</span> input_data.to(device)</span>
<span id="cb48-18"><a href="#cb48-18" aria-hidden="true" tabindex="-1"></a>        label_data <span class="op">=</span> label_data.to(device)</span>
<span id="cb48-19"><a href="#cb48-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-20"><a href="#cb48-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute predictions</span></span>
<span id="cb48-21"><a href="#cb48-21" aria-hidden="true" tabindex="-1"></a>        preds <span class="op">=</span> model(input_data)</span>
<span id="cb48-22"><a href="#cb48-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-23"><a href="#cb48-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute loss</span></span>
<span id="cb48-24"><a href="#cb48-24" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss_fn(preds, label_data)</span>
<span id="cb48-25"><a href="#cb48-25" aria-hidden="true" tabindex="-1"></a>        total_loss <span class="op">+=</span> loss.item()</span>
<span id="cb48-26"><a href="#cb48-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-27"><a href="#cb48-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Backpropagation</span></span>
<span id="cb48-28"><a href="#cb48-28" aria-hidden="true" tabindex="-1"></a>        loss.backward()  <span class="co"># Perform backpropagation</span></span>
<span id="cb48-29"><a href="#cb48-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-30"><a href="#cb48-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Update parameters</span></span>
<span id="cb48-31"><a href="#cb48-31" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb48-32"><a href="#cb48-32" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()  <span class="co"># Zero the gradients before next iteration</span></span>
<span id="cb48-33"><a href="#cb48-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-34"><a href="#cb48-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> batch_count <span class="op">%</span> <span class="dv">100</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb48-35"><a href="#cb48-35" aria-hidden="true" tabindex="-1"></a>            loss, current <span class="op">=</span> loss.item(), batch_count <span class="op">*</span> batch_size <span class="op">+</span> <span class="bu">len</span>(input_data)</span>
<span id="cb48-36"><a href="#cb48-36" aria-hidden="true" tabindex="-1"></a>            <span class="co"># print(f"loss: {loss:&gt;7f}  [{current:&gt;5d}/{size:&gt;5d}]")</span></span>
<span id="cb48-37"><a href="#cb48-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-38"><a href="#cb48-38" aria-hidden="true" tabindex="-1"></a>    avg_train_loss <span class="op">=</span> total_loss <span class="op">/</span> num_batches</span>
<span id="cb48-39"><a href="#cb48-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> avg_train_loss</span>
<span id="cb48-40"><a href="#cb48-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-41"><a href="#cb48-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-42"><a href="#cb48-42" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> eval_loop(model, data_loader, loss_fn):</span>
<span id="cb48-43"><a href="#cb48-43" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()  <span class="co"># Set the model to evaluation mode</span></span>
<span id="cb48-44"><a href="#cb48-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-45"><a href="#cb48-45" aria-hidden="true" tabindex="-1"></a>    correct, test_loss <span class="op">=</span> <span class="fl">0.0</span>, <span class="fl">0.0</span></span>
<span id="cb48-46"><a href="#cb48-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-47"><a href="#cb48-47" aria-hidden="true" tabindex="-1"></a>    size <span class="op">=</span> <span class="bu">len</span>(data_loader.dataset)  <span class="co"># Total data size</span></span>
<span id="cb48-48"><a href="#cb48-48" aria-hidden="true" tabindex="-1"></a>    num_batches <span class="op">=</span> <span class="bu">len</span>(data_loader)  <span class="co"># Number of batches</span></span>
<span id="cb48-49"><a href="#cb48-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-50"><a href="#cb48-50" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():  <span class="co"># Disable gradient calculation within this block</span></span>
<span id="cb48-51"><a href="#cb48-51" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> input_data, label_data <span class="kw">in</span> data_loader:  <span class="co"># No need for enumerate as count is not used</span></span>
<span id="cb48-52"><a href="#cb48-52" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Move data to GPU (if available).</span></span>
<span id="cb48-53"><a href="#cb48-53" aria-hidden="true" tabindex="-1"></a>            input_data <span class="op">=</span> input_data.to(device)</span>
<span id="cb48-54"><a href="#cb48-54" aria-hidden="true" tabindex="-1"></a>            label_data <span class="op">=</span> label_data.to(device)</span>
<span id="cb48-55"><a href="#cb48-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-56"><a href="#cb48-56" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Compute predictions</span></span>
<span id="cb48-57"><a href="#cb48-57" aria-hidden="true" tabindex="-1"></a>            preds <span class="op">=</span> model(input_data)</span>
<span id="cb48-58"><a href="#cb48-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-59"><a href="#cb48-59" aria-hidden="true" tabindex="-1"></a>            test_loss <span class="op">+=</span> loss_fn(preds, label_data).item()</span>
<span id="cb48-60"><a href="#cb48-60" aria-hidden="true" tabindex="-1"></a>            correct <span class="op">+=</span> (preds.argmax(<span class="dv">1</span>) <span class="op">==</span> label_data).<span class="bu">type</span>(torch.<span class="bu">float</span>).<span class="bu">sum</span>().item()</span>
<span id="cb48-61"><a href="#cb48-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-62"><a href="#cb48-62" aria-hidden="true" tabindex="-1"></a>    test_loss <span class="op">/=</span> num_batches</span>
<span id="cb48-63"><a href="#cb48-63" aria-hidden="true" tabindex="-1"></a>    correct <span class="op">/=</span> size</span>
<span id="cb48-64"><a href="#cb48-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-65"><a href="#cb48-65" aria-hidden="true" tabindex="-1"></a>    <span class="co"># print(f"\n Test Result \n Accuracy: {(100 * correct):&gt;0.1f}%, Average loss: {test_loss:&gt;8f} \n")</span></span>
<span id="cb48-66"><a href="#cb48-66" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> test_loss, correct</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="entire-training-process" class="level5">
<h5 class="anchored" data-anchor-id="entire-training-process">Entire Training Process</h5>
<p>The entire training process repeats training and validation for each epoch. It uses <code>tqdm</code> to visually display the progress and TensorBoard to record the change in learning rate.</p>
<div id="cell-57" class="cell" data-execution_count="19">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Progress bar utility</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm.notebook <span class="im">import</span> tqdm</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">5</span>  <span class="co"># Reduced for demonstration</span></span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> tqdm(<span class="bu">range</span>(epochs)):</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ch">\n</span><span class="ss">-------------------------------"</span>)</span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a>    train_loss <span class="op">=</span> train_loop(model, train_dataloader, loss_fn, optimizer, epoch)</span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a>    test_loss, correct <span class="op">=</span> eval_loop(model, test_dataloader, loss_fn)</span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Log training and validation metrics to TensorBoard</span></span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a>    writer.add_scalar(<span class="st">'Loss/train'</span>, train_loss, epoch)</span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a>    writer.add_scalar(<span class="st">'Loss/test'</span>, test_loss, epoch)</span>
<span id="cb49-13"><a href="#cb49-13" aria-hidden="true" tabindex="-1"></a>    writer.add_scalar(<span class="st">'Accuracy/test'</span>, correct, epoch)</span>
<span id="cb49-14"><a href="#cb49-14" aria-hidden="true" tabindex="-1"></a>    writer.add_scalar(<span class="st">'Learning Rate'</span>, optimizer.param_groups[<span class="dv">0</span>][<span class="st">'lr'</span>], epoch) <span class="co"># Log learning rate</span></span>
<span id="cb49-15"><a href="#cb49-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-16"><a href="#cb49-16" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Epoch: </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">, Train Loss: </span><span class="sc">{</span>train_loss<span class="sc">:.4f}</span><span class="ss">, Test Loss: </span><span class="sc">{</span>test_loss<span class="sc">:.4f}</span><span class="ss">, Test Accuracy: </span><span class="sc">{</span>correct<span class="sc">:.2f}</span><span class="ss">%, LR: </span><span class="sc">{</span>optimizer<span class="sc">.</span>param_groups[<span class="dv">0</span>][<span class="st">"lr"</span>]<span class="sc">:.6f}</span><span class="ss">'</span>)</span>
<span id="cb49-17"><a href="#cb49-17" aria-hidden="true" tabindex="-1"></a>    scheduler.step()  <span class="co"># Update learning rate.  Place *after* logging.</span></span>
<span id="cb49-18"><a href="#cb49-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-19"><a href="#cb49-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Done!"</span>)</span>
<span id="cb49-20"><a href="#cb49-20" aria-hidden="true" tabindex="-1"></a>writer.close() <span class="co"># Close TensorBoard Writer</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"84baac2d3bc14a3b960d258d62b7996a","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1
-------------------------------
Epoch: 0, Train Loss: 1.5232, Test Loss: 0.9543, Test Accuracy: 0.71%, LR: 0.001000
Epoch 2
-------------------------------
Epoch: 1, Train Loss: 0.7920, Test Loss: 0.7059, Test Accuracy: 0.76%, LR: 0.001000
Epoch 3
-------------------------------
Epoch: 2, Train Loss: 0.6442, Test Loss: 0.6208, Test Accuracy: 0.78%, LR: 0.001000
Epoch 4
-------------------------------
Epoch: 3, Train Loss: 0.5790, Test Loss: 0.5757, Test Accuracy: 0.79%, LR: 0.001000
Epoch 5
-------------------------------
Epoch: 4, Train Loss: 0.5383, Test Loss: 0.5440, Test Accuracy: 0.80%, LR: 0.001000
Done!</code></pre>
</div>
</div>
<p>This training-validation cycle has been a standard way of training deep learning models since the 1990s, particularly as the validation phase plays an important role in monitoring overfitting and determining early stopping.</p>
</section>
</section>
<section id="model-saving-and-loading" class="level3">
<h3 class="anchored" data-anchor-id="model-saving-and-loading">3.1.8 Model Saving and Loading</h3>
<p>Model saving is a very important part in deep learning practice. The trained model can be saved and reloaded later for reuse or deployed to other environments (e.g., server, mobile device). PyTorch provides two main ways of saving.</p>
<section id="saving-only-weights" class="level5">
<h5 class="anchored" data-anchor-id="saving-only-weights">Saving Only Weights</h5>
<p>The learned parameters (weights and biases) of the model are stored in a Python dictionary called <code>state_dict</code>. The <code>state_dict</code> is a structure that maps each layer to its parameter tensor. This method has the advantage that it can load weights even if the model structure changes, so it is generally recommended.</p>
<div id="cell-60" class="cell" data-execution_count="37">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Save model weights</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>torch.save(model.state_dict(), <span class="st">'model_weights.pth'</span>)</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load weights</span></span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>model_saved_weights <span class="op">=</span> SimpleNetwork()  <span class="co"># Create an empty model with the same architecture</span></span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>model_saved_weights.load_state_dict(torch.load(<span class="st">'model_weights.pth'</span>))</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a>model_saved_weights.to(device) <span class="co"># Don't forget to move to the correct device!</span></span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>model_saved_weights.<span class="bu">eval</span>() <span class="co"># Set to evaluation mode</span></span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Check performance (assuming eval_loop is defined)</span></span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a>eval_loop(model_saved_weights, test_dataloader, loss_fn)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>/tmp/ipykernel_112013/3522135054.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_saved_weights.load_state_dict(torch.load('model_weights.pth'))</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>(0.5459668265935331, 0.8036)</code></pre>
</div>
</div>
</section>
<section id="saving-the-entire-model" class="level5">
<h5 class="anchored" data-anchor-id="saving-the-entire-model">Saving the Entire Model</h5>
<p>Since 2018, as model architectures have become more complex, a method of saving both the model structure and weights together is also used.</p>
<div id="cell-62" class="cell" data-execution_count="38">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>torch.save(model, <span class="st">'model_trained.pth'</span>)</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the entire model</span></span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>model_saved <span class="op">=</span> torch.load(<span class="st">'model_trained.pth'</span>)</span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>model_saved.to(device)  <span class="co"># Move the loaded model to the correct device.</span></span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a>model_saved.<span class="bu">eval</span>() <span class="co">#  Set the loaded model to evaluation mode</span></span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Check performance</span></span>
<span id="cb54-9"><a href="#cb54-9" aria-hidden="true" tabindex="-1"></a>eval_loop(model_saved, test_dataloader, loss_fn)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>/tmp/ipykernel_112013/3185686172.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_saved = torch.load('model_trained.pth')</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="38">
<pre><code>(0.5459668265935331, 0.8036)</code></pre>
</div>
</div>
<p>Storing the entire model can be convenient, but it may cause compatibility issues when the model class definition changes. Especially in production environments, where the model architecture rarely changes, storing only the weights can be more stable. Additionally, storing the entire model uses Python’s <code>pickle</code> module, which has a vulnerability that can execute arbitrary code, making it a security risk.</p>
</section>
<section id="safetensors-a-safer-alternative" class="level5">
<h5 class="anchored" data-anchor-id="safetensors-a-safer-alternative">Safetensors: A Safer Alternative</h5>
<p>Recently, new storage formats like <code>safetensors</code> have emerged to improve security and loading speed instead of <code>pickle</code>. <code>Safetensors</code> is a format for safely and efficiently storing tensor data.</p>
<ul>
<li><strong>Security:</strong> <code>Safetensors</code> does not allow the execution of arbitrary code, making it much safer than <code>pickle</code>.</li>
<li><strong>Zero-copy:</strong> It loads data directly into memory without copying, resulting in fast loading speeds.</li>
<li><strong>Lazy loading:</strong> It can load only the necessary parts, reducing memory usage.</li>
<li><strong>Support for various frameworks</strong>: PyTorch, TensorFlow, JAX, etc.</li>
</ul>
<div id="cell-64" class="cell" data-execution_count="39">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Install safetensors: pip install safetensors</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> safetensors.torch <span class="im">import</span> save_file, load_file</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Save using safetensors</span></span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>state_dict <span class="op">=</span> model.state_dict()</span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a>save_file(state_dict, <span class="st">"model_weights.safetensors"</span>)</span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Load using safetensors</span></span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a>loaded_state_dict <span class="op">=</span> load_file(<span class="st">"model_weights.safetensors"</span>, device<span class="op">=</span>device) <span class="co"># Load directly to the device.</span></span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a>model_new <span class="op">=</span> SimpleNetwork().to(device) <span class="co"># Create an instance of your model class</span></span>
<span id="cb57-12"><a href="#cb57-12" aria-hidden="true" tabindex="-1"></a>model_new.load_state_dict(loaded_state_dict)</span>
<span id="cb57-13"><a href="#cb57-13" aria-hidden="true" tabindex="-1"></a>model_new.<span class="bu">eval</span>()</span>
<span id="cb57-14"><a href="#cb57-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-15"><a href="#cb57-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Check performance</span></span>
<span id="cb57-16"><a href="#cb57-16" aria-hidden="true" tabindex="-1"></a>eval_loop(model_new, test_dataloader, loss_fn)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="39">
<pre><code>(0.5459668265935331, 0.8036)</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="tensorboard" class="level2">
<h2 class="anchored" data-anchor-id="tensorboard">3.2 TensorBoard</h2>
<p>TensorBoard is a tool that records, tracks, and efficiently visualizes various logs generated during deep learning training. It is a type of log data recording/visualization tool, often referred to as a dashboard. Initially developed for TensorFlow, it is now integrated with PyTorch. There are other visualization tools similar to TensorBoard, including:</p>
<ul>
<li>Weights &amp; Biases (WandB): A cloud-based MLOps integrated platform that provides extensive features such as experiment tracking, dataset version management, and model management. It is particularly renowned for its team collaboration features, making it widely used in corporate environments.</li>
<li>Vertex AI: A fully managed ML tool from Google Cloud, offering native integration with BigQuery, Dataproc, and Spark. It enables rapid model building, deployment, and scaling, making it suitable for large-scale ML workflows.</li>
<li>MLflow: An open-source tool that provides experiment tracking, model packaging, and a central registry. It simplifies ML model tracking and deployment, making it widely used in data science and ML fields.</li>
</ul>
<p>There are many other tools besides these three. Here, we will primarily use TensorBoard.</p>
<section id="basic-usage-of-tensorboard" class="level3">
<h3 class="anchored" data-anchor-id="basic-usage-of-tensorboard">3.2.1 Basic Usage of TensorBoard</h3>
<p>TensorBoard emerged in 2015 along with TensorFlow. At that time, the complexity of deep learning models increased rapidly, and the need to effectively monitor the training process arose.</p>
<p>The core features of TensorBoard are as follows: 1. Scalar metric tracking: recording numerical values such as loss and accuracy 2. Model structure visualization: diagramming the computation graph 3. Distribution tracking: observing changes in weight and gradient distributions 4. Embedding projection: 2D/3D visualization of high-dimensional vectors 5. Hyperparameter optimization: comparing experiment results with different settings</p>
<p>TensorBoard is a powerful tool for visualizing and analyzing deep learning training processes. The basic usage of TensorBoard consists of three main steps: installation, log directory setting, and callback setting.</p>
<section id="installation-method" class="level5">
<h5 class="anchored" data-anchor-id="installation-method">Installation Method</h5>
<p>TensorBoard can be installed using pip or conda.</p>
<div id="cell-66" class="cell" data-vscode="{&quot;languageId&quot;:&quot;shellscript&quot;}">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install tensorboard</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 또는</span></span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>conda install <span class="op">-</span>c conda<span class="op">-</span>forge tensorboard</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="log-directory-setting" class="level5">
<h5 class="anchored" data-anchor-id="log-directory-setting">Log Directory Setting</h5>
<p>TensorBoard reads event files stored in the log directory and visualizes them. In Jupyter Notebook or Colab, it is set as follows.</p>
<div id="cell-68" class="cell" data-execution_count="41">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.tensorboard <span class="im">import</span> SummaryWriter</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 로그 디렉토리 설정</span></span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>log_dir <span class="op">=</span> <span class="st">'logs/experiment_1'</span></span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a>writer <span class="op">=</span> SummaryWriter(log_dir)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="running-tensorboard" class="level5">
<h5 class="anchored" data-anchor-id="running-tensorboard">Running TensorBoard</h5>
<p>TensorBoard can be run in two ways.</p>
<ol type="1">
<li>Running from the command line</li>
</ol>
<div id="cell-70" class="cell" data-vscode="{&quot;languageId&quot;:&quot;shellscript&quot;}">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>tensorboard <span class="op">--</span>logdir<span class="op">=</span>logs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<ol start="2" type="1">
<li>Run in Jupyter Notebook</li>
</ol>
<div id="cell-72" class="cell" data-vscode="{&quot;languageId&quot;:&quot;shellscript&quot;}">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>load_ext tensorboard</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>tensorboard <span class="op">--</span>logdir<span class="op">=</span>logs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>After running, you can access the TensorBoard dashboard at http://localhost:6006 in your web browser.</p>
</section>
<section id="running-on-a-remote-server" class="level5">
<h5 class="anchored" data-anchor-id="running-on-a-remote-server">Running on a Remote Server</h5>
<p>When running TensorBoard on a remote server, use SSH tunneling.</p>
<div id="cell-74" class="cell" data-vscode="{&quot;languageId&quot;:&quot;shellscript&quot;}">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>ssh <span class="op">-</span>L <span class="dv">6006</span>:<span class="fl">127.0.0.1</span>:<span class="dv">6006</span> username<span class="op">@</span>server_ip</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><strong>Main Parameters (SummaryWriter)</strong></p>
<p><code>SummaryWriter</code> is a core class that generates data to be recorded in TensorBoard. The main parameters are as follows:</p>
<ul>
<li><code>log_dir</code>: the directory path where log files will be saved.</li>
<li><code>comment</code>: a string to be appended to <code>log_dir</code>.</li>
<li><code>flush_secs</code>: the frequency (in seconds) at which logs are written to disk.</li>
<li><code>max_queue</code>: sets the maximum number of pending events/steps to be stored.</li>
</ul>
<p><strong>Main Methods (SummaryWriter)</strong></p>
<ul>
<li><code>add_scalar(tag, scalar_value, global_step=None)</code>: records a scalar value (e.g., loss, accuracy).</li>
<li><code>add_histogram(tag, values, global_step=None, bins='tensorflow')</code>: records a histogram (value distribution).</li>
<li><code>add_image(tag, img_tensor, global_step=None, dataformats='CHW')</code>: records an image.</li>
<li><code>add_figure(tag, figure, global_step=None, close=True)</code>: records a Matplotlib figure.</li>
<li><code>add_video(tag, vid_tensor, global_step=None, fps=4, dataformats='NCHW')</code>: records a video.</li>
<li><code>add_audio(tag, snd_tensor, global_step=None, sample_rate=44100)</code>: records audio.</li>
<li><code>add_text(tag, text_string, global_step=None)</code>: records text.</li>
<li><code>add_graph(model, input_to_model=None, verbose=False)</code>: records a model graph.</li>
<li><code>add_embedding(mat, metadata=None, label_img=None, global_step=None, tag='default', metadata_header=None)</code>: records an embedding projector.</li>
<li><code>add_hparams(hparam_dict, metric_dict, hparam_domain_discrete=None, run_name=None)</code>: records hyperparameters and their metrics.</li>
<li><code>flush()</code>: writes all pending events to disk.</li>
<li><code>close()</code>: ends logging and releases resources.</li>
</ul>
<p><strong>Main Callback Parameters (TensorFlow/Keras)</strong></p>
<p>When using TensorBoard with TensorFlow/Keras, the <code>tf.keras.callbacks.TensorBoard</code> callback is used. The main parameters are as follows:</p>
<ul>
<li><code>log_dir</code>: the location where logs will be saved.</li>
<li><code>histogram_freq</code>: the frequency (in epochs) at which histograms are computed (0 means no computation). Used to visualize weight, bias, and activation value distributions.</li>
<li><code>write_graph</code>: whether to visualize the model graph.</li>
<li><code>write_images</code>: whether to visualize model weights as images.</li>
<li><code>update_freq</code>: the frequency at which losses and metrics are recorded (‘batch’, ‘epoch’, or an integer).</li>
<li><code>profile_batch</code>: specifies the batch range to profile (e.g., <code>profile_batch='5, 8'</code>). Profiling is useful for finding performance bottlenecks.</li>
<li><code>embeddings_freq</code>: the frequency at which embedding layers are visualized.</li>
<li><code>embeddings_metadata</code>: the path to an embedding metadata file.</li>
</ul>
</section>
</section>
<section id="tensorboards-major-visualization-features" class="level3">
<h3 class="anchored" data-anchor-id="tensorboards-major-visualization-features">3.2.2 TensorBoard’s Major Visualization Features</h3>
<p>TensorBoard can visualize various indicators that occur during the model learning process. The main visualization dashboards include scalars, histograms, distributions, graphs, and embeddings.</p>
<section id="scalar-indicator-visualization" class="level5">
<h5 class="anchored" data-anchor-id="scalar-indicator-visualization">Scalar Indicator Visualization</h5>
<p>The scalar dashboard visualizes changes in numerical indicators such as loss values and accuracy. It can track various statistical values in the model training process, such as learning rates, gradient norms, and average/standard deviation of layer weights. It can also monitor quality evaluation indicators such as FID (Fréchet Inception Distance) scores or QICE (Quantile Interval Coverage Error) in the latest generative models. Through these indicators, it is possible to monitor the model’s learning progress in real-time and detect problems such as overfitting or learning instability early on. Scalar values can be recorded as follows.</p>
<div id="cell-77" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>writer.add_scalar(<span class="st">'Loss/train'</span>, train_loss, step)</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>writer.add_scalar(<span class="st">'Accuracy/train'</span>, train_acc, step)</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a>writer.add_scalar(<span class="st">'Learning/learning_rate'</span>, current_lr, step)</span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a>writer.add_scalar(<span class="st">'Gradients/norm'</span>, grad_norm, step)</span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a>writer.add_scalar(<span class="st">'Quality/fid_score'</span>, fid_score, step)</span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a>writer.add_scalar(<span class="st">'Metrics/qice'</span>, qice_value, step)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="histograms-and-distribution-visualizations" class="level5">
<h5 class="anchored" data-anchor-id="histograms-and-distribution-visualizations">Histograms and Distribution Visualizations</h5>
<p>You can observe the distribution changes of weights and biases. Histograms visually show the distribution of weights, biases, gradients, and activation values for each layer, helping to understand the internal state of the model. In particular, it is very useful for model debugging as it can detect problems such as weights becoming saturated at specific values or gradients vanishing/exploding early in the learning process. Histograms can be logged as follows.</p>
<div id="cell-79" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, param <span class="kw">in</span> model.named_parameters():</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>    writer.add_histogram(<span class="ss">f'Parameters/</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">'</span>, param.data, global_step)</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> param.grad <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a>        writer.add_histogram(<span class="ss">f'Gradients/</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">'</span>, param.grad, global_step)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="model-structure-visualization" class="level5">
<h5 class="anchored" data-anchor-id="model-structure-visualization">Model Structure Visualization</h5>
<p>The model’s structure can be visually confirmed. In particular, the hierarchical structure and connections of complex neural networks can be intuitively grasped. TensorBoard expresses the flow of data, the input/output shape of each layer, the order of operations, etc. in a graphical form through a calculation graph, and detailed information can be reviewed by expanding each node. Recently, it has been especially useful for visualizing complex attention mechanisms, cross-attention layers, and conditional branching structures of Transformers or Diffusion models. This is very useful for model debugging and optimization, and is especially helpful for understanding complex architectures with skip connections or parallel structures. The model graph can be recorded as follows.</p>
<div id="cell-81" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>writer.add_graph(model, input_to_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="embedding-visualization" class="level5">
<h5 class="anchored" data-anchor-id="embedding-visualization">Embedding Visualization</h5>
<p>TensorBoard’s Projector can project high-dimensional embeddings into 2D or 3D space for visualization, which is useful for analyzing the relationship between word embeddings or image feature vectors. It visualizes complex high-dimensional data while preserving cluster structures and relative distances through dimension reduction techniques such as PCA or UMAP. In particular, UMAP preserves both local and global structure well while allowing for fast visualization. This allows you to check how data points with similar characteristics are clustered, whether class distinctions are made well, and track how the feature space changes during training. Embeddings can be recorded as follows.</p>
<div id="cell-83" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>writer.add_embedding(</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>    features,</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>    metadata<span class="op">=</span>labels,</span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a>    label_img<span class="op">=</span>images,</span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a>    global_step<span class="op">=</span>step</span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="hyperparameter-visualization" class="level5">
<h5 class="anchored" data-anchor-id="hyperparameter-visualization">Hyperparameter Visualization</h5>
<p>The results of hyperparameter tuning can be visualized. Not only learning rate, batch size, and dropout ratio, but also structural parameters such as the number of attention heads in Transformer models, prompt length, and token embedding dimensions can be analyzed. Inference parameters such as noise scheduling, sampling step count, and CFG (Classifier-Free Guidance) weights, which are important in the latest LLM or Diffusion models, can also be visualized together. The performance of the model for various hyperparameter combinations is expressed in parallel coordinate graphs or scatter plots to help find the optimal configuration. In particular, it is easy to analyze the effect of interactions between hyperparameters on model performance because multiple experiment results can be compared at a glance. Hyperparameters and related metrics can be recorded as follows.</p>
<div id="cell-85" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>writer.add_hparams(</span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>        <span class="st">'lr'</span>: learning_rate, </span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">'batch_size'</span>: batch_size, </span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">'num_heads'</span>: n_heads,</span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">'cfg_scale'</span>: guidance_scale,</span>
<span id="cb68-7"><a href="#cb68-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">'sampling_steps'</span>: num_steps,</span>
<span id="cb68-8"><a href="#cb68-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">'prompt_length'</span>: max_length</span>
<span id="cb68-9"><a href="#cb68-9" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb68-10"><a href="#cb68-10" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb68-11"><a href="#cb68-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">'accuracy'</span>: accuracy, </span>
<span id="cb68-12"><a href="#cb68-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">'loss'</span>: final_loss,</span>
<span id="cb68-13"><a href="#cb68-13" aria-hidden="true" tabindex="-1"></a>        <span class="st">'fid_score'</span>: fid_score</span>
<span id="cb68-14"><a href="#cb68-14" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb68-15"><a href="#cb68-15" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="image-visualization" class="level5">
<h5 class="anchored" data-anchor-id="image-visualization">Image Visualization</h5>
<p>You can visualize images or intermediate feature maps generated during the learning process. By visualizing the filters and activation maps of convolutional layers, you can intuitively understand what features the model is learning and check which parts of the input image each layer is paying attention to. Especially in latest generation models like Stable Diffusion or DALL-E, it is very useful to visually track changes in the quality of generated images. With the emergence of hybrid models, more sophisticated and realistic image generation has become possible. Images can be recorded as follows.</p>
<div id="cell-87" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 입력 이미지나 생성된 이미지 시각화</span></span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>writer.add_images(<span class="st">'Images/generated'</span>, generated_images, global_step)</span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 디퓨전 모델의 중간 생성 과정 시각화</span></span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a>writer.add_images(<span class="st">'Diffusion/steps'</span>, diffusion_steps, global_step)</span>
<span id="cb69-6"><a href="#cb69-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-7"><a href="#cb69-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 어텐션 맵 시각화</span></span>
<span id="cb69-8"><a href="#cb69-8" aria-hidden="true" tabindex="-1"></a>writer.add_image(<span class="st">'Attention/maps'</span>, attention_visualization, global_step)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Through TensorBoard’s visualization function, you can intuitively understand the model’s learning process and quickly identify problems. In particular, it is useful for early termination of the learning process or hyperparameter adjustment because it can monitor the progress of learning in real time. Embedding visualization is especially useful for understanding the relationship between high-dimensional data, and helps analyze the structure of the feature space learned by the model.</p>
</section>
</section>
<section id="tensorboard-example" class="level3">
<h3 class="anchored" data-anchor-id="tensorboard-example">3.2.3 TensorBoard Example</h3>
<p>This section provides a concrete example of applying the various features of TensorBoard, which were previously discussed, to actual deep learning model training. Using the MNIST handwritten digit dataset, we train a simple CNN (Convolutional Neural Network) model and explain step-by-step how to visualize key indicators and data that occur during training through TensorBoard.</p>
<p><strong>Key Visualization Elements:</strong></p>
<table class="caption-top table">
<colgroup>
<col style="width: 15%">
<col style="width: 76%">
<col style="width: 8%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Visualization Type</th>
<th style="text-align: left;">Visualization Content</th>
<th style="text-align: left;">TensorBoard Tab</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Scalar Metrics</strong></td>
<td style="text-align: left;">Training/test loss, training/test accuracy, learning rate, gradient norm</td>
<td style="text-align: left;">SCALARS</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Histograms/Distributions</strong></td>
<td style="text-align: left;">Weight distributions of all layers, gradient distributions of all layers</td>
<td style="text-align: left;">DISTRIBUTIONS, HISTOGRAMS</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Model Structure</strong></td>
<td style="text-align: left;">Computational graph of the MNIST CNN model</td>
<td style="text-align: left;">GRAPHS</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Feature Maps</strong></td>
<td style="text-align: left;">Feature maps of Conv1 layer, feature maps of Conv2 layer, input image grid, visualization of Conv1 filters</td>
<td style="text-align: left;">IMAGES</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Embeddings</strong></td>
<td style="text-align: left;">32-dimensional feature vectors of FC1 layer, 2D visualization using t-SNE, MNIST image labels</td>
<td style="text-align: left;">PROJECTOR</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Hyperparameters</strong></td>
<td style="text-align: left;">Batch size, learning rate, dropout ratio, optimizer type, weight decay, momentum, scheduler step/gamma</td>
<td style="text-align: left;">HPARAMS</td>
</tr>
</tbody>
</table>
<p><strong>Visualization Frequency:</strong></p>
<ul>
<li>Scalar/histogram: every 50 batches</li>
<li>Feature maps/images: every 50 batches</li>
<li>Embeddings: at the end of each epoch</li>
<li>Hyperparameters: at the start and end of training</li>
</ul>
<p>This example uses the <code>dld</code> package. It imports the necessary modules and starts training. The <code>train()</code> function trains a CNN model on the MNIST dataset with default hyperparameters and logs the training process to TensorBoard. To experiment with different hyperparameters, you can pass an <code>hparams_dict</code> argument to the <code>train()</code> function.</p>
<div id="cell-91" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="co"># In a notebook cell:</span></span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_03.train <span class="im">import</span> train</span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Run with default hyperparameters</span></span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a>train()</span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Run with custom hyperparameters</span></span>
<span id="cb70-8"><a href="#cb70-8" aria-hidden="true" tabindex="-1"></a>my_hparams <span class="op">=</span> {</span>
<span id="cb70-9"><a href="#cb70-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'batch_size'</span>: <span class="dv">128</span>,</span>
<span id="cb70-10"><a href="#cb70-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'learning_rate'</span>: <span class="fl">0.01</span>,</span>
<span id="cb70-11"><a href="#cb70-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">'epochs'</span>: <span class="dv">8</span>,</span>
<span id="cb70-12"><a href="#cb70-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb70-13"><a href="#cb70-13" aria-hidden="true" tabindex="-1"></a>train(hparams_dict<span class="op">=</span>my_hparams, log_dir<span class="op">=</span><span class="st">'runs/my_custom_run'</span>)</span>
<span id="cb70-14"><a href="#cb70-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-15"><a href="#cb70-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Start TensorBoard (in a separate cell, or from the command line)</span></span>
<span id="cb70-16"><a href="#cb70-16" aria-hidden="true" tabindex="-1"></a><span class="co"># %load_ext tensorboard</span></span>
<span id="cb70-17"><a href="#cb70-17" aria-hidden="true" tabindex="-1"></a><span class="co"># %tensorboard --logdir runs</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><strong>Running TensorBoard:</strong></p>
<p>After training is complete, run TensorBoard from the shell using the following command.</p>
<div id="cell-93" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>tensorboard <span class="op">--</span>logdir runs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>You can view the TensorBoard dashboard by accessing <code>http://localhost:6006</code> in your web browser.</p>
<p>You can see that several cards have been created for each item as follows. <img src="../../../assets/images/03_01.png" class="img-fluid" alt="TensorBoard"></p>
<p>In each item, you can check individual values and images. <img src="../../../assets/images/03_02.png" class="img-fluid" alt="TensorBoard"></p>
<p><strong>Utilizing the TensorBoard Dashboard</strong></p>
<ul>
<li><strong>SCALARS tab:</strong> Tracks changes in training/testing loss, accuracy, learning rate, etc. over time. This helps determine if the model is learning well and whether overfitting is occurring.</li>
<li><strong>GRAPHS tab:</strong> Visualizes the model’s computation graph, showing data flow and operations at a glance. This helps understand complex model structures.</li>
<li><strong>DISTRIBUTIONS/HISTOGRAMS tab:</strong> Visualizes weight and gradient distributions. This helps diagnose if weight initialization is proper and whether vanishing or exploding gradients are occurring.</li>
<li><strong>IMAGES tab:</strong> Visualizes input images, feature maps, filters, etc. in image form. This intuitively shows which parts of the image the model is looking at and whether feature extraction is working well.</li>
<li><strong>PROJECTOR tab:</strong> Projects high-dimensional embeddings into 2D/3D for visualization. This helps identify data clustering and outliers.</li>
<li><strong>HPARAMS tab:</strong> Compares experimental results with various hyperparameter combinations, aiding in finding optimal settings.</li>
</ul>
<p>In this example, we looked at how to use TensorBoard to visualize deep learning model training processes. TensorBoard is an essential tool not only for simple visualization but also for understanding model behavior, diagnosing issues, and improving performance.</p>
</section>
</section>
<section id="hugging-face-transformers" class="level2">
<h2 class="anchored" data-anchor-id="hugging-face-transformers">3.3 Hugging Face Transformers</h2>
<p>Hugging Face started in 2016 as a French company that created a chatbot app for teenagers. Initially, it aimed to provide an AI friend for emotional support and entertainment, but it took a significant turn when it open-sourced its chatbot’s NLP model. This coincided with the emergence of high-performance language models like BERT and GPT, which were difficult to utilize at the time, causing a significant stir. The release of the Transformers library in 2019 brought innovation to the field of natural language processing. While PyTorch provides the basic operations and learning framework for deep learning, Hugging Face focused on the implementation and application of actual language models based on it. In particular, it made it easy to share and reuse pre-trained models, making large language models that were once exclusive to a few major companies available to anyone.</p>
<p>Hugging Face has built an open ecosystem, earning it the nickname “AI’s GitHub.” Currently, over 1 million models and tens of thousands of datasets are shared, evolving into a platform for ethical and responsible AI development beyond a simple code repository. The model card system is introduced to specify each model’s limitations and biases, and a community-based feedback system continuously verifies the quality and ethics of models. These efforts have presented a new paradigm for responsible technological advancement beyond democratizing AI development. Hugging Face’s approach balances technical innovation with ethical considerations, making it an exemplary case in modern AI development.</p>
<section id="introduction-to-the-transformers-library" class="level3">
<h3 class="anchored" data-anchor-id="introduction-to-the-transformers-library">3.3.1 Introduction to the Transformers Library</h3>
<p>Transformers provide a unified interface for easily downloading and using pre-trained models. It works on top of frameworks like PyTorch or TensorFlow, ensuring compatibility with existing deep learning ecosystems. Support for new frameworks like JAX has also broadened researchers’ options. The core components of Transformers are largely divided into two parts.</p>
<section id="model-hub-and-pipeline" class="level5">
<h5 class="anchored" data-anchor-id="model-hub-and-pipeline">Model Hub and Pipeline</h5>
<p>The model hub acts as a central repository for pre-trained models. Models specialized in various natural language processing tasks such as text generation, classification, translation, summarization, and question-answering are available. Each model is provided with detailed metadata including performance metrics, license information, and learning data sources. The Model Card system is particularly notable for specifying the limitations and biases of models, encouraging responsible AI development.</p>
<p>The pipeline abstracts complex pre-processing and post-processing steps into a simple interface. This is especially useful in production environments, significantly reducing model integration costs. Internally, pipelines automatically configure tokenizers and models and perform optimizations like batch processing or GPU acceleration.</p>
<div id="cell-96" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a>classifier <span class="op">=</span> pipeline(<span class="st">"sentiment-analysis"</span>)</span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> classifier(<span class="st">"I love this book!"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).
Using a pipeline without specifying a model name and revision in production is not recommended.</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c6703892f09b4ade869f16b776740536","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b5210ba6dfe24216ab409ef41d197c2c","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"cc25443102364b8e96035a7c0218e23b","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4e19048c8971437b82f666267ec92f21","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Device set to use cuda:0</code></pre>
</div>
</div>
</section>
<section id="tokenizer-and-model-class" class="level5">
<h5 class="anchored" data-anchor-id="tokenizer-and-model-class">Tokenizer and Model Class</h5>
<p>The tokenizer converts input text into a numerical sequence that the model can process. Each model has its own dedicated tokenizer, which reflects the characteristics of the training data. The tokenizer consistently handles complex preprocessing beyond simple word separation, including subword tokenization, special token addition, padding, and truncation. In particular, it supports various tokenization algorithms such as WordPiece, BPE, and SentencePiece in an integrated manner, allowing for the selection of the optimal tokenization method suitable for each language and domain.</p>
<p>The model class implements the neural network that performs actual operations. It supports various architectures such as BERT, GPT, and T5, and allows automatic selection of the model architecture through the AutoModel series of classes. Each model is provided with pre-trained weights and can be fine-tuned for specific tasks as needed. Additionally, optimization techniques such as model parallelization, quantization, and pruning can be applied immediately.</p>
<div id="cell-98" class="cell" data-execution_count="43">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoTokenizer, AutoModel</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(<span class="st">"bert-base-uncased"</span>)</span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModel.from_pretrained(<span class="st">"bert-base-uncased"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
</section>
<section id="key-use-cases" class="level3">
<h3 class="anchored" data-anchor-id="key-use-cases">3.3.2 Key Use Cases</h3>
<p>The Transformers library is used for various natural language processing tasks. Since 2020, the advancement of GPT-series models has significantly improved text generation capabilities, and with the emergence of high-performance open-source models like Llama 3 in 2024, the scope of applications has expanded further. In particular, Llama 3’s 405B parameter model shows performance comparable to GPT-4, achieving significant advancements in multilingual processing, coding, and inference capabilities. These developments have enabled various applications in real-world business environments, including customer support, content generation, data analysis, and automated task processing. The improved code generation and debugging capabilities have also contributed to enhanced developer productivity.</p>
<p><strong>Utilizing the Hugging Face Hub:</strong></p>
<p>The Hugging Face Hub (<a href="https://huggingface.co/models">https://huggingface.co/models</a>) is a platform where you can search, filter, and download numerous models and datasets.</p>
<ul>
<li><strong>Model Search:</strong> You can search for models by name (e.g., “bert”, “gpt2”, “t5”) or task (e.g., “text-classification”, “question-answering”) in the top-left search bar.</li>
<li><strong>Filtering:</strong> The left panel allows filtering by task, library, language, dataset, and other criteria.</li>
<li><strong>Model Page:</strong> Each model page provides useful information, including model descriptions, usage examples, performance metrics, and model cards.</li>
</ul>
<p><strong>Text Generation and Classification</strong></p>
<p>Text generation involves creating natural text based on a given prompt. The latest models offer advanced features such as: - Multimodal generation: Creating content that combines text and images - Automated code generation: Writing optimized code in various programming languages - Conversational agents: Implementing intelligent chatbots that understand context - Domain-specific text: Generating documents for specialized domains like medicine or law</p>
<div id="cell-100" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Text generation pipeline (using gpt2 model)</span></span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a>generator <span class="op">=</span> pipeline(<span class="st">'text-generation'</span>, model<span class="op">=</span><span class="st">'gpt2'</span>)  <span class="co"># Smaller model</span></span>
<span id="cb76-5"><a href="#cb76-5" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> generator(<span class="st">"Design a webpage that"</span>, max_length<span class="op">=</span><span class="dv">50</span>, num_return_sequences<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb76-6"><a href="#cb76-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(result[<span class="dv">0</span>][<span class="st">'generated_text'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>Device set to use cuda:0
Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Design a webpage that is compatible with your browser with our FREE SEO Service.

You read that right. By utilizing a web browser's default settings, your webpage should be free from advertisements and other types of spam. The best way to avoid this</code></pre>
</div>
</div>
<p>Text classification will be further refined in 2025, providing the following features:</p>
<ul>
<li>Zero-shot/few-shot learning: Immediate adaptation to new categories is possible through Hugging Face’s Transformer library. In particular, natural language inference-based pre-trained models can achieve over 90% accuracy with fewer than 8 examples and can be applied to various domains.</li>
<li>Multilingual classification: Hugging Face’s ModernBERT and other state-of-the-art multilingual models support more than 16 major languages. In particular, the 150M parameter base model also achieves an F1 score of over 80%, showing excellent performance even in low-resource languages.</li>
<li>Hierarchical classification: Hugging Face’s HiGen framework provides specialized functionality for hierarchical label classification. By capturing the semantic relationship between text and labels through level-based loss functions, it shows high performance, especially in classes with insufficient data.</li>
<li>Real-time classification: Real-time processing of streaming data is possible through Hugging Face pipelines. With optimization techniques like Flash Attention integrated by default, long sequences can be processed efficiently, providing high throughput in real-time applications.</li>
</ul>
<section id="fine-tuning-and-model-sharing" class="level5">
<h5 class="anchored" data-anchor-id="fine-tuning-and-model-sharing">Fine-tuning and Model Sharing</h5>
<p>Hugging Face provides the latest fine-tuning technologies to support efficient learning of large language models. These technologies can greatly reduce learning costs and time while maintaining model performance.</p>
<ul>
<li>QLoRA (Quantized Low-Rank Adaptation): Provided through Hugging Face’s PEFT library, it combines 4-bit quantization and low-rank adaptation to reduce memory usage by over 90%. In particular, fine-tuning of 65B parameter models is possible on a single 48GB GPU.</li>
<li>Spectrum: A selective layer optimization technique integrated with Hugging Face’s TRL library. By analyzing the signal-to-noise ratio of each layer and selectively learning only the important layers, it improves computational efficiency.</li>
<li>Flash Attention: Supported by default from Hugging Face Transformer version 2.2, it can be easily activated with the attn_implementation=“flash_attention_2” parameter. In particular, memory efficiency is greatly improved in long sequence processing.</li>
<li>DeepSpeed: Perfectly integrated through Hugging Face’s Accelerate library, it efficiently supports large-scale distributed learning through the ZeRO optimizer. In particular, it can also be used during inference, allowing large models to be distributed and loaded across multiple GPUs.</li>
</ul>
<div id="cell-102" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer, DataCollatorWithPadding</span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> Dataset</span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb79-5"><a href="#cb79-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-6"><a href="#cb79-6" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 1. Load a pre-trained model and tokenizer ---</span></span>
<span id="cb79-7"><a href="#cb79-7" aria-hidden="true" tabindex="-1"></a>model_name <span class="op">=</span> <span class="st">"distilbert-base-uncased"</span>  <span class="co"># Use a small, fast model</span></span>
<span id="cb79-8"><a href="#cb79-8" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(model_name)</span>
<span id="cb79-9"><a href="#cb79-9" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForSequenceClassification.from_pretrained(model_name, num_labels<span class="op">=</span><span class="dv">2</span>)  <span class="co"># Binary classification</span></span>
<span id="cb79-10"><a href="#cb79-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-11"><a href="#cb79-11" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 2. Create a simple dataset (for demonstration) ---</span></span>
<span id="cb79-12"><a href="#cb79-12" aria-hidden="true" tabindex="-1"></a>raw_data <span class="op">=</span> {</span>
<span id="cb79-13"><a href="#cb79-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">"text"</span>: [</span>
<span id="cb79-14"><a href="#cb79-14" aria-hidden="true" tabindex="-1"></a>        <span class="st">"This is a positive example!"</span>,</span>
<span id="cb79-15"><a href="#cb79-15" aria-hidden="true" tabindex="-1"></a>        <span class="st">"This is a negative example."</span>,</span>
<span id="cb79-16"><a href="#cb79-16" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Another positive one."</span>,</span>
<span id="cb79-17"><a href="#cb79-17" aria-hidden="true" tabindex="-1"></a>        <span class="st">"And a negative one."</span></span>
<span id="cb79-18"><a href="#cb79-18" aria-hidden="true" tabindex="-1"></a>    ],</span>
<span id="cb79-19"><a href="#cb79-19" aria-hidden="true" tabindex="-1"></a>    <span class="st">"label"</span>: [<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>],  <span class="co"># 1 for positive, 0 for negative</span></span>
<span id="cb79-20"><a href="#cb79-20" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb79-21"><a href="#cb79-21" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> Dataset.from_dict(raw_data)</span>
<span id="cb79-22"><a href="#cb79-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-23"><a href="#cb79-23" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 3. Tokenize the dataset ---</span></span>
<span id="cb79-24"><a href="#cb79-24" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tokenize_function(examples):</span>
<span id="cb79-25"><a href="#cb79-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tokenizer(examples[<span class="st">"text"</span>], truncation<span class="op">=</span><span class="va">True</span>) <span class="co">#padding is handled by data collator</span></span>
<span id="cb79-26"><a href="#cb79-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-27"><a href="#cb79-27" aria-hidden="true" tabindex="-1"></a>tokenized_dataset <span class="op">=</span> dataset.<span class="bu">map</span>(tokenize_function, batched<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb79-28"><a href="#cb79-28" aria-hidden="true" tabindex="-1"></a>tokenized_dataset <span class="op">=</span> tokenized_dataset.remove_columns([<span class="st">"text"</span>]) <span class="co"># remove text, keep label</span></span>
<span id="cb79-29"><a href="#cb79-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-30"><a href="#cb79-30" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 4. Data Collator (for dynamic padding) ---</span></span>
<span id="cb79-31"><a href="#cb79-31" aria-hidden="true" tabindex="-1"></a>data_collator <span class="op">=</span> DataCollatorWithPadding(tokenizer<span class="op">=</span>tokenizer)</span>
<span id="cb79-32"><a href="#cb79-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-33"><a href="#cb79-33" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 5. Training Arguments ---</span></span>
<span id="cb79-34"><a href="#cb79-34" aria-hidden="true" tabindex="-1"></a>fp16_enabled <span class="op">=</span> <span class="va">False</span></span>
<span id="cb79-35"><a href="#cb79-35" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> torch.cuda.is_available():</span>
<span id="cb79-36"><a href="#cb79-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb79-37"><a href="#cb79-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> torch.cuda.get_device_capability()[<span class="dv">0</span>] <span class="op">&gt;=</span> <span class="dv">7</span>:</span>
<span id="cb79-38"><a href="#cb79-38" aria-hidden="true" tabindex="-1"></a>            fp16_enabled <span class="op">=</span> <span class="va">True</span></span>
<span id="cb79-39"><a href="#cb79-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span>:</span>
<span id="cb79-40"><a href="#cb79-40" aria-hidden="true" tabindex="-1"></a>        <span class="cf">pass</span></span>
<span id="cb79-41"><a href="#cb79-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-42"><a href="#cb79-42" aria-hidden="true" tabindex="-1"></a>training_args <span class="op">=</span> TrainingArguments(</span>
<span id="cb79-43"><a href="#cb79-43" aria-hidden="true" tabindex="-1"></a>    output_dir<span class="op">=</span><span class="st">"./results"</span>,</span>
<span id="cb79-44"><a href="#cb79-44" aria-hidden="true" tabindex="-1"></a>    num_train_epochs<span class="op">=</span><span class="dv">1</span>,          <span class="co"># Keep it short</span></span>
<span id="cb79-45"><a href="#cb79-45" aria-hidden="true" tabindex="-1"></a>    per_device_train_batch_size<span class="op">=</span><span class="dv">2</span>,  <span class="co"># Small batch size</span></span>
<span id="cb79-46"><a href="#cb79-46" aria-hidden="true" tabindex="-1"></a>    logging_steps<span class="op">=</span><span class="dv">1</span>,           <span class="co"># Log every step</span></span>
<span id="cb79-47"><a href="#cb79-47" aria-hidden="true" tabindex="-1"></a>    save_strategy<span class="op">=</span><span class="st">"no"</span>,         <span class="co"># No saving</span></span>
<span id="cb79-48"><a href="#cb79-48" aria-hidden="true" tabindex="-1"></a>    report_to<span class="op">=</span><span class="st">"none"</span>,          <span class="co"># No reporting</span></span>
<span id="cb79-49"><a href="#cb79-49" aria-hidden="true" tabindex="-1"></a>    fp16<span class="op">=</span>fp16_enabled,  <span class="co"># Use fp16 if avail.</span></span>
<span id="cb79-50"><a href="#cb79-50" aria-hidden="true" tabindex="-1"></a>    <span class="co"># --- Optimization techniques (demonstration) ---</span></span>
<span id="cb79-51"><a href="#cb79-51" aria-hidden="true" tabindex="-1"></a>    <span class="co"># gradient_checkpointing=True,  # Enable gradient checkpointing (if needed for large models)</span></span>
<span id="cb79-52"><a href="#cb79-52" aria-hidden="true" tabindex="-1"></a>    <span class="co"># gradient_accumulation_steps=2, # Increase effective batch size</span></span>
<span id="cb79-53"><a href="#cb79-53" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb79-54"><a href="#cb79-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-55"><a href="#cb79-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-56"><a href="#cb79-56" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 6. Trainer ---</span></span>
<span id="cb79-57"><a href="#cb79-57" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> Trainer(</span>
<span id="cb79-58"><a href="#cb79-58" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model,</span>
<span id="cb79-59"><a href="#cb79-59" aria-hidden="true" tabindex="-1"></a>    args<span class="op">=</span>training_args,</span>
<span id="cb79-60"><a href="#cb79-60" aria-hidden="true" tabindex="-1"></a>    train_dataset<span class="op">=</span>tokenized_dataset,</span>
<span id="cb79-61"><a href="#cb79-61" aria-hidden="true" tabindex="-1"></a>    <span class="co"># eval_dataset=...,  # Add an eval dataset if you have one</span></span>
<span id="cb79-62"><a href="#cb79-62" aria-hidden="true" tabindex="-1"></a>    data_collator<span class="op">=</span>data_collator,  <span class="co"># Use the data collator</span></span>
<span id="cb79-63"><a href="#cb79-63" aria-hidden="true" tabindex="-1"></a>    <span class="co"># optimizers=(optimizer, scheduler) # you could also customize optimizer</span></span>
<span id="cb79-64"><a href="#cb79-64" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb79-65"><a href="#cb79-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-66"><a href="#cb79-66" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 7. Train ---</span></span>
<span id="cb79-67"><a href="#cb79-67" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Starting training..."</span>)</span>
<span id="cb79-68"><a href="#cb79-68" aria-hidden="true" tabindex="-1"></a>trainer.train()</span>
<span id="cb79-69"><a href="#cb79-69" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Training finished!"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ad7aa580feaf4d5fa3abcd96b1bc43e3","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"24731acb95cb4dbea5d194f768b17df3","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ee9456452ccb4910849e2973a1765462","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"688ecbdc102a4cc6b562c911f79851c0","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"62d43521fee04e07a6ce10a5488d2b38","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c2522a9d78974c45beeb8575e3c29e85","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Starting training...</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/sean/anaconda3/envs/DL/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(</code></pre>
</div>
<div class="cell-output cell-output-display">

    <div>
      
      <progress value="1" max="1" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [1/1 00:00, Epoch 1/1]
    </div>
    
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">Step</th>
<th data-quarto-table-cell-role="th">Training Loss</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>0.667500</td>
</tr>
</tbody>
</table>
<p>
</p></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training finished!</code></pre>
</div>
</div>
<p>The model sharing ecosystem currently supports the following latest features as of 2025. - Model card auto-generation: Hugging Face’s automated model card system automatically analyzes and documents performance metrics and bias. In particular, it can clearly describe the characteristics and limitations of the model in a standardized format through the Model Card Toolkit. - Version management: The Git-based version management system on Hugging Face Hub tracks the change history and performance changes of models. It can automatically record and compare performance metrics and parameter changes for each version. - Collaboration tools: It provides an integrated collaboration environment with Hugging Face Spaces. Team members can share and feedback on model development, testing, and deployment processes in real-time, and also support integration with CI/CD pipelines. - Ethical AI: Through Hugging Face’s ethical AI framework, it automatically verifies and evaluates the bias of models. In particular, it can analyze performance differences for various demographic groups and identify potential risks in advance.</p>
</section>
</section>
</section>
<section id="practice-problems" class="level2">
<h2 class="anchored" data-anchor-id="practice-problems">Practice Problems</h2>
<p><strong>1. Basic Problems</strong></p>
<ul>
<li>Explain the differences between PyTorch tensors and NumPy arrays, and how to convert between them.</li>
<li>Describe the role of the <code>torch.nn.Linear</code> layer and how to initialize its weights.</li>
<li>Explain how automatic differentiation works in PyTorch and the role of the <code>requires_grad</code> attribute.</li>
</ul>
<p><strong>2. Applied Problems</strong></p>
<ul>
<li>Write code to split a given dataset into training, validation, and test sets using <code>torch.utils.data.Dataset</code> and <code>torch.utils.data.DataLoader</code>, and load data in batches.</li>
<li>Implement a simple CNN model (e.g., LeNet-5) by inheriting from <code>nn.Module</code>, and use <code>torchsummary</code> to check the model’s structure and number of parameters.</li>
<li>Train a model using the MNIST or Fashion-MNIST dataset, and visualize the training process (loss, accuracy, etc.) using TensorBoard.</li>
</ul>
<p><strong>3. Advanced Problems</strong></p>
<ul>
<li>Implement matrix multiplication, transposition, batch matrix multiplication, and bilinear transformation using <code>torch.einsum</code>. (Provide Einstein notation for each operation and implement it in PyTorch code.)</li>
<li>Create a custom dataset and apply data augmentation using <code>torchvision.transforms</code>. (e.g., image rotation, cropping, color conversion)</li>
<li>Explain how to calculate higher-order derivatives using <code>torch.autograd.grad</code> and provide a simple example code. (e.g., calculating the Hessian matrix)</li>
<li>Explain why the <code>forward()</code> method of <code>torch.nn.Module</code> is not called directly, but instead, the model object is called as a function. (Hint: relationship between the <code>__call__</code> method and the automatic differentiation system)</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled" title="Click to view contents (answer)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Click to view contents (answer)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<section id="practice-problem-solutions" class="level2 callout-body-container callout-body">
<h2 class="anchored" data-anchor-id="practice-problem-solutions">Practice Problem Solutions</h2>
<section id="basic-problem-solutions" class="level3">
<h3 class="anchored" data-anchor-id="basic-problem-solutions">1. Basic Problem Solutions</h3>
<ol type="1">
<li><strong>Tensor vs.&nbsp;NumPy Array:</strong>
<ul>
<li><strong>Difference:</strong> Tensors support GPU acceleration and automatic differentiation. NumPy arrays are CPU-based general-purpose array operations.</li>
<li><strong>Conversion:</strong> <code>torch.from_numpy()</code>, <code>.numpy()</code> (note: for GPU tensors, use <code>.cpu()</code> first).</li>
</ul>
<div class="sourceCode" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example</span></span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a>numpy_array <span class="op">=</span> np.array([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>])</span>
<span id="cb84-5"><a href="#cb84-5" aria-hidden="true" tabindex="-1"></a>torch_tensor <span class="op">=</span> torch.from_numpy(numpy_array)  <span class="co"># or torch.tensor()</span></span>
<span id="cb84-6"><a href="#cb84-6" aria-hidden="true" tabindex="-1"></a>numpy_back <span class="op">=</span> torch_tensor.cpu().numpy()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><strong><code>nn.Linear</code>:</strong>
<ul>
<li><strong>Role:</strong> <code>y = xW^T + b</code> (linear transformation). It multiplies input <code>x</code> by weight <code>W</code> and adds bias <code>b</code>.</li>
<li><strong>Initialization:</strong> Default is Kaiming He initialization (uniform distribution). Can be changed using the <code>torch.nn.init</code> module.</li>
</ul>
<div class="sourceCode" id="cb85"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example</span></span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.init <span class="im">as</span> init</span>
<span id="cb85-4"><a href="#cb85-4" aria-hidden="true" tabindex="-1"></a>linear_layer <span class="op">=</span> nn.Linear(in_features<span class="op">=</span><span class="dv">10</span>, out_features<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb85-5"><a href="#cb85-5" aria-hidden="true" tabindex="-1"></a>init.xavier_uniform_(linear_layer.weight) <span class="co"># Xavier initialization</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><strong>Autograd (Automatic Differentiation):</strong>
<ul>
<li><strong>Operation:</strong> When <code>requires_grad=True</code>, tensor operations create a computation graph, and <code>.backward()</code> calculates gradients using the chain rule.</li>
<li><strong><code>requires_grad</code>:</strong> Sets whether to calculate and track gradients.</li>
</ul>
<div class="sourceCode" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example</span></span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="fl">2.0</span>], requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> x<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> <span class="dv">3</span><span class="op">*</span>x <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a>y.backward()</span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.grad)  <span class="co"># Output: tensor([7.])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ol>
</section>
<section id="applied-problem-solutions" class="level3">
<h3 class="anchored" data-anchor-id="applied-problem-solutions">2. Applied Problem Solutions</h3>
<ol start="4" type="1">
<li><p><strong><code>Dataset</code>, <code>DataLoader</code>:</strong></p>
<div class="sourceCode" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset, DataLoader, random_split</span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.transforms <span class="im">as</span> transforms</span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets</span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-5"><a href="#cb87-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Custom Dataset (example)</span></span>
<span id="cb87-6"><a href="#cb87-6" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> CustomDataset(Dataset):</span>
<span id="cb87-7"><a href="#cb87-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, data, targets, transform<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb87-8"><a href="#cb87-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.data <span class="op">=</span> data</span>
<span id="cb87-9"><a href="#cb87-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.targets <span class="op">=</span> targets</span>
<span id="cb87-10"><a href="#cb87-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.transform <span class="op">=</span> transform</span>
<span id="cb87-11"><a href="#cb87-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb87-12"><a href="#cb87-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.data)</span>
<span id="cb87-13"><a href="#cb87-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, idx):</span>
<span id="cb87-14"><a href="#cb87-14" aria-hidden="true" tabindex="-1"></a>        sample, label <span class="op">=</span> <span class="va">self</span>.data[idx], <span class="va">self</span>.targets[idx]</span>
<span id="cb87-15"><a href="#cb87-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.transform:</span>
<span id="cb87-16"><a href="#cb87-16" aria-hidden="true" tabindex="-1"></a>            sample <span class="op">=</span> <span class="va">self</span>.transform(sample)</span>
<span id="cb87-17"><a href="#cb87-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> sample, label</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<h1 id="mnist-dataloader-example-using-torchvision">MNIST DataLoader Example (using torchvision)</h1>
<p>transform = transforms.ToTensor() # convert image data to tensor mnist_dataset = datasets.MNIST(root=‘./data’, train=True, download=True, transform=transform) train_size = int(0.8 * len(mnist_dataset)) val_size = len(mnist_dataset) - train_size train_dataset, val_dataset = random_split(mnist_dataset, [train_size, val_size]) train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True) val_loader = DataLoader(val_dataset, batch_size=32)</p></li>
</ol>
<pre><code>
5.  **LeNet-5, `torchsummary`, TensorBoard:** (full code is in the previous answer, here's only the key part)

```python
import torch.nn as nn
import torch.nn.functional as F
from torchsummary import summary
from torch.utils.tensorboard import SummaryWriter

# LeNet-5 model
class LeNet5(nn.Module):
    def __init__(self):
        super(LeNet5, self).__init__()
        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2)
        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)
        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)
        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = self.pool1(x)
        x = F.relu(self.conv2(x))
        x = self.pool2(x)
        x = x.view(x.size(0), -1)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

model = LeNet5()
summary(model, input_size=(1, 28, 28)) # model structure summary

# ... (training code, see previous answer) ...

writer = SummaryWriter() # TensorBoard
# ... (log with writer.add_scalar() during training) ...
writer.close()</code></pre>
</section>
<section id="advanced-problem-solutions" class="level3">
<h3 class="anchored" data-anchor-id="advanced-problem-solutions">3. Advanced Problem Solutions</h3>
<ol start="6" type="1">
<li><strong><code>torch.einsum</code>:</strong></li>
</ol>
<div class="sourceCode" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>A = torch.randn(3, 4) B = torch.randn(4, 5) C = torch.einsum(“ij,jk-&gt;ik”, A, B) # matrix multiplication D = torch.einsum(“ij-&gt;ji”, A) # transpose E = torch.einsum(“bi,bj,ijk-&gt;bk”, A, B, torch.randn(2,3,4)) # bilinear transformation ```</p>
<ol start="7" type="1">
<li><p><strong>Custom dataset, data augmentation:</strong></p>
<div class="sourceCode" id="cb90"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset</span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> transforms</span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb90-5"><a href="#cb90-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-6"><a href="#cb90-6" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> CustomImageDataset(Dataset): <span class="co"># inherit from Dataset</span></span>
<span id="cb90-7"><a href="#cb90-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, root_dir, transform<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb90-8"><a href="#cb90-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ... (constructor implementation) ...</span></span>
<span id="cb90-9"><a href="#cb90-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">pass</span></span>
<span id="cb90-10"><a href="#cb90-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb90-11"><a href="#cb90-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ... (return the number of data) ...</span></span>
<span id="cb90-12"><a href="#cb90-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">pass</span></span>
<span id="cb90-13"><a href="#cb90-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, idx):</span>
<span id="cb90-14"><a href="#cb90-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ... (return the sample corresponding to idx) ...</span></span>
<span id="cb90-15"><a href="#cb90-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">pass</span></span>
<span id="cb90-16"><a href="#cb90-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-17"><a href="#cb90-17" aria-hidden="true" tabindex="-1"></a><span class="co"># data augmentation</span></span>
<span id="cb90-18"><a href="#cb90-18" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb90-19"><a href="#cb90-19" aria-hidden="true" tabindex="-1"></a>    transforms.RandomResizedCrop(<span class="dv">224</span>),  <span class="co"># random size and ratio cropping</span></span>
<span id="cb90-20"><a href="#cb90-20" aria-hidden="true" tabindex="-1"></a>    transforms.RandomHorizontalFlip(),     <span class="co"># horizontal flip</span></span>
<span id="cb90-21"><a href="#cb90-21" aria-hidden="true" tabindex="-1"></a>    transforms.ToTensor(),              <span class="co"># convert to tensor</span></span>
<span id="cb90-22"><a href="#cb90-22" aria-hidden="true" tabindex="-1"></a>    transforms.Normalize(mean<span class="op">=</span>[<span class="fl">0.485</span>, <span class="fl">0.456</span>, <span class="fl">0.406</span>], std<span class="op">=</span>[<span class="fl">0.229</span>, <span class="fl">0.224</span>, <span class="fl">0.225</span>]) <span class="co"># normalization</span></span>
<span id="cb90-23"><a href="#cb90-23" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb90-24"><a href="#cb90-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-25"><a href="#cb90-25" aria-hidden="true" tabindex="-1"></a><span class="co"># dataset = CustomImageDataset(root_dir='path/to/images', transform=transform)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p><strong>Higher-order functions:</strong></p>
<div class="sourceCode" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor(<span class="fl">2.0</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> x<span class="op">**</span><span class="dv">3</span></span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-6"><a href="#cb91-6" aria-hidden="true" tabindex="-1"></a><span class="co"># first derivative</span></span>
<span id="cb91-7"><a href="#cb91-7" aria-hidden="true" tabindex="-1"></a>first_derivative <span class="op">=</span> torch.autograd.grad(y, x, create_graph<span class="op">=</span><span class="va">True</span>)[<span class="dv">0</span>]  <span class="co"># create_graph=True</span></span>
<span id="cb91-8"><a href="#cb91-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(first_derivative)</span>
<span id="cb91-9"><a href="#cb91-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-10"><a href="#cb91-10" aria-hidden="true" tabindex="-1"></a><span class="co"># second derivative (hessian)</span></span>
<span id="cb91-11"><a href="#cb91-11" aria-hidden="true" tabindex="-1"></a>second_derivative <span class="op">=</span> torch.autograd.grad(first_derivative, x)[<span class="dv">0</span>]</span>
<span id="cb91-12"><a href="#cb91-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(second_derivative)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p><strong><code>__call__</code> method:</strong></p></li>
</ol>
<p>The <code>__call__</code> method of <code>nn.Module</code> performs additional tasks (such as hook registration and automatic differentiation settings) before and after calling <code>forward()</code>. Simply calling <code>forward()</code> directly may omit these features, resulting in incorrect gradient calculations or malfunctioning of other model features (e.g., setting the <code>training</code> attribute of <code>nn.Module</code>). Therefore, you <em>must</em> call the model object like a function (<code>model(input)</code>).</p>
</section>
</section>
</div>
</div>
<p><strong>Reference Materials</strong></p>
<ol type="1">
<li><strong>PyTorch Official Tutorial:</strong> <a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://pytorch.org/tutorials/">https://pytorch.org/tutorials/</a></li>
<li><strong>Deep Learning with PyTorch (Stevens, Antiga, Viehmann, 2020):</strong> <a href="https://www.google.com/search?q=https://pytorch.org/deep-learning-with-pytorch">https://pytorch.org/deep-learning-with-pytorch</a></li>
<li><strong>Programming PyTorch for Deep Learning (Delugach, 2023):</strong> <a href="https://www.google.com/search?q=https://www.oreilly.com/library/view/programming-pytorch-for/9781098142481/">https://www.oreilly.com/library/view/programming-pytorch-for/9781098142481/</a></li>
<li><strong>PyTorch Recipes (Kalyan, 2019):</strong> <a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://pytorch.org/tutorials/recipes/recipes_index.html">https://pytorch.org/tutorials/recipes/recipes_index.html</a></li>
<li><strong>Understanding the difficulty of training deep feedforward neural networks (Glorot &amp; Bengio, 2010):</strong> <a href="http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf">http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf</a></li>
<li><strong>Fastai library:</strong> <a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://docs.fast.ai/">https://docs.fast.ai/</a></li>
<li><strong>PyTorch Lightning:</strong> <a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://www.pytorchlightning.ai/">https://www.pytorchlightning.ai/</a></li>
<li><strong>Hugging Face Transformers documentation:</strong> <a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://huggingface.co/docs/transformers/index">https://huggingface.co/docs/transformers/index</a></li>
<li><strong>TensorBoard documentation:</strong> <a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://www.tensorflow.org/tensorboard">https://www.tensorflow.org/tensorboard</a></li>
<li><strong>Weights &amp; Biases documentation:</strong> <a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://docs.wandb.ai/">https://docs.wandb.ai/</a></li>
</ol>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>