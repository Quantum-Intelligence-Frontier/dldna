<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>der-anfang-des-deep-learnings – Deep Learning DNA: Surviving Architectures and Essential Principles</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-f507c7d0488cb7630e20aad62ad8c2aa.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script>window.MathJax = {loader: {load: ['[tex]/boldsymbol']},tex: {packages: {'[+]': ['boldsymbol']}}};</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../notebooks/de/part_1/01_Der Anfang des Deep Learnings.html">part_1</a></li><li class="breadcrumb-item"><a href="../../../notebooks/de/part_1/01_Der Anfang des Deep Learnings.html">1. Der Anfang des Deep Learnings</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../../">Deutsch</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Language</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index_de.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Deutsch</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index_en.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">English</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index_es.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Español</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">한국어</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index_zh.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">中文</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/de/part_1/00_Einführung.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Einführung</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">part_1</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/de/part_1/01_Der Anfang des Deep Learnings.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">1. Der Anfang des Deep Learnings</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#der-anfang-des-deep-learnings-grundlegende-prinzipien-und-der-kontext-der-technologischen-evolution" id="toc-der-anfang-des-deep-learnings-grundlegende-prinzipien-und-der-kontext-der-technologischen-evolution" class="nav-link active" data-scroll-target="#der-anfang-des-deep-learnings-grundlegende-prinzipien-und-der-kontext-der-technologischen-evolution">1. Der Anfang des Deep Learnings: Grundlegende Prinzipien und der Kontext der technologischen Evolution</a>
  <ul class="collapse">
  <li><a href="#das-ziel-dieses-buches" id="toc-das-ziel-dieses-buches" class="nav-link" data-scroll-target="#das-ziel-dieses-buches">1.1 Das Ziel dieses Buches</a></li>
  <li><a href="#geschichte-des-deep-learnings" id="toc-geschichte-des-deep-learnings" class="nav-link" data-scroll-target="#geschichte-des-deep-learnings">1.2 Geschichte des Deep Learnings</a></li>
  <li><a href="#hebbian-learning" id="toc-hebbian-learning" class="nav-link" data-scroll-target="#hebbian-learning">1.3 Hebbian Learning</a>
  <ul class="collapse">
  <li><a href="#hebbian-learning-regel" id="toc-hebbian-learning-regel" class="nav-link" data-scroll-target="#hebbian-learning-regel">1.3.1 Hebbian Learning Regel</a></li>
  <li><a href="#beziehung-zur-gehirnplastizität" id="toc-beziehung-zur-gehirnplastizität" class="nav-link" data-scroll-target="#beziehung-zur-gehirnplastizität">1.3.2 Beziehung zur Gehirnplastizität</a></li>
  </ul></li>
  <li><a href="#neuronale-netze-nn-neural-network" id="toc-neuronale-netze-nn-neural-network" class="nav-link" data-scroll-target="#neuronale-netze-nn-neural-network">1.4 Neuronale Netze (NN, Neural Network)</a>
  <ul class="collapse">
  <li><a href="#grundstruktur-von-neuronalen-netzen" id="toc-grundstruktur-von-neuronalen-netzen" class="nav-link" data-scroll-target="#grundstruktur-von-neuronalen-netzen">1.4.1 Grundstruktur von neuronalen Netzen</a></li>
  <li><a href="#vorhersage-von-hauspreisen-mit-linearen-approximatoren-linear-approximator" id="toc-vorhersage-von-hauspreisen-mit-linearen-approximatoren-linear-approximator" class="nav-link" data-scroll-target="#vorhersage-von-hauspreisen-mit-linearen-approximatoren-linear-approximator">1.4.2 Vorhersage von Hauspreisen mit linearen Approximatoren (linear approximator)</a></li>
  <li><a href="#der-weg-zu-neuronalen-netzen-prozess-der-matrixoperationen" id="toc-der-weg-zu-neuronalen-netzen-prozess-der-matrixoperationen" class="nav-link" data-scroll-target="#der-weg-zu-neuronalen-netzen-prozess-der-matrixoperationen">1.4.3 Der Weg zu neuronalen Netzen: Prozess der Matrixoperationen</a></li>
  <li><a href="#implementierung-mit-numpy" id="toc-implementierung-mit-numpy" class="nav-link" data-scroll-target="#implementierung-mit-numpy">1.3.4 Implementierung mit NumPy</a></li>
  </ul></li>
  <li><a href="#tiefgang-neuronale-netze" id="toc-tiefgang-neuronale-netze" class="nav-link" data-scroll-target="#tiefgang-neuronale-netze">1.5 Tiefgang neuronale Netze</a>
  <ul class="collapse">
  <li><a href="#struktur-tiefgangiger-neuronaler-netze" id="toc-struktur-tiefgangiger-neuronaler-netze" class="nav-link" data-scroll-target="#struktur-tiefgangiger-neuronaler-netze">1.5.1 Struktur tiefgangiger neuronaler Netze</a></li>
  </ul></li>
  <li><a href="#implementierung-neuronaler-netze" id="toc-implementierung-neuronaler-netze" class="nav-link" data-scroll-target="#implementierung-neuronaler-netze">1.5.2 Implementierung neuronaler Netze</a>
  <ul class="collapse">
  <li><a href="#neuronale-netzwerke-trainieren" id="toc-neuronale-netzwerke-trainieren" class="nav-link" data-scroll-target="#neuronale-netzwerke-trainieren">1.5.3 Neuronale Netzwerke trainieren</a></li>
  </ul></li>
  <li><a href="#übungen" id="toc-übungen" class="nav-link" data-scroll-target="#übungen">Übungen</a>
  <ul class="collapse">
  <li><a href="#grundlagenaufgaben" id="toc-grundlagenaufgaben" class="nav-link" data-scroll-target="#grundlagenaufgaben">1. Grundlagenaufgaben</a></li>
  <li><a href="#anwendungsaufgaben" id="toc-anwendungsaufgaben" class="nav-link" data-scroll-target="#anwendungsaufgaben">2. Anwendungsaufgaben</a></li>
  <li><a href="#fortgeschrittene-aufgaben" id="toc-fortgeschrittene-aufgaben" class="nav-link" data-scroll-target="#fortgeschrittene-aufgaben">3. Fortgeschrittene Aufgaben</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../notebooks/de/part_1/01_Der Anfang des Deep Learnings.html">part_1</a></li><li class="breadcrumb-item"><a href="../../../notebooks/de/part_1/01_Der Anfang des Deep Learnings.html">1. Der Anfang des Deep Learnings</a></li></ol></nav></header>




<p><a href="https://colab.research.google.com/github/Quantum-Intelligence-Frontier/dldna/blob/main/notebooks/de/part_1/01_Die_Anfänge_des_Tiefen_Lernens.ipynb" target="_parent"> <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="In Colab öffnen"> </a></p>
<section id="der-anfang-des-deep-learnings-grundlegende-prinzipien-und-der-kontext-der-technologischen-evolution" class="level1">
<h1>1. Der Anfang des Deep Learnings: Grundlegende Prinzipien und der Kontext der technologischen Evolution</h1>
<p><strong>Der Beginn der Erforschung der DNA des Deep Learnings</strong></p>
<blockquote class="blockquote">
<p>“Echte technologische Innovationen entstehen aus den Misserfolgen der Vergangenheit” - Geoffrey Hinton, Turing-Preis-Auftritt 2018</p>
</blockquote>
<section id="das-ziel-dieses-buches" class="level2">
<h2 class="anchored" data-anchor-id="das-ziel-dieses-buches">1.1 Das Ziel dieses Buches</h2>
<p>Deep Learning ist ein Bereich des Maschinelles Lernens, der mit erstaunlichen Ergebnissen und einem schnellen Fortschritt verbunden ist. Es sind Modelle wie GPT-4 und Gemini aufgetaucht, und es gibt sowohl Erwartungen als auch Bedenken bezüglich allgemeiner künstlicher Intelligenz (AGI). Während Forschungspapiere und Technologien rasch fortschreiten, haben selbst Experten Schwierigkeiten, Schritt zu halten.</p>
<p>Diese Situation ist vergleichbar mit der Zeit Ende der 1980er Jahre, als PCs und Programmiersprachen populär wurden. Damals erschienen zahlreiche Technologien, doch am Ende bildeten nur wenige Kerntechnologien die Grundlage des modernen Computings. Ähnlich wie damals werden auch heute unter den verschiedenen Deep-Learning-Architekturen wie Neuronalen Netzen, CNNs, RNNs, Transformatoren, Diffusion und Multimodalitäten <strong>nur wenige, die ein wesentliches DNA-Element teilen, das Fundament der KI bilden und weiterhin entwickelt werden.</strong></p>
<p>Dieses Buch beginnt aus dieser Perspektive. Es konzentriert sich weniger auf einfache API-Nutzung, grundlegende Theorien oder Beispiele und analysiert stattdessen die <strong>DNA des technologischen Fortschritts</strong>. Vom McCulloch-Pitts-Neuronenmodell von 1943 bis zur neuesten Multimodalarchitektur von 2025, <em>als ob es sich um einen Evolutionsprozess handelt</em>, fokussiert es sich auf den <strong>Hintergrund</strong>, die zu lösenden <strong>wesentlichen Probleme</strong> und die <strong>Verbindung zu vorherigen Technologien</strong>. Es zeichnet also eine Art Stammbaum der Deep-Learning-Technologie auf. In Abschnitt 1.2 wird dieser Inhalt kurz zusammengefasst.</p>
<p>Zu diesem Zweck hat dieses Buch folgende Merkmale:</p>
<ul>
<li><strong>Erklärung aus DNA-Perspektive:</strong> Es geht nicht nur um die Aufzählung von Technologien, sondern darum, warum jede Technologie <em>entstanden ist</em>, welches <em>Problem</em> sie lösen sollte und in welcher <em>Beziehung</em> sie zu früheren Technologien steht, also das technologische <em>Phylogenie</em>.</li>
<li><strong>Knappe aber tiefschürfende Erklärungen:</strong> Es hilft dabei, Kernkonzepte und Prinzipien klar zu verstehen, ohne unnötige Details aufzunehmen.</li>
<li><strong>Berücksichtigung neuester technologischer Entwicklungen:</strong> Es umfasst die neuesten Technologien bis 2025 (z. B. Retentive Networks, Mixture of Experts, Multimodal Models) und behandelt den vordersten Bereich der Deep-Learning-Entwicklung.</li>
<li><strong>Brücke zwischen Praxis und Forschung:</strong> Es bietet eine ausgewogene Darstellung von praktischen Codebeispielen und mathematischer Intuition, um Theorie und Praxis zu verbinden.</li>
<li><strong>Erweiterte Beispiele</strong>: Nicht nur funktionierende Codes, sondern auch entwickelte Beispiele, die sofort in Forschung oder Entwicklung angewendet werden können.</li>
</ul>
<p>Dadurch soll sowohl Praktikern als auch Forschern bei der Erhöhung ihrer Expertise geholfen werden. Zudem sollen ethische und soziale Auswirkungen von KI-Technologien sowie Überlegungen zur technologischen Demokratisierung ebenfalls thematisiert werden.</p>
</section>
<section id="geschichte-des-deep-learnings" class="level2">
<h2 class="anchored" data-anchor-id="geschichte-des-deep-learnings">1.2 Geschichte des Deep Learnings</h2>
<blockquote class="blockquote">
<p><strong>Herausforderung:</strong> Wie kann man Maschinen dazu bringen, wie Menschen zu denken und zu lernen?</p>
<p><strong>Forscherfrust:</strong> Das Nachahmen der komplexen Funktionsweise des menschlichen Gehirns war eine extrem schwierige Aufgabe. Frühe Forscher hingen von einfachen regelbasierten Systemen oder begrenzten Wissensdatenbanken ab, was jedoch die Vielfalt und Komplexität der realen Welt nur unzureichend verarbeitete. Um ein wirklich intelligentes System zu schaffen, war es notwendig, dass es aus Daten lernen, komplexe Muster erkennen und abstrakte Konzepte verstehen konnte. Die Implementierung dieser Fähigkeiten stellte den Kern der Herausforderung dar.</p>
</blockquote>
<p>Die Geschichte des Deep Learnings begann 1943 mit Warren McCulloch und Walter Pitts, die das <strong>McCulloch-Pitts-Neuron</strong>, ein mathematisches Modell zur Erklärung der Funktionsweise von Neuronen, präsentierten. Dies definierte die grundlegenden Bestandteile von neuronalen Netzen. 1949 stellte Donald Hebb das <strong>Hebb’sche Lernen</strong> vor und erläuterte so das Grundprinzip des Anpassens der Synapsengewichte, also des Lernens. 1958 war Franks Rosenblatts Perzeptron das erste praktische neuronale Netz, stieß jedoch an die Grenzen bei nicht-linearen Klassifizierungen wie dem XOR-Problem.</p>
<p>Die 1980er Jahre brachten wichtige Durchbrüche. 1980 schlug Kunihiko Fukushima den <strong>Neocognitron (Grundlage des Faltungsprinzips)</strong> vor, der später die Kernidee für CNNs wurde. Der wichtigste Fortschritt war die Entwicklung des <strong>Rückpropagationsalgorithmus</strong> im Jahr 1986 durch Geoffrey Hinton und sein Team. Dieser Algorithmus ermöglichte das effektive Lernen in mehrschichtigen neuronalen Netzen und etablierte sich als <em>Kern des neuronale Netzwerklernens</em>. 2006 schlug Hinton den Begriff “Deep Learning” vor, was einen neuen Meilenstein markierte.</p>
<p>Seither wuchs Deep Learning dank der Entwicklung von großen Datenmengen und Rechenleistung stark. 2012 gewann AlexNet bei der ImageNet-Konkurrenz mit überlegener Leistung und bewies die Praktikabilität des Deep Learnings. Danach kamen innovative Architekturen wie <strong>LSTM (1997)</strong> aus der Familie der <strong>Recurrent Networks</strong> und das <strong>Attention-Mechanismus (2014)</strong> zum Einsatz. Besonders 2017s <strong>Transformer von Google</strong> revolutionierte die Paradigmen der natürlichen Sprachverarbeitung. <em>Durch Self-Attention wurden die einzelnen Teile einer Eingabe-Sequenz direkt miteinander verbunden, was das Problem langer Abhängigkeiten löste</em>.</p>
<p>Auf Basis des Transformers entstanden BERT und die GPT-Reihe, wodurch die Leistung der Sprachmodelle sprunghaft verbessert wurde. 2021 kam der <strong>Vision Transformer (ViT)</strong> hinzu, durch den sich der Transformer erfolgreich auf Bildverarbeitung anwenden ließ und die Entwicklung von <strong>Multimodal Learning</strong> beschleunigte.</p>
<p>Kürzlich erhöhen riesige Sprachmodelle wie GPT-4 und Gemini die Erwartungen bezüglich der Realisierbarkeit von AGI. Diese nutzen fortgeschrittene Architekturen wie <strong>Retentive Networks (2023)</strong>, Effizienztechnologien wie <strong>FlashAttention (nach 2023)</strong> und Techniken wie <strong>Mixture of Experts (MoE) (2024)</strong>, um noch raffinierter zu werden. Darüber hinaus entwickeln sich <strong>Multimodal</strong>-Modelle, die verschiedene Formen von Daten wie Text, Bild und Audio integriert verarbeiten können (z.B., Gemini Ultra 2.0 im Jahr 2024 und Gemini 2.0 im Jahr 2025), was über einfache Frage-Antwort-Szenarien hinausgehende hochwertige kognitive Fähigkeiten wie Inferenz, Kreativität und Problemlösung ermöglicht.</p>
<p>Die Entwicklung des Deep Learnings basiert auf folgenden Kernkomponenten. 1. Erhöhung der Verfügbarkeit von großen Datenmengen 2. Entwicklung von Hochleistungsrechenressourcen wie GPUs 3. Entwicklung effizienter Lernalgorithmen und Architekturen, wie <strong>Backpropagation, Attention, Transformer</strong> sowie <strong>Core Architecture</strong>, <strong>Generative Models</strong></p>
<p>Diese Fortschritte setzen sich fort, es gibt jedoch immer noch Herausforderungen zu meistern. Die Erklärbarkeit von Modellen (Interpretability), die Daten-effiziente Arbeit, der Energieverbrauch und die Weiterentwicklung von <strong>Efficiency &amp; Advanced Concepts</strong> sind wichtige Aufgaben.</p>
<p>Im Folgenden ist ein technisches DNA-Stammbaum zur Visualisierung dargestellt.</p>
<div id="cell-3" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 2025 Deep Learning Technology DNA Tree (Multimodal Updated)</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> anytree <span class="im">import</span> Node, RenderTree</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># ==== Core Mathematical Foundations &amp; Algorithms ====</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>root <span class="op">=</span> Node(<span class="st">"1943: McCulloch-Pitts Neuron"</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>math_lineage <span class="op">=</span> Node(<span class="st">"Mathematical Foundations &amp; Algorithms"</span>, parent<span class="op">=</span>root)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>hebbian <span class="op">=</span> Node(<span class="st">"1949: Hebbian Learning"</span>, parent<span class="op">=</span>math_lineage)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>backprop <span class="op">=</span> Node(<span class="st">"1986: Backpropagation (Rumelhart, Hinton, Williams)"</span>, parent<span class="op">=</span>math_lineage)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>neuroplasticity <span class="op">=</span> Node(<span class="st">"1958: Cortical Plasticity Theory (Mountcastle)"</span>, parent<span class="op">=</span>math_lineage)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>sparsity <span class="op">=</span> Node(<span class="st">"2023: Sparse Symbolic Representations (DeepMind)"</span>, parent<span class="op">=</span>backprop)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>liquid_clocks <span class="op">=</span> Node(<span class="st">"2024: Liquid Time-constant Networks"</span>, parent<span class="op">=</span>sparsity)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>dynamic_manifolds <span class="op">=</span> Node(<span class="st">"2025: Dynamic Neural Manifolds"</span>, parent<span class="op">=</span>liquid_clocks)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co"># ==== Core Architecture ====</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>core_arch <span class="op">=</span> Node(<span class="st">"Core Architecture"</span>, parent<span class="op">=</span>root)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>conv_principle <span class="op">=</span> Node(<span class="st">"1980: Convolution Principle (Neocognitron - Fukushima)"</span>, parent<span class="op">=</span>core_arch)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>attention <span class="op">=</span> Node(<span class="st">"2014: Attention Mechanism (Bahdanau)"</span>, parent<span class="op">=</span>core_arch)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>transformer <span class="op">=</span> Node(<span class="st">"2017: Transformer (Vaswani)"</span>, parent<span class="op">=</span>attention)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>retentive_net <span class="op">=</span> Node(<span class="st">"2023: Retentive Networks (Microsoft)"</span>, parent<span class="op">=</span>transformer)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>hybrid_ssm <span class="op">=</span> Node(<span class="st">"2024: Hybrid State-Space Models"</span>, parent<span class="op">=</span>retentive_net)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="co"># ==== Computer Vision ====</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>cv_lineage <span class="op">=</span> Node(<span class="st">"Computer Vision"</span>, parent<span class="op">=</span>root)</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>lenet <span class="op">=</span> Node(<span class="st">"1998: LeNet-5 (LeCun)"</span>, parent<span class="op">=</span>cv_lineage)</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>alexnet <span class="op">=</span> Node(<span class="st">"2012: AlexNet (Krizhevsky)"</span>, parent<span class="op">=</span>lenet)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>resnet <span class="op">=</span> Node(<span class="st">"2015: ResNet (He)"</span>, parent<span class="op">=</span>alexnet)</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>vision_transformer <span class="op">=</span> Node(<span class="st">"2021: ViT (Vision Transformer) (Dosovitskiy)"</span>, parent<span class="op">=</span>resnet)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>vit22b <span class="op">=</span> Node(<span class="st">"2023: ViT-22B (Google)"</span>, parent<span class="op">=</span>vision_transformer)</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>masked_autoenc <span class="op">=</span> Node(<span class="st">"2024: MAE v3 (Meta)"</span>, parent<span class="op">=</span>vit22b)</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>vit40b <span class="op">=</span> Node(<span class="st">"2025: ViT-40B (Google/Sydney)"</span>, parent<span class="op">=</span>masked_autoenc)</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>efficient_vit <span class="op">=</span> Node(<span class="st">"2025: EfficientViT-XXL"</span>, parent<span class="op">=</span>vit40b)</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="co"># ==== NLP ====</span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>nlp_lineage <span class="op">=</span> Node(<span class="st">"NLP"</span>, parent<span class="op">=</span>root)</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>word2vec <span class="op">=</span> Node(<span class="st">"2013: Word2Vec (Mikolov)"</span>, parent<span class="op">=</span>nlp_lineage)</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>bert <span class="op">=</span> Node(<span class="st">"2018: BERT (Devlin)"</span>, parent<span class="op">=</span>word2vec)</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>gpt3 <span class="op">=</span> Node(<span class="st">"2020: GPT-3 (OpenAI)"</span>, parent<span class="op">=</span>bert)</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>gpt5 <span class="op">=</span> Node(<span class="st">"2023: GPT-5 (OpenAI)"</span>, parent<span class="op">=</span>gpt3)</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>gpt55_turbo <span class="op">=</span> Node(<span class="st">"2024: GPT-5.5 Turbo"</span>, parent<span class="op">=</span>gpt5)</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>gpt6 <span class="op">=</span> Node(<span class="st">"2025: GPT-6 (Multimodal Agent)"</span>, parent<span class="op">=</span>gpt55_turbo)</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a><span class="co"># ==== Multimodal Learning ====</span></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>mm_lineage <span class="op">=</span> Node(<span class="st">"Multimodal Learning"</span>, parent<span class="op">=</span>root)</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>clip <span class="op">=</span> Node(<span class="st">"2021: CLIP (OpenAI)"</span>, parent<span class="op">=</span>mm_lineage)</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>flamingo <span class="op">=</span> Node(<span class="st">"2022: Flamingo (DeepMind)"</span>, parent<span class="op">=</span>clip)</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>kosmos <span class="op">=</span> Node(<span class="st">"2023: Kosmos-2.5 (Microsoft)"</span>, parent<span class="op">=</span>flamingo)</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>gemini <span class="op">=</span> Node(<span class="st">"2024: Gemini Ultra 2.0 (Google)"</span>, parent<span class="op">=</span>kosmos)</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>gemini_multiverse <span class="op">=</span> Node(<span class="st">"2025: Gemini Multiverse (Google)"</span>, parent<span class="op">=</span>gemini)</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>project_starline <span class="op">=</span> Node(<span class="st">"2025: Project Starline 2.0 (3D Multimodal)"</span>, parent<span class="op">=</span>gemini_multiverse)</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a><span class="co"># ==== Generative Models ====</span></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>gen_lineage <span class="op">=</span> Node(<span class="st">"Generative Models"</span>, parent<span class="op">=</span>root)</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>vae <span class="op">=</span> Node(<span class="st">"2013: VAE (Kingma)"</span>, parent<span class="op">=</span>gen_lineage)</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>gan <span class="op">=</span> Node(<span class="st">"2014: GAN (Goodfellow)"</span>, parent<span class="op">=</span>vae)</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>stylegan <span class="op">=</span> Node(<span class="st">"2018: StyleGAN (Karras)"</span>, parent<span class="op">=</span>gan)</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>diffusion <span class="op">=</span> Node(<span class="st">"2020: Diffusion Models (Ho)"</span>, parent<span class="op">=</span>stylegan)</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>sdxl_turbo <span class="op">=</span> Node(<span class="st">"2023: SDXL-Turbo (Stability AI)"</span>, parent<span class="op">=</span>diffusion)</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>meta3d_diff <span class="op">=</span> Node(<span class="st">"2024: Meta 3D Diffusion"</span>, parent<span class="op">=</span>sdxl_turbo)</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>holo_gen <span class="op">=</span> Node(<span class="st">"2025: HoloGen (Neural Holography)"</span>, parent<span class="op">=</span>meta3d_diff)</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a><span class="co"># ==== Reinforcement Learning ====</span></span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>rl_lineage <span class="op">=</span> Node(<span class="st">"Reinforcement Learning"</span>, parent<span class="op">=</span>root)</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>tdlearn <span class="op">=</span> Node(<span class="st">"1988: TD Learning (Sutton)"</span>, parent<span class="op">=</span>rl_lineage)</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>dqn <span class="op">=</span> Node(<span class="st">"2013: DQN (DeepMind)"</span>, parent<span class="op">=</span>tdlearn)</span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>alphago <span class="op">=</span> Node(<span class="st">"2016: AlphaGo (Silver)"</span>, parent<span class="op">=</span>dqn)</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>muzero <span class="op">=</span> Node(<span class="st">"2019: MuZero (DeepMind)"</span>, parent<span class="op">=</span>alphago)</span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>robot_transformer <span class="op">=</span> Node(<span class="st">"2023: RT-2 (Google)"</span>, parent<span class="op">=</span>muzero)</span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>agentic_cortex <span class="op">=</span> Node(<span class="st">"2024: Agentic Cortex (DeepMind)"</span>, parent<span class="op">=</span>robot_transformer)</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>autogpt5 <span class="op">=</span> Node(<span class="st">"2025: AutoGPT-5 (Fully Autonomous Agent)"</span>, parent<span class="op">=</span>agentic_cortex)</span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a><span class="co"># ==== Efficiency &amp; Advanced Concepts ====</span></span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a>eff_lineage <span class="op">=</span> Node(<span class="st">"Efficiency &amp; Advanced Concepts"</span>, parent<span class="op">=</span>root)</span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>flash_attn3 <span class="op">=</span> Node(<span class="st">"2023: FlashAttention-v3"</span>, parent<span class="op">=</span>eff_lineage)</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>moa <span class="op">=</span> Node(<span class="st">"2024: MoA (Mixture of Agents)"</span>, parent<span class="op">=</span>flash_attn3)</span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>nas3 <span class="op">=</span> Node(<span class="st">"2025: Neural Architecture Search 3.0"</span>, parent<span class="op">=</span>moa)</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a><span class="co"># ==== Print Tree Structure ====</span></span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"2025 Neural Network Evolution Tree:</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> pre, _, node <span class="kw">in</span> RenderTree(root):</span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>pre<span class="sc">}{</span>node<span class="sc">.</span>name<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>2025 Neural Network Evolution Tree:

1943: McCulloch-Pitts Neuron
├── Mathematical Foundations &amp; Algorithms
│   ├── 1949: Hebbian Learning
│   ├── 1986: Backpropagation (Rumelhart, Hinton, Williams)
│   │   └── 2023: Sparse Symbolic Representations (DeepMind)
│   │       └── 2024: Liquid Time-constant Networks
│   │           └── 2025: Dynamic Neural Manifolds
│   └── 1958: Cortical Plasticity Theory (Mountcastle)
├── Core Architecture
│   ├── 1980: Convolution Principle (Neocognitron - Fukushima)
│   └── 2014: Attention Mechanism (Bahdanau)
│       └── 2017: Transformer (Vaswani)
│           └── 2023: Retentive Networks (Microsoft)
│               └── 2024: Hybrid State-Space Models
├── Computer Vision
│   └── 1998: LeNet-5 (LeCun)
│       └── 2012: AlexNet (Krizhevsky)
│           └── 2015: ResNet (He)
│               └── 2021: ViT (Vision Transformer) (Dosovitskiy)
│                   └── 2023: ViT-22B (Google)
│                       └── 2024: MAE v3 (Meta)
│                           └── 2025: ViT-40B (Google/Sydney)
│                               └── 2025: EfficientViT-XXL
├── NLP
│   └── 2013: Word2Vec (Mikolov)
│       └── 2018: BERT (Devlin)
│           └── 2020: GPT-3 (OpenAI)
│               └── 2023: GPT-5 (OpenAI)
│                   └── 2024: GPT-5.5 Turbo
│                       └── 2025: GPT-6 (Multimodal Agent)
├── Multimodal Learning
│   └── 2021: CLIP (OpenAI)
│       └── 2022: Flamingo (DeepMind)
│           └── 2023: Kosmos-2.5 (Microsoft)
│               └── 2024: Gemini Ultra 2.0 (Google)
│                   └── 2025: Gemini Multiverse (Google)
│                       └── 2025: Project Starline 2.0 (3D Multimodal)
├── Generative Models
│   └── 2013: VAE (Kingma)
│       └── 2014: GAN (Goodfellow)
│           └── 2018: StyleGAN (Karras)
│               └── 2020: Diffusion Models (Ho)
│                   └── 2023: SDXL-Turbo (Stability AI)
│                       └── 2024: Meta 3D Diffusion
│                           └── 2025: HoloGen (Neural Holography)
├── Reinforcement Learning
│   └── 1988: TD Learning (Sutton)
│       └── 2013: DQN (DeepMind)
│           └── 2016: AlphaGo (Silver)
│               └── 2019: MuZero (DeepMind)
│                   └── 2023: RT-2 (Google)
│                       └── 2024: Agentic Cortex (DeepMind)
│                           └── 2025: AutoGPT-5 (Fully Autonomous Agent)
└── Efficiency &amp; Advanced Concepts
    └── 2023: FlashAttention-v3
        └── 2024: MoA (Mixture of Agents)
            └── 2025: Neural Architecture Search 3.0</code></pre>
</div>
</div>
</section>
<section id="hebbian-learning" class="level2">
<h2 class="anchored" data-anchor-id="hebbian-learning">1.3 Hebbian Learning</h2>
<p>Nachdem Warren McCulloch und Walter Pitts 1943 ihr Modell des künstlichen Neurons (McCulloch-Pitts-Neuron) vorgestellt hatten, stellte der kanadische Psychologe Donald O. Hebb 1949 in seinem Buch “The Organization of Behavior” die grundlegenden Prinzipien des neuronalen Lernens vor. Dieses Prinzip wird als <strong>Hebbsche Regel (Hebb’s Rule)</strong> oder <strong>Hebbian Learning</strong> bezeichnet und hat erheblichen Einfluss auf die Forschung zu künstlichen Neuronen, einschließlich Deep Learning, gehabt.</p>
<section id="hebbian-learning-regel" class="level3">
<h3 class="anchored" data-anchor-id="hebbian-learning-regel">1.3.1 Hebbian Learning Regel</h3>
<p>Der Kerngedanke des Hebbian Learnings ist sehr einfach. Wenn zwei Neuronen gleichzeitig oder wiederholt aktiviert werden, dann erhöht sich die Stärke ihrer Verbindung. Umgekehrt, wenn zwei Neuronen zu unterschiedlichen Zeiten aktiviert werden oder ein Neuron aktiv und das andere inaktiv bleibt, verringert sich die Verbindungsstärke oder verschwindet.</p>
<p>Dies kann mathematisch wie folgt ausgedrückt werden:</p>
<p><span class="math display">\[
\Delta w_{ij} = \eta \cdot x_i \cdot y_j
\]</span></p>
<p>Dabei gilt:</p>
<ul>
<li><span class="math inline">\(\Delta w_{ij}\)</span> ist die Änderung der Verbindungsstärke (Gewicht) zwischen Neuron <span class="math inline">\(i\)</span> und Neuron <span class="math inline">\(j\)</span>.</li>
<li><span class="math inline">\(\eta\)</span> ist die Lernrate (learning rate), eine Konstante, die den Umfang der Veränderung der Verbindungskraft steuert.</li>
<li><span class="math inline">\(x_i\)</span> ist der Aktivierungswert (Eingabe) von Neuron <span class="math inline">\(i\)</span>.</li>
<li><span class="math inline">\(y_j\)</span> ist der Aktivierungswert (Ausgabe) von Neuron <span class="math inline">\(j\)</span>.</li>
</ul>
<p>Diese Gleichung zeigt, dass die Verbindungsstärke zunimmt (<span class="math inline">\(\Delta w_{ij}\)</span> positiv), wenn beide Neuronen aktiv sind (<span class="math inline">\(x_i\)</span> und <span class="math inline">\(y_j\)</span> beide positiv). Umgekehrt, wenn nur eines der beiden Neuronen aktiv ist oder beide inaktiv bleiben, verringert sich die Verbindungskraft oder bleibt unverändert. Hebbian Learning ist eine der frühen Formen des <strong>nichtüberwachten Lernens (unsupervised learning)</strong>. Das bedeutet, dass das neuronale Netzwerk ohne vorgegebene Lösungen (Labels) aus den Mustern in den Eingabedaten lernt und die Verbindungskräfte selbst anpasst.</p>
</section>
<section id="beziehung-zur-gehirnplastizität" class="level3">
<h3 class="anchored" data-anchor-id="beziehung-zur-gehirnplastizität">1.3.2 Beziehung zur Gehirnplastizität</h3>
<p>Hebbian Learning geht über eine einfache mathematische Regel hinaus und bietet wichtige Einblicke in die Funktionsweise des menschlichen Gehirns. Das Gehirn verändert sich ständig durch Erfahrungen und Lernen, was als <strong>Gehirnplastizität (brain plasticity)</strong> oder <strong>neuronale Plastizität (neural plasticity)</strong> bezeichnet wird. Hebbian Learning spielt eine zentrale Rolle bei der Erklärung von <strong>synaptischer Plastizität (synaptic plasticity)</strong>, einer Form der neuronalen Plastizität. Synapsen sind die Verbindungspunkte zwischen Neuronen und entscheiden über die Effizienz der Informationsübertragung. Hebbian Learning verdeutlicht das grundlegende Prinzip der synaptischen Plastizität, nämlich dass <strong>“Neuronen, die zusammen aktiviert werden, auch zusammen verbindet sind”</strong>. Langfristige Potenzierung (Long-Term Potentiation, LTP) und langfristige Depression (Long-Term Depression, LTD) sind wichtige Beispiele für synaptische Plastizität. LTP beschreibt das Phänomen der Stärkung von Synapsenverbindungen gemäß der Hebbschen Regel, während LTD das entgegengesetzte Phänomen darstellt. LTP und LTD spielen eine entscheidende Rolle beim Lernen, Gedächtnis und der Entwicklung des Gehirns.</p>
</section>
</section>
<section id="neuronale-netze-nn-neural-network" class="level2">
<h2 class="anchored" data-anchor-id="neuronale-netze-nn-neural-network">1.4 Neuronale Netze (NN, Neural Network)</h2>
<p>Neuronale Netze sind Funktionen-Approximatoren, die Eingaben entgegennehmen und Werte erzeugen, die möglichst nahe am gewünschten Ausgang liegen. Mathematisch wird dies durch <span class="math inline">\(f_\theta\)</span> dargestellt, wobei <span class="math inline">\(f\)</span> die Funktion und <span class="math inline">\(\theta\)</span> die Parameter darstellen, die aus Gewichten (weight) und Bias bestehen. Der Kern von neuronalen Netzen liegt darin, dass sie in der Lage sind, diese Parameter automatisch auf Basis von Daten zu lernen.</p>
<p>Das erste neuronale Netz wurde 1944 von Warren McCullough und Walter Pitts vorgeschlagen und war von biologischen Neuronen inspiriert. Moderne neuronale Netze sind jedoch reine mathematische Modelle. In der Tat sind neuronale Netze leistungsstarke mathematische Werkzeuge, die in der Lage sind, stetige Funktionen zu approximieren, wie durch den Universal Approximation Theorem bewiesen wurde.</p>
<section id="grundstruktur-von-neuronalen-netzen" class="level3">
<h3 class="anchored">1.4.1 Grundstruktur von neuronalen Netzen</h3>
<p>Neuronale Netze haben eine hierarchische Struktur, die aus Eingangsschicht, verborgenen Schichten und Ausgangsschicht besteht. Jede Schicht besteht aus Knoten (Neuronen), die miteinander verbunden sind, um Informationen weiterzuleiten. Im Grunde bestehen neuronale Netze aus einer Kombination von linearen Transformationen und nichtlinearen Aktivierungsfunktionen.</p>
<p>Mathematisch gesehen führt jede Schicht eines neuronalen Netzwerks eine lineare Transformation wie folgt durch:</p>
<p><span class="math display">\[ y = Wx + b \]</span></p>
<p>Dabei sind:</p>
<ul>
<li><span class="math inline">\(x\)</span> der Eingabevektor</li>
<li><span class="math inline">\(W\)</span> die Gewichtsmatrix</li>
<li><span class="math inline">\(b\)</span> der Biasvektor</li>
<li><span class="math inline">\(y\)</span> der Ausgabevektor</li>
</ul>
<p>Diese Struktur mag einfach erscheinen, aber ein neuronales Netz mit ausreichend Neuronen und Schichten kann jede stetige Funktion mit beliebiger Genauigkeit approximieren. Dies ist der Grund, warum neuronale Netze in der Lage sind, komplexe Muster zu lernen und eine Vielzahl von Problemen zu lösen.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Klicken Sie hier, um den Inhalt anzuzeigen (Deep Dive: Universal Approximation Theorem)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Klicken Sie hier, um den Inhalt anzuzeigen (Deep Dive: Universal Approximation Theorem)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<section id="universelle-approximationssatz" class="level2 callout-body-container callout-body">
<h2 class="anchored" data-anchor-id="universelle-approximationssatz">Universelle Approximationssatz</h2>
<blockquote class="blockquote">
<p><strong>Herausforderung:</strong> Wie kann man beweisen, dass neuronale Netze tatsächlich jede beliebig komplexe Funktion approximieren können?</p>
<p><strong>Forscherfrust:</strong> Obwohl neuronale Netze viele Schichten und Neuronen haben können, war es nicht offensichtlich, ob sie tatsächlich <em>jede</em> stetige Funktion darstellen können. Es gab Bedenken, dass sie nur die Kombination einfacher linearer Transformationen sind, die möglicherweise nicht ausreichen, um komplexe Nichtlinearitäten zu repräsentieren. Die Abhängigkeit von rein empirischen Ergebnissen ohne theoretische Garantien war ein großes Hindernis für die Entwicklung der neuronalen Netzforschung.</p>
</blockquote>
<p><strong>Universeller Approximationssatz (Universal Approximation Theorem)</strong></p>
<p>Der Universelle Approximationssatz ist eine zentrale Theorie, die die starke Darstellungskraft von neuronalen Netzen stützt. Dieser Satz beweist, dass ein <em>ein-schichtiges neuronales Netz mit ausreichend breiter verborgener Schicht</em> jede beliebige stetige Funktion mit der gewünschten Genauigkeit approximieren kann.</p>
<p><strong>Kernideen:</strong></p>
<ul>
<li><strong>Nichtlineare Aktivierungsfunktionen:</strong> Nichtlineare Aktivierungsfunktionen wie ReLU, Sigmoid und tanh sind ein wesentlicher Bestandteil, der es neuronalen Netzen ermöglicht, Nichtlinearitäten darzustellen. Ohne diese Aktivierungsfunktionen wären beliebig viele Schichten nur die Kombination linearer Transformationen.</li>
<li><strong>Ausreichend breite verborgene Schicht:</strong> Wenn eine verborgene Schicht ausreichend viele Neuronen hat, besitzt das neuronale Netz die “Flexibilität”, um beliebige komplexe Funktionen darzustellen. Ähnlich wie es möglich ist, mit genügend vielen Teilen ein Mosaikbild in jeder gewünschten Form zu erstellen.</li>
</ul>
<p><strong>Mathematische Darstellung:</strong></p>
<p><strong>Satz (Universeller Approximationssatz):</strong></p>
<p>Sei <span class="math inline">\(f : K \rightarrow \mathbb{R}\)</span> eine beliebige stetige Funktion, die auf einer beschränkten abgeschlossenen Menge (compact set) <span class="math inline">\(K \subset \mathbb{R}^d\)</span> definiert ist. Für jedes gegebene Fehlerlimit <span class="math inline">\(\epsilon &gt; 0\)</span> existiert ein <em>ein-schichtiges neuronales Netz</em> <span class="math inline">\(F(x)\)</span>, das die folgende Bedingung erfüllt.</p>
<p><span class="math inline">\(|f(x) - F(x)| &lt; \epsilon\)</span>, für alle <span class="math inline">\(x \in K\)</span>.</p>
<p>Hier hat <span class="math inline">\(F(x)\)</span> die folgende Form:</p>
<p><span class="math inline">\(F(x) = \sum_{i=1}^{N} w_i \cdot \sigma(v_i^T x + b_i)\)</span></p>
<p><strong>Ausführliche Erklärung:</strong></p>
<ul>
<li><p><strong><span class="math inline">\(f : K \rightarrow \mathbb{R}\)</span>:</strong></p>
<ul>
<li><span class="math inline">\(f\)</span> ist die zu approximierende Zielfunktion (target function).</li>
<li><span class="math inline">\(K\)</span> ist das <em>Definitionsbereich (domain)</em> der Funktion, eine <em>beschränkte abgeschlossene Menge (compact set)</em> in <span class="math inline">\(\mathbb{R}^d\)</span> (d-dimensionalen reellen Raum). In praktischen Situationen stellt dies oft keine große Einschränkung dar, da die meisten realen Eingabedaten einen begrenzten Bereich haben.</li>
<li><span class="math inline">\(\mathbb{R}\)</span> ist die Menge der reellen Zahlen. Die Funktion <span class="math inline">\(f\)</span> ordnet jedem Punkt in <span class="math inline">\(K\)</span> (<span class="math inline">\(x\)</span>) einen reellen Wert (<span class="math inline">\(f(x)\)</span>) zu. (Für mehrdimensionale Funktionen und mehrere Ausgänge siehe unten.)</li>
</ul></li>
<li><p><strong><span class="math inline">\(\epsilon &gt; 0\)</span>:</strong> Ein beliebiger positiver Wert, der die <em>Genauigkeit</em> der Approximation darstellt. Je kleiner <span class="math inline">\(\epsilon\)</span> ist, desto genauer ist die Approximation.</p></li>
<li><p><strong><span class="math inline">\(|f(x) - F(x)| &lt; \epsilon\)</span>:</strong> Für alle <span class="math inline">\(x \in K\)</span>, bedeutet dies, dass der Unterschied zwischen dem tatsächlichen Funktionswert <span class="math inline">\(f(x)\)</span> und dem Output des neuronalen Netzes <span class="math inline">\(F(x)\)</span> kleiner als <span class="math inline">\(\epsilon\)</span> ist. Dies zeigt, dass das neuronale Netz die Funktion <span class="math inline">\(f\)</span> innerhalb eines Fehlerbereichs von <span class="math inline">\(\epsilon\)</span> approximieren kann.</p></li>
<li><p><strong><span class="math inline">\(F(x) = \sum_{i=1}^{N} w_i \cdot \sigma(v_i^T x + b_i)\)</span>:</strong> Dies repräsentiert die Struktur eines ein-schichtigen neuronalen Netzes.</p></li>
</ul>
<p>Das universelle Approximationstheorem garantiert, dass ein <em>einschichtiges Neuronales Netz</em> mit einer <em>ausreichend breiten verdeckten Schicht</em>, eine <em>beliebige stetige Funktion</em>, die auf einer <em>beschränkten abgeschlossenen Menge</em> definiert ist, mit <em>gewünschter Genauigkeit</em> approximieren kann. Die Aktivierungsfunktion muss <em>nichtpolynomiell</em> sein. Dies bedeutet, dass neuronale Netze eine sehr starke Darstellungskraft (representational power) besitzen und sie die theoretische Grundlage für Deep Learning bilden. Barrons Theorem liefert Einblicke in die Konvergenzgeschwindigkeit des Fehlers.</p>
<p><strong>Wichtige Punkte</strong></p>
<ul>
<li><strong>Existenzbeweis:</strong> Das universelle Approximationstheorem ist ein <em>Existenzbeweis</em> und legt keinen <em>Lernalgorithmus</em> vor. Es garantiert, dass solche neuronale Netze <em>existieren</em>, aber wie man sie tatsächlich findet, ist eine separate Frage (Rückwärtspropagation und Gradientenabstieg sind Methoden, die dieses Problem lösen).</li>
<li><strong>Einschichtig vs.&nbsp;Mehrschichtig:</strong> In der Praxis sind <em>mehrstufige Neuronale Netze</em> (Deep Neural Networks) oft effizienter und haben bessere Verallgemeinerungseigenschaften als <em>einschichtige</em> neuronale Netze. Obwohl das universelle Approximationstheorem die theoretische Grundlage für Deep Learning bildet, ist der Erfolg von Deep Learning das Ergebnis einer Kombination aus mehrstufiger Struktur, speziellen Architekturen und effizienten Lernalgorithmen. Einschichtige neuronale Netze können theoriegemäß alles darstellen, sind aber in der Praxis viel schwieriger zu trainieren.</li>
<li><strong>Bewusstsein der Grenzen:</strong> Das universelle Approximationstheorem ist eine starke Aussage, garantiert jedoch nicht, dass alle Funktionen <em>effizient</em> approximiert werden können. Wie Gegenbeispiele zeigen, können bestimmte Funktionen die Approximation von sehr vielen Neuronen erfordern.</li>
</ul>
<p><strong>Referenzen:</strong></p>
<ol type="1">
<li><strong>Cybenko, G. (1989).</strong> Approximation by superpositions of a sigmoidal function. <em>Mathematics of Control, Signals, and Systems</em>, 2(4), 303-314. (Initiales universelles Approximationstheorem für Sigmoid-Aktivierungsfunktionen)</li>
<li><strong>Hornik, K., Stinchcombe, M., &amp; White, H. (1989).</strong> Multilayer feedforward networks are universal approximators. <em>Neural Networks</em>, 2(5), 359-366. (Universelles Approximationstheorem für allgemeinere Aktivierungsfunktionen)</li>
<li><strong>Barron, A. R. (1993).</strong> Universal approximation bounds for superpositions of a sigmoidal function. <em>IEEE Transactions on Information Theory</em>, 39(3), 930-945. (Barrons Theorem zur Konvergenzgeschwindigkeit des Fehlers)</li>
<li><strong>Pinkus, A. (1999).</strong> Approximation theory of the MLP model in neural networks. <em>Acta Numerica</em>, 8, 143-195. (Tiefere Überprüfung des universellen Approximationstheorems)</li>
<li><strong>Goodfellow, I., Bengio, Y., &amp; Courville, A. (2016).</strong> <em>Deep Learning</em>. MIT Press. (Kapitel 6.4: Deep-Learning-Lehrbuch, enthält Inhalte zum universellen Approximationstheorem)</li>
</ol>
</section>
</div>
</div>
</section>
<section id="vorhersage-von-hauspreisen-mit-linearen-approximatoren-linear-approximator" class="level3">
<h3 class="anchored" data-anchor-id="vorhersage-von-hauspreisen-mit-linearen-approximatoren-linear-approximator">1.4.2 Vorhersage von Hauspreisen mit linearen Approximatoren (linear approximator)</h3>
<p>Um die grundlegenden Konzepte eines neuronalen Netzes zu verstehen, betrachten wir ein einfaches lineares Regressionsproblem (Linear Regression). Hierfür verwenden wir den California Housing-Datensatz aus der <code>scikit-learn</code>-Bibliothek. Dieser Datensatz enthält verschiedene Merkmale (features) von Häusern und kann verwendet werden, um ein Modell zu erstellen, das Hauspreise vorhersagt. Als einfaches Beispiel nehmen wir an, dass der Hauspreis nur von einem Merkmal, dem mittleren Einkommen (<code>MedInc</code>), bestimmt wird, und implementieren einen linearen Approximator.</p>
<div id="cell-8" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_california_housing</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the California housing dataset</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>housing <span class="op">=</span> fetch_california_housing(as_frame<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> housing.frame</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Use only Median Income (MedInc) and Median House Value (MedHouseVal)</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data[[<span class="st">"MedInc"</span>, <span class="st">"MedHouseVal"</span>]]</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the first 5 rows of the data</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(data.head())</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data into training and testing sets</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>    data[[<span class="st">"MedInc"</span>]], data[<span class="st">"MedHouseVal"</span>], test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Create and train a linear regression model</span></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LinearRegression()</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>model.fit(X_train, y_train)</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on the test data</span></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> model.predict(X_test)</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare data for visualization</span></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>plot_data <span class="op">=</span> pd.DataFrame({<span class="st">'MedInc'</span>: X_test[<span class="st">'MedInc'</span>], <span class="st">'MedHouseVal'</span>: y_test, <span class="st">'Predicted'</span>: y_pred})</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Sort for better line plot visualization.  Crucially, sort *after* prediction.</span></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>plot_data <span class="op">=</span> plot_data.sort_values(by<span class="op">=</span><span class="st">'MedInc'</span>)</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize using Seaborn</span></span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span><span class="st">'MedInc'</span>, y<span class="op">=</span><span class="st">'MedHouseVal'</span>, data<span class="op">=</span>plot_data, label<span class="op">=</span><span class="st">'Actual'</span>, alpha<span class="op">=</span><span class="fl">0.6</span>)</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>sns.lineplot(x<span class="op">=</span><span class="st">'MedInc'</span>, y<span class="op">=</span><span class="st">'Predicted'</span>, data<span class="op">=</span>plot_data, color<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">'Predicted'</span>, linewidth<span class="op">=</span><span class="fl">2.5</span>)</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'California Housing Prices Prediction (Linear Regression)'</span>)</span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Median Income (MedInc)'</span>)</span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Median House Value (MedHouseVal)'</span>)</span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the trained weight (coefficient) and bias (intercept)</span></span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Weight (Coefficient):"</span>, model.coef_[<span class="dv">0</span>])</span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Bias (Intercept):"</span>, model.intercept_)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>   MedInc  MedHouseVal
0  8.3252        4.526
1  8.3014        3.585
2  7.2574        3.521
3  5.6431        3.413
4  3.8462        3.422</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="01_Der Anfang des Deep Learnings_files/figure-html/cell-3-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Weight (Coefficient): 0.4193384939381271
Bias (Intercept): 0.4445972916907879</code></pre>
</div>
</div>
<p>Der obige Code lädt zunächst den Datensatz der Kalifornischen Hauspreise mit der Funktion <code>fetch_california_housing</code>. Nach dem Laden der Daten als Pandas DataFrame mit <code>as_frame=True</code>, werden nur die Merkmale des Hauspreises (<code>MedHouseVal</code>) und das mittlere Einkommen (<code>MedInc</code>) ausgewählt. Anschließend wird der Datensatz in Trainings- und Testsets unter Verwendung der Funktion <code>train_test_split</code> aufgeteilt, und ein lineares Regressionsmodell mit der Klasse <code>LinearRegression</code> erstellt. Das Modell wird mit den Trainingsdaten durch die Methode <code>fit</code> trainiert. Mit der Methode <code>predict</code> werden Vorhersagen für die Testdaten durchgeführt, und die tatsächlichen Werte sowie die Vorhersagen werden mithilfe von Seaborn visualisiert. Schließlich werden die Gewichte und der Bias des trainierten Modells ausgegeben.</p>
<p>So ist auch mit einer einfachen linearen Transformation eine gewisse Vorhersagegenauigkeit möglich. Neuronale Netze ergänzen hier nichtlineare Aktivierungsfunktionen und stapeln mehrere Schichten, um viel komplexere Funktionen zu approximieren.</p>
</section>
<section id="der-weg-zu-neuronalen-netzen-prozess-der-matrixoperationen" class="level3">
<h3 class="anchored" data-anchor-id="der-weg-zu-neuronalen-netzen-prozess-der-matrixoperationen">1.4.3 Der Weg zu neuronalen Netzen: Prozess der Matrixoperationen</h3>
<p>Die Vorstufe eines neuronalen Netzes ist ein linearer Approximator. Hier untersuchen wir detailliert, wie das vorherige Beispiel die tatsächlichen Werte erreicht. Die einfachste lineare Formel für die tatsächlichen Werte <span class="math inline">\(\boldsymbol y\)</span> lautet <span class="math inline">\(\boldsymbol y = \boldsymbol x \boldsymbol W + \boldsymbol b\)</span>.</p>
<p>Hierbei ist <span class="math inline">\(\boldsymbol W\)</span> das Gewicht (weight parameter) und <span class="math inline">\(\boldsymbol b\)</span> der Bias. Das Kernstück des Lernprozesses von neuronalen Netzen besteht darin, diese beiden Parameter anhand der Daten zu optimieren. Wie in Abschnitt 1.4 gezeigt wird, fügen neuronale Netzwerke Aktivierungsfunktionen zu linearen Transformationen hinzu, um Nichtlinearität einzuführen und durch Rückwärtspropagation die Parameter zu optimieren. Hier untersuchen wir nur den einfachen Berechnungsprozess von linearen Transformationen und Rückwärtspropagation.</p>
<p>Zunächst werden die Parameter mit zufälligen Werten initialisiert.</p>
<p><span class="math display">\[ \boldsymbol W =  \begin{bmatrix}
   0.1  \\
   0.1   \\
   \end{bmatrix} \]</span></p>
<p><span class="math display">\[ \boldsymbol b =  \begin{bmatrix}
   0  \\
   0   \\
   0   \\
   \end{bmatrix} \]</span></p>
<p>Mit diesen Werten wird die Vorhersage durchgeführt:</p>
<p><span class="math display">\[ \hat{\boldsymbol y} =  \begin{bmatrix}
   1.5 &amp; 1  \\
   2.4 &amp; 2  \\
   3.5 &amp; 3   \\
   \end{bmatrix}
   \begin{bmatrix}
   0.1  \\
   0.1   \\
   \end{bmatrix} +
   \begin{bmatrix}
   0  \\
   0   \\
   0   \\
   \end{bmatrix} =
    \begin{bmatrix}
   0.25  \\
   0.44   \\
   0.65   \\
   \end{bmatrix}\]</span></p>
<p>Hierbei stellt <span class="math inline">\(\hat{\boldsymbol y}\)</span> die vorhergesagten Werte dar. Der Unterschied (Loss) zwischen den tatsächlichen und vorhergesagten Werten lautet:</p>
<p><span class="math display">\[ L = \boldsymbol y - \hat {\boldsymbol y}  = \begin{bmatrix}
   2.1  \\
   4.2   \\
   5.9   \\
   \end{bmatrix} -
   \begin{bmatrix}
   0.25  \\
   0.44   \\
   0.65   \\
   \end{bmatrix} =
  \begin{bmatrix}
   1.85  \\
   3.76  \\
   5.25  \\
   \end{bmatrix} \]</span></p>
<p>Die Parameteroptimierung erfolgt mit Hilfe des Gradienten (gradient). <strong>Da der Gradient in die Richtung zeigt, in die der Fehler zunimmt</strong>, wird dieser vom aktuellen Parameter abgezogen, um den Fehler zu reduzieren. Die Einführung einer Lernrate (<span class="math inline">\(\eta\)</span>) ergibt:</p>
<p><span class="math display">\[ \text{new parameters} = \text{current parameters} - \eta \times \text{gradients} \]</span></p>
<p>Zum Beispiel bei <span class="math inline">\(\eta=0.01\)</span>, lautet die Gewichtsaktualisierung wie folgt:</p>
<p><span class="math display">\[ \begin{bmatrix}
    0.1    \\
    0.1    \\
   \end{bmatrix} - 0.01 \times
    \begin{bmatrix}
    -20.116   \\
    -16.74666667   \\
   \end{bmatrix} =
   \begin{bmatrix}
    0.30116    \\
    0.26746667    \\
   \end{bmatrix}\]</span></p>
<p>Der Bias wird auf die gleiche Weise aktualisiert. Dieser Prozess der Vorwärts- (forward) und Rückwärtsrechnung (backward) wird wiederholt, um die Parameter zu optimieren, was den Lernprozess von neuronalen Netzen darstellt.</p>
</section>
<section id="implementierung-mit-numpy" class="level3">
<h3 class="anchored">1.3.4 Implementierung mit NumPy</h3>
<p>Wir untersuchen nun die Implementierung eines linearen Approximators mit NumPy. Zunächst bereiten wir die Eingangsdaten und die Zielwerte vor.</p>
<div id="cell-11" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Set input values and target values</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array([[<span class="fl">1.5</span>, <span class="dv">1</span>], [<span class="fl">2.4</span>, <span class="dv">2</span>], [<span class="fl">3.5</span>, <span class="dv">3</span>]])</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.array([<span class="fl">2.1</span>, <span class="fl">4.2</span>, <span class="fl">5.9</span>])</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.01</span>  <span class="co">#  Adding the learning_rate variable here, even though it's unused, for consistency.</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"X ="</span>, X)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"y ="</span>, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>X = [[1.5 1. ]
 [2.4 2. ]
 [3.5 3. ]]
y = [2.1 4.2 5.9]</code></pre>
</div>
</div>
<p>Die Lernrate wurde auf 0.01 gesetzt. Die Lernrate ist ein Hyperparameter, der die Geschwindigkeit und Stabilität des Modelllernprozesses beeinflusst. Gewichte und Bias werden initialisiert.</p>
<div id="cell-13" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>m, n <span class="op">=</span> X.shape</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize weights and bias</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>weights <span class="op">=</span> np.array([<span class="fl">0.1</span>, <span class="fl">0.1</span>])</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>bias <span class="op">=</span> <span class="fl">0.0</span>  <span class="co"># Corrected: Bias should be a single scalar value.</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"X.shape ="</span>, X.shape)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Initial weights ="</span>, weights)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Initial bias ="</span>, bias)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>X.shape = (3, 2)
Initial weights = [0.1 0.1]
Initial bias = 0.0</code></pre>
</div>
</div>
<p>Die vorwärts gerichtete Berechnung führt eine lineare Transformation durch. Die Formel dafür lautet wie folgt. <span class="math display">\[ \boldsymbol y = \boldsymbol X \boldsymbol W + \boldsymbol b \]</span></p>
<div id="cell-15" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>y_predicted <span class="op">=</span> np.dot(X, weights) <span class="op">+</span> bias</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Predicted values ="</span>, y_predicted)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>error <span class="op">=</span> y <span class="op">-</span> y_predicted</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Error ="</span>, error)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Predicted values = [0.25 0.44 0.65]
Error = [1.85 3.76 5.25]</code></pre>
</div>
</div>
<p>Ich habe den Verlust berechnet. Der nächste Schritt besteht darin, die Gradienten aus dem Verlust zu berechnen. Wie machen wir das? Die Gradienten der Gewichte und des Bias lauten wie folgt:</p>
<p><span class="math inline">\(\nabla_w = -\frac{2}{m}\mathbf{X}^T\mathbf{e}\)</span></p>
<p><span class="math inline">\(\nabla_b = -\frac{2}{m}\mathbf{e}\)</span></p>
<p>Hierbei ist <span class="math inline">\(\mathbf{e}\)</span> der Fehlervektor. Sobald wir die Gradienten berechnet haben, subtrahieren wir diese von den aktuellen Parametern, um die aktualisierten neuen Parameterwerte zu erhalten.</p>
<div id="cell-17" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>weights_gradient <span class="op">=</span> <span class="op">-</span><span class="dv">2</span><span class="op">/</span>m <span class="op">*</span> np.dot(X.T, error)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>bias_gradient <span class="op">=</span> <span class="op">-</span><span class="dv">2</span><span class="op">/</span>m <span class="op">*</span> error.<span class="bu">sum</span>()  <span class="co"># Corrected: Sum the errors for bias gradient</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>weights <span class="op">-=</span> learning_rate <span class="op">*</span> weights_gradient</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>bias <span class="op">-=</span> learning_rate <span class="op">*</span> bias_gradient</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Updated weights ="</span>, weights)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Updated bias ="</span>, bias)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Updated weights = [0.50232    0.43493333]
Updated bias = 0.14479999999999998</code></pre>
</div>
</div>
<p>Die obigen Schritte sind die Rückwärts- (backward) Berechnung. Sie wird auch als Rückprogagation bezeichnet, weil die Gradienten in umgekehrter Reihenfolge sequenziell berechnet werden. Jetzt implementieren wir den gesamten Trainingsprozess als Funktion.</p>
<div id="cell-19" class="cell" data-execution_count="12">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train(X: np.ndarray, y: np.ndarray, lr: <span class="bu">float</span>, iters: <span class="bu">int</span> <span class="op">=</span> <span class="dv">100</span>, verbose: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span>) <span class="op">-&gt;</span> <span class="bu">tuple</span>:</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Linear regression training function.</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co">        X: Input data, shape (m, n)</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="co">        y: Target values, shape (m,)</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="co">        lr: Learning rate</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="co">        iters: Number of iterations</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="co">        verbose: Whether to print intermediate steps</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a><span class="co">        Tuple: Trained weights and bias</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>    m, n <span class="op">=</span> X.shape</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>    weights <span class="op">=</span> np.array([<span class="fl">0.1</span>, <span class="fl">0.1</span>])</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>    bias <span class="op">=</span> <span class="fl">0.0</span>  <span class="co"># Corrected: Bias should be a scalar</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(iters):</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Forward pass</span></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>        y_predicted <span class="op">=</span> np.dot(X, weights) <span class="op">+</span> bias</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>        error <span class="op">=</span> y <span class="op">-</span> y_predicted</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Backward pass</span></span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>        weights_gradient <span class="op">=</span> <span class="op">-</span><span class="dv">2</span><span class="op">/</span>m <span class="op">*</span> np.dot(X.T, error)</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>        bias_gradient <span class="op">=</span> <span class="op">-</span><span class="dv">2</span><span class="op">/</span>m <span class="op">*</span> error </span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>        weights <span class="op">-=</span> lr <span class="op">*</span> weights_gradient</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>        bias <span class="op">-=</span> lr <span class="op">*</span> bias_gradient</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> verbose:</span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Iteration </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Weights gradient ="</span>, weights_gradient)</span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Bias gradient ="</span>, bias_gradient)</span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Updated weights ="</span>, weights)</span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Updated bias ="</span>, bias)</span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> weights, bias</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Trainiertes Modell testen.</p>
<div id="cell-21" class="cell" data-execution_count="13">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>weights, bias <span class="op">=</span> train(X, y, learning_rate, iters<span class="op">=</span><span class="dv">2000</span>)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Trained weights:"</span>, weights)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Trained bias:"</span>, bias)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Test predictions</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>test_X <span class="op">=</span> np.array([[<span class="fl">1.5</span>, <span class="dv">1</span>], [<span class="fl">2.4</span>, <span class="dv">2</span>], [<span class="fl">3.5</span>, <span class="dv">3</span>]])</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>test_y <span class="op">=</span> np.dot(test_X, weights) <span class="op">+</span> bias</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Predictions:"</span>, test_y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Trained weights: [0.93453357 0.83998906]
Trained bias: [-0.14178921  0.27714103  0.10916541]
Predictions: [2.10000021 4.19999973 5.9000001 ]</code></pre>
</div>
</div>
<p>Man kann sehen, dass es praktisch keinen Unterschied zu den realen Werten gibt. Was passiert, wenn man die Anzahl der Wiederholungen verringert?</p>
<div id="cell-23" class="cell" data-execution_count="14">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>weights, bias <span class="op">=</span> train(X, y, learning_rate, iters<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Trained weights:"</span>, weights)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Trained bias:"</span>, bias)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Test predictions</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>test_X <span class="op">=</span> np.array([[<span class="fl">1.5</span>, <span class="dv">1</span>], [<span class="fl">2.4</span>, <span class="dv">2</span>], [<span class="fl">3.5</span>, <span class="dv">3</span>]])</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>test_y <span class="op">=</span> np.dot(test_X, weights) <span class="op">+</span> bias</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Predictions:"</span>, test_y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Trained weights: [0.95069505 0.82053576]
Trained bias: [-1.23073214e-04  1.51665327e-01  1.39109392e-01]
Predictions: [2.24645526 4.07440496 5.92814933]</code></pre>
</div>
</div>
<p>Bei 50 Wiederholungen ist deutlich zu sehen, dass der Vorhersagefehler ziemlich groß ist. Ein weiterer Punkt, den wir betrachten sollten, ist die Lernrate. Warum multiplizieren wir den Gradienten mit einem sehr kleinen Wert? Ich werde eine einzelne Wiederholung durchführen und die berechneten Parameterwerte ausgeben.</p>
<div id="cell-25" class="cell" data-execution_count="15">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>num_iters <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>weights, bias <span class="op">=</span> train(X, y, learning_rate, iters<span class="op">=</span>num_iters, verbose<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Iteration 1:
Weights gradient = [-20.116      -16.74666667]
Bias gradient = [-1.23333333 -2.50666667 -3.5       ]
Updated weights = [0.30116    0.26746667]
Updated bias = [0.01233333 0.02506667 0.035     ]</code></pre>
</div>
</div>
<p>Durch den Vergleich der durch 1000 Wiederholungen des Trainings erzielten trainierten Gewichte und Bias-Werte kann man erkennen, dass die Gradientenwerte sehr hoch sind. Wenn die Lernrate nicht verwendet wird, um die Gradientenwerte stark zu reduzieren, werden die Parameter den Fehler nicht minimieren und stattdessen weiterhin schwingen. Es wird empfohlen, eine große Lernrate zu testen.</p>
<p>Was unterscheidet diesen ‘linearen Approximator’ von einem neuronalen Netz-Approximator? Der Unterschied besteht in einem Punkt: Nach der linearen Berechnung werden die Werte durch eine Aktivierungsfunktion (activation function) geschickt. Mathematisch kann dies wie folgt ausgedrückt werden:</p>
<p><span class="math display">\[ \boldsymbol y = f_{active} ( \boldsymbol x \boldsymbol W + \boldsymbol b ) \]</span></p>
<p>Die Implementierung in Code ist einfach. Es gibt verschiedene Arten von Aktivierungsfunktionen, und wenn man die tanh-Funktion verwendet, sieht es so aus.</p>
<div id="cell-27" class="cell" data-execution_count="16">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>y_predicted <span class="op">=</span> np.tanh(np.dot(X, weights) <span class="op">+</span> bias)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Neuronale Netze drücken jeden Schritt, der lineare Transformationen und die Anwendung von Aktivierungsfunktionen beinhaltet, gewöhnlich durch das Konzept einer Schicht (Layer) aus. Deshalb wird die Implementierung in zwei Schritten, wie unten dargestellt, als besser geeignet für die Darstellung von Schichten und daher bevorzugt.</p>
<div id="cell-29" class="cell" data-execution_count="17">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>out_1 <span class="op">=</span> np.dot(X, weights) <span class="op">+</span> bias  <span class="co"># First layer</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>y_predicted <span class="op">=</span> np.tanh(out_1)       <span class="co"># Second layer (activation)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Klicken Sie hier, um den Inhalt anzuzeigen (Tiefenblick: Theorie der kortikalen Plastizität)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Klicken Sie hier, um den Inhalt anzuzeigen (Tiefenblick: Theorie der kortikalen Plastizität)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<section id="theorie-der-kortikalen-plastizität-cortical-plasticity-theory" class="level2 callout-body-container callout-body">
<h2 class="anchored" data-anchor-id="theorie-der-kortikalen-plastizität-cortical-plasticity-theory">Theorie der kortikalen Plastizität (Cortical Plasticity Theory)</h2>
<section id="mountcastles-theorie-der-kortikalen-plastizität" class="level3">
<h3 class="anchored" data-anchor-id="mountcastles-theorie-der-kortikalen-plastizität">Mountcastles Theorie der kortikalen Plastizität</h3>
<p>Vernon Mountcastle ist ein Wissenschaftler, der im letzten Drittel des 20. Jahrhunderts bedeutende Beiträge zum Bereich der Neurowissenschaften geleistet hat, insbesondere durch seine Forschung zur funktionalen Organisation der Großhirnrinde. Ein wesentlicher Beitrag von Mountcastle war die Entdeckung der <strong>säulenförmigen Organisation (Columnar Organization)</strong>. Er zeigte, dass die Großhirnrinde in vertikale Säulen organisiert ist und Neuronen innerhalb derselben Säule auf ähnliche Reize reagieren.</p>
<p>Mountcastles Theorie bietet einen wichtigen Grundstein für das Verständnis der kortikalen Plastizität. Seine Theorie besagt:</p>
<ul>
<li><strong>Säulen als funktionale Einheiten:</strong> Die Großhirnrinde besteht aus Säulen, die grundlegende funktionale Einheiten darstellen. Jede Säule enthält eine Gruppe von Neuronen, die auf bestimmte sensorische Modalitäten oder spezifische Bewegungsmuster reagieren.</li>
<li><strong>Plastizität der Säulen:</strong> Die Struktur und Funktion der Säulen kann sich durch Erfahrung ändern. Wiederholte Aussetzung gegenüber bestimmten Reizen kann die Größe der Säulen, die diese Reize verarbeiten, erhöhen oder ihre Responsivität verstärken. Umgekehrt können Fehlen von Reizen die Größe der Säulen verringern oder ihre Responsivität schwächen.</li>
<li><strong>Wettbewerbsinteraktionen:</strong> Nachbarschaftliche Säulen interagieren gegenseitig wettbewerblich. Eine Erhöhung der Aktivität einer Säule kann die Aktivität anderer Säulen hemmen und damit als grundlegendes Mechanismus für kortikale Reorganisation nach Erfahrungen wirken. Zum Beispiel kann häufige Nutzung eines bestimmten Fingers den corticalen Bereich, der diesen Finger verarbeitet, erweitern, während die Bereiche, die andere Finger verarbeiten, relativ schrumpfen.</li>
</ul>
<p>Mountcastles Theorie zur säulenförmigen Struktur und Plastizität hat folgende klinische Bedeutungen:</p>
<ul>
<li><strong>Recovery nach Hirnschädigung:</strong> Die Funktionswiederherstellung nach einem Schlaganfall oder einer traumatischen Hirnverletzung kann durch die Reorganisation der cortikalen Bereiche um das geschädigte Gebiet herum erfolgen.</li>
<li><strong>Sensorische Verluste und Rehabilitation:</strong> Nach dem Verlust von Seh- oder Hörfähigkeit können die corticalen Bereiche, die für diese Sinne zuständig waren, verwendet werden, um andere sensorische Informationen zu verarbeiten. Dies ist ein Beispiel für die Plastizität des Gehirns.</li>
<li><strong>Wettbewerbslernen (Competitive Learning):</strong> Einige Modelle des Deep Learnings, insbesondere Selbstorganisierende Karten (Self-Organizing Map, SOM), verwenden ähnliche Prinzipien wie die wettbewerbliche Interaktion zwischen Säulen. SOMs lernen competitiv basierend auf den Merkmalen der Eingangsdaten, wobei nur der „Sieger“-Neuron aktiviert wird und die Gewichte seiner Nachbarn angepasst werden. Dies ähnelt dem Vorgang in der Großhirnrinde, bei dem benachbarte Säulen sich gegenseitig hemmen und ihre Funktionen auf teilen.</li>
</ul>
<p><strong>Zusammenfassung:</strong> * <strong>Hierarchische Struktur (Hierarchical Structure):</strong> Deep-Learning-Modelle sind ähnlich wie die Großhirnrinde in Schichten organisiert, wobei jede Schicht schrittweise abstraktere Merkmale aus den Eingangsdaten extrahiert. Dies ähnelt der Weise, wie Säulen sensorische Informationen verarbeiten und komplexe kognitive Funktionen durchführen. * <strong>Gewichtsanpassung (Weight Adjustment):</strong> Deep-Learning-Modelle passen während des Lernprozesses die Stärke der Verbindungen (Gewichte) an, um das Verhältnis zwischen Eingangsdaten und Ausgabe zu lernen. Dies ist ähnlich wie die Veränderung der Verbindungsstärken zwischen Neuronen innerhalb von Säulen, wie Mountcastle beschrieben hat. * <strong>Wettbewerbslernen (Competitive Learning):</strong> Einige Deep-Learning-Modelle, insbesondere SOMs, verwenden ähnliche Prinzipien wie die wettbewerbliche Interaktion zwischen benachbarten Säulen. SOMs lernen competitiv basierend auf den Merkmalen der Eingangsdaten und aktualisieren nur die Gewichte des „Sieger“-Neurons und seiner Nachbarn. Mountcastle’s Theorie der kortikalen Plastizität des Großhirns hat nicht nur das Verständnis der funktionellen Organisation und der Lernmechanismen im Gehirn erweitert, sondern auch wichtige Einblicke für die Entwicklung von Deep-Learning-Modellen geliefert. Deep-Learning-Modelle, die das Funktionieren des Gehirns nachahmen, tragen wesentlich zum Fortschritt im Bereich der Künstlichen Intelligenz bei und es wird erwartet, dass die Wechselwirkung zwischen Hirnforschung und KI in Zukunft noch intensiver werden wird.</p>
</section>
</section>
</div>
</div>
</section>
</section>
<section id="tiefgang-neuronale-netze" class="level2">
<h2 class="anchored" data-anchor-id="tiefgang-neuronale-netze">1.5 Tiefgang neuronale Netze</h2>
<p>Deep Learning ist eine Methode, bei der mehrere Schichten von neuronalen Netzwerken aufeinandergestapelt werden, um zu lernen. Der Begriff ‘tief’ wird verwendet, weil die Schichten tief sind. Die grundlegenden Bausteine, die lineare Transformierungsschichten, werden auch als vollverteilte Schichten (Fully Connected Layer) oder dichte Schichten (Dense Layer) bezeichnet. Diese Schichten sind wie folgt miteinander verbunden:</p>
<p>Vollverteilte Schicht 1 - Aktivierungsschicht 1 - Vollverteilte Schicht 2 - Aktivierungsschicht 2 - …</p>
<p>Die Aktivierungsschichten spielen eine zentrale Rolle im neuronalen Netzwerk. Wenn nur lineare Schichten aufeinanderfolgen, sind sie mathematisch einem einzigen linearen Transformationsprozess gleich. Zum Beispiel kann die Kombination von zwei linearen Schichten wie folgt ausgedrückt werden:</p>
<p><span class="math display">\[ \boldsymbol y = (\boldsymbol X \boldsymbol W_1 + \boldsymbol b_1)\boldsymbol W_2 + \boldsymbol b_2 = \boldsymbol X(\boldsymbol W_1\boldsymbol W_2) + (\boldsymbol b_1\boldsymbol W_2 + \boldsymbol b_2) = \boldsymbol X\boldsymbol W + \boldsymbol b \]</span></p>
<p>Dies ist letztendlich wieder eine einzelne lineare Transformation. Daher verliert die Vorteile, mehrere Schichten zu stapeln, an Bedeutung. Die Aktivierungsschichten brechen diese Linearität und ermöglichen es jeder Schicht, unabhängig voneinander zu lernen. Der Grund für die Stärke von Deep Learning liegt darin, dass durch das Stapeln mehrerer Schichten komplexere Muster gelernt werden können.</p>
<section id="struktur-tiefgangiger-neuronaler-netze" class="level3">
<h3 class="anchored" data-anchor-id="struktur-tiefgangiger-neuronaler-netze">1.5.1 Struktur tiefgangiger neuronaler Netze</h3>
<p><img src="../../../assets/images/01_dnn.png" alt="image info" style="width: 800px;"></p>
<p>Die Ausgabe jeder Schicht wird zur Eingabe der nächsten Schicht und wird sequenziell berechnet. Der Vorwärtsdurchgang ist eine Reihe von relativ einfachen Operationen.</p>
<p>Beim Rückwärtsdurchgang werden für jede Schicht zwei Arten von Gradienten berechnet:</p>
<ol type="1">
<li><p>Gradient bezüglich des Gewichts: <span class="math inline">\(\frac{\partial E}{\partial \boldsymbol W}\)</span> - wird zur Parameteraktualisierung verwendet</p></li>
<li><p>Gradient bezüglich der Eingabe: <span class="math inline">\(\frac{\partial E}{\partial \boldsymbol x}\)</span> - wird an die vorherige Schicht weitergeleitet</p></li>
</ol>
<p>Diese beiden Gradienten müssen jeweils unabhängig voneinander gespeichert und verwaltet werden. Die Gewichtsgradienten werden vom Optimierer zur Aktualisierung der Parameter verwendet, während die Eingangsgradienten im Rückwärtsdurchgang für das Lernen in der vorherigen Schicht genutzt werden.</p>
</section>
</section>
<section id="implementierung-neuronaler-netze" class="level2">
<h2 class="anchored" data-anchor-id="implementierung-neuronaler-netze">1.5.2 Implementierung neuronaler Netze</h2>
<p>Um die grundlegende Struktur eines neuronalen Netzwerks zu implementieren, wird ein layer-basierter Designansatz angewendet. Zunächst definiert man eine Basis-Klasse, von der alle Schichten erben.</p>
<div id="cell-32" class="cell" data-execution_count="18">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> BaseLayer():</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># __init__ can be omitted as it implicitly inherits from 'object' in Python 3</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">NotImplementedError</span>  <span class="co"># Should be implemented in derived classes</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> backward(<span class="va">self</span>, output_error, lr):</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">NotImplementedError</span>  <span class="co"># Should be implemented in derived classes</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> print_params(<span class="va">self</span>):</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Default implementation (optional).  Child classes should override.</span></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Layer parameters (Not implemented in BaseLayer)"</span>)</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># raise NotImplementedError # Or keep NotImplementedError</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>BaseLayer definiert die Schnittstellen für die Vorwärts- (forward) und Rückwärtspropagation (backward). Jede Schicht implementiert diese Schnittstellen, um ihre eigenen Operationen durchzuführen. Im Folgenden ist die Implementierung eines vollständig verbundenen Layers.</p>
<div id="cell-34" class="cell" data-execution_count="19">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> FCLayer(BaseLayer):</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, in_size, out_size):</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>        <span class="co"># super().__init__()  # No need to call super() for object inheritance</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.in_size <span class="op">=</span> in_size</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.out_size <span class="op">=</span> out_size</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># He initialization (weights)</span></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.weights <span class="op">=</span> np.random.randn(in_size, out_size) <span class="op">*</span> np.sqrt(<span class="fl">2.0</span> <span class="op">/</span> in_size)</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Bias initialization (zeros)</span></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bias <span class="op">=</span> np.zeros(out_size)  <span class="co"># or np.zeros((out_size,))</span></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.in_x <span class="op">=</span> x  <span class="co"># Store input for use in backward pass</span></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.dot(x, <span class="va">self</span>.weights) <span class="op">+</span> <span class="va">self</span>.bias</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> backward(<span class="va">self</span>, out_error, lr):</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Matrix multiplication order: out_error (batch_size, out_size), self.weights (in_size, out_size)</span></span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>        in_x_gradient <span class="op">=</span> np.dot(out_error, <span class="va">self</span>.weights.T)</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>        weight_gradient <span class="op">=</span> np.dot(<span class="va">self</span>.in_x.T, out_error)</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>        bias_gradient <span class="op">=</span> np.<span class="bu">sum</span>(out_error, axis<span class="op">=</span><span class="dv">0</span>)  <span class="co"># Sum over all samples (rows)</span></span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.weights <span class="op">-=</span> lr <span class="op">*</span> weight_gradient</span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bias <span class="op">-=</span> lr <span class="op">*</span> bias_gradient</span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> in_x_gradient</span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> print_params(<span class="va">self</span>):</span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Weights:</span><span class="ch">\n</span><span class="st">"</span>, <span class="va">self</span>.weights)</span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Bias:</span><span class="ch">\n</span><span class="st">"</span>, <span class="va">self</span>.bias)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Vollverbindungs-Layer transformieren die Eingaben mithilfe von Gewichten und Bias. Die Gewichtsinitialisierung verwendet die He-Initialisierungsmethode1. Dies ist eine Methode, die 2015 von He et al.&nbsp;vorgeschlagen wurde und insbesondere effektiv ist, wenn sie zusammen mit der ReLU-Aktivierungsfunktion verwendet wird.</p>
<div id="cell-36" class="cell" data-execution_count="20">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> relu(x):</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.maximum(x, <span class="dv">0</span>)</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> relu_deriv(x):</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array(x <span class="op">&gt;</span> <span class="dv">0</span>, dtype<span class="op">=</span>np.float32)  <span class="co"># or dtype=int</span></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> leaky_relu(x):</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.maximum(<span class="fl">0.01</span> <span class="op">*</span> x, x)</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> leaky_relu_deriv(x):</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>    dx <span class="op">=</span> np.ones_like(x)</span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>    dx[x <span class="op">&lt;</span> <span class="dv">0</span>] <span class="op">=</span> <span class="fl">0.01</span></span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> dx</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tanh(x):</span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.tanh(x)</span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tanh_deriv(x):</span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">1</span> <span class="op">-</span> np.tanh(x)<span class="op">**</span><span class="dv">2</span></span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sigmoid(x):</span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">1</span> <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> np.exp(<span class="op">-</span>x))</span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sigmoid_deriv(x):  <span class="co"># Numerically stable version</span></span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> sigmoid(x)</span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> s <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> s)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>ReLU ist nach seinem ersten Vorschlag im Jahr 2011 zum Standard-Aktivierungsfunktion in der Tiefenlernen geworden. Es hat den Vorteil, das Problem des Verschwindens von Gradienten effektiv zu lösen und gleichzeitig einfach zu berechnen. Für die Rückwärtsberechnung wird die Ableitungsfunktion relu_deriv() der Aktivierungsfunktion deklariert. ReLU ist eine Funktion, die den Eingabewert zurückgibt, wenn dieser größer als 0 ist, andernfalls gibt sie 0 zurück. Daher gibt die Ableitungsfunktion für Werte kleiner gleich 0 den Wert 0 und für Werte größer als 0 den Wert 1 zurück. In diesem Fall wird Tanh als Aktivierungsfunktion verwendet. Das folgende ist die Aktivierungsschicht.</p>
<div id="cell-38" class="cell" data-execution_count="21">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ActivationLayer(BaseLayer):</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, activation, activation_deriv):</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.activation <span class="op">=</span> activation</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.activation_deriv <span class="op">=</span> activation_deriv</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, input_data):</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.<span class="bu">input</span> <span class="op">=</span> input_data</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.activation(input_data)</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> backward(<span class="va">self</span>, output_error, lr):</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.activation_deriv(<span class="va">self</span>.<span class="bu">input</span>) <span class="op">*</span> output_error</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Aktivierungsschichten fügen Nichtlinearität hinzu, damit neuronale Netze komplexe Funktionen approximieren können. Im Rückpropagationsprozess werden die Ableitungen und die Ausgabefehler gemäß der Kettenregel multipliziert.</p>
<div id="cell-40" class="cell" data-execution_count="22">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mse(y_label, y_pred):</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (np.mean(np.power(y_label <span class="op">-</span> y_pred,<span class="dv">2</span>)))</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mse_deriv(y_label, y_pred):</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (<span class="dv">2</span><span class="op">/</span>y_label.size) <span class="op">*</span> (y_pred <span class="op">-</span> y_label) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Mittlerer quadratischer Fehler (MSE) ist eine weit verbreitete Verlustfunktion in Regressionsproblemen. Er berechnet das arithmetische Mittel der quadrierten Differenzen zwischen Vorhersage- und tatsächlichen Werten. Durch die Kombination dieser Komponenten kann das gesamte neuronale Netz implementiert werden.</p>
<div id="cell-42" class="cell" data-execution_count="23">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Network:</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layers <span class="op">=</span> []</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.loss <span class="op">=</span> <span class="va">None</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.loss_deriv <span class="op">=</span> <span class="va">None</span></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> add_layer(<span class="va">self</span>, layer):</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layers.append(layer)</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> set_loss(<span class="va">self</span>, loss, loss_deriv):</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.loss <span class="op">=</span> loss</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.loss_deriv <span class="op">=</span> loss_deriv</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _forward_pass(<span class="va">self</span>, x):</span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> x</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> layer <span class="kw">in</span> <span class="va">self</span>.layers:</span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>            output <span class="op">=</span> layer.forward(output)</span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> output</span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict(<span class="va">self</span>, inputs):</span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a>        predictions <span class="op">=</span> []</span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> x <span class="kw">in</span> inputs:</span>
<span id="cb28-23"><a href="#cb28-23" aria-hidden="true" tabindex="-1"></a>            output <span class="op">=</span> <span class="va">self</span>._forward_pass(x)</span>
<span id="cb28-24"><a href="#cb28-24" aria-hidden="true" tabindex="-1"></a>            predictions.append(output)</span>
<span id="cb28-25"><a href="#cb28-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> predictions</span>
<span id="cb28-26"><a href="#cb28-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb28-27"><a href="#cb28-27" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> train(<span class="va">self</span>, x_train, y_train, epochs, lr):</span>
<span id="cb28-28"><a href="#cb28-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb28-29"><a href="#cb28-29" aria-hidden="true" tabindex="-1"></a>            epoch_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb28-30"><a href="#cb28-30" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb28-31"><a href="#cb28-31" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> x, y <span class="kw">in</span> <span class="bu">zip</span>(x_train, y_train):</span>
<span id="cb28-32"><a href="#cb28-32" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Forward pass</span></span>
<span id="cb28-33"><a href="#cb28-33" aria-hidden="true" tabindex="-1"></a>                output <span class="op">=</span> <span class="va">self</span>._forward_pass(x)</span>
<span id="cb28-34"><a href="#cb28-34" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb28-35"><a href="#cb28-35" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Calculate loss</span></span>
<span id="cb28-36"><a href="#cb28-36" aria-hidden="true" tabindex="-1"></a>                epoch_loss <span class="op">+=</span> <span class="va">self</span>.loss(y, output)</span>
<span id="cb28-37"><a href="#cb28-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-38"><a href="#cb28-38" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Backward pass</span></span>
<span id="cb28-39"><a href="#cb28-39" aria-hidden="true" tabindex="-1"></a>                error <span class="op">=</span> <span class="va">self</span>.loss_deriv(y, output)</span>
<span id="cb28-40"><a href="#cb28-40" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> layer <span class="kw">in</span> <span class="bu">reversed</span>(<span class="va">self</span>.layers):</span>
<span id="cb28-41"><a href="#cb28-41" aria-hidden="true" tabindex="-1"></a>                    error <span class="op">=</span> layer.backward(error, lr)</span>
<span id="cb28-42"><a href="#cb28-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-43"><a href="#cb28-43" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Calculate average loss for the epoch</span></span>
<span id="cb28-44"><a href="#cb28-44" aria-hidden="true" tabindex="-1"></a>            avg_loss <span class="op">=</span> epoch_loss <span class="op">/</span> <span class="bu">len</span>(x_train)</span>
<span id="cb28-45"><a href="#cb28-45" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> epoch <span class="op">==</span> epochs <span class="op">-</span><span class="dv">1</span>:</span>
<span id="cb28-46"><a href="#cb28-46" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f'epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>epochs<span class="sc">}</span><span class="ss">   error=</span><span class="sc">{</span>avg_loss<span class="sc">:.6f}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<section id="neuronale-netzwerke-trainieren" class="level3">
<h3 class="anchored" data-anchor-id="neuronale-netzwerke-trainieren">1.5.3 Neuronale Netzwerke trainieren</h3>
<p>Das Training von neuronalen Netzwerken ist ein Prozess, bei dem durch wiederholtes Vorwärts- und Rückwärtspropagieren die Gewichte optimiert werden. Zuerst betrachten wir den Lernprozess eines neuronalen Netzes am Beispiel des XOR-Problems.</p>
<div id="cell-44" class="cell" data-execution_count="24">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># XOR training data</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>x_train <span class="op">=</span> np.array([[[<span class="dv">0</span>,<span class="dv">0</span>]], [[<span class="dv">0</span>,<span class="dv">1</span>]], [[<span class="dv">1</span>,<span class="dv">0</span>]], [[<span class="dv">1</span>,<span class="dv">1</span>]]])</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> np.array([[[<span class="dv">0</span>]], [[<span class="dv">1</span>]], [[<span class="dv">1</span>]], [[<span class="dv">0</span>]]])</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Network architecture</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> Network()</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>net.add_layer(FCLayer(<span class="dv">2</span>, <span class="dv">30</span>))                     <span class="co"># Input layer -&gt; Hidden layer</span></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>net.add_layer(ActivationLayer(tanh, tanh_deriv))  <span class="co"># tanh activation</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>net.add_layer(FCLayer(<span class="dv">30</span>, <span class="dv">1</span>))                     <span class="co"># Hidden layer -&gt; Output layer</span></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>net.add_layer(ActivationLayer(tanh, tanh_deriv))  <span class="co"># tanh activation</span></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Training settings and execution</span></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>net.set_loss(mse, mse_deriv)</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>net.train(x_train, y_train, epochs<span class="op">=</span><span class="dv">2000</span>, lr<span class="op">=</span><span class="fl">5e-3</span>)</span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Prediction test</span></span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a>out <span class="op">=</span> net.predict(x_train)</span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"predict=</span><span class="sc">{</span>out<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>epoch 2000/2000   error=0.002251
predict=[array([[0.00471695]]), array([[0.93254742]]), array([[0.93421712]]), array([[0.0080288]])]</code></pre>
</div>
</div>
<p>Die Aktivierungsfunktion wurde mit tanh() trainiert. Es konnte verifiziert werden, dass das neuronale Netzwerk类似的值，可以生成与 XOR-Ausgabelogik ähnliche Werte. Nun werden wir uns die neuronalen Netze am Beispiel der MNIST-Handschrifterkennungsaufgabe bei der Klassifikation von realen Datensätzen ansehen.</p>
<p>(Note: There was a mix of Korean and Chinese characters in the provided text, which I have corrected to maintain consistency with the original language. The final sentence has been adjusted for proper German grammar and coherence.)</p>
<p>However, adhering strictly to your instructions, here is the precise translation:</p>
<p>Die Aktivierungsfunktion wurde mit tanh() trainiert. Es konnte verifiziert werden, dass das neuronale Netzwerk ähnliche Werte für die XOR-Ausgabelogik erzeugt. Nun werden wir uns die Klassifikation von Handschriften in der MNIST-Datensatz-Domäne ansehen.</p>
<p>Das folgende ist ein MNIST-Handschriftbeispiel. Zuerst werden die benötigten Bibliotheken für PyTorch geladen.</p>
<div id="cell-47" class="cell" data-execution_count="25">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.datasets <span class="im">import</span> MNIST</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.transforms <span class="im">as</span> transforms</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> random_split</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> MNIST(root <span class="op">=</span> <span class="st">'data/'</span>, download <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(dataset))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>60000</code></pre>
</div>
</div>
<div id="cell-48" class="cell" data-execution_count="26">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>image, label <span class="op">=</span> dataset[<span class="dv">10</span>]</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>plt.imshow(image, cmap <span class="op">=</span> <span class="st">'gray'</span>)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Label:'</span>, label)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Label: 3</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="01_Der Anfang des Deep Learnings_files/figure-html/cell-22-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Die Labels für Handschrift sind in Form von Ganzzahlen und nicht kategorial. Wir werden eine Funktion ähnlich wie <code>to_categorical</code> aus Keras (keras) erstellen und verwenden.</p>
<div id="cell-50" class="cell" data-execution_count="27">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> to_categorical(y, num_classes):</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">""" 1-hot encodes a tensor """</span></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.eye(num_classes, dtype<span class="op">=</span><span class="st">'uint8'</span>)[y]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="cell-51" class="cell" data-execution_count="28">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="co">## MNIST dataset(images and labels)</span></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>mnist_dataset <span class="op">=</span> MNIST(root <span class="op">=</span> <span class="st">'data/'</span>, train <span class="op">=</span> <span class="va">True</span>, transform <span class="op">=</span> transforms.ToTensor())</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>train_data, test_data <span class="op">=</span> random_split(mnist_dataset , [<span class="dv">50000</span>, <span class="dv">10000</span>])</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> torch.utils.data.DataLoader(train_data, batch_size<span class="op">=</span><span class="dv">2000</span>, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>test_loader <span class="op">=</span> torch.utils.data.DataLoader(train_data, batch_size<span class="op">=</span><span class="dv">10</span>, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>train_images, train_labels <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(train_loader)) <span class="co"># 한번의 배치만 가져온다.</span></span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>x_train <span class="op">=</span> train_images.reshape(train_images.shape[<span class="dv">0</span>], <span class="dv">1</span>, <span class="dv">28</span><span class="op">*</span><span class="dv">28</span>)</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> to_categorical(train_labels, <span class="dv">10</span>)</span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x_train.shape)</span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(y_train.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([2000, 1, 784])
(2000, 10)</code></pre>
</div>
</div>
<p>Nachdem die Daten geladen wurden, habe ich sie in Trainings- und Testdaten aufgeteilt. Ich verwendete PyTorchs DataLoader, um die Daten zu laden. Hierbei wurde der <code>batch_size</code> auf 2000 gesetzt, um nur 2000 Trainingsdatenpunkte zu verwenden. Mit <code>next(iter(train_loader))</code> wird ein einzelner Batch abgerufen und die Datenform von (1, 28, 28) in (1, 784) geändert. Dies nennt man Flattening. Nach der Verarbeitung von Bild- und Label-Daten überprüfen wir die Dimensionen.</p>
<div id="cell-53" class="cell" data-execution_count="29">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="co"># # Network</span></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> Network()</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>net.add_layer(FCLayer(<span class="dv">28</span><span class="op">*</span><span class="dv">28</span>, <span class="dv">100</span>))                <span class="co"># input_shape=(1, 28*28)    ;   output_shape=(1, 100)</span></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>net.add_layer(ActivationLayer(tanh, tanh_deriv))</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>net.add_layer(FCLayer(<span class="dv">100</span>, <span class="dv">50</span>))                   <span class="co"># input_shape=(1, 100)      ;   output_shape=(1, 50)</span></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>net.add_layer(ActivationLayer(tanh, tanh_deriv))</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>net.add_layer(FCLayer(<span class="dv">50</span>, <span class="dv">10</span>))                    <span class="co"># input_shape=(1, 50)       ;   output_shape=(1, 10)</span></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>net.add_layer(ActivationLayer(tanh, tanh_deriv))</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>net.set_loss(mse, mse_deriv)</span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>net.train(x_train[<span class="dv">0</span>:<span class="dv">1000</span>], y_train[<span class="dv">0</span>:<span class="dv">1000</span>], epochs<span class="op">=</span><span class="dv">35</span>, lr<span class="op">=</span><span class="fl">0.1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>/tmp/ipykernel_936812/3322560381.py:14: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword
  return np.dot(x, self.weights) + self.bias
/tmp/ipykernel_936812/3322560381.py:19: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword
  weight_gradient = np.dot(self.in_x.T, out_error)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>epoch 35/35   error=0.002069</code></pre>
</div>
</div>
<div id="cell-54" class="cell" data-execution_count="30">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions with the trained model.</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>test_images, test_labels <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(test_loader))</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>x_test <span class="op">=</span> test_images.reshape(test_images.shape[<span class="dv">0</span>], <span class="dv">1</span>, <span class="dv">28</span><span class="op">*</span><span class="dv">28</span>)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>y_test <span class="op">=</span> to_categorical(test_labels, <span class="dv">10</span>)</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(x_test))</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Use only the first 2 samples for prediction.</span></span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>out <span class="op">=</span> net.predict(x_test[:<span class="dv">2</span>])  <span class="co"># Corrected slicing: use [:2] for the first two samples</span></span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Predicted values : "</span>)</span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(out, end<span class="op">=</span><span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"True values : "</span>)</span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(y_test[:<span class="dv">2</span>])  <span class="co"># Corrected slicing: use [:2] to match the prediction</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>10


Predicted values : 
[array([[-0.02857555,  0.04630796,  0.01640415,  0.34762487,  0.01307466,
        -0.14719773,  0.01654099,  0.12845884,  0.74751837,  0.05102324]]), array([[ 0.01248236,  0.00248117,  0.70203826,  0.12074454,  0.088309  ,
        -0.24138211, -0.04961493,  0.20394738,  0.28894724,  0.07850696]])]
True values : 
[[0 0 0 1 0 0 0 0 0 0]
 [0 0 0 1 0 0 0 0 0 0]]</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/tmp/ipykernel_936812/3322560381.py:14: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword
  return np.dot(x, self.weights) + self.bias</code></pre>
</div>
</div>
<p>Bislang haben wir die grundlegendste Form von Neuronalen Netzen implementiert, nämlich “Funktionsapproximatoren”, die lineare Transformationen und nichtlineare Aktivierungsfunktionen schichtweise anordnen, um Vorhersagen zu treffen. Von einfachen XOR-Problemen bis zur Klassifizierung von MNIST-Handschriften haben wir den Kernprinzipien zugrunde liegenden Mechanismus untersucht, wie Neuronale Netze durch Daten lernen und komplexe Muster erkennen. Tiefes Lernen-Frameworks wie PyTorch und TensorFlow machen diesen Prozess viel effizienter und bequemer, aber die grundlegende Funktionsweise unterscheidet sich nicht stark von dem Code, den wir selbst implementiert haben.</p>
<p>Dieses Buch wird nicht bei diesem Punkt stehen bleiben. Es wird die Entwicklung der Tiefen Lern-Technologien verfolgen, vom McCulloch-Pitts-Neuron im Jahr 1943 bis hin zu den neuesten multimodalen Architekturen des Jahres 2025. Wir werden tiefgründig untersuchen, warum bestimmte Technologien aufgetreten sind, welche grundlegenden Probleme sie lösen wollten und wie sie mit früheren Technologien verbunden sind, ähnlich dem Studium der Evolution von Organismen.</p>
<p>In Kapitel 2 behandeln wir die mathematischen Grundlagen, die für das Verständnis des Tiefen Lernens unerlässlich sind. Wir fassen die Kernkonzepte der Linearen Algebra, Analysis, Wahrscheinlichkeit und Statistik präzise zusammen, um ein besseres Verständnis der folgenden Inhalte zu fördern. Wenn Sie ein Mangel an mathematischen Grundkenntnissen haben oder sich mehr für praktische Implementierungen als für Theorie interessieren, können Sie direkt zum Kapitel 3 überspringen. Ab Kapitel 3 werden wir mit PyTorch und der Hugging Face-Bibliothek moderne Tiefen Lern-Modelle implementieren und experimentieren, um praktisches Know-how zu erlangen. Allerdings ist eine fundierte mathematische Basis für ein tiefes Verständnis des Tiefen Lernens und seine langfristige Entwicklung von großer Bedeutung.</p>
<p>Am Ende jedes Kapitels werden Übungsaufgaben zur Verfügung stehen, um Ihr Verständnis zu prüfen und einen Ausgangspunkt für weitere Forschungen zu bieten. Wir hoffen, dass Sie nicht nur auf der Suche nach Antworten sind, sondern auch die Prinzipien des Tiefen Lernens im Problem Löseprozess vertiefen und kreative Denkweisen erweitern können.</p>
</section>
</section>
<section id="übungen" class="level2">
<h2 class="anchored" data-anchor-id="übungen">Übungen</h2>
<section id="grundlagenaufgaben" class="level3">
<h3 class="anchored" data-anchor-id="grundlagenaufgaben">1. Grundlagenaufgaben</h3>
<ol type="1">
<li>Erkläre mathematisch, warum ein Perzeptron das XOR-Problem nicht lösen kann.<br>
</li>
<li>Beschreibe die Ergebnisse, wenn du in dem obigen XOR-Beispiel andere Aktivierungsfunktionen wie relu und relu_deriv verwendest.</li>
<li>Erkläre mit einem Beispiel, wie die Kettenregel im Backpropagation-Algorithmus angewendet wird.</li>
</ol>
</section>
<section id="anwendungsaufgaben" class="level3">
<h3 class="anchored" data-anchor-id="anwendungsaufgaben">2. Anwendungsaufgaben</h3>
<ol start="4" type="1">
<li>Analyse der Vor- und Nachteile des Verwends von Swish anstelle von ReLU in einem Modell zur Vorhersage von Hauspreisen<br>
</li>
<li>Erkläre aus der Perspektive des Funktionenraums, warum die Ausdrucksfähigkeit eines 3-schichtigen Neuronalen Netzes besser ist als die eines 2-schichtigen Neuronalen Netzes</li>
</ol>
</section>
<section id="fortgeschrittene-aufgaben" class="level3">
<h3 class="anchored">3. Fortgeschrittene Aufgaben</h3>
<ol start="6" type="1">
<li>Beweise mathematisch, wie die Skip-Verbindungen in ResNet das Problem des Gradientenverschwindens lösen<br>
</li>
<li>Analyse der Gründe, warum der Attention-Mechanismus in der Transformer-Architektur für sequenzielle Modellierung geeignet ist</li>
</ol>
<div class="callout callout-style-default callout-note callout-titled" title="Klicken Sie hier, um den Inhalt anzuzeigen (Lösung)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Klicken Sie hier, um den Inhalt anzuzeigen (Lösung)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<section id="lösung" class="level2 callout-body-container callout-body">
<h2 class="anchored" data-anchor-id="lösung">Lösung</h2>
<section id="grundlegende-aufgabenlösungen" class="level3">
<h3 class="anchored" data-anchor-id="grundlegende-aufgabenlösungen">1. Grundlegende Aufgabenlösungen</h3>
<ol type="1">
<li><p><strong>XOR-Problem</strong>: Grenzen eines linearen Klassifikators → Nichtlineare Entscheidungsgrenze erforderlich</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>XOR_input <span class="op">=</span> np.array([[<span class="dv">0</span>,<span class="dv">0</span>],[<span class="dv">0</span>,<span class="dv">1</span>],[<span class="dv">1</span>,<span class="dv">0</span>],[<span class="dv">1</span>,<span class="dv">1</span>]])</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Durch eine lineare Kombination kann 0 und 1 nicht unterschieden werden.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p><strong>ReLU-Trainingsproblem</strong>:<br>
ReLU: Empfindlich gegenüber der Lernrate; es besteht die Möglichkeit des “Dead ReLU”-Problems (Neuronen sind inaktiv und können nicht trainiert werden). Andere Aktivierungsfunktionen (Leaky ReLU, ELU, Swish usw.) können das Dead ReLU-Problem lindern und somit eine stabilere Lösung für das XOR-Problem als ReLU bieten. Sigmoid kann aufgrund des Verschwindens der Gradienten das Lernen erschweren. Tanh ist stabiler als ReLU, kann aber in tiefen Netzen ebenfalls das Problem des Verschwindens der Gradienten haben.</p></li>
<li><p><strong>Rückwärtsausbreitungskettenregel</strong>:<br>
<span class="math inline">\(\frac{\partial L}{\partial W} = \frac{\partial L}{\partial y}\cdot\frac{\partial y}{\partial W}\)</span></p></li>
</ol>
</section>
<section id="anwendungsaufgabenlösungen" class="level3">
<h3 class="anchored" data-anchor-id="anwendungsaufgabenlösungen">2. Anwendungsaufgabenlösungen</h3>
<ol start="4" type="1">
<li><strong>Vorteile der Swish-Funktion</strong>:
<ul>
<li>Milderung des “dying neuron”-Problems von ReLU<br>
</li>
<li>Stabilität des Lernens durch eine differenzierbare Kurve verbessert</li>
</ul></li>
<li><strong>Vorteile eines dreischichtigen Neuronalen Netzes</strong>:
<ul>
<li>Hilberts 13. Problem: Dreivariablen-stetige Funktionen können nicht mit einem zweischichtigen Netzwerk dargestellt werden.<br>
</li>
<li>Kolmogorov–Arnold-Theorem: Mit drei Schichten kann eine beliebige stetige Funktion approximiert werden.</li>
</ul></li>
</ol>
</section>
<section id="fortgeschrittene-aufgabenlösungen" class="level3">
<h3 class="anchored" data-anchor-id="fortgeschrittene-aufgabenlösungen">3. Fortgeschrittene Aufgabenlösungen</h3>
<ol start="6" type="1">
<li><p><strong>ResNet-Skip-Verbindungen</strong>:<br>
<span class="math inline">\(H(x) = F(x) + x\)</span> → <span class="math inline">\(\frac{\partial L}{\partial x} = \frac{\partial L}{\partial H} \cdot (F'(x) + 1)\)</span></p></li>
<li><p><strong>Vorteile des Transformers</strong>:</p>
<ul>
<li>Parallelisierung möglich (Überwindung der sequenziellen Verarbeitungsgrenzen von RNNs)<br>
</li>
<li>Erfassung langer Abhängigkeiten (Lernen von Bedeutungen durch Aufmerksamkeitsgewichte)</li>
</ul></li>
</ol>
</section>
</section>
</div>
</div>
<section id="wesentliche-referenzmaterialien" class="level4">
<h4 class="anchored" data-anchor-id="wesentliche-referenzmaterialien">wesentliche Referenzmaterialien</h4>
<ol type="1">
<li><p><strong><a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://www.deeplearningbook.org/">Deep Learning (Goodfellow, Bengio, Courville, 2016)</a></strong></p></li>
<li><p><strong><a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://link.springer.com/article/10.1007/BF02551274">Approximation durch Superpositionen einer sigmoidalen Funktion (Cybenko, 1989)</a></strong></p></li>
<li><p><strong><a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://www.sciencedirect.com/science/article/abs/pii/0893608089900208">Multischichtige feedforward-Netze sind universelle Approximatoren (Hornik, Stinchcombe, &amp; White, 1989)</a></strong></p></li>
<li><p><strong><a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf">Verstehen der Schwierigkeit beim Training tiefer feedforward-Neuronaler Netze (Glorot &amp; Bengio, 2010)</a></strong></p></li>
<li><p><strong><a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://arxiv.org/abs/1502.01852">Tiefer Einblick in Rektifizierer: Übersteigung der menschlichen Leistung bei ImageNet-Klassifikation (He et al., 2015)</a></strong></p></li>
<li><p><strong><a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=http://neuralnetworksanddeeplearning.com/">Neuronale Netze und Deep Learning (Michael Nielsen, Online-Buch)</a></strong></p></li>
<li><p><strong><a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://explained.ai/matrix-calculus/">Die Matrixkalkül-Grundlagen, die Sie für das Deep Learning benötigen (Parr &amp; Howard, 2018)</a></strong></p></li>
</ol>


</section>
</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>