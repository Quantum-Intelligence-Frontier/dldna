<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>el-inicio-del-aprendizaje-profundo – Deep Learning DNA: Surviving Architectures and Essential Principles</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-f507c7d0488cb7630e20aad62ad8c2aa.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script>window.MathJax = {loader: {load: ['[tex]/boldsymbol']},tex: {packages: {'[+]': ['boldsymbol']}}};</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../notebooks/es/part_1/01_El inicio del aprendizaje profundo.html">part_1</a></li><li class="breadcrumb-item"><a href="../../../notebooks/es/part_1/01_El inicio del aprendizaje profundo.html">1. El inicio del aprendizaje profundo</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../../">Español</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Language</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index_de.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Deutsch</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index_en.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">English</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index_es.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Español</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">한국어</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index_zh.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">中文</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/00_Introducción.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introducción</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">part_1</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/01_El inicio del aprendizaje profundo.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">1. El inicio del aprendizaje profundo</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/02_Matemáticas de deep learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2. Matemáticas de deep learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/03_marco de aprendizaje profundo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3. marco de aprendizaje profundo</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/04_función de activación.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4. función de activación</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/05_Optimización y visualización.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5. Optimización y visualización</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/06_Sobreajuste y desarrollo de técnicas de solución.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">6. Sobreajuste y desarrollo de técnicas de solución</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/07_Evolución de las redes neuronales convolucionales.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">7. Evolución de las redes neuronales convolucionales</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/08_El nacimiento del transformer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8. El nacimiento del transformer</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/09_La evolución del transformer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">9. La evolución del transformer</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/10_Multimodal deep learning: el inicio de la fusión multisensorial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">10. Multimodal deep learning: el inicio de la fusión multisensorial</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/11_Multimodal deep learning: inteligencia más allá de los límites.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">11. Multimodal deep learning: inteligencia más allá de los límites</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">la vanguardia del deep learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/la vanguardia del deep learning/01_SLM: pequeño pero poderoso modelo de lenguaje.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1. SLM: pequeño pero poderoso modelo de lenguaje</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/la vanguardia del deep learning/02_conducción autónoma.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2. conducción autónoma</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#el-comienzo-del-aprendizaje-profundo-principios-fundamentales-y-el-contexto-de-la-evolución-tecnológica" id="toc-el-comienzo-del-aprendizaje-profundo-principios-fundamentales-y-el-contexto-de-la-evolución-tecnológica" class="nav-link active" data-scroll-target="#el-comienzo-del-aprendizaje-profundo-principios-fundamentales-y-el-contexto-de-la-evolución-tecnológica">1. El comienzo del aprendizaje profundo: principios fundamentales y el contexto de la evolución tecnológica</a>
  <ul class="collapse">
  <li><a href="#el-propósito-de-este-libro" id="toc-el-propósito-de-este-libro" class="nav-link" data-scroll-target="#el-propósito-de-este-libro">1.1 El propósito de este libro</a></li>
  <li><a href="#historia-del-deep-learning" id="toc-historia-del-deep-learning" class="nav-link" data-scroll-target="#historia-del-deep-learning">1.2 Historia del Deep Learning</a></li>
  <li><a href="#aprendizaje-hebbiano" id="toc-aprendizaje-hebbiano" class="nav-link" data-scroll-target="#aprendizaje-hebbiano">1.3 Aprendizaje Hebbiano</a>
  <ul class="collapse">
  <li><a href="#regla-del-aprendizaje-hebbiano" id="toc-regla-del-aprendizaje-hebbiano" class="nav-link" data-scroll-target="#regla-del-aprendizaje-hebbiano">1.3.1 Regla del Aprendizaje Hebbiano</a></li>
  <li><a href="#relación-con-la-plasticidad-cerebral" id="toc-relación-con-la-plasticidad-cerebral" class="nav-link" data-scroll-target="#relación-con-la-plasticidad-cerebral">1.3.2 Relación con la Plasticidad Cerebral</a></li>
  </ul></li>
  <li><a href="#redes-neuronales-nn-neural-network" id="toc-redes-neuronales-nn-neural-network" class="nav-link" data-scroll-target="#redes-neuronales-nn-neural-network">1.4 Redes Neuronales (NN, Neural Network)</a>
  <ul class="collapse">
  <li><a href="#estructura-básica-de-las-redes-neuronales" id="toc-estructura-básica-de-las-redes-neuronales" class="nav-link" data-scroll-target="#estructura-básica-de-las-redes-neuronales">1.4.1 Estructura Básica de las Redes Neuronales</a></li>
  <li><a href="#predicción-de-precios-de-viviendas-utilizando-un-aproximador-lineal-linear-approximator" id="toc-predicción-de-precios-de-viviendas-utilizando-un-aproximador-lineal-linear-approximator" class="nav-link" data-scroll-target="#predicción-de-precios-de-viviendas-utilizando-un-aproximador-lineal-linear-approximator">1.4.2 Predicción de precios de viviendas utilizando un aproximador lineal (linear approximator)</a></li>
  <li><a href="#el-camino-a-las-redes-neuronales-el-proceso-de-operaciones-matriciales" id="toc-el-camino-a-las-redes-neuronales-el-proceso-de-operaciones-matriciales" class="nav-link" data-scroll-target="#el-camino-a-las-redes-neuronales-el-proceso-de-operaciones-matriciales">1.4.3 El camino a las redes neuronales: el proceso de operaciones matriciales</a></li>
  <li><a href="#implementación-con-numpy" id="toc-implementación-con-numpy" class="nav-link" data-scroll-target="#implementación-con-numpy">1.3.4 Implementación con NumPy</a></li>
  </ul></li>
  <li><a href="#redes-neuronales-profundas" id="toc-redes-neuronales-profundas" class="nav-link" data-scroll-target="#redes-neuronales-profundas">1.5 Redes Neuronales Profundas</a>
  <ul class="collapse">
  <li><a href="#estructura-de-las-redes-neuronales-profundas" id="toc-estructura-de-las-redes-neuronales-profundas" class="nav-link" data-scroll-target="#estructura-de-las-redes-neuronales-profundas">1.5.1 Estructura de las Redes Neuronales Profundas</a></li>
  </ul></li>
  <li><a href="#implementación-de-redes-neuronales" id="toc-implementación-de-redes-neuronales" class="nav-link" data-scroll-target="#implementación-de-redes-neuronales">1.5.2 Implementación de Redes Neuronales</a>
  <ul class="collapse">
  <li><a href="#entrenamiento-de-redes-neuronales" id="toc-entrenamiento-de-redes-neuronales" class="nav-link" data-scroll-target="#entrenamiento-de-redes-neuronales">1.5.3 Entrenamiento de redes neuronales</a></li>
  </ul></li>
  <li><a href="#ejercicios-de-práctica" id="toc-ejercicios-de-práctica" class="nav-link" data-scroll-target="#ejercicios-de-práctica">Ejercicios de práctica</a>
  <ul class="collapse">
  <li><a href="#problemas-básicos" id="toc-problemas-básicos" class="nav-link" data-scroll-target="#problemas-básicos">1. Problemas básicos</a></li>
  <li><a href="#problemas-aplicados" id="toc-problemas-aplicados" class="nav-link" data-scroll-target="#problemas-aplicados">2. Problemas aplicados</a></li>
  <li><a href="#problemas-avanzados" id="toc-problemas-avanzados" class="nav-link" data-scroll-target="#problemas-avanzados">3. Problemas avanzados</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../notebooks/es/part_1/01_El inicio del aprendizaje profundo.html">part_1</a></li><li class="breadcrumb-item"><a href="../../../notebooks/es/part_1/01_El inicio del aprendizaje profundo.html">1. El inicio del aprendizaje profundo</a></li></ol></nav></header>




<p><a href="https://colab.research.google.com/github/Quantum-Intelligence-Frontier/dldna/blob/main/notebooks/es/part_1/01_el_comienzo_del_aprendizaje_profundo.ipynb" target="_parent"> <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Abrir en Colab"> </a></p>
<section id="el-comienzo-del-aprendizaje-profundo-principios-fundamentales-y-el-contexto-de-la-evolución-tecnológica" class="level1">
<h1>1. El comienzo del aprendizaje profundo: principios fundamentales y el contexto de la evolución tecnológica</h1>
<p><strong>El inicio de la exploración del ADN del aprendizaje profundo</strong></p>
<blockquote class="blockquote">
<p>“La verdadera innovación en la tecnología nace de los fracasos pasados” - Geoffrey Hinton, discurso de aceptación del Premio Turing 2018</p>
</blockquote>
<section id="el-propósito-de-este-libro" class="level2">
<h2 class="anchored" data-anchor-id="el-propósito-de-este-libro">1.1 El propósito de este libro</h2>
<p>El aprendizaje profundo es un campo dentro del aprendizaje automático que ha experimentado un desarrollo rápido y ha mostrado resultados sorprendentes recientemente. Han surgido modelos de lenguaje grandes (LLMs) como GPT-4 y Gemini, y coexisten las expectativas y preocupaciones sobre la inteligencia artificial general (AGI). Con el rápido avance de los artículos de investigación y tecnologías, incluso los expertos encuentran difícil mantenerse al día.</p>
<p>Esta situación es similar a finales de la década de 1980, cuando las PC y los lenguajes de programación se popularizaron. En aquel entonces, surgió una gran cantidad de tecnologías, pero solo unas pocas tecnologías nucleares terminaron siendo la base de la computación moderna. De manera similar, entre las diversas arquitecturas de aprendizaje profundo actuales, como redes neuronales, CNNs, RNNs, transformers, difusión y multimodalidad, <strong>solo un pequeño número que comparte ADN clave seguirá siendo fundamental para el desarrollo continuo de la IA.</strong></p>
<p>Este libro comenzó desde esta perspectiva. En lugar de simplemente explicar métodos de API o teoría básica y ejemplos, se centra en la <strong>anatomía del ADN tecnológico</strong>. Desde el modelo de neurona McCulloch-Pitts de 1943 hasta las arquitecturas multimodales más recientes de 2025, <em>como si fuera un proceso evolutivo</em>, se enfoca en el <strong>fondo</strong> que llevó a la aparición de cada tecnología, los <strong>problemas fundamentales</strong> que buscaba resolver y sus <strong>vínculos</strong> con tecnologías anteriores. Es decir, traza un árbolo genealógico de las tecnologías de aprendizaje profundo. La sección 1.2 resume brevemente este contenido.</p>
<p>Para lograrlo, este libro tiene las siguientes características:</p>
<ul>
<li><strong>Explicaciones desde la perspectiva del ADN:</strong> No solo enumera tecnologías, sino que explica <em>por qué</em> surgieron, <em>qué problemas</em> resolvían y <em>cómo se relacionaban</em> con tecnologías anteriores, es decir, el <em>filiación (phylogeny)</em> de la tecnología.</li>
<li><strong>Explicaciones concisas pero profundas:</strong> Ayuda a comprender claramente los conceptos y principios clave, omitiendo audazmente detalles innecesarios.</li>
<li><strong>Refleja las tendencias tecnológicas más recientes:</strong> Incluye las tecnologías más actuales hasta 2025 (por ejemplo, Redes Retentivas, Mezcla de Expertos, Modelos Multimodales) para abordar la vanguardia del desarrollo del aprendizaje profundo.</li>
<li><strong>Puente entre la práctica y la investigación:</strong> Presenta ejemplos de código prácticos y una intuición matemática equilibrada para conectar la teoría con la práctica.</li>
<li><strong>Ejemplos avanzados</strong>: Más allá de simplemente proporcionar códigos que funcionen, ofrece ejemplos lo suficientemente desarrollados como para ser aplicables directamente en investigación o desarrollo.</li>
</ul>
<p>A través de esto, el objetivo es ayudar a los profesionales y investigadores a aumentar su competencia. Además, se pretende abordar las consideraciones éticas y sociales de la tecnología AI y reflexionar sobre la democratización tecnológica.</p>
</section>
<section id="historia-del-deep-learning" class="level2">
<h2 class="anchored" data-anchor-id="historia-del-deep-learning">1.2 Historia del Deep Learning</h2>
<blockquote class="blockquote">
<p><strong>Desafío:</strong> ¿Cómo hacer que las máquinas piensen y aprendan como los humanos?</p>
<p><strong>Angustia de los investigadores:</strong> Imitar el complejo funcionamiento del cerebro humano era una tarea extremadamente difícil. Los investigadores iniciales dependían de sistemas basados en reglas simples o bases de datos de conocimiento limitadas, pero esto tenía limitaciones para manejar la diversidad y complejidad del mundo real. Para crear un sistema verdaderamente inteligente, se necesitaba la capacidad de aprender por sí mismo a partir de los datos, reconocer patrones complejos y comprender conceptos abstractos. Implementar esto era el desafío central.</p>
</blockquote>
<p>La historia del deep learning comenzó en 1943 cuando Warren McCulloch y Walter Pitts presentaron un modelo matemático llamado <strong>McCulloch-Pitts Neuron</strong>, que explicaba cómo funcionan las neuronas, definiendo así los componentes básicos de una red neuronal. En 1949, Donald Hebb propuso la regla del <strong>Aprendizaje Hebbiano</strong>, explicando el ajuste de los pesos sinápticos, es decir, el principio básico del aprendizaje. En 1958, el perceptrón de Frank Rosenblatt fue la primera red neuronal práctica, pero se enfrentó a limitaciones en la clasificación no lineal, como el problema XOR.</p>
<p>La década de 1980 marcó un punto de inflexión crucial. En 1980, Kunihiko Fukushima propuso el <strong>Neocognitron (base del principio de convolución)</strong>, que más tarde se convertiría en la idea central de las CNN. El desarrollo más importante fue el algoritmo de <strong>propagación hacia atrás (backpropagation)</strong> por parte del equipo de Geoffrey Hinton en 1986. Este algoritmo permitió un aprendizaje efectivo en redes neuronales multicapa y se estableció como <em>el núcleo del aprendizaje de redes neuronales</em>. En 2006, Hinton introdujo el término “deep learning”, marcando un nuevo comienzo.</p>
<p>Desde entonces, el deep learning ha crecido rápidamente gracias al desarrollo de grandes conjuntos de datos y poder computacional. En 2012, AlexNet ganó la competencia ImageNet con un rendimiento sobresaliente, demostrando la practicidad del deep learning. Posteriormente, surgieron arquitecturas innovadoras que utilizaban <strong>Redes Recurrentes</strong>, como el <strong>LSTM (1997)</strong> y el <strong>Mecanismo de Atención (2014)</strong>. En particular, en 2017, Google presentó el <strong>Transformer</strong>, que cambió completamente el paradigma del procesamiento de lenguaje natural. <em>A través del Self-Attention, conecta directamente cada parte de la secuencia de entrada con otras partes, resolviendo problemas de dependencia a larga distancia</em>.</p>
<p>Basado en el Transformer, surgieron BERT y las series GPT, lo que llevó a un desarrollo significativo en el rendimiento de los modelos de lenguaje. <strong>Word2Vec (2013)</strong> abrió nuevas perspectivas en el embedding de palabras. En el campo de los <strong>Modelos Generativos</strong>, desde el <strong>LSTM (1997)</strong> hasta <strong>FlashAttention (después de 2023)</strong>, se ha logrado la generación de imágenes de alta calidad con <strong>Vision Transformer (ViT) (2021)</strong>, lo que aceleró el desarrollo del <strong>Aprendizaje Multimodal</strong>.</p>
<p>Los modelos de lenguaje grandes recientes como GPT-4 y Gemini han aumentado las expectativas sobre la posibilidad de lograr una IA general. Estos utilizan arquitecturas avanzadas como <strong>Redes Retentivas (2023)</strong>, técnicas de eficiencia como <strong>FlashAttention</strong> y métodos como <strong>Mixture of Experts (MoE) (2024)</strong> para volverse más sofisticados. Además, evolucionan hacia modelos <strong>Multimodales</strong> que integran diferentes tipos de datos, como texto, imágenes y audio (Gemini Ultra 2.0 en 2024 y Gemini 2.0 en 2025), mostrando habilidades cognitivas de alto nivel más allá del simple Q&amp;A, incluyendo inferencia, creación y resolución de problemas.</p>
<p>El desarrollo del deep learning se basa en los siguientes elementos clave. 1. Aumento de la disponibilidad de datos a gran escala 2. Desarrollo de recursos de computación de alto rendimiento, como GPUs 3. <strong>Backpropagation, Attention, Transformer</strong> y desarrollo de algoritmos de aprendizaje eficientes, así como de <strong>Core Architecture</strong>, <strong>Generative Models</strong></p>
<p>A pesar de estos avances, aún quedan desafíos por resolver. La explicabilidad de los modelos (Interpretability), la eficiencia en el uso de datos, el consumo de energía y los problemas de desarrollo de <strong>Efficiency &amp; Advanced Concepts</strong> son tareas importantes.</p>
<p>A continuación se presenta una visualización del árbol genealógico técnico. |</p>
<div id="cell-3" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 2025 Deep Learning Technology DNA Tree (Multimodal Updated)</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> anytree <span class="im">import</span> Node, RenderTree</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># ==== Core Mathematical Foundations &amp; Algorithms ====</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>root <span class="op">=</span> Node(<span class="st">"1943: McCulloch-Pitts Neuron"</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>math_lineage <span class="op">=</span> Node(<span class="st">"Mathematical Foundations &amp; Algorithms"</span>, parent<span class="op">=</span>root)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>hebbian <span class="op">=</span> Node(<span class="st">"1949: Hebbian Learning"</span>, parent<span class="op">=</span>math_lineage)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>backprop <span class="op">=</span> Node(<span class="st">"1986: Backpropagation (Rumelhart, Hinton, Williams)"</span>, parent<span class="op">=</span>math_lineage)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>neuroplasticity <span class="op">=</span> Node(<span class="st">"1958: Cortical Plasticity Theory (Mountcastle)"</span>, parent<span class="op">=</span>math_lineage)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>sparsity <span class="op">=</span> Node(<span class="st">"2023: Sparse Symbolic Representations (DeepMind)"</span>, parent<span class="op">=</span>backprop)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>liquid_clocks <span class="op">=</span> Node(<span class="st">"2024: Liquid Time-constant Networks"</span>, parent<span class="op">=</span>sparsity)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>dynamic_manifolds <span class="op">=</span> Node(<span class="st">"2025: Dynamic Neural Manifolds"</span>, parent<span class="op">=</span>liquid_clocks)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co"># ==== Core Architecture ====</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>core_arch <span class="op">=</span> Node(<span class="st">"Core Architecture"</span>, parent<span class="op">=</span>root)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>conv_principle <span class="op">=</span> Node(<span class="st">"1980: Convolution Principle (Neocognitron - Fukushima)"</span>, parent<span class="op">=</span>core_arch)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>attention <span class="op">=</span> Node(<span class="st">"2014: Attention Mechanism (Bahdanau)"</span>, parent<span class="op">=</span>core_arch)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>transformer <span class="op">=</span> Node(<span class="st">"2017: Transformer (Vaswani)"</span>, parent<span class="op">=</span>attention)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>retentive_net <span class="op">=</span> Node(<span class="st">"2023: Retentive Networks (Microsoft)"</span>, parent<span class="op">=</span>transformer)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>hybrid_ssm <span class="op">=</span> Node(<span class="st">"2024: Hybrid State-Space Models"</span>, parent<span class="op">=</span>retentive_net)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="co"># ==== Computer Vision ====</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>cv_lineage <span class="op">=</span> Node(<span class="st">"Computer Vision"</span>, parent<span class="op">=</span>root)</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>lenet <span class="op">=</span> Node(<span class="st">"1998: LeNet-5 (LeCun)"</span>, parent<span class="op">=</span>cv_lineage)</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>alexnet <span class="op">=</span> Node(<span class="st">"2012: AlexNet (Krizhevsky)"</span>, parent<span class="op">=</span>lenet)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>resnet <span class="op">=</span> Node(<span class="st">"2015: ResNet (He)"</span>, parent<span class="op">=</span>alexnet)</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>vision_transformer <span class="op">=</span> Node(<span class="st">"2021: ViT (Vision Transformer) (Dosovitskiy)"</span>, parent<span class="op">=</span>resnet)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>vit22b <span class="op">=</span> Node(<span class="st">"2023: ViT-22B (Google)"</span>, parent<span class="op">=</span>vision_transformer)</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>masked_autoenc <span class="op">=</span> Node(<span class="st">"2024: MAE v3 (Meta)"</span>, parent<span class="op">=</span>vit22b)</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>vit40b <span class="op">=</span> Node(<span class="st">"2025: ViT-40B (Google/Sydney)"</span>, parent<span class="op">=</span>masked_autoenc)</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>efficient_vit <span class="op">=</span> Node(<span class="st">"2025: EfficientViT-XXL"</span>, parent<span class="op">=</span>vit40b)</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="co"># ==== NLP ====</span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>nlp_lineage <span class="op">=</span> Node(<span class="st">"NLP"</span>, parent<span class="op">=</span>root)</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>word2vec <span class="op">=</span> Node(<span class="st">"2013: Word2Vec (Mikolov)"</span>, parent<span class="op">=</span>nlp_lineage)</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>bert <span class="op">=</span> Node(<span class="st">"2018: BERT (Devlin)"</span>, parent<span class="op">=</span>word2vec)</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>gpt3 <span class="op">=</span> Node(<span class="st">"2020: GPT-3 (OpenAI)"</span>, parent<span class="op">=</span>bert)</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>gpt5 <span class="op">=</span> Node(<span class="st">"2023: GPT-5 (OpenAI)"</span>, parent<span class="op">=</span>gpt3)</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>gpt55_turbo <span class="op">=</span> Node(<span class="st">"2024: GPT-5.5 Turbo"</span>, parent<span class="op">=</span>gpt5)</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>gpt6 <span class="op">=</span> Node(<span class="st">"2025: GPT-6 (Multimodal Agent)"</span>, parent<span class="op">=</span>gpt55_turbo)</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a><span class="co"># ==== Multimodal Learning ====</span></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>mm_lineage <span class="op">=</span> Node(<span class="st">"Multimodal Learning"</span>, parent<span class="op">=</span>root)</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>clip <span class="op">=</span> Node(<span class="st">"2021: CLIP (OpenAI)"</span>, parent<span class="op">=</span>mm_lineage)</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>flamingo <span class="op">=</span> Node(<span class="st">"2022: Flamingo (DeepMind)"</span>, parent<span class="op">=</span>clip)</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>kosmos <span class="op">=</span> Node(<span class="st">"2023: Kosmos-2.5 (Microsoft)"</span>, parent<span class="op">=</span>flamingo)</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>gemini <span class="op">=</span> Node(<span class="st">"2024: Gemini Ultra 2.0 (Google)"</span>, parent<span class="op">=</span>kosmos)</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>gemini_multiverse <span class="op">=</span> Node(<span class="st">"2025: Gemini Multiverse (Google)"</span>, parent<span class="op">=</span>gemini)</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>project_starline <span class="op">=</span> Node(<span class="st">"2025: Project Starline 2.0 (3D Multimodal)"</span>, parent<span class="op">=</span>gemini_multiverse)</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a><span class="co"># ==== Generative Models ====</span></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>gen_lineage <span class="op">=</span> Node(<span class="st">"Generative Models"</span>, parent<span class="op">=</span>root)</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>vae <span class="op">=</span> Node(<span class="st">"2013: VAE (Kingma)"</span>, parent<span class="op">=</span>gen_lineage)</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>gan <span class="op">=</span> Node(<span class="st">"2014: GAN (Goodfellow)"</span>, parent<span class="op">=</span>vae)</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>stylegan <span class="op">=</span> Node(<span class="st">"2018: StyleGAN (Karras)"</span>, parent<span class="op">=</span>gan)</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>diffusion <span class="op">=</span> Node(<span class="st">"2020: Diffusion Models (Ho)"</span>, parent<span class="op">=</span>stylegan)</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>sdxl_turbo <span class="op">=</span> Node(<span class="st">"2023: SDXL-Turbo (Stability AI)"</span>, parent<span class="op">=</span>diffusion)</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>meta3d_diff <span class="op">=</span> Node(<span class="st">"2024: Meta 3D Diffusion"</span>, parent<span class="op">=</span>sdxl_turbo)</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>holo_gen <span class="op">=</span> Node(<span class="st">"2025: HoloGen (Neural Holography)"</span>, parent<span class="op">=</span>meta3d_diff)</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a><span class="co"># ==== Reinforcement Learning ====</span></span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>rl_lineage <span class="op">=</span> Node(<span class="st">"Reinforcement Learning"</span>, parent<span class="op">=</span>root)</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>tdlearn <span class="op">=</span> Node(<span class="st">"1988: TD Learning (Sutton)"</span>, parent<span class="op">=</span>rl_lineage)</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>dqn <span class="op">=</span> Node(<span class="st">"2013: DQN (DeepMind)"</span>, parent<span class="op">=</span>tdlearn)</span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>alphago <span class="op">=</span> Node(<span class="st">"2016: AlphaGo (Silver)"</span>, parent<span class="op">=</span>dqn)</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>muzero <span class="op">=</span> Node(<span class="st">"2019: MuZero (DeepMind)"</span>, parent<span class="op">=</span>alphago)</span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>robot_transformer <span class="op">=</span> Node(<span class="st">"2023: RT-2 (Google)"</span>, parent<span class="op">=</span>muzero)</span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>agentic_cortex <span class="op">=</span> Node(<span class="st">"2024: Agentic Cortex (DeepMind)"</span>, parent<span class="op">=</span>robot_transformer)</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>autogpt5 <span class="op">=</span> Node(<span class="st">"2025: AutoGPT-5 (Fully Autonomous Agent)"</span>, parent<span class="op">=</span>agentic_cortex)</span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a><span class="co"># ==== Efficiency &amp; Advanced Concepts ====</span></span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a>eff_lineage <span class="op">=</span> Node(<span class="st">"Efficiency &amp; Advanced Concepts"</span>, parent<span class="op">=</span>root)</span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>flash_attn3 <span class="op">=</span> Node(<span class="st">"2023: FlashAttention-v3"</span>, parent<span class="op">=</span>eff_lineage)</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>moa <span class="op">=</span> Node(<span class="st">"2024: MoA (Mixture of Agents)"</span>, parent<span class="op">=</span>flash_attn3)</span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>nas3 <span class="op">=</span> Node(<span class="st">"2025: Neural Architecture Search 3.0"</span>, parent<span class="op">=</span>moa)</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a><span class="co"># ==== Print Tree Structure ====</span></span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"2025 Neural Network Evolution Tree:</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> pre, _, node <span class="kw">in</span> RenderTree(root):</span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>pre<span class="sc">}{</span>node<span class="sc">.</span>name<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>2025 Neural Network Evolution Tree:

1943: McCulloch-Pitts Neuron
├── Mathematical Foundations &amp; Algorithms
│   ├── 1949: Hebbian Learning
│   ├── 1986: Backpropagation (Rumelhart, Hinton, Williams)
│   │   └── 2023: Sparse Symbolic Representations (DeepMind)
│   │       └── 2024: Liquid Time-constant Networks
│   │           └── 2025: Dynamic Neural Manifolds
│   └── 1958: Cortical Plasticity Theory (Mountcastle)
├── Core Architecture
│   ├── 1980: Convolution Principle (Neocognitron - Fukushima)
│   └── 2014: Attention Mechanism (Bahdanau)
│       └── 2017: Transformer (Vaswani)
│           └── 2023: Retentive Networks (Microsoft)
│               └── 2024: Hybrid State-Space Models
├── Computer Vision
│   └── 1998: LeNet-5 (LeCun)
│       └── 2012: AlexNet (Krizhevsky)
│           └── 2015: ResNet (He)
│               └── 2021: ViT (Vision Transformer) (Dosovitskiy)
│                   └── 2023: ViT-22B (Google)
│                       └── 2024: MAE v3 (Meta)
│                           └── 2025: ViT-40B (Google/Sydney)
│                               └── 2025: EfficientViT-XXL
├── NLP
│   └── 2013: Word2Vec (Mikolov)
│       └── 2018: BERT (Devlin)
│           └── 2020: GPT-3 (OpenAI)
│               └── 2023: GPT-5 (OpenAI)
│                   └── 2024: GPT-5.5 Turbo
│                       └── 2025: GPT-6 (Multimodal Agent)
├── Multimodal Learning
│   └── 2021: CLIP (OpenAI)
│       └── 2022: Flamingo (DeepMind)
│           └── 2023: Kosmos-2.5 (Microsoft)
│               └── 2024: Gemini Ultra 2.0 (Google)
│                   └── 2025: Gemini Multiverse (Google)
│                       └── 2025: Project Starline 2.0 (3D Multimodal)
├── Generative Models
│   └── 2013: VAE (Kingma)
│       └── 2014: GAN (Goodfellow)
│           └── 2018: StyleGAN (Karras)
│               └── 2020: Diffusion Models (Ho)
│                   └── 2023: SDXL-Turbo (Stability AI)
│                       └── 2024: Meta 3D Diffusion
│                           └── 2025: HoloGen (Neural Holography)
├── Reinforcement Learning
│   └── 1988: TD Learning (Sutton)
│       └── 2013: DQN (DeepMind)
│           └── 2016: AlphaGo (Silver)
│               └── 2019: MuZero (DeepMind)
│                   └── 2023: RT-2 (Google)
│                       └── 2024: Agentic Cortex (DeepMind)
│                           └── 2025: AutoGPT-5 (Fully Autonomous Agent)
└── Efficiency &amp; Advanced Concepts
    └── 2023: FlashAttention-v3
        └── 2024: MoA (Mixture of Agents)
            └── 2025: Neural Architecture Search 3.0</code></pre>
</div>
</div>
</section>
<section id="aprendizaje-hebbiano" class="level2">
<h2 class="anchored" data-anchor-id="aprendizaje-hebbiano">1.3 Aprendizaje Hebbiano</h2>
<p>Después de que Warren McCulloch y Walter Pitts propusieran el modelo de red neuronal artificial (McCulloch-Pitts Neuron) en 1943, en 1949, Donald O. Hebb, un psicólogo canadiense, presentó los principios fundamentales del aprendizaje de redes neuronales en su libro “The Organization of Behavior”. Este principio se conoce como <strong>regla de Hebb (Hebb’s Rule)</strong> o <strong>aprendizaje hebbiano (Hebbian Learning)</strong> y ha tenido un gran impacto en la investigación de redes neuronales artificiales, incluido el deep learning.</p>
<section id="regla-del-aprendizaje-hebbiano" class="level3">
<h3 class="anchored" data-anchor-id="regla-del-aprendizaje-hebbiano">1.3.1 Regla del Aprendizaje Hebbiano</h3>
<p>La idea central del aprendizaje hebbiano es muy simple: si dos neuronas se activan simultáneamente o repetidamente, la fuerza de conexión entre ellas aumenta. Por el contrario, si las dos neuronas se activan en diferentes momentos o una neurona se activa y la otra no, la fuerza de conexión disminuye o desaparece.</p>
<p>Esto se puede expresar matemáticamente de la siguiente manera:</p>
<p><span class="math display">\[
\Delta w_{ij} = \eta \cdot x_i \cdot y_j
\]</span></p>
<p>Donde,</p>
<ul>
<li><span class="math inline">\(\Delta w_{ij}\)</span> es el cambio en la fuerza de conexión (peso) entre la neurona <span class="math inline">\(i\)</span> y la neurona <span class="math inline">\(j\)</span>.</li>
<li><span class="math inline">\(\eta\)</span> es la tasa de aprendizaje (learning rate), una constante que ajusta la magnitud del cambio en la fuerza de conexión.</li>
<li><span class="math inline">\(x_i\)</span> es el valor de activación (entrada) de la neurona <span class="math inline">\(i\)</span>.</li>
<li><span class="math inline">\(y_j\)</span> es el valor de activación (salida) de la neurona <span class="math inline">\(j\)</span>.</li>
</ul>
<p>Esta ecuación muestra que cuando ambas neuronas <span class="math inline">\(i\)</span> y <span class="math inline">\(j\)</span> se activan (<span class="math inline">\(x_i\)</span> y <span class="math inline">\(y_j\)</span> son ambos positivos), la fuerza de conexión aumenta (<span class="math inline">\(\Delta w_{ij}\)</span> es positivo). Por el contrario, si solo una de ellas se activa o ninguna de las dos se activa, la fuerza de conexión disminuye o no cambia. El aprendizaje hebbiano es una de las primeras formas de <strong>aprendizaje no supervisado (unsupervised learning)</strong>. Es decir, sin que se proporcionen respuestas correctas (labels), la red neuronal ajusta por sí misma la fuerza de conexión mientras aprende a partir de los patrones en los datos de entrada.</p>
</section>
<section id="relación-con-la-plasticidad-cerebral" class="level3">
<h3 class="anchored" data-anchor-id="relación-con-la-plasticidad-cerebral">1.3.2 Relación con la Plasticidad Cerebral</h3>
<p>El aprendizaje hebbiano va más allá de ser una simple regla matemática y proporciona importantes insights sobre el funcionamiento del cerebro real. El cerebro cambia constantemente a través de la experiencia y el aprendizaje, y estos cambios se conocen como <strong>plasticidad cerebral (brain plasticity)</strong> o <strong>plasticidad neural (neural plasticity)</strong>. El aprendizaje hebbiano desempeña un papel clave en la explicación de una forma de plasticidad neural llamada <strong>plasticidad sináptica (synaptic plasticity)</strong>. Los sinapsis son las conexiones entre las neuronas y determinan la eficiencia del intercambio de información. El aprendizaje hebbiano ilustra claramente el principio fundamental de la plasticidad sináptica, es decir, <strong>“las neuronas que se activan juntas, se conectan juntas”</strong>. La potenciación a largo plazo (Long-Term Potentiation, LTP) y la depresión a largo plazo (Long-Term Depression, LTD) son ejemplos representativos de plasticidad sináptica. LTP es un fenómeno en el que las conexiones sinápticas se fortalecen según la regla del aprendizaje hebbiano, mientras que LTD es el fenómeno contrario. LTP y LTD desempeñan roles importantes en el aprendizaje, la memoria y el desarrollo cerebral.</p>
</section>
</section>
<section id="redes-neuronales-nn-neural-network" class="level2">
<h2 class="anchored" data-anchor-id="redes-neuronales-nn-neural-network">1.4 Redes Neuronales (NN, Neural Network)</h2>
<p>Las redes neuronales son aproximadores de funciones que reciben entradas y generan valores lo más cercanos posible a la salida deseada. Esto se expresa matemáticamente como <span class="math inline">\(f_\theta\)</span>, donde <span class="math inline">\(f\)</span> es la función y <span class="math inline">\(\theta\)</span> representa los parámetros compuestos por pesos (weight) y sesgos (bias). El núcleo de las redes neuronales radica en su capacidad para aprender automáticamente estos parámetros a partir de los datos.</p>
<p>La primera red neuronal, propuesta por Warren McCullough y Walter Pitts en 1944, se inspiró en las neuronas biológicas, aunque las redes neuronales modernas son modelos puramente matemáticos. En realidad, las redes neuronales son poderosas herramientas matemáticas capaces de aproximar funciones continuas, lo cual ha sido demostrado por el teorema de aproximación universal (Universal Approximation Theorem).</p>
<section id="estructura-básica-de-las-redes-neuronales" class="level3">
<h3 class="anchored">1.4.1 Estructura Básica de las Redes Neuronales</h3>
<p>Las redes neuronales tienen una estructura jerárquica compuesta por capas de entrada, capas ocultas y capas de salida. Cada capa está formada por nodos (neuronas) que se conectan entre sí para transmitir información. Básicamente, las redes neuronales están constituidas por una combinación de transformaciones lineales y funciones de activación no lineales.</p>
<p>Matemáticamente, cada capa de una red neuronal realiza la siguiente transformación lineal:</p>
<p><span class="math display">\[ y = Wx + b \]</span></p>
<p>donde:</p>
<ul>
<li><span class="math inline">\(x\)</span> es el vector de entrada</li>
<li><span class="math inline">\(W\)</span> es la matriz de pesos</li>
<li><span class="math inline">\(b\)</span> es el vector de sesgos</li>
<li><span class="math inline">\(y\)</span> es el vector de salida</li>
</ul>
<p>A pesar de que esta estructura puede parecer simple, una red neuronal con suficientes neuronas y capas puede aproximar cualquier función continua con la precisión deseada. Este es el motivo por el cual las redes neuronales pueden aprender patrones complejos y resolver diversos problemas.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Haga clic para ver el contenido (deep dive: teorema de aproximación universal)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Haga clic para ver el contenido (deep dive: teorema de aproximación universal)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<section id="teorema-de-aproximación-universal" class="level2 callout-body-container callout-body">
<h2 class="anchored" data-anchor-id="teorema-de-aproximación-universal">Teorema de Aproximación Universal</h2>
<blockquote class="blockquote">
<p><strong>Desafío:</strong> ¿Cómo se puede demostrar que una red neuronal puede aproximar cualquier función compleja?</p>
<p><strong>Preocupaciones del investigador:</strong> Incluso con muchas capas y neuronas, no era evidente si una red neuronal realmente podía representar <em>cualquier</em> función continua. Había preocupación de que solo combinando transformaciones lineales simples podría ser difícil expresar la complejidad no lineal. Depender únicamente de resultados empíricos sin garantías teóricas fue un gran obstáculo para el desarrollo de la investigación en redes neuronales.</p>
</blockquote>
<p><strong>Teorema de Aproximación Universal (Universal Approximation Theorem)</strong></p>
<p>El Teorema de Aproximación Universal es una teoría fundamental que respalda el poder de representación de las redes neuronales. Este teorema demuestra que, <em>una red neuronal de una sola capa con un número suficientemente grande de neuronas ocultas</em>, puede aproximar <strong>cualquier función continua</strong> con la precisión deseada.</p>
<p><strong>Idea clave:</strong></p>
<ul>
<li><strong>Funciones de activación no lineales:</strong> Las funciones de activación no lineales como ReLU, sigmoid y tanh son componentes esenciales que permiten a las redes neuronales expresar no linealidad. Sin estas funciones de activación, incluso con muchas capas, solo serían una combinación de transformaciones lineales.</li>
<li><strong>Capa oculta suficientemente grande:</strong> Si el número de neuronas en la capa oculta es suficiente, la red neuronal adquiere la “flexibilidad” para representar cualquier función compleja. Es similar a poder crear cualquier imagen de mosaico con un número suficiente de piezas.</li>
</ul>
<p><strong>Expresión matemática:</strong></p>
<p><strong>Teorema (Teorema de Aproximación Universal):</strong></p>
<p>Sea <span class="math inline">\(f : K \rightarrow \mathbb{R}\)</span> una función continua definida en un conjunto compacto <span class="math inline">\(K \subset \mathbb{R}^d\)</span>. Dado cualquier límite de error <span class="math inline">\(\epsilon &gt; 0\)</span>, existe una <em>red neuronal de una sola capa</em> <span class="math inline">\(F(x)\)</span> que satisface la siguiente condición.</p>
<p><span class="math inline">\(|f(x) - F(x)| &lt; \epsilon\)</span>, para todo <span class="math inline">\(x \in K\)</span>.</p>
<p>Aquí, <span class="math inline">\(F(x)\)</span> tiene la siguiente forma.</p>
<p><span class="math inline">\(F(x) = \sum_{i=1}^{N} w_i \cdot \sigma(v_i^T x + b_i)\)</span></p>
<p><strong>Explicación detallada:</strong></p>
<ul>
<li><p><strong><span class="math inline">\(f : K \rightarrow \mathbb{R}\)</span>:</strong></p>
<ul>
<li><span class="math inline">\(f\)</span> es la función objetivo que se desea aproximar.</li>
<li><span class="math inline">\(K\)</span> es el <em>dominio</em> de la función, un <em>conjunto compacto</em> en <span class="math inline">\(\mathbb{R}^d\)</span> (espacio real d-dimensional). Un conjunto compacto intuitivamente significa “con fronteras y cerrado”. Por ejemplo, en una dimensión, un intervalo cerrado [a, b] es un conjunto compacto. Esta condición no es restrictiva en la práctica, ya que la mayoría de los datos de entrada reales tienen un rango limitado.</li>
<li><span class="math inline">\(\mathbb{R}\)</span> es el conjunto de números reales. Es decir, la función <span class="math inline">\(f\)</span> asigna cada punto (<span class="math inline">\(x\)</span>) en <span class="math inline">\(K\)</span> a un valor real (<span class="math inline">\(f(x)\)</span>). (Para funciones multivariables y múltiples salidas, se explica adicionalmente a continuación.)</li>
</ul></li>
<li><p><strong><span class="math inline">\(\epsilon &gt; 0\)</span>:</strong> Un número positivo arbitrario que representa la <em>precisión</em> de la aproximación. Cuanto más pequeño sea <span class="math inline">\(\epsilon\)</span>, más precisa será la aproximación.</p></li>
<li><p><strong><span class="math inline">\(|f(x) - F(x)| &lt; \epsilon\)</span>:</strong> Significa que para todo <span class="math inline">\(x \in K\)</span>, la diferencia entre el valor real de la función <span class="math inline">\(f(x)\)</span> y la salida de la red neuronal <span class="math inline">\(F(x)\)</span> es menor que <span class="math inline">\(\epsilon\)</span>. Es decir, la red neuronal puede aproximar la función <span class="math inline">\(f\)</span> dentro del rango de error <span class="math inline">\(\epsilon\)</span>.</p></li>
<li><p><strong><span class="math inline">\(F(x) = \sum_{i=1}^{N} w_i \cdot \sigma(v_i^T x + b_i)\)</span>:</strong> Representa la estructura de una red neuronal de una sola capa.</p></li>
<li><p><strong><span class="math inline">\(N\)</span>:</strong> es el número de neuronas (unidades) en la capa oculta. El teorema de aproximación universal garantiza la existencia de un <span class="math inline">\(N\)</span> <em>suficientemente grande</em>, pero no especifica cuánto debe ser exactamente.</p></li>
<li><p><strong><span class="math inline">\(w_i \in \mathbb{R}\)</span>:</strong> es el <em>peso de salida (output weight)</em> entre la neurona <span class="math inline">\(i\)</span>-ésima de la capa oculta y la neurona de la capa de salida. Es un valor escalar.</p></li>
<li><p><strong><span class="math inline">\(\sigma\)</span>:</strong> es una <em>función de activación no lineal</em>. Se pueden usar diversas funciones como ReLU, sigmoid, tanh, leaky ReLU, etc. Para que el teorema de aproximación universal se cumpla, <span class="math inline">\(\sigma\)</span> debe ser <strong>no polinomial (non-polynomial)</strong> y debe ser <strong>acotada (bounded)</strong> o <strong>continua por tramos (piecewise continuous)</strong>.</p></li>
<li><p><strong><span class="math inline">\(v_i \in \mathbb{R}^d\)</span>:</strong> es el <em>vector de pesos de entrada (input weight vector)</em> para la neurona <span class="math inline">\(i\)</span>-ésima de la capa oculta. Tiene la misma dimensión que la entrada <span class="math inline">\(x\)</span>.</p></li>
<li><p><strong><span class="math inline">\(v_i^T x\)</span>:</strong> es el producto interno (inner product, dot product) entre los vectores <span class="math inline">\(v_i\)</span> y <span class="math inline">\(x\)</span>.</p></li>
<li><p><strong><span class="math inline">\(b_i \in \mathbb{R}\)</span>:</strong> es el <em>sesgo (bias)</em> de la neurona <span class="math inline">\(i\)</span>-ésima de la capa oculta. Es un valor escalar.</p></li>
</ul>
<p><strong>Explicación adicional (funciones multivariables, múltiples salidas):</strong></p>
<ul>
<li><p><strong>Funciones multivariables:</strong> El teorema de aproximación universal también se aplica cuando la entrada <span class="math inline">\(x\)</span> es un vector (<span class="math inline">\(x \in \mathbb{R}^d\)</span>, <span class="math inline">\(d &gt; 1\)</span>). La operación <span class="math inline">\(v_i^T x\)</span> (producto interno) maneja naturalmente las entradas multivariables.</p></li>
<li><p><strong>Múltiples salidas:</strong> Cuando la función <span class="math inline">\(f\)</span> tiene múltiples valores de salida (<span class="math inline">\(f : K \rightarrow \mathbb{R}^m\)</span>, <span class="math inline">\(m &gt; 1\)</span>), se pueden usar neuronas y pesos de salida separados para cada salida. Así, <span class="math inline">\(F(x)\)</span> tendrá una salida en forma de vector y se puede asegurar que el error de aproximación para cada salida sea menor que <span class="math inline">\(\epsilon\)</span>.</p></li>
</ul>
<p><strong>Velocidad de convergencia del error (Teorema de Barron):</strong></p>
<p>Según el teorema de Barron, bajo ciertas condiciones (condiciones sobre la transformada de Fourier de la función de activación y la función a aproximar), el error <span class="math inline">\(\epsilon\)</span> tiene la siguiente relación con el número de neuronas <span class="math inline">\(N\)</span>:</p>
<p><span class="math inline">\(\epsilon(N) = O(N^{-1/2})\)</span></p>
<p>Esto significa que el error disminuye a una tasa de <span class="math inline">\(N^{-1/2}\)</span> a medida que aumenta el número de neuronas. En otras palabras, al cuadruplicar el número de neuronas, el error se reduce aproximadamente a la mitad. Esta es la <em>velocidad general</em> de convergencia, aunque para funciones o funciones de activación específicas, la velocidad puede ser más rápida o más lenta.</p>
<p><strong>Contraejemplos y limitaciones:</strong></p>
<ul>
<li><p><strong>Aproximación en frontera:</strong> Funciones como <span class="math inline">\(e^{-1/x^2}\)</span> que son infinitamente diferenciables en <span class="math inline">\(x=0\)</span>, pero con cambios bruscos, pueden ser difíciles de aproximar cerca de <span class="math inline">\(x=0\)</span> usando redes neuronales. Este problema surge porque la serie de Taylor de dichas funciones es cero, aunque la función misma no lo sea.</p></li>
<li><p><strong>Complejidad exponencial de funciones discretas:</strong> El número de neuronas necesarias para aproximar una función booleana de <span class="math inline">\(n\)</span> variables puede ser proporcional a <span class="math inline">\(2^n / n\)</span> en el peor caso. Esto significa que el número de neuronas requeridas puede aumentar <em>exponencialmente</em> con el número de variables de entrada, mostrando que las redes neuronales no pueden aproximar eficientemente todas las funciones.</p></li>
</ul>
<p><strong>Resumen clave:</strong> El teorema de aproximación universal establece que una <em>red neuronal de un solo nivel</em> con un <em>capa oculta suficientemente ancha</em> puede aproximar cualquier función continua definida en un conjunto acotado y cerrado con la precisión deseada. La función de activación debe ser <em>no polinomial</em>. Esto implica que las redes neuronales tienen una gran capacidad representativa (representational power) y proporcionan una base teórica para el aprendizaje profundo. El teorema de Barron ofrece insights sobre la velocidad de convergencia del error.</p>
<p><strong>Puntos importantes</strong></p>
<ul>
<li><strong>Prueba de existencia:</strong> El teorema de aproximación universal es una <em>prueba de existencia</em> y no propone un <em>algoritmo de aprendizaje</em>. Asegura que existe tal red neuronal, pero cómo encontrarla en la práctica es otro problema. (Los algoritmos de retropropagación y descenso del gradiente son métodos para resolver este problema.)</li>
<li><strong>Redes simples vs.&nbsp;redes profundas:</strong> En la práctica, las <em>redes neuronales profundas</em> suelen ser más eficientes y tener un mejor rendimiento en generalización que las redes neuronales de un solo nivel. Aunque el teorema de aproximación universal proporciona una base teórica para el aprendizaje profundo, el éxito del aprendizaje profundo es el resultado de la combinación de múltiples capas, arquitecturas especializadas y algoritmos de aprendizaje eficientes. Teóricamente, las redes neuronales de un solo nivel pueden representar todo, pero su entrenamiento en la práctica puede ser mucho más difícil.</li>
<li><strong>Conocimiento de los límites:</strong> Aunque el teorema de aproximación universal es un resultado poderoso, no garantiza que todas las funciones puedan ser aproximadas <em>eficientemente</em>. Como se ve en contraejemplos, ciertas funciones pueden requerir una cantidad muy grande de neuronas para ser aproximadas.</li>
</ul>
<p><strong>Referencias:</strong></p>
<ol type="1">
<li><strong>Cybenko, G. (1989).</strong> Approximation by superpositions of a sigmoidal function. <em>Mathematics of Control, Signals, and Systems</em>, 2(4), 303-314. (Teorema de aproximación universal inicial para funciones de activación sigmoide)</li>
<li><strong>Hornik, K., Stinchcombe, M., &amp; White, H. (1989).</strong> Multilayer feedforward networks are universal approximators. <em>Neural Networks</em>, 2(5), 359-366. (Teorema de aproximación universal para funciones de activación más generales)</li>
<li><strong>Barron, A. R. (1993).</strong> Universal approximation bounds for superpositions of a sigmoidal function. <em>IEEE Transactions on Information Theory</em>, 39(3), 930-945. (Teorema de Barron sobre la velocidad de convergencia del error)</li>
<li><strong>Pinkus, A. (1999).</strong> Approximation theory of the MLP model in neural networks. <em>Acta Numerica</em>, 8, 143-195. (Revisión más profunda del teorema de aproximación universal)</li>
<li><strong>Goodfellow, I., Bengio, Y., &amp; Courville, A. (2016).</strong> <em>Deep Learning</em>. MIT Press. (Capítulo 6.4: Texto de aprendizaje profundo. Incluye contenido relacionado con el teorema de aproximación universal)</li>
</ol>
</section>
</div>
</div>
</section>
<section id="predicción-de-precios-de-viviendas-utilizando-un-aproximador-lineal-linear-approximator" class="level3">
<h3 class="anchored" data-anchor-id="predicción-de-precios-de-viviendas-utilizando-un-aproximador-lineal-linear-approximator">1.4.2 Predicción de precios de viviendas utilizando un aproximador lineal (linear approximator)</h3>
<p>Para comprender los conceptos básicos de las redes neuronales, examinaremos un problema de regresión lineal simple. Aquí utilizamos el conjunto de datos de precios de viviendas en California de la biblioteca <code>scikit-learn</code>. Este conjunto de datos incluye varias características (features) de las viviendas y se puede usar para crear un modelo que prediga los precios de las viviendas. Como ejemplo simple, asumiremos que el precio de una vivienda depende solo de una característica: el ingreso medio (<code>MedInc</code>), e implementaremos un aproximador lineal.</p>
<div id="cell-8" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_california_housing</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the California housing dataset</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>housing <span class="op">=</span> fetch_california_housing(as_frame<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> housing.frame</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Use only Median Income (MedInc) and Median House Value (MedHouseVal)</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data[[<span class="st">"MedInc"</span>, <span class="st">"MedHouseVal"</span>]]</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the first 5 rows of the data</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(data.head())</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data into training and testing sets</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>    data[[<span class="st">"MedInc"</span>]], data[<span class="st">"MedHouseVal"</span>], test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Create and train a linear regression model</span></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LinearRegression()</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>model.fit(X_train, y_train)</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on the test data</span></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> model.predict(X_test)</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare data for visualization</span></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>plot_data <span class="op">=</span> pd.DataFrame({<span class="st">'MedInc'</span>: X_test[<span class="st">'MedInc'</span>], <span class="st">'MedHouseVal'</span>: y_test, <span class="st">'Predicted'</span>: y_pred})</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Sort for better line plot visualization.  Crucially, sort *after* prediction.</span></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>plot_data <span class="op">=</span> plot_data.sort_values(by<span class="op">=</span><span class="st">'MedInc'</span>)</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize using Seaborn</span></span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span><span class="st">'MedInc'</span>, y<span class="op">=</span><span class="st">'MedHouseVal'</span>, data<span class="op">=</span>plot_data, label<span class="op">=</span><span class="st">'Actual'</span>, alpha<span class="op">=</span><span class="fl">0.6</span>)</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>sns.lineplot(x<span class="op">=</span><span class="st">'MedInc'</span>, y<span class="op">=</span><span class="st">'Predicted'</span>, data<span class="op">=</span>plot_data, color<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">'Predicted'</span>, linewidth<span class="op">=</span><span class="fl">2.5</span>)</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'California Housing Prices Prediction (Linear Regression)'</span>)</span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Median Income (MedInc)'</span>)</span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Median House Value (MedHouseVal)'</span>)</span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the trained weight (coefficient) and bias (intercept)</span></span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Weight (Coefficient):"</span>, model.coef_[<span class="dv">0</span>])</span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Bias (Intercept):"</span>, model.intercept_)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>   MedInc  MedHouseVal
0  8.3252        4.526
1  8.3014        3.585
2  7.2574        3.521
3  5.6431        3.413
4  3.8462        3.422</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="01_El inicio del aprendizaje profundo_files/figure-html/cell-3-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Weight (Coefficient): 0.4193384939381271
Bias (Intercept): 0.4445972916907879</code></pre>
</div>
</div>
<p>El código primero carga el conjunto de datos de precios de viviendas de California usando la función <code>fetch_california_housing</code>. Luego, obtiene los datos en formato de DataFrame de Pandas con <code>as_frame=True</code> y selecciona solo las características del precio de la vivienda (<code>MedHouseVal</code>) y el ingreso mediano (<code>MedInc</code>). Después de dividir los datos en conjuntos de entrenamiento y prueba utilizando la función <code>train_test_split</code>, se crea un modelo de regresión lineal con la clase <code>LinearRegression</code> y se entrena el modelo con los datos de entrenamiento usando el método <code>fit</code>. El modelo entrenado realiza predicciones en los datos de prueba mediante el método <code>predict</code> y visualiza los valores reales y las predicciones utilizando Seaborn. Finalmente, se imprimen los pesos y sesgos del modelo entrenado.</p>
<p>Así, es posible realizar ciertas predicciones con una simple transformación lineal. Las redes neuronales agregan funciones de activación no lineales y apilan múltiples capas para aproximar funciones mucho más complejas.</p>
</section>
<section id="el-camino-a-las-redes-neuronales-el-proceso-de-operaciones-matriciales" class="level3">
<h3 class="anchored" data-anchor-id="el-camino-a-las-redes-neuronales-el-proceso-de-operaciones-matriciales">1.4.3 El camino a las redes neuronales: el proceso de operaciones matriciales</h3>
<p>La etapa previa de una red neuronal es un aproximador lineal. Aquí, examinaremos en detalle cómo el ejemplo anterior llega al valor real. La forma lineal más simple para el valor real <span class="math inline">\(\boldsymbol y\)</span> es <span class="math inline">\(\boldsymbol y = \boldsymbol x \boldsymbol W + \boldsymbol b\)</span>.</p>
<p>Aquí, <span class="math inline">\(\boldsymbol W\)</span> es el peso (weight parameter), y <span class="math inline">\(\boldsymbol b\)</span> es el sesgo (bias). Optimizar estos dos parámetros a partir de los datos es la clave del aprendizaje de la red neuronal. Como veremos en 1.4, las redes neuronales introducen no linealidad agregando funciones de activación a las transformaciones lineales y optimizando los parámetros a través del backpropagation. Aquí, solo examinaremos el proceso de cálculo simple utilizando transformaciones lineales y backpropagation.</p>
<p>Inicialmente, se establecen los parámetros con valores aleatorios.</p>
<p><span class="math display">\[ \boldsymbol W =  \begin{bmatrix}
   0.1  \\
   0.1   \\
   \end{bmatrix} \]</span></p>
<p><span class="math display">\[ \boldsymbol b =  \begin{bmatrix}
   0  \\
   0   \\
   0   \\
   \end{bmatrix} \]</span></p>
<p>Con estos valores, se realiza la predicción.</p>
<p><span class="math display">\[ \hat{\boldsymbol y} =  \begin{bmatrix}
   1.5 &amp; 1  \\
   2.4 &amp; 2  \\
   3.5 &amp; 3   \\
   \end{bmatrix}
   \begin{bmatrix}
   0.1  \\
   0.1   \\
   \end{bmatrix} +
   \begin{bmatrix}
   0  \\
   0   \\
   0   \\
   \end{bmatrix} =
    \begin{bmatrix}
   0.25  \\
   0.44   \\
   0.65   \\
   \end{bmatrix}\]</span></p>
<p>Aquí, <span class="math inline">\(\hat{\boldsymbol y}\)</span> representa el valor predicho. La diferencia (pérdida) con respecto al valor real es la siguiente.</p>
<p><span class="math display">\[ L = \boldsymbol y - \hat {\boldsymbol y}  = \begin{bmatrix}
   2.1  \\
   4.2   \\
   5.9   \\
   \end{bmatrix} -
   \begin{bmatrix}
   0.25  \\
   0.44   \\
   0.65   \\
   \end{bmatrix} =
  \begin{bmatrix}
   1.85  \\
   3.76  \\
   5.25  \\
   \end{bmatrix} \]</span></p>
<p>La optimización de los parámetros se realiza utilizando el gradiente (gradient). <strong>El gradiente apunta en la dirección en la que el error aumenta</strong>, por lo que se resta del parámetro actual para reducir el error. Introduciendo una tasa de aprendizaje (<span class="math inline">\(\eta\)</span>),</p>
<p><span class="math display">\[ \text{new parameters} = \text{current parameters} - \eta \times \text{gradients} \]</span></p>
<p>Por ejemplo, cuando <span class="math inline">\(\eta=0.01\)</span>, la actualización del peso es la siguiente.</p>
<p><span class="math display">\[ \begin{bmatrix}
   0.30116    \\
   0.26746667    \\
   \end{bmatrix} =
   \begin{bmatrix}
    0.1    \\
    0.1    \\
   \end{bmatrix} - 0.01 \times
    \begin{bmatrix}
    -20.116   \\
    -16.74666667   \\
   \end{bmatrix}\]</span></p>
<p>El sesgo también se actualiza de la misma manera. Repitiendo este cálculo de adelante (forward) y atrás (backward), los parámetros se optimizan, lo cual es el proceso de aprendizaje de una red neuronal.</p>
</section>
<section id="implementación-con-numpy" class="level3">
<h3 class="anchored">1.3.4 Implementación con NumPy</h3>
<p>Examinemos la implementación de un aproximador lineal utilizando NumPy. Primero, preparamos los datos de entrada y los valores objetivo.</p>
<div id="cell-11" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Set input values and target values</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array([[<span class="fl">1.5</span>, <span class="dv">1</span>], [<span class="fl">2.4</span>, <span class="dv">2</span>], [<span class="fl">3.5</span>, <span class="dv">3</span>]])</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.array([<span class="fl">2.1</span>, <span class="fl">4.2</span>, <span class="fl">5.9</span>])</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.01</span>  <span class="co">#  Adding the learning_rate variable here, even though it's unused, for consistency.</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"X ="</span>, X)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"y ="</span>, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>X = [[1.5 1. ]
 [2.4 2. ]
 [3.5 3. ]]
y = [2.1 4.2 5.9]</code></pre>
</div>
</div>
<p>La tasa de aprendizaje se estableció en 0.01. La tasa de aprendizaje es un hiperparámetro que afecta la velocidad y estabilidad del aprendizaje del modelo. Se inicializan los pesos y sesgos.</p>
<div id="cell-13" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>m, n <span class="op">=</span> X.shape</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize weights and bias</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>weights <span class="op">=</span> np.array([<span class="fl">0.1</span>, <span class="fl">0.1</span>])</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>bias <span class="op">=</span> <span class="fl">0.0</span>  <span class="co"># Corrected: Bias should be a single scalar value.</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"X.shape ="</span>, X.shape)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Initial weights ="</span>, weights)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Initial bias ="</span>, bias)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>X.shape = (3, 2)
Initial weights = [0.1 0.1]
Initial bias = 0.0</code></pre>
</div>
</div>
<p>El cálculo en dirección forward realiza una transformación lineal. La fórmula es la siguiente. <span class="math display">\[ \boldsymbol y = \boldsymbol X \boldsymbol W + \boldsymbol b \]</span></p>
<div id="cell-15" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>y_predicted <span class="op">=</span> np.dot(X, weights) <span class="op">+</span> bias</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Predicted values ="</span>, y_predicted)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>error <span class="op">=</span> y <span class="op">-</span> y_predicted</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Error ="</span>, error)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Predicted values = [0.25 0.44 0.65]
Error = [1.85 3.76 5.25]</code></pre>
</div>
</div>
<p>He calculado hasta la pérdida. El siguiente paso es calcular el gradiente a partir de la pérdida. ¿Cómo se hace? Los gradientes de los pesos y sesgos son los siguientes.</p>
<p><span class="math inline">\(\nabla_w = -\frac{2}{m}\mathbf{X}^T\mathbf{e}\)</span></p>
<p><span class="math inline">\(\nabla_b = -\frac{2}{m}\mathbf{e}\)</span></p>
<p>Aquí, <span class="math inline">\(\mathbf{e}\)</span> es el vector de error. Una vez que se han calculado los gradientes, se resta el valor del gradiente de los parámetros existentes para obtener el nuevo valor actualizado de los parámetros.</p>
<div id="cell-17" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>weights_gradient <span class="op">=</span> <span class="op">-</span><span class="dv">2</span><span class="op">/</span>m <span class="op">*</span> np.dot(X.T, error)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>bias_gradient <span class="op">=</span> <span class="op">-</span><span class="dv">2</span><span class="op">/</span>m <span class="op">*</span> error.<span class="bu">sum</span>()  <span class="co"># Corrected: Sum the errors for bias gradient</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>weights <span class="op">-=</span> learning_rate <span class="op">*</span> weights_gradient</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>bias <span class="op">-=</span> learning_rate <span class="op">*</span> bias_gradient</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Updated weights ="</span>, weights)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Updated bias ="</span>, bias)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Updated weights = [0.50232    0.43493333]
Updated bias = 0.14479999999999998</code></pre>
</div>
</div>
<p>El paso anterior es el cálculo backward (reverso). Se llama backpropagation (retropropagación) porque los gradientes se calculan y transmiten en orden inverso. Ahora implementamos todo el proceso de entrenamiento como una función.</p>
<div id="cell-19" class="cell" data-execution_count="12">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train(X: np.ndarray, y: np.ndarray, lr: <span class="bu">float</span>, iters: <span class="bu">int</span> <span class="op">=</span> <span class="dv">100</span>, verbose: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span>) <span class="op">-&gt;</span> <span class="bu">tuple</span>:</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Linear regression training function.</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co">        X: Input data, shape (m, n)</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="co">        y: Target values, shape (m,)</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="co">        lr: Learning rate</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="co">        iters: Number of iterations</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="co">        verbose: Whether to print intermediate steps</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a><span class="co">        Tuple: Trained weights and bias</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>    m, n <span class="op">=</span> X.shape</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>    weights <span class="op">=</span> np.array([<span class="fl">0.1</span>, <span class="fl">0.1</span>])</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>    bias <span class="op">=</span> <span class="fl">0.0</span>  <span class="co"># Corrected: Bias should be a scalar</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(iters):</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Forward pass</span></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>        y_predicted <span class="op">=</span> np.dot(X, weights) <span class="op">+</span> bias</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>        error <span class="op">=</span> y <span class="op">-</span> y_predicted</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Backward pass</span></span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>        weights_gradient <span class="op">=</span> <span class="op">-</span><span class="dv">2</span><span class="op">/</span>m <span class="op">*</span> np.dot(X.T, error)</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>        bias_gradient <span class="op">=</span> <span class="op">-</span><span class="dv">2</span><span class="op">/</span>m <span class="op">*</span> error </span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>        weights <span class="op">-=</span> lr <span class="op">*</span> weights_gradient</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>        bias <span class="op">-=</span> lr <span class="op">*</span> bias_gradient</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> verbose:</span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Iteration </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Weights gradient ="</span>, weights_gradient)</span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Bias gradient ="</span>, bias_gradient)</span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Updated weights ="</span>, weights)</span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Updated bias ="</span>, bias)</span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> weights, bias</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Prueba el modelo entrenado.</p>
<div id="cell-21" class="cell" data-execution_count="13">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>weights, bias <span class="op">=</span> train(X, y, learning_rate, iters<span class="op">=</span><span class="dv">2000</span>)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Trained weights:"</span>, weights)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Trained bias:"</span>, bias)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Test predictions</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>test_X <span class="op">=</span> np.array([[<span class="fl">1.5</span>, <span class="dv">1</span>], [<span class="fl">2.4</span>, <span class="dv">2</span>], [<span class="fl">3.5</span>, <span class="dv">3</span>]])</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>test_y <span class="op">=</span> np.dot(test_X, weights) <span class="op">+</span> bias</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Predictions:"</span>, test_y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Trained weights: [0.93453357 0.83998906]
Trained bias: [-0.14178921  0.27714103  0.10916541]
Predictions: [2.10000021 4.19999973 5.9000001 ]</code></pre>
</div>
</div>
<p>Se puede ver que casi no hay diferencia con el valor real. ¿Qué sucedería si redujéramos el número de repeticiones?</p>
<div id="cell-23" class="cell" data-execution_count="14">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>weights, bias <span class="op">=</span> train(X, y, learning_rate, iters<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Trained weights:"</span>, weights)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Trained bias:"</span>, bias)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Test predictions</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>test_X <span class="op">=</span> np.array([[<span class="fl">1.5</span>, <span class="dv">1</span>], [<span class="fl">2.4</span>, <span class="dv">2</span>], [<span class="fl">3.5</span>, <span class="dv">3</span>]])</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>test_y <span class="op">=</span> np.dot(test_X, weights) <span class="op">+</span> bias</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Predictions:"</span>, test_y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Trained weights: [0.95069505 0.82053576]
Trained bias: [-1.23073214e-04  1.51665327e-01  1.39109392e-01]
Predictions: [2.24645526 4.07440496 5.92814933]</code></pre>
</div>
</div>
<p>Se puede observar que en el caso de 50 iteraciones, hay un error bastante significativo entre los valores predichos y los reales. Otra cosa a considerar es la tasa de aprendizaje. ¿Por qué se multiplica un valor muy pequeño por el gradiente? Vamos a realizar una sola iteración e imprimir los valores de los parámetros calculados.</p>
<div id="cell-25" class="cell" data-execution_count="15">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>num_iters <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>weights, bias <span class="op">=</span> train(X, y, learning_rate, iters<span class="op">=</span>num_iters, verbose<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Iteration 1:
Weights gradient = [-20.116      -16.74666667]
Bias gradient = [-1.23333333 -2.50666667 -3.5       ]
Updated weights = [0.30116    0.26746667]
Updated bias = [0.01233333 0.02506667 0.035     ]</code></pre>
</div>
</div>
<p>Al comparar los valores de los pesos y sesgos obtenidos después de 1000 iteraciones de entrenamiento, podemos ver que los valores del gradiente son muy grandes. Si no se reduce el valor del gradiente a un nivel muy bajo mediante la tasa de aprendizaje, los parámetros no podrán reducir el error y seguirán fluctuando. Se recomienda probar con una tasa de aprendizaje de un valor alto.</p>
<p>¿Cuál es la diferencia entre este ‘aproximador lineal’ y un aproximador de red neuronal? La diferencia es solo una: después del cálculo lineal, se pasa a través de una función de activación. Esto se expresa matemáticamente como:</p>
<p><span class="math display">\[ \boldsymbol y = f_{active} ( \boldsymbol x \boldsymbol W + \boldsymbol b ) \]</span></p>
<p>Implementar esto en código también es simple. Hay varias funciones de activación disponibles, y si usamos la función tanh, sería así.</p>
<div id="cell-27" class="cell" data-execution_count="16">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>y_predicted <span class="op">=</span> np.tanh(np.dot(X, weights) <span class="op">+</span> bias)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Las redes neuronales expresan comúnmente cada paso de transformación lineal y aplicación de funciones de activación con el concepto de capa (layer). Por lo tanto, se prefiere implementarlos en dos pasos, ya que esta representación es más adecuada para las capas.</p>
<div id="cell-29" class="cell" data-execution_count="17">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>out_1 <span class="op">=</span> np.dot(X, weights) <span class="op">+</span> bias  <span class="co"># First layer</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>y_predicted <span class="op">=</span> np.tanh(out_1)       <span class="co"># Second layer (activation)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Haga clic para ver el contenido (deep dive: teoría de la plasticidad cortical)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Haga clic para ver el contenido (deep dive: teoría de la plasticidad cortical)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<section id="teoría-de-la-plasticidad-cortical-cortical-plasticity-theory" class="level2 callout-body-container callout-body">
<h2 class="anchored" data-anchor-id="teoría-de-la-plasticidad-cortical-cortical-plasticity-theory">Teoría de la plasticidad cortical (Cortical Plasticity Theory)</h2>
<section id="teoría-de-la-plasticidad-cortical-de-mountcastle" class="level3">
<h3 class="anchored" data-anchor-id="teoría-de-la-plasticidad-cortical-de-mountcastle">Teoría de la plasticidad cortical de Mountcastle</h3>
<p>Vernon Mountcastle es un científico que realizó importantes contribuciones al campo de las neurociencias en la segunda mitad del siglo XX, especialmente conocido por sus investigaciones sobre la organización funcional de la corteza cerebral. Uno de los logros principales de Mountcastle fue el descubrimiento de la <strong>organización en columnas (Columnar Organization)</strong>. Él demostró que la corteza cerebral está organizada en columnas verticales y que las neuronas dentro de la misma columna responden a estímulos similares.</p>
<p>La teoría de Mountcastle proporciona una base importante para comprender la plasticidad de la corteza cerebral. Según su teoría:</p>
<ul>
<li><strong>Columnas como unidades funcionales:</strong> La corteza cerebral está compuesta por columnas, que son las unidades funcionales básicas. Cada columna contiene un grupo de neuronas que responden a una modalidad sensorial específica o a un patrón de movimiento específico.</li>
<li><strong>Plasticidad de las columnas:</strong> La estructura y función de las columnas pueden cambiar con la experiencia. La exposición repetida a ciertos estímulos puede aumentar el tamaño de las columnas que procesan esos estímulos o potenciar su reactividad. Por el contrario, la falta de estímulo puede reducir el tamaño de las columnas o disminuir su reactividad.</li>
<li><strong>Interacción competitiva:</strong> Las columnas adyacentes interactúan entre sí de manera competitiva. Un aumento en la actividad de una columna puede inhibir la actividad de otras columnas, lo cual actúa como un mecanismo subyacente para la reorganización cortical según la experiencia. Por ejemplo, el uso frecuente de un dedo específico puede expandir la región cortical que controla ese dedo, mientras que las regiones que controlan otros dedos pueden reducirse en tamaño.</li>
</ul>
<p>La teoría de Mountcastle sobre la estructura y plasticidad de las columnas tiene las siguientes implicaciones clínicas:</p>
<ul>
<li><strong>Recuperación después de lesiones cerebrales:</strong> La recuperación funcional después de un accidente cerebrovascular o una lesión cerebral traumática puede ocurrir mediante la reorganización de las regiones corticales adyacentes a las áreas dañadas.</li>
<li><strong>Pérdida y rehabilitación sensorial:</strong> Después de la pérdida del sentido de la vista o el oído, las regiones corticales que procesaban esos sentidos pueden ser utilizadas para procesar otros sentidos (plasticidad cruzada modal, cross-modal plasticity).</li>
<li><strong>Aprendizaje y adquisición de habilidades:</strong> Aprender nuevas habilidades o mejorar funciones específicas a través del entrenamiento repetitivo puede ajustar los pesos sinápticos en las redes neuronales, similar a cómo Mountcastle describió que la reactividad de las neuronas cambia con la experiencia.</li>
</ul>
</section>
<section id="relación-con-el-aprendizaje-profundo" class="level3">
<h3 class="anchored" data-anchor-id="relación-con-el-aprendizaje-profundo">Relación con el aprendizaje profundo</h3>
<ul>
<li><strong>Estructura jerárquica:</strong> Los modelos de aprendizaje profundo tienen una estructura jerárquica similar a la organización en columnas de la corteza. Estos modelos constan de múltiples capas, y cada capa extrae características abstractas progresivamente más complejas de los datos de entrada. Esto es análogo a cómo las columnas corticales procesan información sensorial de manera incremental para realizar funciones cognitivas complejas.</li>
<li><strong>Ajuste de pesos:</strong> Los modelos de aprendizaje profundo ajustan la intensidad de las conexiones (pesos) durante el proceso de entrenamiento para aprender la relación entre los datos de entrada y salida. Este mecanismo es similar al cambio en la intensidad de las conexiones neuronales dentro de una columna, como describió Mountcastle. Al igual que las neuronas pueden volverse más o menos reactivas a ciertos estímulos con la experiencia, los modelos de aprendizaje profundo ajustan sus pesos para mejorar el rendimiento.</li>
<li><strong>Aprendizaje competitivo:</strong> Algunos modelos de aprendizaje profundo, especialmente los mapas autoorganizativos (Self-Organizing Map, SOM), utilizan principios similares a la interacción competitiva entre columnas. Los SOMs permiten que las neuronas compitan por el aprendizaje basado en las características de los datos de entrada, y solo el neurona ganadora se activa y actualiza los pesos de sus vecinos. Esto es similar a cómo las columnas adyacentes en la corteza cerebral pueden inhibirse mutuamente para dividir funciones competitivamente. La teoría de la plasticidad cortical del cerebro propuesta por Mountcastle no solo amplió nuestra comprensión de la organización funcional y los mecanismos de aprendizaje en el cerebro, sino que también proporcionó importantes insights para el desarrollo de modelos de deep learning. Los modelos de deep learning que imitan el funcionamiento del cerebro están contribuyendo significativamente al avance del campo de la inteligencia artificial, y se espera que la interacción entre la neurociencia y la inteligencia artificial sea aún más activa en el futuro.</li>
</ul>
</section>
</section>
</div>
</div>
</section>
</section>
<section id="redes-neuronales-profundas" class="level2">
<h2 class="anchored" data-anchor-id="redes-neuronales-profundas">1.5 Redes Neuronales Profundas</h2>
<p>El aprendizaje profundo es un método que entrena redes neuronales con múltiples capas. Se utiliza el término ‘deep’ (profundo) debido a la profundidad de las capas. La capa lineal, componente básico, se conoce como capa completamente conectada (Fully Connected Layer) o capa densa (Dense Layer). Estas capas están estructuradas de la siguiente manera:</p>
<p>Capa completamente conectada 1 - Capa de activación 1 - Capa completamente conectada 2 - Capa de activación 2 - …</p>
<p>Las capas de activación desempeñan un papel crucial en las redes neuronales. Si solo se apilan capas lineales, matemáticamente resultaría en una única transformación lineal. Por ejemplo, dos capas lineales conectadas pueden expresarse como:</p>
<p><span class="math display">\[ \boldsymbol y = (\boldsymbol X \boldsymbol W_1 + \boldsymbol b_1)\boldsymbol W_2 + \boldsymbol b_2 = \boldsymbol X(\boldsymbol W_1\boldsymbol W_2) + (\boldsymbol b_1\boldsymbol W_2 + \boldsymbol b_2) = \boldsymbol X\boldsymbol W + \boldsymbol b \]</span></p>
<p>Esto resulta en otra transformación lineal. Por lo tanto, se pierde la ventaja de apilar múltiples capas. Las capas de activación rompen esta linealidad y permiten que cada capa aprenda de manera independiente. La razón del poder del aprendizaje profundo es precisamente que a medida que se apilan más capas, se pueden aprender patrones más complejos.</p>
<section id="estructura-de-las-redes-neuronales-profundas" class="level3">
<h3 class="anchored" data-anchor-id="estructura-de-las-redes-neuronales-profundas">1.5.1 Estructura de las Redes Neuronales Profundas</h3>
<p><img src="../../../assets/images/01_dnn.png" alt="image info" style="width: 800px;"></p>
<p>La salida de cada capa se convierte en la entrada de la siguiente capa, y los cálculos se realizan secuencialmente. La propagación hacia adelante es una serie de operaciones relativamente simples.</p>
<p>En la propagación hacia atrás, se calculan dos tipos de gradientes para cada capa:</p>
<ol type="1">
<li><p>Gradiente con respecto a los pesos: <span class="math inline">\(\frac{\partial E}{\partial \boldsymbol W}\)</span> - utilizado para actualizar parámetros</p></li>
<li><p>Gradiente con respecto a las entradas: <span class="math inline">\(\frac{\partial E}{\partial \boldsymbol x}\)</span> - propagado hacia la capa anterior</p></li>
</ol>
<p>Estos dos gradientes deben ser almacenados y gestionados de manera independiente. El gradiente de los pesos se utiliza por el optimizador para actualizar los parámetros, mientras que el gradiente de las entradas se usa en el proceso de retropropagación para el aprendizaje de la capa anterior.</p>
</section>
</section>
<section id="implementación-de-redes-neuronales" class="level2">
<h2 class="anchored" data-anchor-id="implementación-de-redes-neuronales">1.5.2 Implementación de Redes Neuronales</h2>
<p>Para implementar la estructura básica de una red neuronal, aplicamos un diseño basado en capas. Primero definimos una clase base que todas las capas heredarán.</p>
<div id="cell-32" class="cell" data-execution_count="18">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> BaseLayer():</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># __init__ can be omitted as it implicitly inherits from 'object' in Python 3</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">NotImplementedError</span>  <span class="co"># Should be implemented in derived classes</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> backward(<span class="va">self</span>, output_error, lr):</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">NotImplementedError</span>  <span class="co"># Should be implemented in derived classes</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> print_params(<span class="va">self</span>):</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Default implementation (optional).  Child classes should override.</span></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Layer parameters (Not implemented in BaseLayer)"</span>)</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># raise NotImplementedError # Or keep NotImplementedError</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>BaseLayer define la interfaz para las operaciones de propagación hacia adelante (forward) y hacia atrás (backward). Cada capa implementa esta interfaz para realizar sus propias operaciones únicas. A continuación se presenta la implementación de una capa completamente conectada.</p>
<div id="cell-34" class="cell" data-execution_count="19">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> FCLayer(BaseLayer):</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, in_size, out_size):</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>        <span class="co"># super().__init__()  # No need to call super() for object inheritance</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.in_size <span class="op">=</span> in_size</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.out_size <span class="op">=</span> out_size</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># He initialization (weights)</span></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.weights <span class="op">=</span> np.random.randn(in_size, out_size) <span class="op">*</span> np.sqrt(<span class="fl">2.0</span> <span class="op">/</span> in_size)</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Bias initialization (zeros)</span></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bias <span class="op">=</span> np.zeros(out_size)  <span class="co"># or np.zeros((out_size,))</span></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.in_x <span class="op">=</span> x  <span class="co"># Store input for use in backward pass</span></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.dot(x, <span class="va">self</span>.weights) <span class="op">+</span> <span class="va">self</span>.bias</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> backward(<span class="va">self</span>, out_error, lr):</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Matrix multiplication order: out_error (batch_size, out_size), self.weights (in_size, out_size)</span></span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>        in_x_gradient <span class="op">=</span> np.dot(out_error, <span class="va">self</span>.weights.T)</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>        weight_gradient <span class="op">=</span> np.dot(<span class="va">self</span>.in_x.T, out_error)</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>        bias_gradient <span class="op">=</span> np.<span class="bu">sum</span>(out_error, axis<span class="op">=</span><span class="dv">0</span>)  <span class="co"># Sum over all samples (rows)</span></span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.weights <span class="op">-=</span> lr <span class="op">*</span> weight_gradient</span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bias <span class="op">-=</span> lr <span class="op">*</span> bias_gradient</span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> in_x_gradient</span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> print_params(<span class="va">self</span>):</span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Weights:</span><span class="ch">\n</span><span class="st">"</span>, <span class="va">self</span>.weights)</span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Bias:</span><span class="ch">\n</span><span class="st">"</span>, <span class="va">self</span>.bias)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>La capa completamente conectada transforma las entradas utilizando pesos y sesgos. Se aplicó la inicialización de pesos de He1. Este método fue propuesto por He et al.&nbsp;en 2015 y es especialmente efectivo cuando se utiliza junto con la función de activación ReLU.</p>
<div id="cell-36" class="cell" data-execution_count="20">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> relu(x):</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.maximum(x, <span class="dv">0</span>)</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> relu_deriv(x):</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array(x <span class="op">&gt;</span> <span class="dv">0</span>, dtype<span class="op">=</span>np.float32)  <span class="co"># or dtype=int</span></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> leaky_relu(x):</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.maximum(<span class="fl">0.01</span> <span class="op">*</span> x, x)</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> leaky_relu_deriv(x):</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>    dx <span class="op">=</span> np.ones_like(x)</span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>    dx[x <span class="op">&lt;</span> <span class="dv">0</span>] <span class="op">=</span> <span class="fl">0.01</span></span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> dx</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tanh(x):</span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.tanh(x)</span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tanh_deriv(x):</span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">1</span> <span class="op">-</span> np.tanh(x)<span class="op">**</span><span class="dv">2</span></span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sigmoid(x):</span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">1</span> <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> np.exp(<span class="op">-</span>x))</span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sigmoid_deriv(x):  <span class="co"># Numerically stable version</span></span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> sigmoid(x)</span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> s <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> s)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>ReLU se convirtió en la función de activación estándar en el aprendizaje profundo desde su propuesta inicial en 2011. Tiene la ventaja de resolver eficazmente el problema del desvanecimiento del gradiente, mientras que también es simple de calcular. Para el cálculo inverso, declaramos la función derivada de la función de activación relu_deriv(). ReLU es una función que devuelve 0 si la entrada es menor que 0 y su propio valor si es mayor. Por lo tanto, la función derivada devuelve 0 para valores menores o iguales a 0 y 1 para valores mayores a 0. Aquí se utiliza Tanh como función de activación. A continuación se presenta la capa de activación.</p>
<div id="cell-38" class="cell" data-execution_count="21">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ActivationLayer(BaseLayer):</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, activation, activation_deriv):</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.activation <span class="op">=</span> activation</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.activation_deriv <span class="op">=</span> activation_deriv</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, input_data):</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.<span class="bu">input</span> <span class="op">=</span> input_data</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.activation(input_data)</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> backward(<span class="va">self</span>, output_error, lr):</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.activation_deriv(<span class="va">self</span>.<span class="bu">input</span>) <span class="op">*</span> output_error</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>La capa de activación añade no linealidad, permitiendo que la red neuronal pueda aproximar funciones complejas. Durante el proceso de retropropagación, se multiplica el gradiente con el error de salida según la regla de la cadena.</p>
<div id="cell-40" class="cell" data-execution_count="22">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mse(y_label, y_pred):</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (np.mean(np.power(y_label <span class="op">-</span> y_pred,<span class="dv">2</span>)))</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mse_deriv(y_label, y_pred):</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (<span class="dv">2</span><span class="op">/</span>y_label.size) <span class="op">*</span> (y_pred <span class="op">-</span> y_label) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>El error cuadrático medio (MSE) es una función de pérdida ampliamente utilizada en problemas de regresión. Calcula el promedio de las diferencias al cuadrado entre los valores predichos y los valores reales. Integrando estos componentes, se puede implementar la red neuronal completa.</p>
<div id="cell-42" class="cell" data-execution_count="23">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Network:</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layers <span class="op">=</span> []</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.loss <span class="op">=</span> <span class="va">None</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.loss_deriv <span class="op">=</span> <span class="va">None</span></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> add_layer(<span class="va">self</span>, layer):</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layers.append(layer)</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> set_loss(<span class="va">self</span>, loss, loss_deriv):</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.loss <span class="op">=</span> loss</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.loss_deriv <span class="op">=</span> loss_deriv</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _forward_pass(<span class="va">self</span>, x):</span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> x</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> layer <span class="kw">in</span> <span class="va">self</span>.layers:</span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>            output <span class="op">=</span> layer.forward(output)</span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> output</span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict(<span class="va">self</span>, inputs):</span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a>        predictions <span class="op">=</span> []</span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> x <span class="kw">in</span> inputs:</span>
<span id="cb28-23"><a href="#cb28-23" aria-hidden="true" tabindex="-1"></a>            output <span class="op">=</span> <span class="va">self</span>._forward_pass(x)</span>
<span id="cb28-24"><a href="#cb28-24" aria-hidden="true" tabindex="-1"></a>            predictions.append(output)</span>
<span id="cb28-25"><a href="#cb28-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> predictions</span>
<span id="cb28-26"><a href="#cb28-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb28-27"><a href="#cb28-27" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> train(<span class="va">self</span>, x_train, y_train, epochs, lr):</span>
<span id="cb28-28"><a href="#cb28-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb28-29"><a href="#cb28-29" aria-hidden="true" tabindex="-1"></a>            epoch_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb28-30"><a href="#cb28-30" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb28-31"><a href="#cb28-31" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> x, y <span class="kw">in</span> <span class="bu">zip</span>(x_train, y_train):</span>
<span id="cb28-32"><a href="#cb28-32" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Forward pass</span></span>
<span id="cb28-33"><a href="#cb28-33" aria-hidden="true" tabindex="-1"></a>                output <span class="op">=</span> <span class="va">self</span>._forward_pass(x)</span>
<span id="cb28-34"><a href="#cb28-34" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb28-35"><a href="#cb28-35" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Calculate loss</span></span>
<span id="cb28-36"><a href="#cb28-36" aria-hidden="true" tabindex="-1"></a>                epoch_loss <span class="op">+=</span> <span class="va">self</span>.loss(y, output)</span>
<span id="cb28-37"><a href="#cb28-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-38"><a href="#cb28-38" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Backward pass</span></span>
<span id="cb28-39"><a href="#cb28-39" aria-hidden="true" tabindex="-1"></a>                error <span class="op">=</span> <span class="va">self</span>.loss_deriv(y, output)</span>
<span id="cb28-40"><a href="#cb28-40" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> layer <span class="kw">in</span> <span class="bu">reversed</span>(<span class="va">self</span>.layers):</span>
<span id="cb28-41"><a href="#cb28-41" aria-hidden="true" tabindex="-1"></a>                    error <span class="op">=</span> layer.backward(error, lr)</span>
<span id="cb28-42"><a href="#cb28-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-43"><a href="#cb28-43" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Calculate average loss for the epoch</span></span>
<span id="cb28-44"><a href="#cb28-44" aria-hidden="true" tabindex="-1"></a>            avg_loss <span class="op">=</span> epoch_loss <span class="op">/</span> <span class="bu">len</span>(x_train)</span>
<span id="cb28-45"><a href="#cb28-45" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> epoch <span class="op">==</span> epochs <span class="op">-</span><span class="dv">1</span>:</span>
<span id="cb28-46"><a href="#cb28-46" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f'epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>epochs<span class="sc">}</span><span class="ss">   error=</span><span class="sc">{</span>avg_loss<span class="sc">:.6f}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<section id="entrenamiento-de-redes-neuronales" class="level3">
<h3 class="anchored" data-anchor-id="entrenamiento-de-redes-neuronales">1.5.3 Entrenamiento de redes neuronales</h3>
<p>El entrenamiento de una red neuronal es un proceso que implica la optimización de los pesos a través de la repetición de la propagación hacia adelante y la propagación hacia atrás. Primero, examinaremos el proceso de aprendizaje de las redes neuronales mediante el problema XOR.</p>
<div id="cell-44" class="cell" data-execution_count="24">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># XOR training data</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>x_train <span class="op">=</span> np.array([[[<span class="dv">0</span>,<span class="dv">0</span>]], [[<span class="dv">0</span>,<span class="dv">1</span>]], [[<span class="dv">1</span>,<span class="dv">0</span>]], [[<span class="dv">1</span>,<span class="dv">1</span>]]])</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> np.array([[[<span class="dv">0</span>]], [[<span class="dv">1</span>]], [[<span class="dv">1</span>]], [[<span class="dv">0</span>]]])</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Network architecture</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> Network()</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>net.add_layer(FCLayer(<span class="dv">2</span>, <span class="dv">30</span>))                     <span class="co"># Input layer -&gt; Hidden layer</span></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>net.add_layer(ActivationLayer(tanh, tanh_deriv))  <span class="co"># tanh activation</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>net.add_layer(FCLayer(<span class="dv">30</span>, <span class="dv">1</span>))                     <span class="co"># Hidden layer -&gt; Output layer</span></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>net.add_layer(ActivationLayer(tanh, tanh_deriv))  <span class="co"># tanh activation</span></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Training settings and execution</span></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>net.set_loss(mse, mse_deriv)</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>net.train(x_train, y_train, epochs<span class="op">=</span><span class="dv">2000</span>, lr<span class="op">=</span><span class="fl">5e-3</span>)</span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Prediction test</span></span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a>out <span class="op">=</span> net.predict(x_train)</span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"predict=</span><span class="sc">{</span>out<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>epoch 2000/2000   error=0.002251
predict=[array([[0.00471695]]), array([[0.93254742]]), array([[0.93421712]]), array([[0.0080288]])]</code></pre>
</div>
</div>
<p>La función de activación se entrenó usando tanh(). Se puede verificar que la red neuronal ha sido entrenada para producir valores similares para la lógica de salida XOR. Ahora examinaremos el aprendizaje de redes neuronales con un conjunto de datos real a través del problema de clasificación de dígitos manuscritos MNIST.</p>
<p>El siguiente es un ejemplo de escritura a mano de MNIST. Primero, importamos las bibliotecas necesarias para usar PyTorch.</p>
<div id="cell-47" class="cell" data-execution_count="25">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.datasets <span class="im">import</span> MNIST</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.transforms <span class="im">as</span> transforms</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> random_split</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> MNIST(root <span class="op">=</span> <span class="st">'data/'</span>, download <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(dataset))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>60000</code></pre>
</div>
</div>
<div id="cell-48" class="cell" data-execution_count="26">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>image, label <span class="op">=</span> dataset[<span class="dv">10</span>]</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>plt.imshow(image, cmap <span class="op">=</span> <span class="st">'gray'</span>)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Label:'</span>, label)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Label: 3</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="01_El inicio del aprendizaje profundo_files/figure-html/cell-22-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Las etiquetas de escritura a mano no son de tipo entero, no están en formato categórico. Crearemos y usaremos una función similar a <code>to_categorical</code> en keras.</p>
<div id="cell-50" class="cell" data-execution_count="27">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> to_categorical(y, num_classes):</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">""" 1-hot encodes a tensor """</span></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.eye(num_classes, dtype<span class="op">=</span><span class="st">'uint8'</span>)[y]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="cell-51" class="cell" data-execution_count="28">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="co">## MNIST dataset(images and labels)</span></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>mnist_dataset <span class="op">=</span> MNIST(root <span class="op">=</span> <span class="st">'data/'</span>, train <span class="op">=</span> <span class="va">True</span>, transform <span class="op">=</span> transforms.ToTensor())</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>train_data, test_data <span class="op">=</span> random_split(mnist_dataset , [<span class="dv">50000</span>, <span class="dv">10000</span>])</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> torch.utils.data.DataLoader(train_data, batch_size<span class="op">=</span><span class="dv">2000</span>, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>test_loader <span class="op">=</span> torch.utils.data.DataLoader(train_data, batch_size<span class="op">=</span><span class="dv">10</span>, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>train_images, train_labels <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(train_loader)) <span class="co"># 한번의 배치만 가져온다.</span></span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>x_train <span class="op">=</span> train_images.reshape(train_images.shape[<span class="dv">0</span>], <span class="dv">1</span>, <span class="dv">28</span><span class="op">*</span><span class="dv">28</span>)</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> to_categorical(train_labels, <span class="dv">10</span>)</span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x_train.shape)</span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(y_train.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([2000, 1, 784])
(2000, 10)</code></pre>
</div>
</div>
<p>Después de cargar los datos, los dividí en dos conjuntos: uno para entrenamiento y otro para prueba. Usé DataLoader de PyTorch para cargar los datos. Aquí, para usar solo 2000 muestras de datos de entrenamiento, establecí el batch_size en 2000. Luego, con next(iter(train_loader)), obtuve solo un lote una vez y cambié la forma de los datos de (1, 28, 28) a (1, 784). Esto se llama aplanamiento. Después de procesar por separado los datos de imagen y etiqueta, verifiqué las dimensiones.</p>
<div id="cell-53" class="cell" data-execution_count="29">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="co"># # Network</span></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> Network()</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>net.add_layer(FCLayer(<span class="dv">28</span><span class="op">*</span><span class="dv">28</span>, <span class="dv">100</span>))                <span class="co"># input_shape=(1, 28*28)    ;   output_shape=(1, 100)</span></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>net.add_layer(ActivationLayer(tanh, tanh_deriv))</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>net.add_layer(FCLayer(<span class="dv">100</span>, <span class="dv">50</span>))                   <span class="co"># input_shape=(1, 100)      ;   output_shape=(1, 50)</span></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>net.add_layer(ActivationLayer(tanh, tanh_deriv))</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>net.add_layer(FCLayer(<span class="dv">50</span>, <span class="dv">10</span>))                    <span class="co"># input_shape=(1, 50)       ;   output_shape=(1, 10)</span></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>net.add_layer(ActivationLayer(tanh, tanh_deriv))</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>net.set_loss(mse, mse_deriv)</span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>net.train(x_train[<span class="dv">0</span>:<span class="dv">1000</span>], y_train[<span class="dv">0</span>:<span class="dv">1000</span>], epochs<span class="op">=</span><span class="dv">35</span>, lr<span class="op">=</span><span class="fl">0.1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>/tmp/ipykernel_936812/3322560381.py:14: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword
  return np.dot(x, self.weights) + self.bias
/tmp/ipykernel_936812/3322560381.py:19: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword
  weight_gradient = np.dot(self.in_x.T, out_error)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>epoch 35/35   error=0.002069</code></pre>
</div>
</div>
<div id="cell-54" class="cell" data-execution_count="30">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions with the trained model.</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>test_images, test_labels <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(test_loader))</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>x_test <span class="op">=</span> test_images.reshape(test_images.shape[<span class="dv">0</span>], <span class="dv">1</span>, <span class="dv">28</span><span class="op">*</span><span class="dv">28</span>)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>y_test <span class="op">=</span> to_categorical(test_labels, <span class="dv">10</span>)</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(x_test))</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Use only the first 2 samples for prediction.</span></span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>out <span class="op">=</span> net.predict(x_test[:<span class="dv">2</span>])  <span class="co"># Corrected slicing: use [:2] for the first two samples</span></span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Predicted values : "</span>)</span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(out, end<span class="op">=</span><span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"True values : "</span>)</span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(y_test[:<span class="dv">2</span>])  <span class="co"># Corrected slicing: use [:2] to match the prediction</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>10


Predicted values : 
[array([[-0.02857555,  0.04630796,  0.01640415,  0.34762487,  0.01307466,
        -0.14719773,  0.01654099,  0.12845884,  0.74751837,  0.05102324]]), array([[ 0.01248236,  0.00248117,  0.70203826,  0.12074454,  0.088309  ,
        -0.24138211, -0.04961493,  0.20394738,  0.28894724,  0.07850696]])]
True values : 
[[0 0 0 1 0 0 0 0 0 0]
 [0 0 0 1 0 0 0 0 0 0]]</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/tmp/ipykernel_936812/3322560381.py:14: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword
  return np.dot(x, self.weights) + self.bias</code></pre>
</div>
</div>
<p>Hasta ahora, hemos implementado directamente la forma más básica de red neuronal, es decir, un “aproximador de funciones (function approximator)” que realiza predicciones apilando capa tras capa transformaciones lineales y funciones de activación no lineales. Desde el problema simple XOR hasta la clasificación de dígitos manuscritos MNIST, hemos examinado los principios fundamentales de cómo las redes neuronales aprenden a través de datos y reconocen patrones complejos. Los marcos de deep learning como PyTorch y TensorFlow hacen este proceso mucho más eficiente y conveniente, pero el funcionamiento fundamental no difiere significativamente del código que implementamos directamente.</p>
<p>Este libro continuará rastreando la evolución de las tecnologías de deep learning desde la neurona McCulloch-Pitts en 1943 hasta las arquitecturas multimodales más recientes en 2025. Examinaremos profundamente por qué surgieron cada una de estas tecnologías, cuáles problemas fundamentales intentaron resolver y cómo están conectadas con las tecnologías anteriores, al igual que si estuviéramos investigando la evolución de un organismo.</p>
<p>En el Capítulo 2, abordaremos los fundamentos matemáticos esenciales para comprender el deep learning. Resumiremos concisamente los conceptos clave del álgebra lineal, cálculo, probabilidad y estadística desde la perspectiva del deep learning, con el fin de facilitar la comprensión de los contenidos posteriores. Si te falta conocimiento de matemáticas o estás más interesado en la implementación práctica que en la teoría, puedes saltar directamente al Capítulo 3. A partir del Capítulo 3, podrás implementar y experimentar con los modelos de deep learning más recientes utilizando PyTorch y las bibliotecas Hugging Face, adquiriendo un sentido práctico del trabajo real. Sin embargo, para una comprensión profunda y el desarrollo a largo plazo en deep learning, es muy importante sentar bases matemáticas sólidas.</p>
<p>Al final de cada capítulo, proporcionaremos problemas de ejercicios para que puedas evaluar tu comprensión y obtener un punto de partida para investigaciones adicionales. Esperamos que vayas más allá de simplemente encontrar las respuestas y profundices en los principios del deep learning durante el proceso de resolución de problemas, expandiendo así tu pensamiento creativo.</p>
</section>
</section>
<section id="ejercicios-de-práctica" class="level2">
<h2 class="anchored" data-anchor-id="ejercicios-de-práctica">Ejercicios de práctica</h2>
<section id="problemas-básicos" class="level3">
<h3 class="anchored" data-anchor-id="problemas-básicos">1. Problemas básicos</h3>
<ol type="1">
<li>Explique matemáticamente por qué un perceptrón no puede resolver el problema XOR.<br>
</li>
<li>Explique los resultados si se cambian las funciones de activación a relu, relu_deriv en el ejemplo XOR anterior.</li>
<li>Explique con un ejemplo cómo se aplica la regla de la cadena en el algoritmo de retropropagación.</li>
</ol>
</section>
<section id="problemas-aplicados" class="level3">
<h3 class="anchored" data-anchor-id="problemas-aplicados">2. Problemas aplicados</h3>
<ol start="4" type="1">
<li>Análisis de las ventajas y desventajas de usar la función de activación Swish en lugar de ReLU en modelos de predicción de precios de viviendas.</li>
<li>Explique por qué la capacidad expresiva de una red neuronal con tres capas es superior a la de una red con dos capas desde la perspectiva del espacio de funciones.</li>
</ol>
</section>
<section id="problemas-avanzados" class="level3">
<h3 class="anchored">3. Problemas avanzados</h3>
<ol start="6" type="1">
<li>Pruebe matemáticamente el mecanismo por el cual las conexiones de salto en ResNet resuelven el problema de desvanecimiento del gradiente.</li>
<li>Analice por qué el mecanismo de atención en la arquitectura Transformer es adecuado para modelar secuencias.</li>
</ol>
<div class="callout callout-style-default callout-note callout-titled" title="Haga clic para ver el contenido (solución)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Haga clic para ver el contenido (solución)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<section id="solución" class="level2 callout-body-container callout-body">
<h2 class="anchored" data-anchor-id="solución">Solución</h2>
<section id="respuestas-a-problemas-básicos" class="level3">
<h3 class="anchored" data-anchor-id="respuestas-a-problemas-básicos">1. Respuestas a problemas básicos</h3>
<ol type="1">
<li><p><strong>Problema XOR</strong>: Limitación de los clasificadores lineales → Necesidad de una frontera de decisión no lineal</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>XOR_input <span class="op">=</span> np.array([[<span class="dv">0</span>,<span class="dv">0</span>],[<span class="dv">0</span>,<span class="dv">1</span>],[<span class="dv">1</span>,<span class="dv">0</span>],[<span class="dv">1</span>,<span class="dv">1</span>]])</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Con combinaciones lineales no es posible distinguir entre 0 y 1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p><strong>Problema de entrenamiento con ReLU</strong>: ReLU: Es sensible a la tasa de aprendizaje y tiene una alta probabilidad de presentar el problema de “Dead ReLU” (neuronas inactivas que no pueden aprender). Otros funciones de activación (Leaky ReLU, ELU, Swish) pueden mitigar el problema de Dead ReLU y son más estables para resolver el problema XOR. Sigmoid puede tener dificultades para aprender debido al problema de desvanecimiento del gradiente. Tanh es más estable que ReLU, pero en redes profundas también puede sufrir del problema de desvanecimiento del gradiente.</p></li>
<li><p><strong>Regla de la cadena en retropropagación</strong>:<br>
<span class="math inline">\(\frac{\partial L}{\partial W} = \frac{\partial L}{\partial y}\cdot\frac{\partial y}{\partial W}\)</span></p></li>
</ol>
</section>
<section id="respuestas-a-problemas-aplicados" class="level3">
<h3 class="anchored" data-anchor-id="respuestas-a-problemas-aplicados">2. Respuestas a problemas aplicados</h3>
<ol start="4" type="1">
<li><strong>Ventajas de la función Swish</strong>:
<ul>
<li>Mitiga el problema de neuronas inactivas en ReLU<br>
</li>
<li>Curva diferenciable que mejora la estabilidad del aprendizaje</li>
</ul></li>
<li><strong>Superioridad de las redes neuronales de 3 capas</strong>:
<ul>
<li>Problema 13 de Hilbert: Las funciones continuas de 3 variables no pueden ser representadas por una red de 2 capas<br>
</li>
<li>Teorema de Kolmogorov–Arnold: Es posible aproximar cualquier función continua con una red de 3 capas</li>
</ul></li>
</ol>
</section>
<section id="respuestas-a-problemas-avanzados" class="level3">
<h3 class="anchored" data-anchor-id="respuestas-a-problemas-avanzados">3. Respuestas a problemas avanzados</h3>
<ol start="6" type="1">
<li><p><strong>Conexiones skip en ResNet</strong>:<br>
<span class="math inline">\(H(x) = F(x) + x\)</span> → <span class="math inline">\(\frac{\partial L}{\partial x} = \frac{\partial L}{\partial H} \cdot (F'(x) + 1)\)</span></p></li>
<li><p><strong>Ventajas de los transformadores</strong>:</p>
<ul>
<li>Procesamiento paralelo posible (superación de la limitación de procesamiento secuencial en RNN)<br>
</li>
<li>Captura de dependencias a larga distancia (aprendizaje de importancia mediante pesos de atención)</li>
</ul></li>
</ol>
</section>
</section>
</div>
</div>
<section id="referencias-esenciales" class="level4">
<h4 class="anchored" data-anchor-id="referencias-esenciales">Referencias esenciales</h4>
<ol type="1">
<li><p><strong><a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://www.deeplearningbook.org/">Deep Learning (Goodfellow, Bengio, Courville, 2016)</a></strong></p></li>
<li><p><strong><a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://link.springer.com/article/10.1007/BF02551274">Aproximación mediante superposiciones de una función sigmoide (Cybenko, 1989)</a></strong></p></li>
<li><p><strong><a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://www.sciencedirect.com/science/article/abs/pii/0893608089900208">Las redes alimentadas en capas múltiples son aproximadores universales (Hornik, Stinchcombe, &amp; White, 1989)</a></strong></p></li>
<li><p><strong><a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf">Comprender la dificultad de entrenar redes neuronales alimentadas en capas profundas (Glorot &amp; Bengio, 2010)</a></strong></p></li>
<li><p><strong><a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://arxiv.org/abs/1502.01852">Sumergiéndose profundamente en los rectificadores: superando el rendimiento de nivel humano en la clasificación de ImageNet (He et al., 2015)</a></strong></p></li>
<li><p><strong><a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=http://neuralnetworksanddeeplearning.com/">Redes Neuronales y Aprendizaje Profundo (Michael Nielsen, libro en línea)</a></strong></p></li>
<li><p><strong><a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://explained.ai/matrix-calculus/">El cálculo matricial que necesitas para el aprendizaje profundo (Parr &amp; Howard, 2018)</a></strong></p></li>
</ol>


</section>
</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>