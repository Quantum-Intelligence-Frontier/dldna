<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>matemáticas-de-deep-learning – Deep Learning DNA: Surviving Architectures and Essential Principles</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-f507c7d0488cb7630e20aad62ad8c2aa.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script>window.MathJax = {loader: {load: ['[tex]/boldsymbol']},tex: {packages: {'[+]': ['boldsymbol']}}};</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../notebooks/es/part_1/01_El inicio del aprendizaje profundo.html">part_1</a></li><li class="breadcrumb-item"><a href="../../../notebooks/es/part_1/02_Matemáticas de deep learning.html">2. Matemáticas de deep learning</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../../">Español</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Language</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index_de.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Deutsch</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index_en.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">English</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index_es.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Español</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">한국어</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index_zh.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">中文</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/00_Introducción.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introducción</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">part_1</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/01_El inicio del aprendizaje profundo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1. El inicio del aprendizaje profundo</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/02_Matemáticas de deep learning.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">2. Matemáticas de deep learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/03_marco de aprendizaje profundo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3. marco de aprendizaje profundo</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/04_función de activación.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4. función de activación</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/05_Optimización y visualización.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5. Optimización y visualización</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/06_Sobreajuste y desarrollo de técnicas de solución.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">6. Sobreajuste y desarrollo de técnicas de solución</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/07_Evolución de las redes neuronales convolucionales.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">7. Evolución de las redes neuronales convolucionales</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/08_El nacimiento del transformer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8. El nacimiento del transformer</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/09_La evolución del transformer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">9. La evolución del transformer</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/10_Multimodal deep learning: el inicio de la fusión multisensorial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">10. Multimodal deep learning: el inicio de la fusión multisensorial</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/11_Multimodal deep learning: inteligencia más allá de los límites.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">11. Multimodal deep learning: inteligencia más allá de los límites</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">la vanguardia del deep learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/la vanguardia del deep learning/01_SLM: pequeño pero poderoso modelo de lenguaje.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1. SLM: pequeño pero poderoso modelo de lenguaje</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/la vanguardia del deep learning/02_conducción autónoma.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2. conducción autónoma</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#matemáticas-de-la-aprendizaje-profundo" id="toc-matemáticas-de-la-aprendizaje-profundo" class="nav-link active" data-scroll-target="#matemáticas-de-la-aprendizaje-profundo">2. Matemáticas de la Aprendizaje Profundo</a>
  <ul class="collapse">
  <li><a href="#fundamentos-del-álgebra-lineal" id="toc-fundamentos-del-álgebra-lineal" class="nav-link" data-scroll-target="#fundamentos-del-álgebra-lineal">2.1 Fundamentos del Álgebra Lineal</a>
  <ul class="collapse">
  <li><a href="#vectores" id="toc-vectores" class="nav-link" data-scroll-target="#vectores">2.1.1 Vectores</a></li>
  <li><a href="#dimensiones-rango" id="toc-dimensiones-rango" class="nav-link" data-scroll-target="#dimensiones-rango">2.1.2 Dimensiones, Rango</a></li>
  <li><a href="#fundamentos-de-la-transformación-lineal" id="toc-fundamentos-de-la-transformación-lineal" class="nav-link" data-scroll-target="#fundamentos-de-la-transformación-lineal">2.1.3 Fundamentos de la transformación lineal</a></li>
  <li><a href="#operaciones-de-tensores" id="toc-operaciones-de-tensores" class="nav-link" data-scroll-target="#operaciones-de-tensores">2.1.4 Operaciones de tensores</a></li>
  </ul></li>
  <li><a href="#cálculo-y-optimización" id="toc-cálculo-y-optimización" class="nav-link" data-scroll-target="#cálculo-y-optimización">2.2 Cálculo y optimización</a>
  <ul class="collapse">
  <li><a href="#regla-de-la-cadena" id="toc-regla-de-la-cadena" class="nav-link" data-scroll-target="#regla-de-la-cadena">2.2.1 Regla de la cadena</a></li>
  <li><a href="#gradiente-y-jacobiano" id="toc-gradiente-y-jacobiano" class="nav-link" data-scroll-target="#gradiente-y-jacobiano">2.2.2 Gradiente y Jacobiano</a></li>
  <li><a href="#regla-de-la-cadena-y-retropropagación-en-redes-neuronales" id="toc-regla-de-la-cadena-y-retropropagación-en-redes-neuronales" class="nav-link" data-scroll-target="#regla-de-la-cadena-y-retropropagación-en-redes-neuronales">2.2.3 Regla de la cadena y retropropagación en redes neuronales</a></li>
  <li><a href="#cálculo-de-gradientes-para-la-propagación-hacia-atrás" id="toc-cálculo-de-gradientes-para-la-propagación-hacia-atrás" class="nav-link" data-scroll-target="#cálculo-de-gradientes-para-la-propagación-hacia-atrás">2.2.4 Cálculo de gradientes para la propagación hacia atrás</a></li>
  </ul></li>
  <li><a href="#probabilidad-y-estadística" id="toc-probabilidad-y-estadística" class="nav-link" data-scroll-target="#probabilidad-y-estadística">2.3 Probabilidad y estadística</a>
  <ul class="collapse">
  <li><a href="#distribuciones-de-probabilidad-y-valor-esperado" id="toc-distribuciones-de-probabilidad-y-valor-esperado" class="nav-link" data-scroll-target="#distribuciones-de-probabilidad-y-valor-esperado">2.3.1 Distribuciones de probabilidad y valor esperado</a></li>
  <li><a href="#teorema-de-bayes-y-estimación-de-máxima-verosimilitud" id="toc-teorema-de-bayes-y-estimación-de-máxima-verosimilitud" class="nav-link" data-scroll-target="#teorema-de-bayes-y-estimación-de-máxima-verosimilitud">2.3.2 Teorema de Bayes y Estimación de Máxima Verosimilitud</a></li>
  <li><a href="#fundamentos-de-la-teoría-de-la-información" id="toc-fundamentos-de-la-teoría-de-la-información" class="nav-link" data-scroll-target="#fundamentos-de-la-teoría-de-la-información">2.3.3 Fundamentos de la teoría de la información</a></li>
  <li><a href="#función-de-pérdida" id="toc-función-de-pérdida" class="nav-link" data-scroll-target="#función-de-pérdida">2.3.4 Función de pérdida</a></li>
  </ul></li>
  <li><a href="#ejercicios-de-práctica" id="toc-ejercicios-de-práctica" class="nav-link" data-scroll-target="#ejercicios-de-práctica">Ejercicios de práctica</a>
  <ul class="collapse">
  <li><a href="#álgebra-lineal" id="toc-álgebra-lineal" class="nav-link" data-scroll-target="#álgebra-lineal">1. Álgebra lineal</a></li>
  </ul></li>
  <li><a href="#ejercicios-de-práctica-1" id="toc-ejercicios-de-práctica-1" class="nav-link" data-scroll-target="#ejercicios-de-práctica-1">Ejercicios de práctica</a>
  <ul class="collapse">
  <li><a href="#probabilidad-y-estadística-1" id="toc-probabilidad-y-estadística-1" class="nav-link" data-scroll-target="#probabilidad-y-estadística-1">3 Probabilidad y estadística</a></li>
  </ul></li>
  <li><a href="#referencias" id="toc-referencias" class="nav-link" data-scroll-target="#referencias">Referencias</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../notebooks/es/part_1/01_El inicio del aprendizaje profundo.html">part_1</a></li><li class="breadcrumb-item"><a href="../../../notebooks/es/part_1/02_Matemáticas de deep learning.html">2. Matemáticas de deep learning</a></li></ol></nav></header>




<p><a href="https://colab.research.google.com/github/Quantum-Intelligence-Frontier/dldna/blob/main/notebooks/es/part_1/02_la_matemática_del_aprendizaje_profundo.ipynb" target="_parent"> <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Abrir en Colab"> </a></p>
<section id="matemáticas-de-la-aprendizaje-profundo" class="level1">
<h1>2. Matemáticas de la Aprendizaje Profundo</h1>
<blockquote class="blockquote">
<p>“Todos los números están compuestos por unidades, y todos los números se pueden dividir en unidades” - Al-Khwarizmi (780-850), matemático persa.</p>
</blockquote>
<p>En este capítulo, examinaremos los conceptos matemáticos fundamentales que constituyen el núcleo del aprendizaje profundo. Los modelos de aprendizaje profundo están compuestos por combinaciones de funciones matemáticas complejas. Un entendimiento profundo del álgebra lineal, cálculo, probabilidad y estadística es esencial para comprender el funcionamiento de los modelos, mejorar su rendimiento y diseñar nuevos modelos. Por ejemplo, la comprensión de las operaciones matriciales es crucial para entender cómo funciona una Red Neuronal Convolucional (CNN), mientras que la diferenciación y optimización juegan un papel fundamental en la comprensión del proceso de aprendizaje de los modelos.</p>
<p>Si este capítulo resulta difícil, puede pasar al siguiente. Es aconsejable volver periódicamente para familiarizarse con el contenido.</p>
<section id="fundamentos-del-álgebra-lineal" class="level2">
<h2 class="anchored" data-anchor-id="fundamentos-del-álgebra-lineal">2.1 Fundamentos del Álgebra Lineal</h2>
<p>El álgebra lineal es la base fundamental del aprendizaje profundo. Desde las operaciones matriciales hasta técnicas de optimización avanzadas, el álgebra lineal es una herramienta esencial. En esta sección, abordaremos desde los conceptos básicos como vectores, matrices y tensores hasta temas avanzados como la descomposición en valores singulares y el análisis de componentes principales.</p>
<section id="vectores" class="level3">
<h3 class="anchored" data-anchor-id="vectores">2.1.1 Vectores</h3>
<p>Los vectores y las matrices son las operaciones fundamentales para representar datos y transformar cada dato.</p>
<p><strong>Conceptos básicos de los vectores</strong></p>
<p>Un vector es un objeto matemático que representa una cantidad con magnitud y dirección. La definición matemática es la misma, pero la perspectiva puede variar ligeramente dependiendo del campo de aplicación.</p>
<ul>
<li>Perspectiva matemática: En matemáticas, un vector se define como un objeto abstracto con magnitud y dirección. Como elemento de un espacio vectorial, posee las propiedades de estar cerrado bajo la suma y el producto por escalares.</li>
<li>Perspectiva física: En física, los vectores se utilizan principalmente para representar cantidades físicas como fuerza, velocidad y aceleración. En este caso, la magnitud y dirección del vector tienen un significado físico real. La física trata todos los cambios como vectores, y las dimensiones de los vectores son limitadas. Por ejemplo, el espacio es tridimensional y el espacio-tiempo cuatridimensional.</li>
<li>Perspectiva de ciencias de la computación: En ciencias de la computación, especialmente en aprendizaje automático y aprendizaje profundo, los vectores se utilizan principalmente para representar características (features) de los datos. Cada elemento del vector representa una característica específica de los datos y no necesariamente tiene una dirección física. Para representar características, las dimensiones del vector pueden variar desde decenas hasta miles.</li>
</ul>
<p>Entender estas perspectivas diversas es importante al trabajar con vectores en el aprendizaje profundo. Aunque en el aprendizaje profundo se utilizan principalmente los vectores desde la perspectiva de ciencias de la computación, también se aplican conceptos matemáticos y intuiciones físicas.</p>
<p>En el aprendizaje profundo, los vectores se utilizan principalmente para representar simultáneamente varias características de los datos. Por ejemplo, un vector de 5 dimensiones utilizado en un modelo de predicción de precios de viviendas puede expresarse como sigue:</p>
<p><span class="math inline">\(\mathbf{v} = \begin{bmatrix} v_1 \ v_2 \ v_3 \ v_4 \ v_5 \end{bmatrix}\)</span></p>
<p>Cada elemento de este vector representa una característica diferente de la vivienda. <span class="math inline">\(v_1\)</span>: área de la vivienda (en metros cuadrados), <span class="math inline">\(v_2\)</span>: número de habitaciones, <span class="math inline">\(v_3\)</span>: edad de la vivienda (en años), <span class="math inline">\(v_4\)</span>: distancia a escuelas cercanas (en kilómetros), <span class="math inline">\(v_5\)</span>: tasa de criminalidad (porcentaje)</p>
<p>Los modelos de aprendizaje profundo pueden usar estos vectores multidimensionales como entrada para predecir el precio de una vivienda. De esta manera, los vectores se utilizan para representar y procesar eficazmente las diversas características de datos complejos del mundo real.</p>
<p>En NumPy, los vectores se pueden crear y utilizar fácilmente.</p>
<div id="cell-2" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install dldna[colab] <span class="co"># in Colab</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip install dldna[all] # in your local</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="cell-3" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Vector creation</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>v <span class="op">=</span> np.array([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>])</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Vector magnitude (L2 norm)</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>magnitude <span class="op">=</span> np.linalg.norm(v)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Vector magnitude: </span><span class="sc">{</span>magnitude<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Vector normalization</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>normalized_v <span class="op">=</span> v <span class="op">/</span> magnitude</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Normalized vector: </span><span class="sc">{</span>normalized_v<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Vector magnitude: 3.7416573867739413
Normalized vector: [0.26726124 0.53452248 0.80178373]</code></pre>
</div>
</div>
<p>Si exploramos más a fondo el concepto de vector, encontramos la distinción entre vectores fila y vectores columna, así como los conceptos de covectores (vectores covariantes) y contravectores (vectores contravariantes), que se utilizan en física e ingeniería.</p>
<p><strong>Vectores fila y vectores columna</strong></p>
<p>Los vectores se representan generalmente como vectores columna. Los vectores fila pueden considerarse la transpuesta de los vectores columna. Matemáticamente, con mayor precisión, un vector fila también puede llamarse covector (dual vector).</p>
<p>Vector columna: <span class="math inline">\(\mathbf{v} = \begin{bmatrix} v_1 \\ v_2 \\ v_3 \end{bmatrix}\)</span>, Vector fila: <span class="math inline">\(\mathbf{v}^T = [v_1 \quad v_2 \quad v_3]\)</span></p>
<p>Los vectores fila y los vectores columna tienen propiedades diferentes. Un vector fila actúa como una función lineal sobre un vector columna para producir un escalar. Esto se expresa mediante el producto interno.</p>
<p><span class="math display">\[\mathbf{u}^T\mathbf{v} = u_1v_1 + u_2v_2 + u_3v_3\]</span></p>
<p><strong>Covectores y contravectores</strong></p>
<p>En física e ingeniería, los conceptos de covector (vector covariante) y contravector (vector contravariante) son tratados con importancia. Estos describen las características de transformación de un vector bajo cambios en el sistema de coordenadas.</p>
<ul>
<li>Contravector: Un vector que se transforma en la dirección opuesta a la base cuando cambia el sistema de coordenadas. Generalmente se denota con un superíndice (por ejemplo, <span class="math inline">\(v^i\)</span>).</li>
<li>Covector: Un vector que se transforma en la misma dirección que la base cuando cambia el sistema de coordenadas. Generalmente se denota con un subíndice (por ejemplo, <span class="math inline">\(v_i\)</span>).</li>
</ul>
<p>En la notación tensorial, esta distinción es crucial. Por ejemplo, <span class="math inline">\(T^i_j\)</span> indica que el superíndice <span class="math inline">\(i\)</span> representa contravarianza y el subíndice <span class="math inline">\(j\)</span> representa covarianza. En teoría de la relatividad general, estos conceptos de covarianza y contravarianza son tratados como fundamentales.</p>
<p><strong>Aplicación en aprendizaje profundo</strong></p>
<p>En el aprendizaje profundo, la distinción entre covarianza y contravarianza a menudo no se enfatiza explícitamente. Esto se debe a las siguientes razones:</p>
<ol type="1">
<li>Representación estandarizada de datos: En el aprendizaje profundo, los datos generalmente se manejan en una forma estandarizada (por ejemplo, vectores columna), lo que hace que la distinción entre covarianza y contravarianza sea menos importante.</li>
<li>Suposición del espacio euclidiano: Muchos modelos de aprendizaje profundo asumen que los datos residen en un espacio euclidiano, donde la distinción entre covarianza y contravarianza no es clara.</li>
<li>Simplificación de operaciones: Las principales operaciones en el aprendizaje profundo (por ejemplo, multiplicación matricial, aplicación de funciones de activación) pueden realizarse eficazmente sin esta distinción.</li>
<li>Diferenciación automática: Las funciones de diferenciación automática en los frameworks modernos de aprendizaje profundo pueden calcular gradientes precisos sin necesidad de estas distinciones detalladas.</li>
</ol>
<p>Sin embargo, en ciertos campos, particularmente en el aprendizaje de máquinas basado en física o en el aprendizaje profundo geométrico, estos conceptos aún son importantes. Por ejemplo, en modelos de aprendizaje profundo que utilizan geometría diferencial, la distinción entre covarianza y contravarianza puede desempeñar un papel crucial en el diseño e interpretación del modelo.</p>
<p>En conclusión, aunque los conceptos básicos de vectores en el aprendizaje profundo se usan de manera simplificada, ideas matemáticas más complejas siguen siendo importantes en el diseño avanzado de modelos y aplicaciones específicas.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Haga clic para ver el contenido (buceo profundo: espacio vectorial y combinación lineal)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Haga clic para ver el contenido (buceo profundo: espacio vectorial y combinación lineal)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<section id="espacio-vectorial-y-combinación-lineal" class="level3 callout-body-container callout-body">
<h3 class="anchored" data-anchor-id="espacio-vectorial-y-combinación-lineal">Espacio vectorial y combinación lineal</h3>
<p>El espacio vectorial, un concepto fundamental del álgebra lineal, proporciona el marco básico para representar y transformar datos en el aprendizaje profundo. En este análisis detallado, examinamos la definición rigurosa de los espacios vectoriales y conceptos relacionados, así como ejemplos de su aplicación en el aprendizaje profundo.</p>
<section id="espacio-vectorial-vector-space" class="level4">
<h4 class="anchored" data-anchor-id="espacio-vectorial-vector-space">Espacio Vectorial (Vector Space)</h4>
<p>Un espacio vectorial es un conjunto <span class="math inline">\(V\)</span> que satisface las siguientes 8 axiomas, junto con las operaciones de adición y multiplicación escalar. Aquí, los elementos de <span class="math inline">\(V\)</span> se denominan vectores, y los escalares son elementos del conjunto de números reales <span class="math inline">\(\mathbb{R}\)</span> o complejos <span class="math inline">\(\mathbb{C}\)</span>. (En el aprendizaje profundo, se utilizan principalmente números reales).</p>
<p><strong>Adición vectorial (Vector Addition):</strong> Para cualquier par de elementos <span class="math inline">\(\mathbf{u}, \mathbf{v}\)</span> en <span class="math inline">\(V\)</span>, <span class="math inline">\(\mathbf{u} + \mathbf{v}\)</span> también es un elemento de <span class="math inline">\(V\)</span>. (Cerrado bajo adición, closed under addition)</p>
<p><strong>Multiplicación escalar (Scalar Multiplication):</strong> Para cualquier elemento <span class="math inline">\(\mathbf{u}\)</span> en <span class="math inline">\(V\)</span> y cualquier escalar <span class="math inline">\(c\)</span>, <span class="math inline">\(c\mathbf{u}\)</span> también es un elemento de <span class="math inline">\(V\)</span>. (Cerrado bajo multiplicación escalar, closed under scalar multiplication)</p>
<p><strong>La adición vectorial y la multiplicación escalar deben satisfacer los siguientes 8 axiomas.</strong> (<span class="math inline">\(\mathbf{u}, \mathbf{v}, \mathbf{w} \in V\)</span>, <span class="math inline">\(c, d\)</span>: escalares)</p>
<ol type="1">
<li><strong>Conmutatividad de la adición (Commutativity of addition):</strong> <span class="math inline">\(\mathbf{u} + \mathbf{v} = \mathbf{v} + \mathbf{u}\)</span></li>
<li><strong>Asociatividad de la adición (Associativity of addition):</strong> <span class="math inline">\((\mathbf{u} + \mathbf{v}) + \mathbf{w} = \mathbf{u} + (\mathbf{v} + \mathbf{w})\)</span></li>
<li><strong>Elemento neutro de la adición (Additive identity):</strong> Existe un <span class="math inline">\(\mathbf{0} \in V\)</span> (vector cero) tal que para todo <span class="math inline">\(\mathbf{u} \in V\)</span>, se cumple <span class="math inline">\(\mathbf{u} + \mathbf{0} = \mathbf{u}\)</span>.</li>
<li><strong>Elemento inverso de la adición (Additive inverse):</strong> Para cada <span class="math inline">\(\mathbf{u} \in V\)</span>, existe un <span class="math inline">\(-\mathbf{u} \in V\)</span> (elemento inverso) tal que <span class="math inline">\(\mathbf{u} + (-\mathbf{u}) = \mathbf{0}\)</span>.</li>
<li><strong>Distributividad de la multiplicación escalar con respecto a la adición vectorial (Distributivity of scalar multiplication with respect to vector addition):</strong> <span class="math inline">\(c(\mathbf{u} + \mathbf{v}) = c\mathbf{u} + c\mathbf{v}\)</span></li>
<li><strong>Distributividad de la multiplicación escalar con respecto a la adición escalar (Distributivity of scalar multiplication with respect to scalar addition):</strong> <span class="math inline">\((c + d)\mathbf{u} = c\mathbf{u} + d\mathbf{u}\)</span></li>
<li><strong>Asociatividad de la multiplicación escalar con respecto a la multiplicación escalar (Compatibility of scalar multiplication with scalar multiplication):</strong> <span class="math inline">\(c(d\mathbf{u}) = (cd)\mathbf{u}\)</span></li>
<li><strong>Elemento neutro de la multiplicación escalar (Identity element of scalar multiplication):</strong> <span class="math inline">\(1\mathbf{u} = \mathbf{u}\)</span> (donde 1 es el elemento neutro de la multiplicación escalar)</li>
</ol>
<p><strong>Ejemplo:</strong> * <span class="math inline">\(\mathbb{R}^n\)</span>: espacio vectorial real de <span class="math inline">\(n\)</span> dimensiones (n-uplas de números reales) * <span class="math inline">\(\mathbb{C}^n\)</span>: espacio vectorial complejo de <span class="math inline">\(n\)</span> dimensiones * <span class="math inline">\(M_{m \times n}(\mathbb{R})\)</span>: espacio de matrices reales de <span class="math inline">\(m \times n\)</span> * <span class="math inline">\(P_n\)</span>: espacio de polinomios con coeficientes reales de grado <span class="math inline">\(\leq n\)</span> * <span class="math inline">\(C[a, b]\)</span>: espacio de funciones valoradas en los reales continuas en el intervalo <span class="math inline">\([a, b]\)</span></p>
</section>
<section id="subespacio" class="level4">
<h4 class="anchored" data-anchor-id="subespacio">Subespacio</h4>
<p>Un subconjunto <span class="math inline">\(W\)</span> del espacio vectorial <span class="math inline">\(V\)</span> es un subespacio si cumple las siguientes condiciones:</p>
<ol type="1">
<li><span class="math inline">\(\mathbf{0} \in W\)</span> (contiene al vector cero)</li>
<li>Si <span class="math inline">\(\mathbf{u}, \mathbf{v} \in W\)</span>, entonces <span class="math inline">\(\mathbf{u} + \mathbf{v} \in W\)</span> (cerrado bajo adición)</li>
<li>Si <span class="math inline">\(\mathbf{u} \in W\)</span> y <span class="math inline">\(c\)</span> es un escalar, entonces <span class="math inline">\(c\mathbf{u} \in W\)</span> (cerrado bajo multiplicación escalar)</li>
</ol>
<p>Es decir, un subespacio es un subconjunto de un espacio vectorial que también cumple con las propiedades de un espacio vectorial.</p>
</section>
<section id="combinación-lineal" class="level4">
<h4 class="anchored" data-anchor-id="combinación-lineal">Combinación lineal</h4>
<p>Dada una colección de vectores <span class="math inline">\(\mathbf{v}_1, \mathbf{v}_2, ..., \mathbf{v}_k\)</span> en el espacio vectorial <span class="math inline">\(V\)</span> y escalares <span class="math inline">\(c_1, c_2, ..., c_k\)</span>, la expresión siguiente se llama combinación lineal:</p>
<p><span class="math inline">\(c_1\mathbf{v}_1 + c_2\mathbf{v}_2 + ... + c_k\mathbf{v}_k\)</span></p>
</section>
<section id="independencia-lineal-y-dependencia-lineal" class="level4">
<h4 class="anchored" data-anchor-id="independencia-lineal-y-dependencia-lineal">Independencia lineal y dependencia lineal</h4>
<p>Un conjunto de vectores {<span class="math inline">\(\mathbf{v}_1, \mathbf{v}_2, ..., \mathbf{v}_k\)</span>} es <em>linealmente independiente</em> si la única solución a la ecuación</p>
<p><span class="math inline">\(c_1\mathbf{v}_1 + c_2\mathbf{v}_2 + ... + c_k\mathbf{v}_k = \mathbf{0}\)</span></p>
<p>es <span class="math inline">\(c_1 = c_2 = ... = c_k = 0\)</span>.</p>
<p>Si no se cumple esta condición (es decir, existen escalares no todos nulos <span class="math inline">\(c_1, ..., c_k\)</span> que satisfacen la ecuación anterior), el conjunto de vectores es <em>linealmente dependiente</em>.</p>
<p><strong>Significado intuitivo:</strong></p>
<ul>
<li><strong>Independencia lineal:</strong> los vectores pueden pensarse como apuntando en “direcciones diferentes”. Ningún vector puede ser expresado como una combinación lineal de los demás.</li>
<li><strong>Dependencia lineal:</strong> algunos de los vectores pueden estar en la “misma dirección” (o “plano”, “hiperplano”). Un vector puede ser expresado como una combinación lineal de los otros.</li>
</ul>
</section>
<section id="base-y-dimensión" class="level4">
<h4 class="anchored" data-anchor-id="base-y-dimensión">Base y dimensión</h4>
<ul>
<li><strong>Base:</strong> un conjunto de vectores del espacio vectorial <span class="math inline">\(V\)</span> es una <em>base</em> si:
<ol type="1">
<li>Son linealmente independientes.</li>
<li>Span a <span class="math inline">\(V\)</span> (véase explicación de span a continuación).</li>
</ol></li>
<li><strong>Dimensión:</strong> el número de vectores en una base se llama <em>dimensión</em>. (dim <span class="math inline">\(V\)</span>)</li>
</ul>
<p><strong>Clave:</strong> aunque una base para un espacio vectorial dado no es única, todas las bases tienen el mismo número de vectores.</p>
</section>
<section id="span" class="level4">
<h4 class="anchored" data-anchor-id="span">Span</h4>
<p>El <em>span</em> de un conjunto de vectores {<span class="math inline">\(\mathbf{v}_1, \mathbf{v}_2, ..., \mathbf{v}_k\)</span>} es el conjunto de todas las posibles combinaciones lineales de estos vectores.</p>
<p>span{<span class="math inline">\(\mathbf{v}_1, \mathbf{v}_2, ..., \mathbf{v}_k\)</span>} = {<span class="math inline">\(c_1\mathbf{v}_1 + c_2\mathbf{v}_2 + ... + c_k\mathbf{v}_k\)</span> | <span class="math inline">\(c_1, c_2, ..., c_k\)</span> son escalares}</p>
<p>En otras palabras, es el conjunto de todos los vectores que se pueden formar usando los vectores dados. El span siempre forma un subespacio. #### Ejemplos de espacios vectoriales en el aprendizaje profundo</p>
<ul>
<li><strong>Vector de características (Feature Vector):</strong> los datos de entrada para modelos de aprendizaje profundo, como imágenes, texto y audio, a menudo se representan como vectores de alta dimensión. Por ejemplo, una imagen en escala de grises de 28x28 píxeles puede representarse como un vector de 784 dimensiones. Cada dimensión representa el valor de brillo de un píxel específico de la imagen.</li>
<li><strong>Vector de pesos (Weight Vector):</strong> cada capa de una red neuronal está compuesta por una matriz de pesos y un vector de sesgo. Cada fila (o columna) de la matriz de pesos puede verse como un vector que representa los pesos de un neurona específica.</li>
<li><strong>Vector de incrustación (Embedding Vector):</strong> se utiliza para representar palabras, usuarios, elementos, etc., en espacios vectoriales de baja dimensión. Word2Vec, GloVe, BERT son técnicas de incrustación típicas que representan palabras como vectores.</li>
<li><strong>Espacio latente (Latent Space):</strong> los autoencoder, los autoencoder variacionales (Variational Autoencoder, VAE) y las redes generativas adversarias (Generative Adversarial Network, GAN) aprenden métodos para mapear datos a un espacio latente de baja dimensión. Este espacio latente también puede verse como un espacio vectorial.</li>
</ul>
</section>
</section>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Haga clic para ver el contenido (análisis detallado: normas y distancias - perspectiva del aprendizaje profundo)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Haga clic para ver el contenido (análisis detallado: normas y distancias - perspectiva del aprendizaje profundo)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<section id="normas-y-distancias-en-el-aprendizaje-profundo" class="level3 callout-body-container callout-body">
<h3 class="anchored" data-anchor-id="normas-y-distancias-en-el-aprendizaje-profundo">Normas y Distancias en el Aprendizaje Profundo</h3>
<p>Medir el tamaño (magnitude) de un vector o la distancia entre dos vectores es muy importante en el aprendizaje profundo. Se utiliza en diversas áreas, como funciones de pérdida, regularización, medición de similitud, etc.</p>
<section id="norma-norm" class="level4">
<h4 class="anchored" data-anchor-id="norma-norm">Norma (Norm)</h4>
<p>La Lp-norm de un vector <span class="math inline">\(\mathbf{x} = [x_1, x_2, ..., x_n]\)</span> se define como sigue (<span class="math inline">\(p \ge 1\)</span>).</p>
<p><span class="math inline">\(||\mathbf{x}||_p = \left( \sum_{i=1}^{n} |x_i|^p \right)^{1/p}\)</span></p>
<ul>
<li><strong>L1-norm (<span class="math inline">\(p=1\)</span>):</strong> <span class="math inline">\(||\mathbf{x}||_1 = \sum_{i=1}^{n} |x_i|\)</span> (distancia de Manhattan, norma del taxi)
<ul>
<li><strong>Características:</strong> suma de los valores absolutos de cada elemento. Útil cuando la magnitud de cada elemento del vector de características es importante.</li>
<li><strong>Uso en aprendizaje profundo:</strong> La regularización L1 (regresión Lasso) se utiliza para crear modelos escasos (algunos pesos son 0) al limitar la suma de los valores absolutos de los pesos.</li>
</ul></li>
<li><strong>L2-norm (<span class="math inline">\(p=2\)</span>):</strong> <span class="math inline">\(||\mathbf{x}||_2 = \sqrt{\sum_{i=1}^{n} x_i^2}\)</span> (norma euclidiana)
<ul>
<li><strong>Características:</strong> distancia en línea recta desde el origen hasta las coordenadas del vector (teorema de Pitágoras). Es la norma más comúnmente utilizada.</li>
<li><strong>Uso en aprendizaje profundo:</strong> La regularización L2 (regresión Ridge) se utiliza para prevenir que los pesos sean demasiado grandes (previniendo el sobreajuste, overfitting). También se conoce como atenuación de pesos (weight decay).</li>
</ul></li>
<li><strong>L∞-norm (<span class="math inline">\(p \to \infty\)</span>):</strong> <span class="math inline">\(||\mathbf{x}||_\infty = \max_i |x_i|\)</span>
<ul>
<li><strong>Características:</strong> el valor absoluto más grande entre los elementos del vector.</li>
<li><strong>Uso en aprendizaje profundo:</strong> (menos común) se utiliza para limitar que ciertos elementos sean demasiado grandes.</li>
</ul></li>
</ul>
</section>
<section id="distancia-distance" class="level4">
<h4 class="anchored" data-anchor-id="distancia-distance">Distancia (Distance)</h4>
<p>La distancia entre dos vectores <span class="math inline">\(\mathbf{x}\)</span> y <span class="math inline">\(\mathbf{y}\)</span> generalmente se define como la norma de su diferencia.</p>
<p><span class="math inline">\(d(\mathbf{x}, \mathbf{y}) = ||\mathbf{x} - \mathbf{y}||\)</span></p>
<ul>
<li><strong>L1 distancia:</strong> <span class="math inline">\(d(\mathbf{x}, \mathbf{y}) = ||\mathbf{x} - \mathbf{y}||_1 = \sum_{i=1}^{n} |x_i - y_i|\)</span></li>
<li><strong>L2 distancia:</strong> <span class="math inline">\(d(\mathbf{x}, \mathbf{y}) = ||\mathbf{x} - \mathbf{y}||_2 = \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2}\)</span></li>
</ul>
<p><strong>Ejemplos de uso en aprendizaje profundo:</strong></p>
<ul>
<li><strong>Funciones de pérdida:</strong> MSE (L2 Loss), MAE (L1 Loss)</li>
<li><strong>Regularización:</strong> regularización L1, regularización L2 (atenuación de pesos, weight decay)</li>
<li><strong>Aprendizaje basado en similitud/distancia:</strong> k-NN, SVM, Red Siamesa, Red Triplet, Aprendizaje Contrastivo</li>
<li><strong>Embeddings:</strong> representar palabras, usuarios, ítems, etc., en un espacio vectorial y determinar su similitud/relación a través de la distancia entre vectores.</li>
<li><strong>Detección de anomalías (Outlier Detection):</strong> detectar anomalías basándose en las distancias entre puntos de datos.</li>
</ul>
<p><strong>Referencia:</strong> En el aprendizaje profundo, es importante distinguir entre “distancia” y “similitud”. La distancia es menor cuando la similitud es mayor, y la similitud es mayor cuando los valores son más cercanos. La similitud coseno (cosine similarity) es uno de los métodos de medición de similitud más comúnmente utilizados en el aprendizaje profundo.</p>
</section>
</section>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Haga clic para ver el contenido (análisis detallado: espacio afín)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Haga clic para ver el contenido (análisis detallado: espacio afín)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<section id="espacio-afín-affine-space" class="level3 callout-body-container callout-body">
<h3 class="anchored" data-anchor-id="espacio-afín-affine-space">Espacio afín (Affine Space)</h3>
<p>El espacio afín es una generalización del concepto de espacio vectorial en álgebra lineal, y es una herramienta útil para entender los modelos de aprendizaje profundo desde un punto de vista geométrico. En particular, la transformación afín representa la forma de agregar un sesgo (bias) a las transformaciones lineales que se utilizan comúnmente en el aprendizaje profundo.</p>
<section id="definición-del-espacio-afín" class="level4">
<h4 class="anchored" data-anchor-id="definición-del-espacio-afín">Definición del espacio afín</h4>
<p>Un espacio afín es una estructura compuesta por tres elementos: (conjunto de puntos, espacio vectorial, adición de punto y vector). Más específicamente,</p>
<ul>
<li><strong>Conjunto de puntos (<span class="math inline">\(\mathcal{A}\)</span>):</strong> Conjunto de objetos geométricos (puntos). A diferencia del espacio vectorial, <em>no tiene un origen fijo</em>.</li>
<li><strong>Espacio vectorial (<span class="math inline">\(V\)</span>):</strong> Conjunto de vectores que representan el <em>desplazamiento</em> o la <em>diferencia</em> entre puntos. Satisface todas las propiedades del espacio vectorial (adición, producto escalar, 8 axiomas).</li>
<li><strong>Adición de punto y vector (<span class="math inline">\(\mathcal{A} \times V \to \mathcal{A}\)</span>):</strong> Operación que suma un punto <span class="math inline">\(P \in \mathcal{A}\)</span> con un vector <span class="math inline">\(\mathbf{v} \in V\)</span> para obtener un nuevo punto <span class="math inline">\(Q \in \mathcal{A}\)</span>. Se denota como <span class="math inline">\(Q = P + \mathbf{v}\)</span>.</li>
</ul>
<p>Esta operación de adición debe satisfacer las siguientes dos propiedades:</p>
<ol type="1">
<li><strong>Para cualquier punto <span class="math inline">\(P \in \mathcal{A}\)</span>, <span class="math inline">\(P + \mathbf{0} = P\)</span> (donde <span class="math inline">\(\mathbf{0}\)</span> es el vector cero del espacio vectorial <span class="math inline">\(V\)</span>)</strong></li>
<li><strong>Para cualquier punto <span class="math inline">\(P, Q, R \in \mathcal{A}\)</span>, <span class="math inline">\((P + \mathbf{u}) + \mathbf{v} = P + (\mathbf{u} + \mathbf{v})\)</span> (donde <span class="math inline">\(\mathbf{u}, \mathbf{v} \in V\)</span>)</strong></li>
</ol>
<p><strong>Características importantes</strong></p>
<ul>
<li>En el espacio afín, no existe un punto “origen” especial. Todos los puntos son equivalentes.</li>
<li>La “diferencia” entre dos puntos <span class="math inline">\(P, Q \in \mathcal{A}\)</span> se expresa como un vector del espacio vectorial <span class="math inline">\(V\)</span>: <span class="math inline">\(\overrightarrow{PQ} = Q - P \in V\)</span>. (Sin embargo, la “suma” de dos puntos no está definida.)</li>
<li>A través de la adición de punto y vector, es posible moverse de un punto a otro.</li>
</ul>
</section>
<section id="combinación-afín" class="level4">
<h4 class="anchored" data-anchor-id="combinación-afín">Combinación afín</h4>
<p>Dado un conjunto de puntos <span class="math inline">\(P_1, P_2, ..., P_k\)</span> en el espacio afín <span class="math inline">\(\mathcal{A}\)</span> y escalares <span class="math inline">\(c_1, c_2, ..., c_k\)</span>, una combinación afín tiene la siguiente forma:</p>
<p><span class="math inline">\(c_1P_1 + c_2P_2 + ... + c_kP_k\)</span> (con la condición de que <span class="math inline">\(c_1 + c_2 + ... + c_k = 1\)</span>)</p>
<p><strong>Importante:</strong> A diferencia de las combinaciones lineales, en una combinación afín <em>la suma de los coeficientes debe ser 1</em>. Esta condición refleja la propiedad del espacio afín de que “no tiene un origen”.</p>
</section>
<section id="transformación-afín" class="level4">
<h4 class="anchored" data-anchor-id="transformación-afín">Transformación afín</h4>
<p>Una transformación afín es una función del espacio afín al espacio afín, que se puede expresar como una combinación de una transformación lineal y una traslación. Es decir, una transformación afín incluye tanto una <em>transformación lineal</em> como un <em>sesgo (bias)</em>.</p>
<p><span class="math inline">\(f(P) = T(P) + \mathbf{b}\)</span></p>
<ul>
<li><span class="math inline">\(T\)</span>: Transformación lineal (transformación lineal del espacio vectorial <span class="math inline">\(V\)</span> a sí mismo)</li>
<li><span class="math inline">\(\mathbf{b}\)</span>: Vector de traslación (elemento del espacio vectorial <span class="math inline">\(V\)</span>)</li>
</ul>
<p><strong>Representación matricial:</strong></p>
<p>Una transformación afín se puede representar utilizando una matriz aumentada. En un espacio afín de <span class="math inline">\(n\)</span> dimensiones, se utiliza un vector de <span class="math inline">\(n+1\)</span> dimensiones para representar la transformación afín como una matriz <span class="math inline">\((n+1) \times (n+1)\)</span>. <span class="math inline">\(\begin{bmatrix} \mathbf{y} \\ 1 \end{bmatrix} = \begin{bmatrix} \mathbf{A} &amp; \mathbf{b} \\ \mathbf{0}^T &amp; 1 \end{bmatrix} \begin{bmatrix} \mathbf{x} \\ 1 \end{bmatrix}\)</span></p>
<ul>
<li><span class="math inline">\(\mathbf{A}\)</span>: matriz de transformación lineal <span class="math inline">\(n \times n\)</span></li>
<li><span class="math inline">\(\mathbf{b}\)</span>: vector de traslación <span class="math inline">\(n\)</span>-dimensional</li>
<li><span class="math inline">\(\mathbf{x}\)</span>: vector de entrada <span class="math inline">\(n\)</span>-dimensional (punto en el espacio afín)</li>
<li><span class="math inline">\(\mathbf{y}\)</span>: vector de salida <span class="math inline">\(n\)</span>-dimensional (punto en el espacio afín)</li>
</ul>
</section>
<section id="espacio-afín-y-transformación-afín-en-el-aprendizaje-profundo" class="level4">
<h4 class="anchored" data-anchor-id="espacio-afín-y-transformación-afín-en-el-aprendizaje-profundo">Espacio afín y transformación afín en el aprendizaje profundo</h4>
<ul>
<li><strong>Capa completamente conectada:</strong> la capa fully connected (capa densa) del aprendizaje profundo realiza una transformación afín. En <span class="math inline">\(\mathbf{y} = \mathbf{W}\mathbf{x} + \mathbf{b}\)</span>, <span class="math inline">\(\mathbf{W}\mathbf{x}\)</span> representa la transformación lineal y <span class="math inline">\(\mathbf{b}\)</span> el sesgo (traslación).</li>
<li><strong>Espacio de entrada:</strong> los datos de entrada del modelo de aprendizaje profundo a menudo se representan como vectores de alta dimensión, pero en sentido estricto, pueden considerarse puntos en un espacio afín sin origen. Por ejemplo, los datos de imagen se representan como vectores con los valores de brillo de cada píxel, pero este espacio vectorial no tiene un origen especial.</li>
<li><strong>Espacio de características (Feature Space):</strong> cada capa de la red neuronal transforma las entradas a un nuevo espacio de características. Estas transformaciones suelen consistir en una combinación de transformaciones afines (transformación lineal + sesgo) y funciones de activación no lineales.</li>
<li><strong>Aumento de datos (Data Augmentation):</strong> las rotaciones, traslaciones y ajustes de escala de los datos de imagen se pueden representar como transformaciones afines.</li>
<li><strong>Capa Afín</strong>: a diferencia de la transformación lineal, considera el sesgo.</li>
</ul>
</section>
<section id="modelos-de-aprendizaje-profundo-sin-sesgo" class="level4">
<h4 class="anchored" data-anchor-id="modelos-de-aprendizaje-profundo-sin-sesgo">Modelos de aprendizaje profundo sin sesgo</h4>
<p>En investigaciones recientes en aprendizaje profundo, se han propuesto modelos que eliminan los términos de sesgo (bias) para mejorar la eficiencia computacional, la interpretabilidad del modelo o basándose en ciertos marcos teóricos.</p>
<ul>
<li><strong>MuZero de DeepMind (2020):</strong> el modelo de aprendizaje por refuerzo MuZero no utiliza sesgo en sus redes policy y value. El paper menciona que eliminar el sesgo ayuda al aprendizaje de representaciones.</li>
<li><strong>Serie GPT (Generative Pre-trained Transformer) de OpenAI</strong>: en algunas investigaciones y implementaciones, se eliminan los términos de sesgo por eficiencia computacional. Sin embargo, <em>no todos los modelos de la serie GPT omiten el sesgo.</em> Modelos a gran escala como GPT-3 siguen utilizando sesgo en muchos casos.</li>
<li><strong>Redes sin Sesgo</strong>: algunos estudios analizan sistemáticamente el impacto de eliminar el sesgo en el rendimiento de generalización del modelo.</li>
</ul>
<p><strong>Razones para eliminar el sesgo</strong></p>
<ul>
<li><strong>Eficiencia computacional:</strong> al eliminar el término de sesgo, se reduce el número de parámetros del modelo, lo que disminuye la cantidad de cálculos y uso de memoria. Este efecto puede ser más significativo en modelos a gran escala.</li>
<li><strong>Aprendizaje de representaciones (Representation Learning):</strong> en ciertos problemas, el término de sesgo puede ser innecesario o incluso perjudicial para el aprendizaje de representaciones. Por ejemplo, en MuZero, se cree que las representaciones sin sesgo son más abstractas y generalizadas.</li>
<li><strong>Fundamento teórico/matemático:</strong> en algunos modelos (por ejemplo, ciertos tipos de modelos generativos), la ausencia de términos de sesgo puede ser matemáticamente más natural o más adecuada para ciertos análisis teóricos.</li>
<li><strong>Efecto regularizador</strong>: se ha encontrado que sin el sesgo, la matriz de pesos puede contener información más relevante, lo que actúa como un efecto regularizador. <strong>Nota:</strong> Eliminar el bias <em>no siempre</em> garantiza una mejora en el rendimiento. El impacto del bias en el rendimiento puede variar según las características del problema, la estructura del modelo, la cantidad de datos, entre otros factores.</li>
</ul>
<p>El concepto de espacio afín y transformación afín puede ser utilizado en la interpretación geométrica de los modelos de aprendizaje profundo, en el análisis del rendimiento de generalización y en el diseño de nuevas arquitecturas.</p>
</section>
</section>
</div>
</div>
</section>
<section id="dimensiones-rango" class="level3">
<h3 class="anchored" data-anchor-id="dimensiones-rango">2.1.2 Dimensiones, Rango</h3>
<p>Los términos relacionados con tensores, vectores y matrices se utilizan de manera ligeramente diferente en las áreas de matemáticas, física y ciencias de la computación, lo que puede causar confusión. Para evitar esta confusión, revisemos los conceptos principales. Primero, examinaremos el rango y las dimensiones de un tensor. El rango de un tensor se refiere al número de índices que tiene el tensor. Por ejemplo, un escalar es un tensor de rango 0, un vector es un tensor de rango 1, una matriz es un tensor de rango 2. Los tensores de tres o más dimensiones generalmente se denominan simplemente tensores.</p>
<p>El término “dimensión” puede tener dos significados diferentes y requiere atención. En primer lugar, a veces se usa en el mismo sentido que el rango del tensor. En este caso, un vector se llama tensor de una dimensión, y una matriz se llama tensor de dos dimensiones. En segundo lugar, también se puede usar para indicar la longitud o tamaño de un arreglo. Por ejemplo, cuando decimos que las dimensiones del vector <span class="math inline">\(\mathbf{a} = [1, 2, 3, 4]\)</span> son 4, nos referimos a esto.</p>
<p>Es importante conocer las diferencias en el uso de los términos según el campo. En física, el número de elementos tiene un significado físico, por lo que tiende a usarse más estrictamente. Por otro lado, en ciencias de la computación, se tratan los vectores, matrices y tensores principalmente como arreglos de números, y el término “dimensión” se usa indistintamente para referirse tanto al número de datos como al número de índices.</p>
<p>Para evitar confusiones debido a estas diferencias en el uso de términos, hay algunos puntos que deben tenerse en cuenta. El significado de los términos puede variar según el contexto y debe interpretarse con cuidado. Es necesario distinguir claramente cómo se usa “dimensión” en un artículo o libro. En particular, en el campo del aprendizaje profundo, a menudo se utiliza “dimensión” para referirse tanto al rango del tensor como al tamaño de la matriz, por lo que una interpretación coherente es importante.</p>
<p>En los marcos de aprendizaje profundo, los términos ‘dimensión’ o ‘eje’ se utilizan para describir la forma (shape) de un tensor. Por ejemplo, en PyTorch, se puede verificar el tamaño de cada dimensión del tensor mediante <code>tensor.shape</code> o <code>tensor.size()</code>. En este libro, el rango de un tensor (rank) se denominará ‘dimensión’, y la longitud/tamaño del arreglo se expresará como los valores de los elementos de shape o como dimensiones.</p>
</section>
<section id="fundamentos-de-la-transformación-lineal" class="level3">
<h3 class="anchored" data-anchor-id="fundamentos-de-la-transformación-lineal">2.1.3 Fundamentos de la transformación lineal</h3>
<p>Vamos a revisar las matemáticas necesarias para el entrenamiento de deep learning. La transformación lineal, que es una operación central en las redes neuronales, se expresa muy simplemente en el cálculo forward. En esta sección nos centraremos en las operaciones lineales básicas antes de pasar por la función de activación.</p>
<p>La forma básica del cálculo forward es la siguiente.</p>
<p><span class="math display">\[\boldsymbol y = \boldsymbol x \boldsymbol W + \boldsymbol b\]</span></p>
<p>Aquí, <span class="math inline">\(\boldsymbol x\)</span> es la entrada, <span class="math inline">\(\boldsymbol W\)</span> son los pesos, <span class="math inline">\(\boldsymbol b\)</span> es el sesgo, y <span class="math inline">\(\boldsymbol y\)</span> es la salida. En las matemáticas de las redes neuronales, las entradas y salidas a menudo se representan como vectores, mientras que los pesos se representan como matrices. El sesgo (<span class="math inline">\(\boldsymbol b\)</span>) puede representarse a veces como un valor escalar, pero técnicamente debe ser un vector del mismo tamaño que la salida.</p>
<p><strong>Matrices y transformaciones lineales</strong></p>
<p>Las matrices son una herramienta poderosa para representar transformaciones lineales. Una transformación lineal es un proceso que mapea un punto en el espacio de vectores a otro punto, lo cual se puede ver como una deformación del espacio completo. Para comprender este concepto visualmente, recomiendo el video “Linear transformations and matrices” de 3Blue1Brown[1]. Este video explica de manera intuitiva los conceptos básicos del álgebra lineal y muestra claramente cómo las matrices deforman el espacio.</p>
<p>Cuando la entrada de datos <span class="math inline">\(\boldsymbol x\)</span> se representa como un vector, esto significa un solo punto de datos y la longitud del vector es igual al número de características. Sin embargo, en el proceso de entrenamiento real, generalmente se procesan múltiples datos a la vez. En este caso, la entrada es una matriz <span class="math inline">\(\boldsymbol X\)</span> de forma (n, m), donde n es el número de datos y m es el número de características.</p>
<p>En modelos de deep learning reales, los datos de entrada pueden tener formas tensoriales de más alta dimensión que las matrices bidimensionales.</p>
<ul>
<li>Datos de imágenes: un tensor de 4 dimensiones con la forma (tamaño del lote, altura, anchura, canales)</li>
<li>Datos de video: un tensor de 5 dimensiones con la forma (tamaño del lote, número de frames, altura, anchura, canales)</li>
</ul>
<p>Las redes neuronales utilizan varias formas de transformaciones lineales y no lineales para procesar estos datos de alta dimensión. El proceso de retropropagación en las transformaciones lineales implica calcular los gradientes y pasarlos hacia atrás a través de cada capa para actualizar los parámetros. Aunque este proceso puede ser complejo, se realiza eficientemente con herramientas de diferenciación automática. Aunque la transformación lineal es un componente fundamental de los modelos de deep learning, el rendimiento real de estos modelos se obtiene a través de la combinación con funciones de activación no lineales. En la próxima sección, examinaremos cómo esta no linealidad aumenta la capacidad de representación del modelo.</p>
<div id="cell-10" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># if in Colab, plase don't run this and below code. just see the result video bleow the following cell.</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="co">#from manim import *  </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="cell-11" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>manim <span class="op">-</span>qh <span class="op">-</span>v WARNING LinearTransformations  </span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> manim <span class="im">import</span> <span class="op">*</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> manim <span class="im">import</span> config</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LinearTransformations(ThreeDScene):</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> construct(<span class="va">self</span>):</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.set_camera_orientation(phi<span class="op">=</span><span class="dv">75</span> <span class="op">*</span> DEGREES, theta<span class="op">=-</span><span class="dv">45</span> <span class="op">*</span> DEGREES)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>        axes <span class="op">=</span> ThreeDAxes(x_range<span class="op">=</span>[<span class="op">-</span><span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">1</span>], y_range<span class="op">=</span>[<span class="op">-</span><span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">1</span>], z_range<span class="op">=</span>[<span class="op">-</span><span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">1</span>], x_length<span class="op">=</span><span class="dv">10</span>, y_length<span class="op">=</span><span class="dv">10</span>, z_length<span class="op">=</span><span class="dv">10</span>).set_color(GRAY)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.add(axes)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># --- 3D Linear Transformation (Rotation and Shear) ---</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>        title <span class="op">=</span> Text(<span class="st">"3D Linear Transformations"</span>, color<span class="op">=</span>BLACK).to_edge(UP)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.play(Write(title))</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.wait(<span class="dv">1</span>)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 1. Rotation around Z-axis</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>        text_rotation <span class="op">=</span> Text(<span class="st">"Rotation around Z-axis"</span>, color<span class="op">=</span>BLUE).scale(<span class="fl">0.7</span>).next_to(title, DOWN, buff<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.play(Write(text_rotation))</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>        cube <span class="op">=</span> Cube(side_length<span class="op">=</span><span class="dv">2</span>, fill_color<span class="op">=</span>BLUE, fill_opacity<span class="op">=</span><span class="fl">0.5</span>, stroke_color<span class="op">=</span>WHITE, stroke_width<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.play(Create(cube))</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.play(Rotate(cube, angle<span class="op">=</span>PI<span class="op">/</span><span class="dv">2</span>, axis<span class="op">=</span>OUT, about_point<span class="op">=</span>ORIGIN), run_time<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.wait(<span class="dv">1</span>)</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.play(FadeOut(text_rotation))</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 2. Shear</span></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>        text_shear <span class="op">=</span> Text(<span class="st">"Shear Transformation"</span>, color<span class="op">=</span>GREEN).scale(<span class="fl">0.7</span>).next_to(title, DOWN, buff<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.play(Write(text_shear))</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Define the shear transformation matrix.  This shears in x relative to y, and in y relative to x.</span></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>        shear_matrix <span class="op">=</span> np.array([</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>            [<span class="dv">1</span>, <span class="fl">0.5</span>, <span class="dv">0</span>],</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>            [<span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">0</span>],</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>            [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>]</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.play(</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>            cube.animate.apply_matrix(shear_matrix),</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>            run_time<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.wait(<span class="dv">1</span>)</span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add transformed axes to visualize the shear</span></span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>        transformed_axes <span class="op">=</span> axes.copy().apply_matrix(shear_matrix)</span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.play(Create(transformed_axes), run_time<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.wait(<span class="dv">1</span>)</span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.play(FadeOut(cube), FadeOut(transformed_axes), FadeOut(text_shear))</span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>        <span class="co"># --- 2D to 3D Transformation (Paraboloid) ---</span></span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>        text_2d_to_3d <span class="op">=</span> Text(<span class="st">"2D to 3D: Paraboloid"</span>, color<span class="op">=</span>MAROON).scale(<span class="fl">0.7</span>).next_to(title, DOWN, buff<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.play(Write(text_2d_to_3d))</span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a>        square <span class="op">=</span> Square(side_length<span class="op">=</span><span class="dv">4</span>, fill_color<span class="op">=</span>MAROON, fill_opacity<span class="op">=</span><span class="fl">0.5</span>, stroke_color<span class="op">=</span>WHITE, stroke_width<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.play(Create(square))</span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a>        <span class="kw">def</span> paraboloid(point):  <span class="co"># Function for the transformation</span></span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a>            x, y, _ <span class="op">=</span> point</span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> [x, y, <span class="fl">0.2</span> <span class="op">*</span> (x<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> y<span class="op">**</span><span class="dv">2</span>)]  <span class="co"># Adjust scaling factor (0.2) as needed</span></span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a>        paraboloid_surface <span class="op">=</span> always_redraw(<span class="kw">lambda</span>: Surface(</span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a>            <span class="kw">lambda</span> u, v: axes.c2p(<span class="op">*</span>paraboloid(axes.p2c(np.array([u,v,<span class="dv">0</span>])))),</span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a>            u_range<span class="op">=</span>[<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>],</span>
<span id="cb5-63"><a href="#cb5-63" aria-hidden="true" tabindex="-1"></a>            v_range<span class="op">=</span>[<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>],</span>
<span id="cb5-64"><a href="#cb5-64" aria-hidden="true" tabindex="-1"></a>            resolution<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">15</span>), <span class="co"># Added for smoothness</span></span>
<span id="cb5-65"><a href="#cb5-65" aria-hidden="true" tabindex="-1"></a>            fill_color<span class="op">=</span>MAROON,</span>
<span id="cb5-66"><a href="#cb5-66" aria-hidden="true" tabindex="-1"></a>            fill_opacity<span class="op">=</span><span class="fl">0.7</span>,</span>
<span id="cb5-67"><a href="#cb5-67" aria-hidden="true" tabindex="-1"></a>            stroke_color<span class="op">=</span>WHITE,</span>
<span id="cb5-68"><a href="#cb5-68" aria-hidden="true" tabindex="-1"></a>            stroke_width<span class="op">=</span><span class="fl">0.5</span></span>
<span id="cb5-69"><a href="#cb5-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-70"><a href="#cb5-70" aria-hidden="true" tabindex="-1"></a>        ).set_shade_in_3d(<span class="va">True</span>))</span>
<span id="cb5-71"><a href="#cb5-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-72"><a href="#cb5-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-73"><a href="#cb5-73" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.play(</span>
<span id="cb5-74"><a href="#cb5-74" aria-hidden="true" tabindex="-1"></a>            Transform(square, paraboloid_surface),</span>
<span id="cb5-75"><a href="#cb5-75" aria-hidden="true" tabindex="-1"></a>            run_time<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb5-76"><a href="#cb5-76" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb5-77"><a href="#cb5-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-78"><a href="#cb5-78" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.wait(<span class="dv">2</span>)</span>
<span id="cb5-79"><a href="#cb5-79" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.play(FadeOut(square), FadeOut(text_2d_to_3d))</span>
<span id="cb5-80"><a href="#cb5-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-81"><a href="#cb5-81" aria-hidden="true" tabindex="-1"></a>        <span class="co"># --- 3D to 2D Transformation (Projection) ---</span></span>
<span id="cb5-82"><a href="#cb5-82" aria-hidden="true" tabindex="-1"></a>        text_3d_to_2d <span class="op">=</span> Text(<span class="st">"3D to 2D: Projection"</span>, color<span class="op">=</span>PURPLE).scale(<span class="fl">0.7</span>).next_to(title, DOWN, buff<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb5-83"><a href="#cb5-83" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.play(Write(text_3d_to_2d))</span>
<span id="cb5-84"><a href="#cb5-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-85"><a href="#cb5-85" aria-hidden="true" tabindex="-1"></a>        sphere <span class="op">=</span> Sphere(radius<span class="op">=</span><span class="fl">1.5</span>, fill_color<span class="op">=</span>PURPLE, fill_opacity<span class="op">=</span><span class="fl">0.7</span>, stroke_color<span class="op">=</span>WHITE, stroke_width<span class="op">=</span><span class="dv">1</span>, resolution<span class="op">=</span>(<span class="dv">20</span>,<span class="dv">20</span>)).set_shade_in_3d(<span class="va">True</span>)</span>
<span id="cb5-86"><a href="#cb5-86" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.play(Create(sphere))</span>
<span id="cb5-87"><a href="#cb5-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-88"><a href="#cb5-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-89"><a href="#cb5-89" aria-hidden="true" tabindex="-1"></a>        <span class="kw">def</span> project_to_2d(mob, alpha):</span>
<span id="cb5-90"><a href="#cb5-90" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> p <span class="kw">in</span> mob.points:</span>
<span id="cb5-91"><a href="#cb5-91" aria-hidden="true" tabindex="-1"></a>                p[<span class="dv">2</span>] <span class="op">*=</span> (<span class="dv">1</span><span class="op">-</span>alpha)</span>
<span id="cb5-92"><a href="#cb5-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-93"><a href="#cb5-93" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.play(</span>
<span id="cb5-94"><a href="#cb5-94" aria-hidden="true" tabindex="-1"></a>            UpdateFromAlphaFunc(sphere, project_to_2d),</span>
<span id="cb5-95"><a href="#cb5-95" aria-hidden="true" tabindex="-1"></a>            run_time<span class="op">=</span><span class="dv">2</span></span>
<span id="cb5-96"><a href="#cb5-96" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb5-97"><a href="#cb5-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-98"><a href="#cb5-98" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.wait(<span class="dv">1</span>)</span>
<span id="cb5-99"><a href="#cb5-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-100"><a href="#cb5-100" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Show a circle representing the final projection </span></span>
<span id="cb5-101"><a href="#cb5-101" aria-hidden="true" tabindex="-1"></a>        circle <span class="op">=</span> Circle(radius<span class="op">=</span><span class="fl">1.5</span>, color<span class="op">=</span>PURPLE, fill_opacity<span class="op">=</span><span class="fl">0.7</span>, stroke_color <span class="op">=</span> WHITE, stroke_width<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb5-102"><a href="#cb5-102" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.add(circle)</span>
<span id="cb5-103"><a href="#cb5-103" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.wait(<span class="dv">1</span>)</span>
<span id="cb5-104"><a href="#cb5-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-105"><a href="#cb5-105" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.play(FadeOut(sphere), FadeOut(text_3d_to_2d), FadeOut(circle), FadeOut(title))</span>
<span id="cb5-106"><a href="#cb5-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-107"><a href="#cb5-107" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.wait(<span class="dv">1</span>)</span>
<span id="cb5-108"><a href="#cb5-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-109"><a href="#cb5-109" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> logging</span>
<span id="cb5-110"><a href="#cb5-110" aria-hidden="true" tabindex="-1"></a>logging.getLogger(<span class="st">"manim"</span>).setLevel(logging.WARNING)</span>
<span id="cb5-111"><a href="#cb5-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-112"><a href="#cb5-112" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">"__main__"</span>:</span>
<span id="cb5-113"><a href="#cb5-113" aria-hidden="true" tabindex="-1"></a>    config.video_dir <span class="op">=</span> <span class="st">"./"</span></span>
<span id="cb5-114"><a href="#cb5-114" aria-hidden="true" tabindex="-1"></a>    scene <span class="op">=</span> LinearTransformations()</span>
<span id="cb5-115"><a href="#cb5-115" aria-hidden="true" tabindex="-1"></a>    scene.render()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<video width="640" height="480" controls="">
<source src="../../../assets/videos/LinearTransformations.mp4" type="video/mp4">
<p>Su navegador no soporta la etiqueta de video. </p>
<p>Las transformaciones lineales son funciones que mapean un espacio vectorial a otro mientras preservan su estructura. Estas transformaciones pueden representarse mediante operaciones matriciales, lo cual es fundamental en el aprendizaje profundo. La animación anterior visualiza una transformación lineal.</p>
<p>La comprensión de las transformaciones lineales es crucial para entender cómo funcionan las redes neuronales. Por ejemplo, un modelo sobreajustado puede distorsionar excesivamente el espacio de entrada, mientras que un modelo bien generalizado puede realizar una transformación más suave. La intuición geométrica puede ser muy útil al diseñar y optimizar modelos de aprendizaje profundo.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Haga clic para ver el contenido (deep dive: definición rigurosa de las transformaciones lineales y propiedades adicionales)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Haga clic para ver el contenido (deep dive: definición rigurosa de las transformaciones lineales y propiedades adicionales)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<section id="definición-rigurosa-de-transformación-lineal-y-propiedades-adicionales" class="level3 callout-body-container callout-body">
<h3 class="anchored" data-anchor-id="definición-rigurosa-de-transformación-lineal-y-propiedades-adicionales">Definición rigurosa de transformación lineal y propiedades adicionales</h3>
<p>La transformación lineal es una función entre espacios vectoriales que preserva la estructura lineal del espacio vectorial (suma y multiplicación escalar). En el aprendizaje profundo, la capa fully connected es un ejemplo típico de transformación lineal.</p>
<section id="definición-rigurosa-de-transformación-lineal" class="level4">
<h4 class="anchored" data-anchor-id="definición-rigurosa-de-transformación-lineal">Definición rigurosa de transformación lineal</h4>
<p>Si <span class="math inline">\(V\)</span> y <span class="math inline">\(W\)</span> son espacios vectoriales, una función <span class="math inline">\(T: V \to W\)</span> se llama <em>transformación lineal</em> si satisface las siguientes dos condiciones:</p>
<ol type="1">
<li><strong>Preservación de la suma:</strong> Para cualquier <span class="math inline">\(\mathbf{u}, \mathbf{v} \in V\)</span>, <span class="math inline">\(T(\mathbf{u} + \mathbf{v}) = T(\mathbf{u}) + T(\mathbf{v})\)</span></li>
<li><strong>Preservación del producto escalar:</strong> Para cualquier <span class="math inline">\(\mathbf{u} \in V\)</span> y escalar <span class="math inline">\(c\)</span>, <span class="math inline">\(T(c\mathbf{u}) = cT(\mathbf{u})\)</span></li>
</ol>
<p>Solo las funciones que cumplen estas dos condiciones se pueden llamar transformaciones lineales.</p>
</section>
<section id="ejemplo-de-transformación-lineal-en-el-aprendizaje-profundo-capa-fully-connected" class="level4">
<h4 class="anchored" data-anchor-id="ejemplo-de-transformación-lineal-en-el-aprendizaje-profundo-capa-fully-connected">Ejemplo de transformación lineal en el aprendizaje profundo: Capa Fully Connected</h4>
<p>La capa fully connected (capa densa) del aprendizaje profundo es un ejemplo típico de transformación lineal. Para un vector de entrada <span class="math inline">\(\mathbf{x} \in \mathbb{R}^m\)</span>, una matriz de pesos <span class="math inline">\(\mathbf{W} \in \mathbb{R}^{n \times m}\)</span> y un vector de sesgo <span class="math inline">\(\mathbf{b} \in \mathbb{R}^n\)</span>, la operación de la capa fully connected se expresa como sigue:</p>
<p><span class="math inline">\(\mathbf{y} = \mathbf{W}\mathbf{x} + \mathbf{b}\)</span></p>
<p>Aquí, <span class="math inline">\(\mathbf{y} \in \mathbb{R}^n\)</span> es el vector de salida. La parte <span class="math inline">\(\mathbf{W}\mathbf{x}\)</span> corresponde a la transformación lineal y <span class="math inline">\(\mathbf{b}\)</span> representa la traslación (translation) para una transformación afín. (Estrictamente, con el sesgo incluido se llama <em>transformación afín</em>, pero en el aprendizaje profundo se suele llamar <em>transformación lineal</em>).</p>
</section>
<section id="núcleo-kernel-y-recorrido-range" class="level4">
<h4 class="anchored" data-anchor-id="núcleo-kernel-y-recorrido-range">Núcleo (Kernel) y Recorrido (Range)</h4>
<p>Para la transformación lineal <span class="math inline">\(T: V \to W\)</span>,</p>
<ul>
<li><strong>Núcleo (Kernel, o espacio nulo Null Space):</strong> El conjunto de todos los vectores en <span class="math inline">\(V\)</span> que se mapean a <span class="math inline">\(\mathbf{0}_W\)</span> (el vector cero en <span class="math inline">\(W\)</span>).
<ul>
<li><span class="math inline">\(\text{ker}(T) = \{\mathbf{v} \in V | T(\mathbf{v}) = \mathbf{0}_W \}\)</span></li>
<li><span class="math inline">\(\text{ker}(T)\)</span> es un subespacio de <span class="math inline">\(V\)</span>.</li>
</ul></li>
<li><strong>Recorrido (Range, o imagen Image):</strong> El subconjunto de <span class="math inline">\(W\)</span> al que se mapean todos los vectores en <span class="math inline">\(V\)</span> por medio de <span class="math inline">\(T\)</span>.
<ul>
<li><span class="math inline">\(\text{range}(T) = \{T(\mathbf{v}) | \mathbf{v} \in V \}\)</span></li>
<li><span class="math inline">\(\text{range}(T)\)</span> es un subespacio de <span class="math inline">\(W\)</span>.</li>
</ul></li>
</ul>
</section>
<section id="teorema-del-rango-y-la-nulidad-rank-nullity-theorem" class="level4">
<h4 class="anchored" data-anchor-id="teorema-del-rango-y-la-nulidad-rank-nullity-theorem">Teorema del rango y la nulidad (Rank-Nullity Theorem)</h4>
<p>Para una transformación lineal <span class="math inline">\(T: V \to W\)</span>, si <span class="math inline">\(V\)</span> es un espacio vectorial de dimensión finita, entonces se cumple lo siguiente:</p>
<p><span class="math inline">\(\text{dim}(\text{ker}(T)) + \text{dim}(\text{range}(T)) = \text{dim}(V)\)</span></p>
<ul>
<li><span class="math inline">\(\text{dim}(\text{ker}(T))\)</span>: la <em>nulidad</em> de <span class="math inline">\(T\)</span></li>
<li><span class="math inline">\(\text{dim}(\text{range}(T))\)</span>: el <em>rango</em> de <span class="math inline">\(T\)</span></li>
</ul>
<p>Es decir, la dimensión del espacio de entrada es igual a la suma de la dimensión del núcleo (nulidad) y la dimensión del recorrido (rango).</p>
</section>
<section id="representación-matricial-de-transformación-lineal-matrix-representation" class="level4">
<h4 class="anchored" data-anchor-id="representación-matricial-de-transformación-lineal-matrix-representation">Representación matricial de transformación lineal (Matrix Representation)</h4>
<p>La transformación lineal entre espacios vectoriales de dimensión finita siempre se puede expresar mediante una matriz. Si tomamos la base (basis) de <span class="math inline">\(V\)</span> como {<span class="math inline">\(\mathbf{v}_1, \mathbf{v}_2, ..., \mathbf{v}_m\)</span>} y la base de <span class="math inline">\(W\)</span> como {<span class="math inline">\(\mathbf{w}_1, \mathbf{w}_2, ..., \mathbf{w}_n\)</span>}, entonces la transformación lineal <span class="math inline">\(T: V \to W\)</span> se puede expresar mediante una matriz <span class="math inline">\(\mathbf{A}\)</span> de tamaño <span class="math inline">\(n \times m\)</span> de la siguiente manera:</p>
<p><span class="math inline">\(T(\mathbf{v}_j) = \sum_{i=1}^{n} a_{ij}\mathbf{w}_i\)</span> (para <span class="math inline">\(j = 1, 2, ..., m\)</span>)</p>
<p>Aquí, <span class="math inline">\(a_{ij}\)</span> es el elemento en la fila <span class="math inline">\(i\)</span> y columna <span class="math inline">\(j\)</span> de la matriz <span class="math inline">\(\mathbf{A}\)</span>. Es decir, la <span class="math inline">\(j\)</span>-ésima columna de la matriz <span class="math inline">\(\mathbf{A}\)</span> contiene los coeficientes cuando se expresa <span class="math inline">\(T(\mathbf{v}_j)\)</span> en términos de la base de <span class="math inline">\(W\)</span>.</p>
<p>Si un vector <span class="math inline">\(\mathbf{v} \in V\)</span> se expresa como una combinación lineal de la base {<span class="math inline">\(\mathbf{v}_1, \mathbf{v}_2, ..., \mathbf{v}_m\)</span>}, entonces <span class="math inline">\(\mathbf{v} = c_1\mathbf{v}_1 + c_2\mathbf{v}_2 + ... + c_m\mathbf{v}_m\)</span>, y las coordenadas de este vector se pueden representar como el vector columna <span class="math inline">\(\begin{bmatrix} c_1 \\ c_2 \\ \vdots \\ c_m \end{bmatrix}\)</span>. Entonces,</p>
<p><span class="math inline">\(T(\mathbf{v}) = \mathbf{A} \begin{bmatrix} c_1 \\ c_2 \\ \vdots \\ c_m \end{bmatrix}\)</span></p>
<p><strong>Representación matricial en el deep learning:</strong> La operación de la capa fully connected <span class="math inline">\(\mathbf{y} = \mathbf{W}\mathbf{x}\)</span> en el deep learning coincide exactamente con la representación matricial de una transformación lineal.</p>
</section>
</section>
</div>
</div>
</video></section>
<section id="operaciones-de-tensores" class="level3">
<h3 class="anchored" data-anchor-id="operaciones-de-tensores">2.1.4 Operaciones de tensores</h3>
<blockquote class="blockquote">
<p><strong>Desafío:</strong> ¿Cómo se pueden expresar y operar eficientemente los datos multidimensionales?</p>
<p><strong>Lucha del investigador:</strong> Al principio del aprendizaje profundo, los investigadores tuvieron que manejar diferentes tipos de datos, como imágenes, texto, audio, entre otros. Estos datos eran difíciles de representar con vectores o matrices simples y se necesitaba un método para procesar eficazmente estructuras de datos complejas. Además, era una tarea importante encontrar formas eficientes de procesar rápidamente grandes volúmenes de datos.</p>
</blockquote>
<p>Los tensores son los objetos matemáticos básicos utilizados en el aprendizaje profundo para representar datos y parámetros del modelo. Son un concepto generalizado que incluye escalares, vectores y matrices, y pueden pensarse como arreglos multidimensionales. Los tensores se clasifican según su dimensión (dimensión, rango) de la siguiente manera:</p>
<ul>
<li>0D tensor: escalar (ejemplo: 3.14)</li>
<li>1D tensor: vector (ejemplo: [1, 2, 3])</li>
<li>2D tensor: matriz (ejemplo: [[1, 2], [3, 4]])</li>
<li>3D o más: tensores de alta dimensión</li>
</ul>
<p>En el aprendizaje profundo, se manejan principalmente los siguientes tipos de tensores:</p>
<ul>
<li><strong>Datos de entrada:</strong>
<ul>
<li><strong>General:</strong> (tamaño del lote, número de características)</li>
<li><strong>Secuencia/texto:</strong> (tamaño del lote, longitud de la secuencia, número de características/dimensión de incrustación)</li>
<li><strong>Imagenes:</strong> (tamaño del lote, altura, ancho, canales)</li>
</ul></li>
<li><strong>Pesos (Weights):</strong>
<ul>
<li><strong>Conexiones completas (Fully-connected):</strong> (número de características de entrada, número de características de salida)</li>
<li><strong>Convolutivas (Convolutional):</strong> (número de canales de salida, número de canales de entrada, altura del kernel, ancho del kernel)</li>
</ul></li>
<li><strong>Datos de salida (Output/Prediction):</strong>
<ul>
<li><strong>Clasificación (Classification):</strong> (tamaño del lote, número de clases)</li>
<li><strong>Regresión (Regression):</strong> (tamaño del lote, dimensión de salida)</li>
</ul></li>
<li><strong>Sesgo (Bias):</strong>
<ul>
<li><strong>Conexiones completas:</strong> (número de características de salida,)</li>
<li><strong>Convolutivas:</strong> (número de canales de salida,)</li>
</ul></li>
<li><strong>Mapas de características (salida de capas convolucionales):</strong> (tamaño del lote, número de canales de salida, altura, ancho)</li>
</ul>
<p>La transformación lineal básica en una red neuronal es la siguiente.</p>
<p><span class="math inline">\(y_j = \sum\limits_{i} x_i w_{ij} + b_j\)</span></p>
<p>Aquí, <span class="math inline">\(i\)</span> es el índice de entrada y <span class="math inline">\(j\)</span> es el índice de salida. Esto se puede expresar en forma de vector y matriz de la siguiente manera.</p>
<p><span class="math inline">\(\boldsymbol x = \begin{bmatrix}x_{1} &amp; x_{2} &amp; \cdots &amp; x_{i} \end{bmatrix}\)</span></p>
<p><span class="math inline">\(\boldsymbol W = \begin{bmatrix}
w_{11} &amp; \cdots &amp; w_{1j} \
\vdots &amp; \ddots &amp; \vdots \
w_{i1} &amp; \cdots &amp; w_{ij}
\end{bmatrix}\)</span></p>
<p><span class="math inline">\(\boldsymbol y = \boldsymbol x \boldsymbol W + \boldsymbol b\)</span></p>
<p>Las principales características de las operaciones de tensores son:</p>
<ol type="1">
<li><p>Broadcasting: Permite realizar operaciones entre tensores de diferentes tamaños.</p></li>
<li><p>Reducción de dimensiones: Se pueden reducir dimensiones específicas de un tensor usando operaciones como sum(), mean(), etc.</p></li>
<li><p>Reshape (reformado): Permite cambiar la forma del tensor para convertirlo en un tensor de otras dimensiones.</p></li>
</ol>
<p>Una de las operaciones más importantes en el aprendizaje de redes neuronales es el cálculo de gradientes. Los principales cálculos de gradientes son:</p>
<ol type="1">
<li><p>Gradiente con respecto a la entrada: <span class="math inline">\(\frac{\partial \boldsymbol y}{\partial \boldsymbol{x}}\)</span></p></li>
<li><p>Gradiente con respecto a los pesos: <span class="math inline">\(\frac{\partial \boldsymbol y}{\partial \boldsymbol W}\)</span></p></li>
</ol>
<p>Estos gradientes representan el cambio en la salida debido al cambio en las entradas y los pesos, respectivamente, y son fundamentales para el algoritmo de retropropagación. Las operaciones de tensor son fundamentales en el aprendizaje profundo moderno, y permiten un procesamiento paralelo avanzado mediante el uso de GPU, facilitando así el entrenamiento eficiente y la inferencia de modelos a gran escala. Además, la diferenciación automática (automatic differentiation) de las operaciones de tensor posibilita cálculos de gradiente eficientes, convirtiéndose en un punto de inflexión crucial en la investigación moderna de aprendizaje profundo. Esto va más allá de simples cálculos numéricos y transforma la estructura del modelo y el propio proceso de aprendizaje en objetos programables. Veremos ejemplos prácticos de operaciones de tensor en el Capítulo 3 sobre PyTorch.</p>
<ol type="1">
<li><strong>Centrado de datos (Data Centering):</strong> Se asegura de que la media de cada característica (feature) sea 0.</li>
<li><strong>Cálculo de la matriz de covarianza:</strong> Se calcula la matriz de covarianza, que representa las correlaciones entre las características.</li>
<li><strong>Descomposición en valores propios:</strong> Se calculan los valores propios (eigenvalue) y vectores propios (eigenvector) de la matriz de covarianza.
<ul>
<li>Vectores propios: dirección de los componentes principales</li>
<li>Valores propios: magnitud de la varianza en la dirección del componente principal correspondiente</li>
</ul></li>
<li><strong>Selección de componentes principales:</strong> Se seleccionan <span class="math inline">\(k\)</span> vectores propios, comenzando desde el que tiene el mayor valor propio. (reducción a un espacio de <span class="math inline">\(k\)</span> dimensiones)</li>
<li><strong>Proyección de datos:</strong> Los datos se proyectan sobre los <span class="math inline">\(k\)</span> componentes principales seleccionados para reducir la dimensionalidad.</li>
</ol>
<p><strong>Uso en el aprendizaje profundo:</strong></p>
<ul>
<li><strong>Preprocesamiento de datos:</strong> Al proyectar datos de alta dimensión, como imágenes o texto, a un espacio de baja dimensión y usarlos como entrada para modelos de aprendizaje profundo, se puede reducir el costo computacional y prevenir el sobreajuste. En particular, al representar imágenes de alta resolución en dimensiones más bajas mediante PCA, se puede aumentar la velocidad de entrenamiento del modelo.</li>
<li><strong>Extracción de características:</strong> Los componentes principales extraídos a través de PCA pueden interpretarse como nuevas características (features) que son independientes entre sí y preservan la máxima varianza en los datos.</li>
</ul>
<p><strong>SVD vs.&nbsp;PCA</strong></p>
<ul>
<li>SVD es una técnica de <em>descomposición de matrices</em>, mientras que PCA es una técnica de <em>reducción de dimensionalidad</em> de los datos.</li>
<li>PCA puede implementarse utilizando SVD (la descomposición en valores singulares de la matriz de datos está relacionada con la descomposición en valores propios de la matriz de covarianza).</li>
<li>PCA requiere un preprocesamiento para ajustar la media de los datos a 0, mientras que SVD puede aplicarse directamente sin este proceso.</li>
</ul>
<p>SVD y PCA son herramientas matemáticas importantes que juegan un papel crucial en el aprendizaje profundo para representar eficientemente los datos y mejorar el rendimiento del modelo.</p>
<div id="cell-16" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_02.pca <span class="im">import</span> visualize_pca</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>visualize_pca()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="02_Matemáticas de deep learning_files/figure-html/cell-6-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Explained variance ratio: 0.5705</code></pre>
</div>
</div>
<p>Este ejemplo muestra la capacidad de PCA para proyectar estructuras 2D complejas a una dimensión. En el caso de datos espirales, un solo componente principal no puede capturar toda la variabilidad, pero puede capturar la tendencia principal de los datos. A través de la proporción de varianza explicada, se puede evaluar qué tan bien esta representación unidimensional preserva la estructura de los datos originales.</p>
<p>Estas técnicas son herramientas poderosas para extraer patrones importantes de datos complejos.</p>
<ol type="1">
<li>Preprocesamiento de datos: reducción de dimensionalidad de los datos de entrada</li>
<li>Compresión del modelo: aproximación eficiente de la matriz de pesos</li>
<li>Extracción de características: identificación y selección de características importantes</li>
</ol>
<p>SVD y PCA son herramientas poderosas para extraer patrones importantes de datos de alta dimensión y simplificar estructuras de datos complejas.</p>
</section>
</section>
<section id="cálculo-y-optimización" class="level2">
<h2 class="anchored" data-anchor-id="cálculo-y-optimización">2.2 Cálculo y optimización</h2>
<section id="regla-de-la-cadena" class="level3">
<h3 class="anchored" data-anchor-id="regla-de-la-cadena">2.2.1 Regla de la cadena</h3>
<blockquote class="blockquote">
<p><strong>Desafío:</strong> ¿Cómo se pueden calcular eficientemente las derivadas de funciones complejas y anidadas?</p>
<p><strong>Dilema del investigador:</strong> Los primeros investigadores en aprendizaje profundo tenían que utilizar el algoritmo de retropropagación para actualizar los pesos de las redes neuronales. Sin embargo, las redes neuronales son estructuras en las que varias capas de funciones están conectadas de manera compleja, por lo que calcular la derivada de la función de pérdida con respecto a cada peso era un problema muy difícil. En particular, a medida que aumentaba el número de capas, la cantidad de cálculos crecía exponencialmente, haciendo que el aprendizaje fuera ineficiente.</p>
</blockquote>
<p>La regla de la cadena es una de las reglas de cálculo más importantes utilizadas en el aprendizaje profundo. La regla de la cadena es una regla poderosa y elegante que permite expresar la derivada de una función compuesta como el producto de las derivadas de las funciones componentes. Visualizar la regla de la cadena puede facilitar la comprensión del concepto. Por ejemplo, supongamos que <span class="math inline">\(z\)</span> es una función de <span class="math inline">\(x\)</span> y <span class="math inline">\(y\)</span>, y que <span class="math inline">\(x\)</span> y <span class="math inline">\(y\)</span> son a su vez funciones de <span class="math inline">\(s\)</span> y <span class="math inline">\(t\)</span>. Esta relación se puede representar mediante un diagrama de árbol.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../../assets/images/02_01.chain_rule.png" class="img-fluid figure-img"></p>
<figcaption>Regla de la cadena</figcaption>
</figure>
</div>
<p>En este diagrama, la derivada parcial de <span class="math inline">\(z\)</span> con respecto a <span class="math inline">\(s\)</span>, <span class="math inline">\(\frac{\partial z}{\partial s}\)</span>, es igual a la suma de los productos de las derivadas parciales a lo largo de todas las rutas desde <span class="math inline">\(z\)</span> hasta <span class="math inline">\(s\)</span>.</p>
<p><span class="math inline">\(\frac{\partial z}{\partial s} = \frac{\partial z}{\partial x} \frac{\partial x}{\partial s} + \frac{\partial z}{\partial y} \frac{\partial y}{\partial s}\)</span></p>
<p>En esta fórmula,</p>
<ul>
<li><span class="math inline">\(\frac{\partial z}{\partial x}\)</span> y <span class="math inline">\(\frac{\partial z}{\partial y}\)</span> representan cómo <span class="math inline">\(z\)</span> cambia con respecto a <span class="math inline">\(x\)</span> y <span class="math inline">\(y\)</span>, respectivamente.</li>
<li><span class="math inline">\(\frac{\partial x}{\partial s}\)</span> y <span class="math inline">\(\frac{\partial y}{\partial s}\)</span> representan cómo <span class="math inline">\(x\)</span> y <span class="math inline">\(y\)</span> cambian con respecto a <span class="math inline">\(s\)</span>, respectivamente.</li>
</ul>
<p>Consideremos otro caso donde la regla de la cadena se utiliza para expresar una diferencial total. Consideremos el caso en que <span class="math inline">\(z\)</span> es una función de variables independientes. En este caso, la regla de la cadena se simplifica a la forma de una diferencial total. Por ejemplo, si <span class="math inline">\(z = f(x, y)\)</span> con <span class="math inline">\(x = g(s)\)</span> y <span class="math inline">\(y = h(t)\)</span>, y si <span class="math inline">\(s\)</span> y <span class="math inline">\(t\)</span> son independientes entre sí, entonces la diferencial total de <span class="math inline">\(z\)</span> se puede expresar como sigue.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../../assets/images/02_02_chain_rule.png" class="img-fluid figure-img"></p>
<figcaption>Regla de la cadena</figcaption>
</figure>
</div>
<p><span class="math inline">\(dz = \frac{\partial z}{\partial x}dx + \frac{\partial z}{\partial y}dy\)</span></p>
<p>Aquí, <span class="math inline">\(dx = \frac{\partial x}{\partial s}ds\)</span> y <span class="math inline">\(dy = \frac{\partial y}{\partial t}dt\)</span>, por lo que finalmente se obtiene la siguiente forma.</p>
<p><span class="math inline">\(dz = \frac{\partial z}{\partial x}\frac{\partial x}{\partial s}ds + \frac{\partial z}{\partial y}\frac{\partial y}{\partial t}dt\)</span></p>
<p>Esta ecuación tiene una forma similar a la de la regla de la cadena, pero en realidad representa una diferencial total. Un punto importante aquí es que <span class="math inline">\(s\)</span> y <span class="math inline">\(t\)</span> son independientes, por lo que <span class="math inline">\(\frac{\partial x}{\partial t}\)</span> y <span class="math inline">\(\frac{\partial y}{\partial s}\)</span> son 0. Esta forma es una diferencial total. La diferencial total representa el impacto total del cambio en todas las variables independientes sobre el valor de la función, expresada como la suma de las derivadas parciales con respecto a cada variable. La estructura de la regla de la cadena permite descomponer la derivada de una función compleja en partes más simples. Esto es especialmente importante en el aprendizaje profundo, ya que las redes neuronales tienen una estructura compuesta por múltiples capas de funciones superpuestas. El uso de diagramas de árbol facilita la aplicación de la regla de la cadena incluso en situaciones más complejas. Se trata de encontrar todas las rutas desde la variable dependiente hasta las variables independientes a través de las variables intermedias, multiplicar las derivadas parciales a lo largo de cada ruta y sumar todos estos resultados.</p>
<p>La regla de la cadena es la base matemática del algoritmo de retropropagación en el aprendizaje profundo. Proporciona los fundamentos para actualizar eficientemente los pesos en modelos de redes neuronales complejas.</p>
</section>
<section id="gradiente-y-jacobiano" class="level3">
<h3 class="anchored">2.2.2 Gradiente y Jacobiano</h3>
<blockquote class="blockquote">
<p><strong>Desafío</strong>: ¿Cómo se pueden generalizar las derivadas para funciones con diferentes formas de entrada y salida?</p>
<p><strong>Reflexión del investigador</strong>: En sus inicios, el aprendizaje profundo se centró principalmente en funciones escalares, pero gradualmente comenzó a abordar funciones con entradas y salidas de diferentes formas, como vectores y matrices. Expresar y calcular las derivadas de estas funciones de manera uniforme fue una tarea esencial en el desarrollo de marcos de aprendizaje profundo.</p>
</blockquote>
<p>En el aprendizaje profundo se tratan funciones con diferentes formas de entrada (escalares, vectores, matrices, tensores) y salida (escalares, vectores, matrices, tensores). En consecuencia, la representación de las derivadas (o gradientes) de estas funciones también varía. La clave es expresar coherentemente las derivadas en estos diferentes casos y aplicar la regla de la cadena para calcularlas de manera eficiente.</p>
<section id="conceptos-clave" class="level4">
<h4 class="anchored" data-anchor-id="conceptos-clave">Conceptos clave</h4>
<ul>
<li><p><strong>Gradiente (Gradient):</strong> Expresión utilizada al diferenciar una función escalar con respecto a un vector. Es un vector columna que contiene las derivadas parciales de la función con respecto a cada elemento del vector de entrada. Indica la dirección de mayor ascenso de la función.</p></li>
<li><p><strong>Matriz Jacobiana (Jacobian Matrix):</strong> Expresión utilizada al diferenciar una función vectorial con respecto a un vector. Es una matriz que contiene las derivadas parciales de cada elemento del vector de salida con respecto a cada elemento del vector de entrada.</p></li>
</ul>
</section>
<section id="representación-de-derivadas-según-diferentes-formas-de-entrada-y-salida" class="level4">
<h4 class="anchored" data-anchor-id="representación-de-derivadas-según-diferentes-formas-de-entrada-y-salida">Representación de derivadas según diferentes formas de entrada y salida</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 14%">
<col style="width: 12%">
<col style="width: 57%">
<col style="width: 15%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Forma de entrada</th>
<th style="text-align: left;">Forma de salida</th>
<th style="text-align: left;">Representación de la derivada</th>
<th style="text-align: left;">Dimensiones</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Vector (<span class="math inline">\(\mathbf{x}\)</span>)</td>
<td style="text-align: left;">Vector (<span class="math inline">\(\mathbf{f}\)</span>)</td>
<td style="text-align: left;">Matriz Jacobiana (<span class="math inline">\(\mathbf{J} = \frac{\partial \mathbf{f}}{\partial \mathbf{x}}\)</span>)</td>
<td style="text-align: left;"><span class="math inline">\(n \times m\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Matriz (<span class="math inline">\(\mathbf{X}\)</span>)</td>
<td style="text-align: left;">Vector (<span class="math inline">\(\mathbf{f}\)</span>)</td>
<td style="text-align: left;">Tensor tridimensional (generalmente no se maneja bien)</td>
<td style="text-align: left;">-</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Vector (<span class="math inline">\(\mathbf{x}\)</span>)</td>
<td style="text-align: left;">Matriz (<span class="math inline">\(\mathbf{F}\)</span>)</td>
<td style="text-align: left;">Tensor tridimensional (generalmente no se maneja bien)</td>
<td style="text-align: left;">-</td>
</tr>
<tr class="even">
<td style="text-align: left;">Escalar (<span class="math inline">\(x\)</span>)</td>
<td style="text-align: left;">Vector (<span class="math inline">\(\mathbf{f}\)</span>)</td>
<td style="text-align: left;">Vector columna (<span class="math inline">\(\frac{\partial \mathbf{f}}{\partial x}\)</span>)</td>
<td style="text-align: left;"><span class="math inline">\(n \times 1\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Vector (<span class="math inline">\(\mathbf{x}\)</span>)</td>
<td style="text-align: left;">Escalar (<span class="math inline">\(f\)</span>)</td>
<td style="text-align: left;">Gradiente (<span class="math inline">\(\nabla f = \frac{\partial f}{\partial \mathbf{x}}\)</span>)</td>
<td style="text-align: left;"><span class="math inline">\(m \times 1\)</span> (vector columna)</td>
</tr>
<tr class="even">
<td style="text-align: left;">Matriz (<span class="math inline">\(\mathbf{X}\)</span>)</td>
<td style="text-align: left;">Escalar (<span class="math inline">\(f\)</span>)</td>
<td style="text-align: left;">Matriz (<span class="math inline">\(\frac{\partial f}{\partial \mathbf{X}}\)</span>)</td>
<td style="text-align: left;"><span class="math inline">\(m \times n\)</span></td>
</tr>
</tbody>
</table>
<p><strong>Referencia:</strong></p>
<ul>
<li><span class="math inline">\(m\)</span>: dimensiones del vector/matriz de entrada, <span class="math inline">\(n\)</span>: dimensiones del vector/matriz de salida, <span class="math inline">\(p, q\)</span>: número de filas/columnas de la matriz</li>
<li>En el caso de entradas matriciales y salidas vectoriales/matriciales, la derivada se convierte en un tensor tridimensional. Aunque los marcos de aprendizaje profundo manejan internamente estos cálculos de tensores de alta dimensión de manera eficiente, generalmente el cálculo de jacobianas y gradientes para entradas/salidas vectoriales/matriciales es lo más común.</li>
</ul>
</section>
<section id="aplicación-en-aprendizaje-profundo" class="level4">
<h4 class="anchored">Aplicación en Aprendizaje Profundo</h4>
<ul>
<li><strong>Algoritmo de Retropropagación:</strong> Las matrices jacobianas y los gradientes desempeñan un papel fundamental al implementar el algoritmo de retropropagación en aprendizaje profundo. Se aplica la regla de la cadena a través de cada capa de la red neuronal para calcular el gradiente de la función de pérdida con respecto a los pesos, y se utilizan estos gradientes para actualizar los pesos.</li>
<li><strong>Diferenciación Automática:</strong> Los marcos modernos de aprendizaje profundo (como TensorFlow, PyTorch, etc.) proporcionan funcionalidades de diferenciación automática (Automatic Differentiation) que manejan automáticamente estos cálculos complejos de derivadas. Los usuarios no necesitan implementar fórmulas de derivada complejas por sí mismos; solo deben definir la estructura del modelo y la función de pérdida.</li>
</ul>
<p>De esta manera, los conceptos de gradientes y matrices jacobianas son herramientas esenciales en el aprendizaje profundo para generalizar la diferenciación de funciones de varias formas y aprender modelos de manera eficiente a través de la retropropagación.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Haz clic para ver el contenido (deep dive: matriz Hessiana)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Haz clic para ver el contenido (deep dive: matriz Hessiana)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<section id="matriz-hessiana-hessian-matrix" class="level2 callout-body-container callout-body">
<h2 class="anchored" data-anchor-id="matriz-hessiana-hessian-matrix">Matriz Hessiana (Hessian Matrix)</h2>
<section id="definición-y-significado-de-la-matriz-hessiana" class="level3">
<h3 class="anchored" data-anchor-id="definición-y-significado-de-la-matriz-hessiana">1. Definición y significado de la matriz Hessiana</h3>
<ul>
<li><p><strong>Definición:</strong> La matriz Hessiana es una representación matricial de las derivadas parciales de segundo orden de una función escalar (scalar-valued function). Es decir, dada una función <span class="math inline">\(f(x_1, x_2, ..., x_n)\)</span>, la matriz Hessiana <span class="math inline">\(H\)</span> se define como:</p>
<p><span class="math display">\[
H = \begin{bmatrix}
\frac{\partial^2 f}{\partial x_1^2} &amp; \frac{\partial^2 f}{\partial x_1 \partial x_2} &amp; \cdots &amp; \frac{\partial^2 f}{\partial x_1 \partial x_n} \\
\frac{\partial^2 f}{\partial x_2 \partial x_1} &amp; \frac{\partial^2 f}{\partial x_2^2} &amp; \cdots &amp; \frac{\partial^2 f}{\partial x_2 \partial x_n} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\frac{\partial^2 f}{\partial x_n \partial x_1} &amp; \frac{\partial^2 f}{\partial x_n \partial x_2} &amp; \cdots &amp; \frac{\partial^2 f}{\partial x_n^2}
\end{bmatrix}
\]</span></p>
<ul>
<li>Cada elemento representa el valor de la segunda derivada parcial de la función con respecto a cada variable.</li>
<li><strong>Matriz simétrica (Symmetric Matrix):</strong> Si las derivadas parciales de segundo orden son continuas, el orden en que se toman las derivadas parciales no importa (teorema de Schwarz), por lo que la matriz Hessiana es una matriz simétrica. (<span class="math inline">\(\frac{\partial^2 f}{\partial x_i \partial x_j} = \frac{\partial^2 f}{\partial x_j \partial x_i}\)</span>)</li>
</ul></li>
<li><p><strong>Significado:</strong></p>
<ul>
<li><strong>Curvatura (Curvature):</strong> La matriz Hessiana contiene información sobre la curvatura local de la función. Indica cuánto se curva el gráfico de la función en un punto específico.</li>
<li><strong>Tasa de cambio de la tasa de cambio:</strong> Mientras que las derivadas parciales de primer orden (gradiente, Gradient) indican la tasa de cambio de la función, la matriz Hessiana indica cuán rápidamente cambia esa tasa de cambio.</li>
</ul></li>
</ul>
</section>
<section id="uso-de-la-matriz-hessiana-para-clasificar-los-puntos-críticos-critical-point" class="level3">
<h3 class="anchored" data-anchor-id="uso-de-la-matriz-hessiana-para-clasificar-los-puntos-críticos-critical-point">2. Uso de la matriz Hessiana para clasificar los puntos críticos (Critical Point)</h3>
<ul>
<li><strong>Punto crítico (Critical Point):</strong> Un punto donde la pendiente de la función (gradiente) es cero. Es decir, un punto donde todas las derivadas parciales de primer orden son cero. (<span class="math inline">\(\nabla f = 0\)</span>)</li>
<li><strong>Clasificación del punto crítico:</strong>
<ul>
<li>La matriz Hessiana se utiliza para determinar si un punto crítico es un máximo local (local maximum), un mínimo local (local minimum) o un punto de silla (saddle point).</li>
<li><strong>Mínimo local (Local Minimum):</strong> Si la matriz Hessiana es una matriz <strong>definida positiva (positive definite)</strong>, el punto crítico es un mínimo local. (Todos los valores propios son positivos)</li>
<li><strong>Máximo local (Local Maximum):</strong> Si la matriz Hessiana es una matriz <strong>definida negativa (negative definite)</strong>, el punto crítico es un máximo local. (Todos los valores propios son negativos)</li>
<li><strong>Punto de silla (Saddle Point):</strong> Si la matriz Hessiana es una matriz <strong>indefinida (indefinite)</strong>, el punto crítico es un punto de silla. (Tiene tanto valores propios positivos como negativos)</li>
<li><strong>Semidefinida:</strong> Si la matriz Hessiana es positive/negative semidefinite, no se puede determinar el tipo de punto crítico sin información adicional. (Los valores propios incluyen cero)</li>
</ul></li>
</ul>
</section>
<section id="uso-de-la-matriz-hessiana-en-el-aprendizaje-profundo-deep-learning" class="level3">
<h3 class="anchored" data-anchor-id="uso-de-la-matriz-hessiana-en-el-aprendizaje-profundo-deep-learning">3. Uso de la matriz Hessiana en el aprendizaje profundo (Deep Learning)</h3>
<ul>
<li><strong>Método de Newton:</strong>
<ul>
<li>Es uno de los algoritmos de optimización para encontrar los valores extremos de una función.</li>
<li>Mientras que el descenso por gradiente utiliza la derivada primera (gradiente), el método de Newton utiliza la derivada segunda (hessiana) para converger más rápidamente.</li>
<li>Regla de actualización: <span class="math inline">\(x_{k+1} = x_k - H^{-1}(x_k) \nabla f(x_k)\)</span> (H es la matriz hessiana)</li>
</ul></li>
<li><strong>Matriz de Curvatura:</strong>
<ul>
<li>La matriz hessiana puede ser utilizada como una matriz de curvatura para representar la curvatura de la función de pérdida.</li>
<li>Se utiliza la información de curvatura para ajustar la tasa de aprendizaje o mejorar el rendimiento del algoritmo de optimización. (por ejemplo, Descenso por Gradiente Natural)</li>
</ul></li>
</ul>
</section>
</section>
</div>
</div>
</section>
</section>
<section id="regla-de-la-cadena-y-retropropagación-en-redes-neuronales" class="level3">
<h3 class="anchored" data-anchor-id="regla-de-la-cadena-y-retropropagación-en-redes-neuronales">2.2.3 Regla de la cadena y retropropagación en redes neuronales</h3>
<p>El núcleo del aprendizaje de las redes neuronales es el algoritmo de retropropagación (Backpropagation). La retropropagación es un método eficiente para propagar el error que ocurre en la capa de salida hacia la capa de entrada, actualizando los pesos y sesgos de cada capa. En este proceso, la regla de la cadena (Chain Rule) permite expresar la derivada de funciones compuestas complejas como el producto de derivadas simples, lo que facilita los cálculos.</p>
<section id="aplicación-de-la-regla-de-la-cadena-en-redes-neuronales" class="level4">
<h4 class="anchored" data-anchor-id="aplicación-de-la-regla-de-la-cadena-en-redes-neuronales">Aplicación de la regla de la cadena en redes neuronales</h4>
<p>Las redes neuronales consisten en una composición de funciones en múltiples capas. Por ejemplo, una red neuronal de dos capas puede expresarse como sigue:</p>
<p><span class="math inline">\(\mathbf{z} = f_1(\mathbf{x}; \mathbf{W_1}, \mathbf{b_1})\)</span> <span class="math inline">\(\mathbf{y} = f_2(\mathbf{z}; \mathbf{W_2}, \mathbf{b_2})\)</span></p>
<p>Aquí, <span class="math inline">\(\mathbf{x}\)</span> es la entrada, <span class="math inline">\(\mathbf{z}\)</span> es la salida de la primera capa (entrada de la segunda capa), <span class="math inline">\(\mathbf{y}\)</span> es la salida final, <span class="math inline">\(\mathbf{W_1}\)</span>, <span class="math inline">\(\mathbf{b_1}\)</span> son los pesos y sesgos de la primera capa, <span class="math inline">\(\mathbf{W_2}\)</span>, <span class="math inline">\(\mathbf{b_2}\)</span> son los pesos y sesgos de la segunda capa.</p>
<p>Durante el proceso de retropropagación, debemos calcular los gradientes del error <span class="math inline">\(E\)</span> con respecto a cada parámetro (<span class="math inline">\(\frac{\partial E}{\partial \mathbf{W_1}}\)</span>, <span class="math inline">\(\frac{\partial E}{\partial \mathbf{b_1}}\)</span>, <span class="math inline">\(\frac{\partial E}{\partial \mathbf{W_2}}\)</span>, <span class="math inline">\(\frac{\partial E}{\partial \mathbf{b_2}}\)</span>). Al aplicar la regla de la cadena, podemos realizar los cálculos como sigue:</p>
<p><span class="math inline">\(\frac{\partial E}{\partial \mathbf{W_2}} = \frac{\partial E}{\partial \mathbf{y}} \frac{\partial \mathbf{y}}{\partial \mathbf{W_2}}\)</span> <span class="math inline">\(\frac{\partial E}{\partial \mathbf{b_2}} = \frac{\partial E}{\partial \mathbf{y}} \frac{\partial \mathbf{y}}{\partial \mathbf{b_2}}\)</span> <span class="math inline">\(\frac{\partial E}{\partial \mathbf{W_1}} = \frac{\partial E}{\partial \mathbf{y}} \frac{\partial \mathbf{y}}{\partial \mathbf{z}} \frac{\partial \mathbf{z}}{\partial \mathbf{W_1}}\)</span> <span class="math inline">\(\frac{\partial E}{\partial \mathbf{b_1}} = \frac{\partial E}{\partial \mathbf{y}} \frac{\partial \mathbf{y}}{\partial \mathbf{z}} \frac{\partial \mathbf{z}}{\partial \mathbf{b_1}}\)</span></p>
<p>De esta manera, utilizando la regla de la cadena, podemos descomponer los gradientes de cada parámetro en una red neuronal compleja en productos de derivadas sucesivas y calcularlos eficientemente. La teoría detallada del proceso se explica en 2.2.4.</p>
</section>
<section id="gradientes-y-derivadas-direccionales" class="level4">
<h4 class="anchored" data-anchor-id="gradientes-y-derivadas-direccionales">Gradientes y derivadas direccionales</h4>
<ul>
<li><strong>Gradiente (Gradient):</strong> Un vector que contiene las derivadas parciales (partial derivatives) de una función multivariable con respecto a cada variable. Indica la dirección de mayor pendiente de la función.</li>
<li><strong>Derivada direccional (Directional Derivative):</strong> Representa la tasa de cambio de la función en una dirección específica. Se puede calcular como el producto punto (dot product) del gradiente y el vector de dirección.</li>
</ul>
</section>
<section id="puntos-a-tener-en-cuenta-sobre-la-representación-del-gradiente" class="level4">
<h4 class="anchored" data-anchor-id="puntos-a-tener-en-cuenta-sobre-la-representación-del-gradiente">Puntos a tener en cuenta sobre la representación del gradiente</h4>
<ul>
<li><strong>Vector de columna vs.&nbsp;vector de fila:</strong> Generalmente, es convención representar los vectores como vectores de columna, pero en el aprendizaje profundo, también pueden representarse como vectores de fila según el contexto. Es importante mantener la consistencia. (Este libro utiliza la notación molecular.)</li>
<li><strong>Matriz jacobiana (Jacobian Matrix):</strong> Para funciones con múltiples variables de entrada y múltiples variables de salida (funciones vectoriales), es una matriz que contiene todos los valores de las derivadas parciales. Se usa en el cálculo del retropropagación en el aprendizaje profundo.</li>
</ul>
<p>Basados en estos conceptos, en la siguiente sección examinaremos detalladamente el método de cálculo de gradientes durante el proceso de retropropagación, junto con ejemplos específicos.</p>
</section>
</section>
<section id="cálculo-de-gradientes-para-la-propagación-hacia-atrás" class="level3">
<h3 class="anchored" data-anchor-id="cálculo-de-gradientes-para-la-propagación-hacia-atrás">2.2.4 Cálculo de gradientes para la propagación hacia atrás</h3>
<p>El núcleo de la propagación hacia atrás es calcular los gradientes de la función de pérdida (Loss Function) para actualizar los pesos. Tomemos como ejemplo una transformación lineal simple (<span class="math inline">\(\mathbf{y} = \mathbf{xW} + \mathbf{b}\)</span>) para examinar el proceso de propagación hacia atrás.</p>
<section id="idea-central-de-la-propagación-hacia-atrás" class="level4">
<h4 class="anchored" data-anchor-id="idea-central-de-la-propagación-hacia-atrás">1. Idea central de la propagación hacia atrás</h4>
<p>La propagación hacia atrás es un algoritmo que propaga el error calculado en la capa de salida hacia la capa de entrada, actualizando cada peso según su contribución al error. El cálculo de los gradientes de la función de pérdida con respecto a cada peso es fundamental en este proceso.</p>
</section>
<section id="gradiente-de-la-función-de-pérdida" class="level4">
<h4 class="anchored" data-anchor-id="gradiente-de-la-función-de-pérdida">2. Gradiente de la función de pérdida</h4>
<p>Si usamos el error cuadrático medio (Mean Squared Error, MSE) como función de pérdida, el gradiente de la función de pérdida <span class="math inline">\(E\)</span> con respecto a la salida <span class="math inline">\(\mathbf{y}\)</span> se expresa de la siguiente manera:</p>
<p><span class="math inline">\(E = \frac{1}{M} \sum_{i=1}^{M} (y_i - \hat{y}_i)^2\)</span></p>
<p><span class="math inline">\(\frac{\partial E}{\partial \mathbf{y}} = \frac{2}{M}(\mathbf{y} - \hat{\mathbf{y}})\)</span></p>
<p>Aquí, <span class="math inline">\(y_i\)</span> es el valor real, <span class="math inline">\(\hat{y}_i\)</span> es el valor predicho por el modelo, y <span class="math inline">\(M\)</span> es el número de datos.</p>
</section>
<section id="gradiente-con-respecto-a-los-pesos" class="level4">
<h4 class="anchored" data-anchor-id="gradiente-con-respecto-a-los-pesos">3. Gradiente con respecto a los pesos</h4>
<p>Aplicando la regla de la cadena, podemos calcular el gradiente de la función de pérdida <span class="math inline">\(E\)</span> con respecto a los pesos <span class="math inline">\(\mathbf{W}\)</span>:</p>
<p><span class="math inline">\(\frac{\partial E}{\partial \mathbf{W}} = \frac{\partial E}{\partial \mathbf{y}} \frac{\partial \mathbf{y}}{\partial \mathbf{W}}\)</span></p>
<p>Dado que <span class="math inline">\(\mathbf{y} = \mathbf{xW} + \mathbf{b}\)</span>, tenemos <span class="math inline">\(\frac{\partial \mathbf{y}}{\partial \mathbf{W}} = \mathbf{x}^T\)</span>.</p>
<p>Finalmente, el gradiente con respecto a los pesos se expresa de la siguiente manera:</p>
<p><span class="math inline">\(\frac{\partial E}{\partial \mathbf{W}} = \mathbf{x}^T \frac{\partial E}{\partial \mathbf{y}}\)</span></p>
</section>
<section id="gradiente-con-respecto-a-la-entrada" class="level4">
<h4 class="anchored" data-anchor-id="gradiente-con-respecto-a-la-entrada">4. Gradiente con respecto a la entrada</h4>
<p>El gradiente de la función de pérdida <span class="math inline">\(E\)</span> con respecto a la entrada <span class="math inline">\(\mathbf{x}\)</span> se utiliza para propagar el error hacia la capa anterior:</p>
<p><span class="math inline">\(\frac{\partial E}{\partial \mathbf{x}} = \frac{\partial E}{\partial \mathbf{y}} \frac{\partial \mathbf{y}}{\partial \mathbf{x}}\)</span></p>
<p>Dado que <span class="math inline">\(\mathbf{y} = \mathbf{xW} + \mathbf{b}\)</span>, tenemos <span class="math inline">\(\frac{\partial \mathbf{y}}{\partial \mathbf{x}} = \mathbf{W}^T\)</span>.</p>
<p>Por lo tanto, el gradiente con respecto a la entrada es:</p>
<p><span class="math inline">\(\frac{\partial E}{\partial \mathbf{x}} = \frac{\partial E}{\partial \mathbf{y}} \mathbf{W}^T\)</span></p>
</section>
<section id="resumen" class="level4">
<h4 class="anchored" data-anchor-id="resumen">5. Resumen</h4>
<p>La propagación hacia atrás se realiza a través de los siguientes pasos clave. 1. <strong>Propagación hacia adelante (Forward Propagation):</strong> se pasa el dato de entrada <span class="math inline">\(\mathbf{x}\)</span> a través de la red neuronal para calcular la predicción <span class="math inline">\(\hat{\mathbf{y}}\)</span>. 2. <strong>Cálculo de la función de pérdida:</strong> se compara la predicción <span class="math inline">\(\hat{\mathbf{y}}\)</span> con el valor real <span class="math inline">\(\mathbf{y}\)</span> para calcular la pérdida <span class="math inline">\(E\)</span>. 3. <strong>Propagación hacia atrás (Backward Propagation):</strong> * se calcula el gradiente de la función de pérdida respecto a la capa de salida <span class="math inline">\(\frac{\partial E}{\partial \mathbf{y}}\)</span>. * utilizando la regla de la cadena, se calcula el gradiente con respecto a los pesos <span class="math inline">\(\frac{\partial E}{\partial \mathbf{W}} = \mathbf{x}^T \frac{\partial E}{\partial \mathbf{y}}\)</span>. * se calcula el gradiente con respecto a las entradas <span class="math inline">\(\frac{\partial E}{\partial \mathbf{x}} = \frac{\partial E}{\partial \mathbf{y}} \mathbf{W}^T\)</span> para propagar el error hacia la capa anterior. 4. <strong>Actualización de los pesos:</strong> se utilizan los gradientes calculados para actualizar los pesos mediante algoritmos de optimización como el descenso por gradiente.</p>
<p>El algoritmo de propagación hacia atrás es fundamental en el entrenamiento de modelos de aprendizaje profundo, permitiendo aproximar eficazmente funciones no lineales complejas.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Haz clic para ver el contenido (deep dive: cálculo de gradientes para retropropagación)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Haz clic para ver el contenido (deep dive: cálculo de gradientes para retropropagación)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>La clave de la retropropagación es calcular el gradiente de la función de pérdida (Loss Function) para actualizar los pesos. Tomemos como ejemplo una transformación lineal simple (<span class="math inline">\(\mathbf{y} = \mathbf{xW} + \mathbf{b}\)</span>) y examinemos el proceso de retropropagación. Aquí explicamos el proceso de cálculo en detalle.</p>
<section id="gradiente-de-la-función-de-pérdida-1" class="level4">
<h4 class="anchored" data-anchor-id="gradiente-de-la-función-de-pérdida-1">Gradiente de la función de pérdida</h4>
<p>El objetivo del aprendizaje de redes neuronales es minimizar la función de pérdida <span class="math inline">\(E\)</span>. Cuando se utiliza el error cuadrático medio (MSE) como función de pérdida, esto se ve de la siguiente manera.</p>
<p><span class="math inline">\(E = f(\mathbf{y}) = \frac{1}{M} \sum_{i=1}^{M} (y_i - \hat{y}_i)^2\)</span></p>
<p>Aquí, <span class="math inline">\(y_i\)</span> es el valor real, <span class="math inline">\(\hat{y}_i\)</span> es el valor predicho y <span class="math inline">\(M\)</span> es el número de datos (o la dimensión del vector de salida).</p>
<p>La derivada de <span class="math inline">\(E\)</span> con respecto a <span class="math inline">\(\mathbf{y}\)</span> es:</p>
<p><span class="math inline">\(\frac{\partial E}{\partial \mathbf{y}} = \frac{2}{M} (\mathbf{y} - \hat{\mathbf{y}})\)</span></p>
<p>Aquí, <span class="math inline">\(\mathbf{y}\)</span> es el vector de salida de la red neuronal y <span class="math inline">\(\hat{\mathbf{y}}\)</span> es el vector de valores reales (objetivos). Como <span class="math inline">\(y_i\)</span> son constantes (cada elemento del objetivo), solo quedan las derivadas parciales con respecto a <span class="math inline">\(\mathbf{y}\)</span>.</p>
<p><strong>Nota:</strong> En el código de ejemplo del Capítulo 1, se utilizó el término <span class="math inline">\(-\frac{2}{M}\)</span>. Esto fue debido a que la definición de la función de pérdida incluía un signo negativo (-). Aquí usamos la definición general de MSE, por lo que se utiliza el valor positivo <span class="math inline">\(\frac{2}{M}\)</span>. En el aprendizaje real, este constante se multiplica por la tasa de aprendizaje (learning rate), por lo que su magnitud absoluta no es crucial.</p>
</section>
<section id="gradiente-de-la-función-de-pérdida-con-respecto-a-los-pesos" class="level4">
<h4 class="anchored" data-anchor-id="gradiente-de-la-función-de-pérdida-con-respecto-a-los-pesos">Gradiente de la función de pérdida con respecto a los pesos</h4>
<p>Ahora, calculemos el gradiente de la función de pérdida <span class="math inline">\(E\)</span> con respecto a los pesos <span class="math inline">\(\mathbf{W}\)</span>. Dado que <span class="math inline">\(E = f(\mathbf{y})\)</span> y <span class="math inline">\(\mathbf{y} = \mathbf{xW} + \mathbf{b}\)</span>, donde <span class="math inline">\(\mathbf{x}\)</span> es el vector de entrada, <span class="math inline">\(\mathbf{W}\)</span> es la matriz de pesos y <span class="math inline">\(\mathbf{b}\)</span> es el vector de sesgo.</p>
<p><strong>Gráfico de cálculo:</strong></p>
<p>Para visualizar el proceso de retropropagación, se puede usar un gráfico de cálculo. (Inserción de imagen del gráfico de cálculo)</p>
<p><span class="math inline">\(E\)</span> es un valor escalar y necesitamos calcular la derivada parcial de <span class="math inline">\(E\)</span> con respecto a cada <span class="math inline">\(w_{ij}\)</span> (cada elemento de la matriz de pesos <span class="math inline">\(\mathbf{W}\)</span>). <span class="math inline">\(\mathbf{W}\)</span> es una matriz de tamaño (dimensión de entrada) x (dimensión de salida). Por ejemplo, si la entrada tiene 3 dimensiones (<span class="math inline">\(x_1, x_2, x_3\)</span>) y la salida tiene 2 dimensiones (<span class="math inline">\(y_1, y_2\)</span>), entonces <span class="math inline">\(\mathbf{W}\)</span> es una matriz de 3x2.</p>
<p><span class="math inline">\(\frac{\partial E}{\partial \mathbf{W}} = \begin{bmatrix}
\frac{\partial E}{\partial w_{11}} &amp; \frac{\partial E}{\partial w_{12}} \\
\frac{\partial E}{\partial w_{21}} &amp; \frac{\partial E}{\partial w_{22}} \\
\frac{\partial E}{\partial w_{31}} &amp; \frac{\partial E}{\partial w_{32}}
\end{bmatrix}\)</span></p>
<p>La derivada de <span class="math inline">\(E\)</span> con respecto a <span class="math inline">\(\mathbf{y}\)</span> puede expresarse como un vector fila: <span class="math inline">\(\frac{\partial E}{\partial \mathbf{y}} = \begin{bmatrix} \frac{\partial E}{\partial y_1} &amp; \frac{\partial E}{\partial y_2} \end{bmatrix}\)</span> (usando la notación de numerador). Técnicamente, el gradiente debe expresarse como un vector columna, pero aquí usamos un vector fila por conveniencia en los cálculos.</p>
<p>Por la regla de la cadena, <span class="math inline">\(\frac{\partial E}{\partial \mathbf{W}} = \frac{\partial E}{\partial \mathbf{y}} \frac{\partial \mathbf{y}}{\partial \mathbf{W}}\)</span></p>
<p><span class="math inline">\(\frac{\partial E}{\partial w_{ij}} = \sum_k \frac{\partial E}{\partial y_k} \frac{\partial y_k}{\partial w_{ij}}\)</span> (donde <span class="math inline">\(k\)</span> es el índice del vector de salida <span class="math inline">\(\mathbf{y}\)</span>)</p>
<p>Desarrollando la ecuación anterior,</p>
<p><span class="math inline">\(\frac{\partial E}{\partial \mathbf{W}} = \frac{\partial E}{\partial y_1} \frac{\partial y_1}{\partial \mathbf{W}} + \frac{\partial E}{\partial y_2} \frac{\partial y_2}{\partial \mathbf{W}}\)</span></p>
<p>Ahora debemos calcular <span class="math inline">\(\frac{\partial y_k}{\partial w_{ij}}\)</span>. Dado que <span class="math inline">\(\mathbf{y} = \mathbf{xW} + \mathbf{b}\)</span>,</p>
<p><span class="math inline">\(y_1 = x_1w_{11} + x_2w_{21} + x_3w_{31} + b_1\)</span> <span class="math inline">\(y_2 = x_1w_{12} + x_2w_{22} + x_3w_{32} + b_2\)</span></p>
<p><span class="math inline">\(\frac{\partial y_1}{\partial w_{ij}} = \begin{bmatrix}
\frac{\partial y_1}{\partial w_{11}} &amp; \frac{\partial y_1}{\partial w_{12}} \\
\frac{\partial y_1}{\partial w_{21}} &amp; \frac{\partial y_1}{\partial w_{22}} \\
\frac{\partial y_1}{\partial w_{31}} &amp; \frac{\partial y_1}{\partial w_{32}}
\end{bmatrix} =
\begin{bmatrix}
x_1 &amp; 0 \\
x_2 &amp; 0 \\
x_3 &amp; 0
\end{bmatrix}\)</span></p>
<p><span class="math inline">\(\frac{\partial y_2}{\partial w_{ij}} = \begin{bmatrix}
0 &amp; x_1 \\
0 &amp; x_2 \\
0 &amp; x_3
\end{bmatrix}\)</span></p>
<p>Por lo tanto,</p>
<p><span class="math inline">\(\frac{\partial E}{\partial \mathbf{W}} = \frac{\partial E}{\partial y_1} \begin{bmatrix}
x_1 &amp; 0 \\
x_2 &amp; 0 \\
x_3 &amp; 0
\end{bmatrix} + \frac{\partial E}{\partial y_2} \begin{bmatrix}
0 &amp; x_1 \\
0 &amp; x_2 \\
0 &amp; x_3
\end{bmatrix} = \begin{bmatrix}
\frac{\partial E}{\partial y_1}x_1 &amp; \frac{\partial E}{\partial y_2}x_1 \\
\frac{\partial E}{\partial y_1}x_2 &amp; \frac{\partial E}{\partial y_2}x_2 \\
\frac{\partial E}{\partial y_1}x_3 &amp; \frac{\partial E}{\partial y_2}x_3
\end{bmatrix} = \begin{bmatrix} x_1 \\ x_2 \\ x_3 \end{bmatrix} \begin{bmatrix} \frac{\partial E}{\partial y_1} &amp; \frac{\partial E}{\partial y_2} \end{bmatrix} = \mathbf{x}^T \frac{\partial E}{\partial \mathbf{y}}\)</span></p>
<p><strong>Generalización:</strong></p>
<p>Cuando la entrada es un vector fila <span class="math inline">\(1 \times m\)</span> <span class="math inline">\(\mathbf{x}\)</span>, y la salida es un vector fila <span class="math inline">\(1 \times n\)</span> <span class="math inline">\(\mathbf{y}\)</span>, los pesos <span class="math inline">\(\mathbf{W}\)</span> son una matriz <span class="math inline">\(m \times n\)</span>. En este caso, <span class="math inline">\(\frac{\partial E}{\partial \mathbf{W}} = \mathbf{x}^T \frac{\partial E}{\partial \mathbf{y}}\)</span></p>
</section>
<section id="gradiente-de-la-función-de-pérdida-con-respecto-a-la-entrada" class="level4">
<h4 class="anchored" data-anchor-id="gradiente-de-la-función-de-pérdida-con-respecto-a-la-entrada">Gradiente de la función de pérdida con respecto a la entrada</h4>
<p>El gradiente de la función de pérdida <span class="math inline">\(E\)</span> con respecto a la entrada <span class="math inline">\(\mathbf{x}\)</span> también se puede calcular utilizando la regla de la cadena.</p>
<p><span class="math inline">\(\frac{\partial E}{\partial \mathbf{x}} = \frac{\partial E}{\partial \mathbf{y}} \frac{\partial \mathbf{y}}{\partial \mathbf{x}}\)</span></p>
<p>Dado que <span class="math inline">\(\mathbf{y} = \mathbf{xW} + \mathbf{b}\)</span>, entonces <span class="math inline">\(\frac{\partial \mathbf{y}}{\partial \mathbf{x}} = \mathbf{W}^T\)</span>.</p>
<p>Por lo tanto,</p>
<p><span class="math inline">\(\frac{\partial E}{\partial \mathbf{x}} = \frac{\partial E}{\partial \mathbf{y}} \mathbf{W}^T\)</span></p>
</section>
<section id="gradiente-con-respecto-al-sesgo" class="level4">
<h4 class="anchored" data-anchor-id="gradiente-con-respecto-al-sesgo">Gradiente con respecto al sesgo</h4>
<p>El gradiente de la función de pérdida con respecto al sesgo <span class="math inline">\(\mathbf{b}\)</span> es el siguiente.</p>
<p><span class="math inline">\(\frac{\partial E}{\partial \mathbf{b}} = \frac{\partial E}{\partial \mathbf{y}} \frac{\partial \mathbf{y}}{\partial \mathbf{b}}\)</span></p>
<p>Dado que <span class="math inline">\(\mathbf{y} = \mathbf{xW} + \mathbf{b}\)</span>, entonces <span class="math inline">\(\frac{\partial \mathbf{y}}{\partial \mathbf{b}} = \begin{bmatrix} 1 &amp; 1 &amp; \dots &amp; 1\end{bmatrix}\)</span> (un vector fila de <span class="math inline">\(1 \times n\)</span> compuesto únicamente por unos).</p>
<p><span class="math inline">\(\frac{\partial E}{\partial \mathbf{b}} = \frac{\partial E}{\partial \mathbf{y}}\)</span></p>
</section>
<section id="resumen-y-explicaciones-adicionales" class="level4">
<h4 class="anchored" data-anchor-id="resumen-y-explicaciones-adicionales">Resumen y explicaciones adicionales</h4>
<ol type="1">
<li><strong>Gradiente con respecto a los pesos:</strong> <span class="math inline">\(\frac{\partial E}{\partial \mathbf{W}} = \mathbf{x}^T \frac{\partial E}{\partial \mathbf{y}}\)</span>
<ul>
<li>Se calcula como el producto matricial del vector de entrada transpuesto <span class="math inline">\(\mathbf{x}\)</span> y el gradiente de la función de pérdida con respecto a la salida (<span class="math inline">\(\frac{\partial E}{\partial \mathbf{y}}\)</span>, que se expresa como un vector fila).</li>
</ul></li>
<li><strong>Gradiente con respecto a la entrada:</strong> <span class="math inline">\(\frac{\partial E}{\partial \mathbf{x}} = \frac{\partial E}{\partial \mathbf{y}} \mathbf{W}^T\)</span>
<ul>
<li>Se calcula como el producto matricial del gradiente de la función de pérdida con respecto a la salida (<span class="math inline">\(\frac{\partial E}{\partial \mathbf{y}}\)</span>) y la matriz de pesos transpuesta <span class="math inline">\(\mathbf{W}\)</span>. Este resultado se retropropaga al capa anterior para actualizar los pesos de esa capa.</li>
</ul></li>
<li><strong>Gradiente con respecto al sesgo:</strong> <span class="math inline">\(\frac{\partial E}{\partial \mathbf{b}} = \frac{\partial E}{\partial \mathbf{y}}\)</span>
<ul>
<li>Es igual al gradiente de la función de pérdida con respecto a la salida.</li>
</ul></li>
<li><strong>Uso del gradiente:</strong> Los gradientes calculados se utilizan en algoritmos de optimización como el descenso por gradiente (Gradient Descent) para actualizar los pesos y sesgos. Cada parámetro se actualiza en la dirección opuesta al gradiente para minimizar la función de pérdida.</li>
<li><strong>Notación:</strong> En la descripción anterior, se utilizó la notación de numerador para calcular el gradiente. También se puede usar la notación de denominador, pero al final se obtendrá la misma regla de actualización. Lo importante es usar una notación consistente. Este libro utiliza la notación de numerador.</li>
</ol>
<p>A través de este proceso matemático, los modelos de aprendizaje profundo pueden aprender transformaciones no lineales complejas de datos de entrada a datos de salida.</p>
</section>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="probabilidad-y-estadística" class="level2">
<h2 class="anchored" data-anchor-id="probabilidad-y-estadística">2.3 Probabilidad y estadística</h2>
<p>El aprendizaje profundo se basa profundamente en la teoría de probabilidad y estadística para manejar la incertidumbre de los datos. En este capítulo, examinaremos conceptos clave como distribuciones de probabilidad, valor esperado, teorema de Bayes y estimación de máxima verosimilitud. Estos conceptos son esenciales para comprender el proceso de aprendizaje e inferencia en los modelos.</p>
<section id="distribuciones-de-probabilidad-y-valor-esperado" class="level3">
<h3 class="anchored" data-anchor-id="distribuciones-de-probabilidad-y-valor-esperado">2.3.1 Distribuciones de probabilidad y valor esperado</h3>
<blockquote class="blockquote">
<p><strong>Desafío</strong>: ¿Cómo se puede modelar matemáticamente la incertidumbre de datos reales?</p>
<p><strong>Angustia del investigador</strong>: Los primeros investigadores en aprendizaje automático reconocieron que los datos del mundo real no podían ser explicados por reglas deterministas. Esto se debe a que los datos contienen errores de medición, ruido y variaciones impredecibles. Se necesitaban herramientas matemáticas para cuantificar esta incertidumbre e incorporarla en los modelos.</p>
</blockquote>
<p>Una distribución de probabilidad representa todos los posibles resultados y sus probabilidades de ocurrencia. Estas pueden dividirse en distribuciones de probabilidad discretas y continuas.</p>
<section id="distribuciones-de-probabilidad-discretas" class="level4">
<h4 class="anchored" data-anchor-id="distribuciones-de-probabilidad-discretas">Distribuciones de probabilidad discretas</h4>
<p>Las distribuciones de probabilidad discretas tratan con variables aleatorias que pueden tomar un número finito o contable de valores. Su característica distintiva es que se puede asignar una probabilidad clara a cada resultado posible.</p>
<p>Matemáticamente, las distribuciones de probabilidad discretas se representan mediante la función de masa de probabilidad (PMF).</p>
<p><span class="math display">\[P(X = x) = p(x)\]</span></p>
<p>Aquí, ( p(x) ) es la probabilidad de que ( X ) tenga el valor ( x ). Las principales propiedades son las siguientes:</p>
<ol type="1">
<li>Para todo ( x ), ( 0 ≤ p(x) ≤ 1 )</li>
<li>( _{x} p(x) = 1 )</li>
</ol>
<p>Ejemplos típicos incluyen la distribución de Bernoulli, la distribución binomial y la distribución de Poisson.</p>
<p>La función de masa de probabilidad de tirar un dado es la siguiente:</p>
<p><span class="math display">\[P(X = x) = \begin{cases}
\frac{1}{6} &amp; \text{si } x \in \{1, 2, 3, 4, 5, 6\} \\
0 &amp; \text{en otro caso}
\end{cases}\]</span></p>
<p>Las distribuciones de probabilidad discretas se utilizan en el aprendizaje automático y el aprendizaje profundo para problemas de clasificación, aprendizaje por refuerzo, procesamiento del lenguaje natural y otros campos. A continuación se presentan los resultados de una simulación de tirar un dado.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Resultado</th>
<th>Frecuencia</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>10</td>
</tr>
<tr class="even">
<td>2</td>
<td>8</td>
</tr>
<tr class="odd">
<td>3</td>
<td>12</td>
</tr>
<tr class="even">
<td>4</td>
<td>9</td>
</tr>
<tr class="odd">
<td>5</td>
<td>11</td>
</tr>
<tr class="even">
<td>6</td>
<td>10</td>
</tr>
</tbody>
</table>
<div id="cell-25" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_02.statistics <span class="im">import</span> simulate_dice_roll</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>simulate_dice_roll()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="02_Matemáticas de deep learning_files/figure-html/cell-7-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="distribución-de-probabilidad-continua" class="level4">
<h4 class="anchored" data-anchor-id="distribución-de-probabilidad-continua">Distribución de probabilidad continua</h4>
<p>La distribución de probabilidad continua trata los casos en los que una variable aleatoria puede tomar valores continuos. A diferencia de la distribución de probabilidad discreta, la probabilidad en un punto específico es 0 y se maneja la probabilidad para intervalos. Matemáticamente, la distribución de probabilidad continua se expresa mediante la función de densidad de probabilidad (Probability Density Function, PDF).</p>
<p><span class="math display">\[f(x) = \lim_{\Delta x \to 0} \frac{P(x &lt; X \leq x + \Delta x)}{\Delta x}\]</span></p>
<p>Aquí, f(x) representa la densidad de probabilidad cerca de x. Las principales propiedades son las siguientes.</p>
<ol type="1">
<li>Para todo x, f(x) ≥ 0</li>
<li><span class="math inline">\(\int_{-\infty}^{\infty} f(x) dx = 1\)</span></li>
</ol>
<p>Ejemplos típicos incluyen la distribución normal, la distribución exponencial y la distribución gamma.</p>
<p>La función de densidad de probabilidad de la distribución normal es la siguiente.</p>
<p><span class="math display">\[f(x) = \frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}\]</span></p>
<p>Aquí, μ es la media y σ es la desviación estándar.</p>
<p>La distribución de probabilidad continua se utiliza importante en diversos campos de aplicación del aprendizaje automático y el aprendizaje profundo, como problemas de regresión, procesamiento de señales y análisis de series temporales.</p>
<div id="cell-27" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_02.statistics <span class="im">import</span> plot_normal_distribution</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>plot_normal_distribution()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="02_Matemáticas de deep learning_files/figure-html/cell-8-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="valor-esperado" class="level4">
<h4 class="anchored" data-anchor-id="valor-esperado">Valor esperado</h4>
<p>El valor esperado es un concepto importante que indica la tendencia central de una distribución de probabilidad. Se puede interpretar como el promedio ponderado de todos los valores posibles de una variable aleatoria. En el caso de una distribución de probabilidad discreta, el valor esperado se calcula de la siguiente manera.</p>
<p><span class="math display">\[E[X] = \sum_{i} x_i P(X = x_i)\]</span></p>
<p>Donde <span class="math inline">\(x_i\)</span> son los valores posibles de la variable aleatoria X y <span class="math inline">\(P(X = x_i)\)</span> es la probabilidad de ese valor. Para una distribución de probabilidad continua, el valor esperado se calcula mediante integración.</p>
<p><span class="math display">\[E[X] = \int_{-\infty}^{\infty} x f(x) dx\]</span></p>
<p>Donde <span class="math inline">\(f(x)\)</span> es la función de densidad de probabilidad. El valor esperado tiene las siguientes propiedades importantes:</p>
<ol type="1">
<li>Linealidad: <span class="math inline">\(E[aX + b] = aE[X] + b\)</span></li>
<li>Valor esperado del producto de variables aleatorias independientes: <span class="math inline">\(E[XY] = E[X]E[Y]\)</span> (cuando X y Y son independientes)</li>
</ol>
<p>En el aprendizaje profundo, el valor esperado se utiliza esencialmente para la minimización de funciones de pérdida o la estimación de parámetros del modelo. Por ejemplo, el error cuadrático medio (MSE) se define de la siguiente manera.</p>
<p><span class="math display">\[MSE = E[(Y - \hat{Y})^2]\]</span></p>
<p>Donde <span class="math inline">\(Y\)</span> es el valor real y <span class="math inline">\(\hat{Y}\)</span> es el valor predicho.</p>
<p>El concepto de valor esperado proporciona una base teórica para algoritmos de optimización como el descenso del gradiente estocástico (Stochastic Gradient Descent) y también se utiliza importantemente en la estimación de funciones de valor en el aprendizaje por refuerzo.</p>
<div id="cell-29" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_02.statistics <span class="im">import</span> calculate_dice_expected_value</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>calculate_dice_expected_value()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Expected value of dice roll: 3.5</code></pre>
</div>
</div>
<p>Estos conceptos fundamentales de probabilidad y estadística juegan un papel crucial en el diseño, aprendizaje y evaluación de modelos de deep learning. En la siguiente sección, exploraremos el teorema de Bayes y la estimación de máxima verosimilitud basándonos en esto.</p>
</section>
</section>
<section id="teorema-de-bayes-y-estimación-de-máxima-verosimilitud" class="level3">
<h3 class="anchored">2.3.2 Teorema de Bayes y Estimación de Máxima Verosimilitud</h3>
<blockquote class="blockquote">
<p><strong>Desafío:</strong> ¿Cómo estimar los parámetros del modelo lo mejor posible con datos limitados?</p>
<p><strong>Angustia del investigador:</strong> Los estadísticos iniciales y los investigadores de aprendizaje automático a menudo se enfrentaban a la situación de tener que crear modelos con solo datos limitados. Estimar con precisión los parámetros del modelo en ausencia de suficientes datos era un problema muy difícil. Se necesitaba una forma de mejorar la precisión de las estimaciones utilizando no solo los datos, sino también conocimientos previos o creencias.</p>
</blockquote>
<p>El teorema de Bayes y la estimación de máxima verosimilitud son conceptos fundamentales en probabilidad y estadística que se aplican ampliamente en el aprendizaje profundo para el entrenamiento e inferencia de modelos.</p>
<section id="teorema-de-bayes" class="level4">
<h4 class="anchored" data-anchor-id="teorema-de-bayes">Teorema de Bayes</h4>
<p>El teorema de Bayes proporciona un método para calcular probabilidades condicionales. Se utiliza para actualizar la probabilidad de una hipótesis dada nueva evidencia. La representación matemática del teorema de Bayes es como sigue:</p>
<p><span class="math display">\[P(A|B) = \frac{P(B|A)P(A)}{P(B)}\]</span></p>
<p>Donde: - <span class="math inline">\(P(A|B)\)</span> es la probabilidad de A dado B (probabilidad posterior) - <span class="math inline">\(P(B|A)\)</span> es la probabilidad de B dado A (verosimilitud) - <span class="math inline">\(P(A)\)</span> es la probabilidad de A (probabilidad a priori) - <span class="math inline">\(P(B)\)</span> es la probabilidad de B (evidencia)</p>
<p>El teorema de Bayes se utiliza en el aprendizaje automático de las siguientes maneras:</p>
<ol type="1">
<li>Problemas de clasificación: Se usa para calcular la probabilidad de que una observación pertenezca a una clase específica en un clasificador Naive Bayes.</li>
<li>Estimación de parámetros: Se utiliza para calcular la distribución posterior de los parámetros del modelo.</li>
<li>Teoría de decisión: Se aplica para tomar decisiones óptimas bajo incertidumbre.</li>
</ol>
</section>
<section id="estimación-de-máxima-verosimilitud" class="level4">
<h4 class="anchored">Estimación de Máxima Verosimilitud</h4>
<p>La estimación de máxima verosimilitud (Maximum Likelihood Estimation, MLE) es un método para encontrar los parámetros del modelo que mejor explican los datos observados. En el contexto del aprendizaje profundo, esto implica encontrar los pesos y sesgos de una red neuronal que mejor expliquen los datos observados. Es decir, la estimación de máxima verosimilitud busca los parámetros que maximizan la probabilidad de que el modelo genere los datos de entrenamiento, lo cual está directamente relacionado con el proceso de entrenamiento del modelo. Matemáticamente, dado un conjunto de datos <span class="math inline">\(X = (x_1, ..., x_n)\)</span>, la función de verosimilitud para un parámetro <span class="math inline">\(\theta\)</span> se define como:</p>
<p><span class="math display">\[L(\theta|X) = \prod_{i=1}^n P(x_i|\theta)\]</span></p>
<p>Para facilitar el cálculo, a menudo se utiliza el logaritmo de la función de verosimilitud:</p>
<p><span class="math display">\[\log L(\theta|X) = \sum_{i=1}^n \log P(x_i|\theta)\]</span></p>
<p>El uso del logaritmo de la verosimilitud tiene varias ventajas matemáticas importantes:</p>
<ol type="1">
<li>Conversión de multiplicación en suma: Debido a que <span class="math inline">\(\log(ab) = \log(a) + \log(b)\)</span>, el producto de probabilidades se convierte en una suma de logaritmos de probabilidades, lo que simplifica los cálculos y mejora la estabilidad numérica.</li>
<li>Mejor estabilidad numérica: Cuando se manejan valores de probabilidad muy pequeños, la multiplicación puede causar desbordamiento por debajo (underflow). El uso del logaritmo evita este problema.</li>
<li>Simplificación de derivadas: En el proceso de optimización, las derivadas son más fáciles de calcular cuando se utilizan funciones logarítmicas, especialmente en distribuciones exponenciales.</li>
<li>Función monótona creciente: Dado que la función logarítmica es monótona creciente, maximizar la verosimilitud y maximizar el logaritmo de la verosimilitud dan el mismo resultado.</li>
</ol>
<p>Por estas razones, muchos algoritmos de aprendizaje automático, incluyendo los del aprendizaje profundo, utilizan el logaritmo de la verosimilitud para realizar optimización.</p>
<p>La estimación de máxima verosimilitud se utiliza en el aprendizaje profundo de las siguientes maneras: 1. Aprendizaje del modelo: el proceso de minimizar la función de pérdida al aprender los pesos de una red neuronal es, en esencia, equivalente a la estimación de máxima verosimilitud. 2. Modelado probabilístico: se utiliza para estimar la distribución de datos en modelos generativos. 3. Ajuste de hiperparámetros: puede ser utilizado para seleccionar los hiperparámetros del modelo.</p>
<p>El teorema de Bayes y la estimación de máxima verosimilitud están estrechamente relacionados. En la estimación bayesiana, cuando la distribución previa es uniforme, la estimación de máxima probabilidad a posteriori (MAP) se vuelve idéntica a la estimación de máxima verosimilitud. Matemáticamente, esto se expresa como <span class="math inline">\(P(\theta|X) \propto P(X|\theta)P(\theta)\)</span> donde, si <span class="math inline">\(P(\theta)\)</span> es constante, <span class="math inline">\(\operatorname{argmax}_{\theta} P(\theta|X) = \operatorname{argmax}_{\theta} P(X|\theta)P(\theta)\)</span>. Esto significa que cuando la distribución previa no proporciona información adicional sobre los parámetros, la estimación basada únicamente en los datos (MLE) coincide con la estimación bayesiana (MAP).</p>
<p>Estos conceptos son esenciales para comprender y optimizar el proceso de aprendizaje e inferencia en modelos de deep learning. En la siguiente sección, exploraremos los fundamentos de la teoría de la información.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Inmersión profunda: análisis detallado del teorema de Bayes">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Inmersión profunda: análisis detallado del teorema de Bayes
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<section id="teorema-de-bayes---análisis-detallado" class="level2 callout-body-container callout-body">
<h2 class="anchored" data-anchor-id="teorema-de-bayes---análisis-detallado">Teorema de Bayes - Análisis detallado</h2>
<section id="derivación-rigurosa-del-teorema-de-bayes-y-espacio-de-probabilidad" class="level3">
<h3 class="anchored" data-anchor-id="derivación-rigurosa-del-teorema-de-bayes-y-espacio-de-probabilidad">1. Derivación rigurosa del teorema de Bayes y espacio de probabilidad</h3>
<ul>
<li><strong>Espacio de probabilidad (Probability Space):</strong> El teorema de Bayes se define en el espacio de probabilidad <span class="math inline">\((\Omega, \mathcal{F}, P)\)</span>.
<ul>
<li><span class="math inline">\(\Omega\)</span>: espacio muestral (Sample Space, conjunto de todos los resultados posibles)</li>
<li><span class="math inline">\(\mathcal{F}\)</span>: espacio de eventos (Event Space, conjunto de subconjuntos del espacio muestral, <span class="math inline">\(\sigma\)</span>-algebra)</li>
<li><span class="math inline">\(P\)</span>: medida de probabilidad (Probability Measure, función que asigna una probabilidad a cada evento en el espacio de eventos)</li>
</ul></li>
<li><strong>Definición rigurosa de la probabilidad condicional:</strong>
<ul>
<li>Para un evento <span class="math inline">\(B \in \mathcal{F}\)</span> donde <span class="math inline">\(P(B) &gt; 0\)</span>, la probabilidad condicional de un evento <span class="math inline">\(A \in \mathcal{F}\)</span> dado <span class="math inline">\(B\)</span> se define como: <span class="math inline">\(P(A|B) = \frac{P(A \cap B)}{P(B)}\)</span></li>
</ul></li>
<li><strong>Probabilidad conjunta:</strong>
<ul>
<li>La probabilidad conjunta <span class="math inline">\(P(A \cap B)\)</span> de dos eventos <span class="math inline">\(A, B \in \mathcal{F}\)</span> representa la probabilidad de que ambos eventos ocurran simultáneamente.</li>
<li>Usando la definición de probabilidad condicional, se puede expresar como:
<ul>
<li><span class="math inline">\(P(A \cap B) = P(A|B)P(B)\)</span></li>
<li><span class="math inline">\(P(A \cap B) = P(B|A)P(A)\)</span></li>
</ul></li>
</ul></li>
<li><strong>Derivación del teorema de Bayes:</strong>
<ol type="1">
<li><span class="math inline">\(P(A|B)P(B) = P(B|A)P(A)\)</span> (dos expresiones de la probabilidad conjunta)</li>
<li><span class="math inline">\(P(A|B) = \frac{P(B|A)P(A)}{P(B)}\)</span> (dividiendo ambos lados por <span class="math inline">\(P(B)\)</span>, <span class="math inline">\(P(B) &gt; 0\)</span>)</li>
</ol></li>
</ul>
</section>
<section id="significado-detallado-y-interpretación-estadística-de-cada-término-del-teorema-de-bayes" class="level3">
<h3 class="anchored" data-anchor-id="significado-detallado-y-interpretación-estadística-de-cada-término-del-teorema-de-bayes">2. Significado detallado y interpretación estadística de cada término del teorema de Bayes</h3>
<ul>
<li><strong><span class="math inline">\(P(A|B)\)</span>: Probabilidad a posteriori (Posterior Probability)</strong>
<ul>
<li><strong>Interpretación:</strong> Distribución de probabilidad actualizada para la hipótesis <span class="math inline">\(A\)</span> después de obtener los datos observados <span class="math inline">\(B\)</span>. Representa el resultado de la inferencia basada en los datos.</li>
<li><strong>Perspectiva bayesiana:</strong> La probabilidad a posteriori cuantifica la incertidumbre mediante la combinación de la probabilidad a priori y la verosimilitud, proporcionando una base para la toma de decisiones.</li>
</ul></li>
<li><strong><span class="math inline">\(P(B|A)\)</span>: Verosimilitud (Likelihood)</strong>
<ul>
<li><strong>Interpretación:</strong> Probabilidad de observar los datos <span class="math inline">\(B\)</span> dado que la hipótesis <span class="math inline">\(A\)</span> es verdadera. Indica qué tan bien la hipótesis <span class="math inline">\(A\)</span> explica los datos <span class="math inline">\(B\)</span>.</li>
<li><strong>Perspectiva frecuentista vs.&nbsp;bayesiana:</strong>
<ul>
<li><strong>Frecuentista:</strong> La verosimilitud es una función del parámetro (parameter) fijo que describe la distribución de los datos.</li>
<li><strong>Bayesiana:</strong> La verosimilitud es una función que proporciona información sobre el parámetro dado los datos.</li>
</ul></li>
</ul></li>
<li><strong><span class="math inline">\(P(A)\)</span>: Probabilidad a priori (Prior Probability)</strong>
<ul>
<li><strong>Interpretación:</strong> Distribución de probabilidad que representa la creencia previa (prior belief) sobre la hipótesis <span class="math inline">\(A\)</span> antes de obtener los datos observados <span class="math inline">\(B\)</span>.</li>
<li><strong>Probabilidad a priori subjetiva vs.&nbsp;objetiva:</strong>
<ul>
<li><strong>Subjetiva (Subjective):</strong> Establecida basada en el conocimiento experto, experiencias previas, etc.</li>
<li><strong>Objetiva (Objective):</strong> Utiliza una distribución uniforme o un prior no informativo que contiene la mínima cantidad de información.</li>
</ul></li>
</ul></li>
<li><strong><span class="math inline">\(P(B)\)</span>: evidencia (Evidence) o probabilidad marginal (Marginal Likelihood)</strong>
<ul>
<li><strong>interpretación:</strong> probabilidad de que los datos observados <span class="math inline">\(B\)</span> ocurran bajo todas las hipótesis posibles. Actúa como constante normalizadora (normalizing constant) para convertir <span class="math inline">\(P(A|B)\)</span> en una distribución de probabilidad.</li>
<li><strong>cálculo:</strong> <span class="math inline">\(P(B) = \sum_{A'} P(B|A')P(A')\)</span> (para variables aleatorias discretas) <span class="math inline">\(P(B) = \int P(B|A)p(A) dA\)</span> (para variables aleatorias continuas, donde <span class="math inline">\(p(A)\)</span> es la función de densidad de probabilidad)</li>
<li><strong>comparación de modelos:</strong> se usa para comparar la evidencia entre diferentes modelos, por ejemplo en el cálculo del factor de Bayes.</li>
</ul></li>
</ul>
</section>
<section id="teorema-de-bayes-y-inferencia-bayesiana-bayesian-inference" class="level3">
<h3 class="anchored" data-anchor-id="teorema-de-bayes-y-inferencia-bayesiana-bayesian-inference">3. Teorema de Bayes y inferencia bayesiana (Bayesian Inference)</h3>
<ul>
<li><strong>punto clave:</strong> el teorema de Bayes es el principio fundamental de la inferencia bayesiana, que se utiliza para deducir la distribución de probabilidad de los parámetros o hipótesis dados los datos.</li>
<li><strong>proceso:</strong>
<ol type="1">
<li><strong>Prior:</strong> se establece una distribución a priori <span class="math inline">\(p(\theta)\)</span> para el parámetro <span class="math inline">\(\theta\)</span>.</li>
<li><strong>Likelihood:</strong> se define la probabilidad de observar los datos <span class="math inline">\(x\)</span> dado el parámetro <span class="math inline">\(\theta\)</span>, <span class="math inline">\(p(x|\theta)\)</span> (función de verosimilitud).</li>
<li><strong>Posterior:</strong> se calcula la distribución a posteriori <span class="math inline">\(p(\theta|x)\)</span> utilizando el teorema de Bayes. <span class="math inline">\(p(\theta|x) = \frac{p(x|\theta)p(\theta)}{p(x)} = \frac{p(x|\theta)p(\theta)}{\int p(x|\theta')p(\theta') d\theta'}\)</span></li>
<li><strong>Inferencia:</strong> se realizan estimaciones, intervalos de confianza y pruebas de hipótesis sobre el parámetro basándose en la distribución a posteriori.</li>
</ol></li>
<li><strong>actualización iterativa:</strong> es posible actualizar continuamente las creencias utilizando la distribución a posteriori previa como nueva distribución a priori cada vez que se recibe nuevo dato (actualización bayesiana secuencial).</li>
</ul>
</section>
<section id="generalizaciones-y-aplicaciones-del-teorema-de-bayes" class="level3">
<h3 class="anchored" data-anchor-id="generalizaciones-y-aplicaciones-del-teorema-de-bayes">4. Generalizaciones y aplicaciones del teorema de Bayes</h3>
<ul>
<li><strong>variables aleatorias continuas:</strong> aplicación del teorema de Bayes utilizando funciones de densidad de probabilidad.</li>
<li><strong>distribuciones a priori conjugadas (Conjugate Prior):</strong>
<ul>
<li>distribuciones a priori que aseguran que la distribución a posteriori pertenezca a la misma familia de distribuciones. Se usan por su comodidad en los cálculos (por ejemplo, distribución beta para datos bernoulli, distribución gamma para datos poisson).</li>
</ul></li>
<li><strong>Bayes variacional (Variational Bayes):</strong>
<ul>
<li>método para aproximar distribuciones a posteriori complejas.</li>
<li>se busca una distribución manejable similar a la a posteriori y se minimiza la divergencia de Kullback-Leibler entre ambas distribuciones.</li>
</ul></li>
<li><strong>MCMC (Markov Chain Monte Carlo):</strong>
<ul>
<li>método para estimar las características de la distribución a posteriori mediante el muestreo de esta.</li>
<li>incluye algoritmos como Metropolis-Hastings y Gibbs sampling.</li>
</ul></li>
<li><strong>aplicaciones en deep learning:</strong>
<ul>
<li><strong>Redes Neuronales Bayesianas:</strong> tratan los pesos de una red neuronal como variables aleatorias para cuantificar la incertidumbre en las predicciones.</li>
<li><strong>Procesos Gaussianos:</strong> definen distribuciones a priori sobre espacios funcionales utilizando kernels y calculan distribuciones predictivas mediante el teorema de Bayes.</li>
</ul></li>
</ul>
</section>
</section>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Inmersión profunda: análisis detallado de la estimación de máxima verosimilitud (MLE) y comparación con MAP (para estudiantes de posgrado)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Inmersión profunda: análisis detallado de la estimación de máxima verosimilitud (MLE) y comparación con MAP (para estudiantes de posgrado)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<section id="estimación-de-máxima-verosimilitud-maximum-likelihood-estimation-mle---análisis-profundo-y-comparación-con-map" class="level2 callout-body-container callout-body">
<h2 class="anchored" data-anchor-id="estimación-de-máxima-verosimilitud-maximum-likelihood-estimation-mle---análisis-profundo-y-comparación-con-map">Estimación de Máxima Verosimilitud (Maximum Likelihood Estimation, MLE) - Análisis profundo y comparación con MAP</h2>
<section id="ejemplo-concreto-del-cálculo-de-mle" class="level3">
<h3 class="anchored" data-anchor-id="ejemplo-concreto-del-cálculo-de-mle">1. Ejemplo concreto del cálculo de MLE</h3>
<p>MLE es un método para encontrar el parámetro que mejor explica los datos observados. Se trata de encontrar el valor del parámetro que maximiza la verosimilitud de los datos observados.</p>
<ul>
<li><p><strong>Función de Verosimilitud (Likelihood Function):</strong></p>
<ul>
<li>Si se asume que los datos <span class="math inline">\(x_1, x_2, ..., x_n\)</span> son extraídos independientemente de una misma distribución de probabilidad (i.i.d), la función de verosimilitud se define como sigue. <span class="math display">\[L(\theta; x_1, ..., x_n) = \prod_{i=1}^{n} p(x_i | \theta)\]</span>
<ul>
<li><span class="math inline">\(\theta\)</span>: parámetro (parameter)</li>
<li><span class="math inline">\(p(x_i | \theta)\)</span>: probabilidad (o densidad de probabilidad) de que el dato <span class="math inline">\(x_i\)</span> ocurra dado el parámetro <span class="math inline">\(\theta\)</span></li>
</ul></li>
</ul></li>
<li><p><strong>Función de Log-Verosimilitud (Log-Likelihood Function):</strong></p>
<ul>
<li>Para facilitar los cálculos, se utiliza la función de log-verosimilitud, que es el logaritmo de la función de verosimilitud. <span class="math display">\[l(\theta; x_1, ..., x_n) = \log L(\theta; x_1, ..., x_n) = \sum_{i=1}^{n} \log p(x_i | \theta)\]</span></li>
<li>Ya que el logaritmo no cambia la posición del máximo valor, también se puede encontrar el parámetro que maximiza la log-verosimilitud.</li>
</ul></li>
<li><p><strong>Procedimiento de cálculo de MLE:</strong></p>
<ol type="1">
<li>Definir la función de verosimilitud para los datos dados y el modelo de distribución de probabilidad.</li>
<li>Aplicar el logaritmo a la función de verosimilitud para obtener la función de log-verosimilitud.</li>
<li>Diferenciar la función de log-verosimilitud con respecto al parámetro <span class="math inline">\(\theta\)</span>.</li>
<li>Encontrar el valor de <span class="math inline">\(\theta\)</span> que hace que la derivada sea cero. (Si es necesario, usar la segunda derivada para determinar si es un máximo o mínimo)</li>
<li>El valor de <span class="math inline">\(\theta\)</span> encontrado es el estimador MLE.</li>
</ol></li>
<li><p><strong>Ejemplo concreto:</strong></p>
<ul>
<li><strong>Distribución Normal (Normal Distribution):</strong>
<ul>
<li>Supongamos que los datos <span class="math inline">\(x_1, ..., x_n\)</span> siguen una distribución normal con media <span class="math inline">\(\mu\)</span> y varianza <span class="math inline">\(\sigma^2\)</span>.</li>
<li>Función de log-verosimilitud: <span class="math display">\[l(\mu, \sigma^2; x_1, ..., x_n) = -\frac{n}{2}\log(2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^{n}(x_i - \mu)^2\]</span></li>
<li>Al diferenciar con respecto a <span class="math inline">\(\mu\)</span> y <span class="math inline">\(\sigma^2\)</span>, y encontrar los puntos donde la derivada es cero, los estimadores MLE son:
<ul>
<li><span class="math inline">\(\hat{\mu}_{MLE} = \frac{1}{n}\sum_{i=1}^{n} x_i\)</span> (media de la muestra)</li>
<li><span class="math inline">\(\hat{\sigma}^2_{MLE} = \frac{1}{n}\sum_{i=1}^{n} (x_i - \hat{\mu}_{MLE})^2\)</span> (varianza de la muestra)</li>
</ul></li>
</ul></li>
<li><strong>Distribución Bernoulli (Bernoulli Distribution):</strong>
<ul>
<li>Supongamos que los datos <span class="math inline">\(x_1, ..., x_n\)</span> siguen una distribución de Bernoulli con probabilidad de éxito <span class="math inline">\(p\)</span>. (<span class="math inline">\(x_i = 1\)</span> (éxito), <span class="math inline">\(x_i = 0\)</span> (fracaso))</li>
<li>Función de log-verosimilitud: <span class="math display">\[ l(p; x_1, ..., x_n) = \sum_{i=1}^n [x_i \log p + (1-x_i) \log (1-p)] \]</span></li>
<li>Al diferenciar con respecto a <span class="math inline">\(p\)</span> y encontrar el punto donde la derivada es cero, el estimador MLE es:
<ul>
<li><span class="math inline">\(\hat{p}_{MLE} = \frac{1}{n}\sum_{i=1}^{n} x_i\)</span> (número de éxitos / número total de ensayos)</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="ventajas-y-desventajas-de-mle" class="level3">
<h3 class="anchored" data-anchor-id="ventajas-y-desventajas-de-mle">2. Ventajas y desventajas de MLE</h3>
<ul>
<li><strong>Ventajas:</strong>
<ul>
<li><strong>Facilidad de cálculo:</strong> Es posible realizar estimaciones paramétricas con cálculos relativamente simples. (Especialmente en el caso de distribuciones de la familia exponencial)</li>
<li><strong>Propiedades asintóticas (Asymptotic Properties):</strong> (Se explica más detalladamente a continuación)
<ul>
<li><strong>Consistencia (Consistency):</strong> A medida que aumenta el tamaño de la muestra, la estimación MLE converge al parámetro real.</li>
<li><strong>Normalidad asintótica (Asymptotic Normality):</strong> A medida que aumenta el tamaño de la muestra, la estimación MLE se aproxima a una distribución normal.</li>
<li><strong>Eficiencia (Efficiency):</strong> Es un estimador insesgado con la varianza más pequeña asintóticamente (Cota inferior de Cramér–Rao).</li>
</ul></li>
</ul></li>
<li><strong>Desventajas:</strong>
<ul>
<li><strong>Posibilidad de sobreajuste (Overfitting):</strong> En particular, cuando el tamaño de la muestra es pequeño, puede ajustarse excesivamente a los datos y disminuir el rendimiento general.</li>
<li><strong>Sensibilidad a los valores atípicos (Outliers):</strong> Si existen valores atípicos, la estimación MLE puede distorsionarse significativamente.</li>
<li><strong>No es aplicable a todas las distribuciones:</strong> MLE requiere un modelo probabilístico para ser aplicado (no se aplica a métodos no paramétricos).</li>
<li><strong>Posibilidad de sesgo (Bias):</strong> En algunos casos, la estimación MLE puede estar sesgada (por ejemplo, en la estimación de la varianza de una distribución normal).</li>
</ul></li>
</ul>
</section>
<section id="comparación-con-la-estimación-de-máxima-probabilidad-a-posteriori-maximum-a-posteriori-map" class="level3">
<h3 class="anchored" data-anchor-id="comparación-con-la-estimación-de-máxima-probabilidad-a-posteriori-maximum-a-posteriori-map">3. Comparación con la estimación de máxima probabilidad a posteriori (Maximum A Posteriori, MAP)</h3>
<ul>
<li><p><strong>MAP:</strong> Se basa en el teorema de Bayes y combina la probabilidad a priori y la verosimilitud para encontrar el parámetro que maximiza la probabilidad a posteriori.</p></li>
<li><p><strong>Estimación MAP:</strong> <span class="math display">\[
  \hat{\theta}_{MAP} = \arg\max_{\theta} p(\theta|x) = \arg\max_{\theta} \frac{p(x|\theta)p(\theta)}{p(x)} = \arg\max_{\theta} p(x|\theta)p(\theta)
  \]</span></p>
<ul>
<li><span class="math inline">\(p(\theta|x)\)</span>: Probabilidad a posteriori (Posterior Probability)</li>
<li><span class="math inline">\(p(x|\theta)\)</span>: Verosimilitud (Likelihood)</li>
<li><span class="math inline">\(p(\theta)\)</span>: Probabilidad a priori (Prior Probability)</li>
<li><span class="math inline">\(p(x)\)</span>: Evidencia (Evidence, constante y por lo tanto se puede ignorar)</li>
</ul></li>
<li><p><strong>MLE vs.&nbsp;MAP:</strong> | Característica | MLE | MAP | | ———————— | ——————————————————————– | ———————————————————————- | | <strong>Base</strong> | Frecuentista (Frequentist) | Bayesiana (Bayesian) | | <strong>Objetivo</strong> | Maximización de la verosimilitud | Maximización de la probabilidad a posteriori | | <strong>Probabilidad previa</strong> | No se considera | Se considera | | <strong>Resultado</strong> | Estimación puntual (Point Estimate) | Estimación puntual (generalmente) o estimación de distribución (en el caso de la inferencia bayesiana) | | <strong>Sobreajuste</strong> | Alta probabilidad de sobreajuste | Posible prevención del sobreajuste a través de la probabilidad previa (por ejemplo, efecto de regularización) | | <strong>Complejidad computacional</strong> | Generalmente baja | La complejidad puede aumentar según la probabilidad previa (especialmente si no es una distribución conjugada previa) |</p></li>
<li><p><strong>Influencia de la probabilidad previa:</strong></p>
<ul>
<li><strong>Distribución previa no informativa (Non-informative Prior):</strong> Cuando la probabilidad previa sigue una distribución uniforme, como <span class="math inline">\(p(\theta) \propto 1\)</span> (constante), la estimación MAP es idéntica a la estimación MLE.</li>
<li><strong>Distribución previa informativa (Informative Prior):</strong> Cuando la probabilidad previa sigue una distribución específica (por ejemplo, normal o beta), la estimación MAP se ve influenciada por la probabilidad previa y difiere de la estimación MLE. Cuanto más fuerte es el prior belief representado por la distribución previa, más cercano será el posterior al prior.</li>
</ul></li>
</ul>
</section>
<section id="propiedad-asintótica-de-mle-asymptotic-property" class="level3">
<h3 class="anchored" data-anchor-id="propiedad-asintótica-de-mle-asymptotic-property">4. Propiedad asintótica de MLE (Asymptotic Property)</h3>
<ul>
<li><strong>Consistencia (Consistency):</strong>
<ul>
<li>Cuando el tamaño de la muestra <span class="math inline">\(n\)</span> tiende a infinito, el estimador MLE <span class="math inline">\(\hat{\theta}_{MLE}\)</span> converge en probabilidad al parámetro real <span class="math inline">\(\theta_0\)</span>. <span class="math display">\[\hat{\theta}_{MLE} \xrightarrow{p} \theta_0 \text{ as } n \rightarrow \infty\]</span></li>
</ul></li>
<li><strong>Normalidad Asintótica (Asymptotic Normality):</strong>
<ul>
<li>Cuando el tamaño de la muestra <span class="math inline">\(n\)</span> es suficientemente grande, la distribución del estimador MLE <span class="math inline">\(\hat{\theta}_{MLE}\)</span> se aproxima a la siguiente distribución normal. <span class="math display">\[\sqrt{n}(\hat{\theta}_{MLE} - \theta_0) \xrightarrow{d} N(0, I(\theta_0)^{-1})\]</span>
<ul>
<li><span class="math inline">\(I(\theta_0)\)</span>: Matriz de Información de Fisher (FIM)
<ul>
<li><span class="math inline">\(I(\theta) = -E[\frac{\partial^2}{\partial \theta^2} l(\theta; x_1, ...,x_n)]\)</span> (en el caso de un solo parámetro)</li>
<li>La FIM representa la curvatura de la función log-verosimilitud y significa la cantidad de información sobre el parámetro.</li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Eficiencia (Efficiency):</strong>
<ul>
<li>El MLE es un estimador eficiente que asintóticamente alcanza el límite inferior de Cramér–Rao (CRLB). Tiene la varianza asintótica más pequeña en comparación con otros estimadores insesgados.</li>
</ul></li>
</ul>
</section>
</section>
</div>
</div>
</section>
</section>
<section id="fundamentos-de-la-teoría-de-la-información" class="level3">
<h3 class="anchored">2.3.3 Fundamentos de la teoría de la información</h3>
<blockquote class="blockquote">
<p><strong>Desafío:</strong> ¿Cómo medir la cantidad de información y cuantificar la incertidumbre?</p>
<p><strong>Angustia del investigador:</strong> Claude Shannon se enfrentó a preguntas fundamentales sobre la transmisión eficiente y la compresión de la información en sistemas de comunicación. Necesitaba una base teórica para cuantificar la información, determinar hasta qué punto se podía comprimir los datos sin pérdida de información, y cómo transmitir la máxima cantidad de información de manera estable a través de canales ruidosos.</p>
</blockquote>
<p>La teoría de la información es una teoría matemática que trata sobre la compresión, transmisión y almacenamiento de datos, y desempeña un papel crucial en la evaluación y optimización del rendimiento de los modelos en el aprendizaje profundo. En esta sección, exploraremos conceptos clave de la teoría de la información, como la entropía, la información mutua y la divergencia KL.</p>
<section id="entropía" class="level4">
<h4 class="anchored" data-anchor-id="entropía">Entropía</h4>
<p>La entropía es una medida de la incertidumbre de la información. La entropía H(P) de una distribución de probabilidad P se define como sigue:</p>
<p><span class="math display">\[H(P) = -\sum_{x} P(x) \log P(x)\]</span></p>
<p>Aquí, x representa todos los eventos posibles. Las principales características de la entropía son las siguientes.</p>
<ol type="1">
<li>No negatividad: <span class="math inline">\(H(P) ≥ 0\)</span></li>
<li>Máxima en distribuciones uniformes: La entropía es máxima cuando todas las probabilidades de los eventos son iguales.</li>
<li>Entropía cero para eventos seguros: Si <span class="math inline">\(P(x) = 1\)</span>, entonces <span class="math inline">\(H(P) = 0\)</span></li>
</ol>
<p>En el aprendizaje profundo, la entropía se utiliza principalmente como base para la función de pérdida de entropía cruzada, que es común en problemas de clasificación. El siguiente ejemplo calcula la entropía para diferentes distribuciones de probabilidad y visualiza la entropía de una distribución binaria.</p>
<div id="cell-35" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_02.information_theory <span class="im">import</span> calculate_entropy</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>calculate_entropy()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Entropy of fair coin: 0.69
Entropy of biased coin: 0.33
Entropy of fair die: 1.39</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="02_Matemáticas de deep learning_files/figure-html/cell-10-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="información-mutua" class="level4">
<h4 class="anchored" data-anchor-id="información-mutua">Información mutua</h4>
<p>La información mutua (Mutual Information) mide la dependencia entre dos variables aleatorias X y Y. Matemáticamente, se define como sigue.</p>
<p><span class="math display">\[I(X;Y) = \sum_{x}\sum_{y} P(x,y) \log \frac{P(x,y)}{P(x)P(y)}\]</span></p>
<p>Las principales características de la información mutua son las siguientes:</p>
<ol type="1">
<li>No negatividad: <span class="math inline">\(I(X;Y) \ge 0\)</span></li>
<li>Simetría: <span class="math inline">\(I(X;Y) = I(Y;X)\)</span></li>
<li>Es cero cuando X y Y son independientes: Si X y Y son independientes, entonces <span class="math inline">\(I(X;Y) = 0\)</span></li>
</ol>
<p>La información mutua se utiliza en diversas tareas de aprendizaje automático, como selección de características y reducción de dimensionalidad. El siguiente ejemplo calcula y visualiza la información mutua para una distribución de probabilidad conjunta simple.</p>
<div id="cell-37" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_02.information_theory <span class="im">import</span> mutual_information_example</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>mutual_information_example()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Mutual Information: 0.0058</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="02_Matemáticas de deep learning_files/figure-html/cell-11-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="divergencia-kl" class="level4">
<h4 class="anchored">Divergencia KL</h4>
<p>La divergencia KL (Kullback-Leibler) es un método para medir la diferencia entre dos distribuciones de probabilidad P y Q. La divergencia KL de Q con respecto a P se define como sigue.</p>
<p><span class="math display">\[D_{KL}(P||Q) = \sum_{x} P(x) \log \frac{P(x)}{Q(x)}\]</span></p>
<p>Las principales características de la divergencia KL son las siguientes:</p>
<ol type="1">
<li>No negatividad: <span class="math inline">\(D_{KL}(P||Q) \ge 0\)</span></li>
<li>Es cero solo si P = Q: <span class="math inline">\(D_{KL}(P||Q) = 0\)</span> si y solo si <span class="math inline">\(P = Q\)</span></li>
<li>Asimetría: Generalmente <span class="math inline">\(D_{KL}(P||Q) \ne D_{KL}(Q||P)\)</span></li>
</ol>
<p>La divergencia KL se utiliza en el aprendizaje profundo de las siguientes maneras:</p>
<ol type="1">
<li>Inferencia variacional: Se utiliza para minimizar la diferencia entre una distribución aproximada y una distribución real.</li>
<li>Compresión de modelos: Se utiliza en redes de maestro-alumno para la destilación de conocimiento.</li>
<li>Detección de anomalías: Se utiliza para medir la diferencia con respecto a la distribución de datos normales.</li>
</ol>
<p>Los conceptos de la teoría de la información están estrechamente relacionados entre sí. Por ejemplo, la información mutua puede expresarse como la diferencia entre la entropía y la entropía condicional.</p>
<p><span class="math inline">\(I(X;Y) = H(X) - H(X|Y)\)</span></p>
<p>Además, la divergencia KL se puede representar como la diferencia entre la entropía cruzada y la entropía.</p>
<p><span class="math inline">\(D_{KL}(P||Q) = H(P,Q) - H(P)\)</span></p>
<p>Aquí, <span class="math inline">\(H(P,Q)\)</span> es la entropía cruzada de <span class="math inline">\(P\)</span> y <span class="math inline">\(Q\)</span>. A continuación se calcula la divergencia KL entre dos distribuciones de probabilidad y se visualizan las distribuciones.</p>
<div id="cell-39" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_02.information_theory <span class="im">import</span> kl_divergence_example</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>kl_divergence_example()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>KL(P||Q): 0.0823
KL(Q||P): 0.0872</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="02_Matemáticas de deep learning_files/figure-html/cell-12-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Estos conceptos de la teoría de la información se aplican ampliamente en el diseño y optimización de modelos de aprendizaje profundo. Por ejemplo, se utilizan de diversas maneras, como combinar el error de reconstrucción y la divergencia KL en la función de pérdida del autoencoder, o usar la divergencia KL como condición de restricción para la optimización de políticas en el aprendizaje por refuerzo.</p>
<p>En el siguiente capítulo examinaremos cómo estos conceptos de probabilidad, estadística y teoría de la información se aplican en modelos de aprendizaje profundo reales.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Inmersión profunda: conceptos clave de la teoría de la información">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Inmersión profunda: conceptos clave de la teoría de la información
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse">
<section id="teoría-de-la-información-conceptos-clave---information-content-cross-entropy-kl-divergence-mutual-information" class="level2 callout-body-container callout-body">
<h2 class="anchored" data-anchor-id="teoría-de-la-información-conceptos-clave---information-content-cross-entropy-kl-divergence-mutual-information">Teoría de la Información Conceptos Clave - Information Content, Cross Entropy, KL-Divergence, Mutual Information</h2>
<section id="information-content-self-information" class="level3">
<h3 class="anchored" data-anchor-id="information-content-self-information">1. Information Content (Self-information)</h3>
<ul>
<li><p><strong>Definición:</strong> La cantidad de información (Information Content, Self-information) representa la cantidad de información que se obtiene cuando ocurre un evento específico. Cuanto más raro es el evento, mayor será su contenido informativo.</p></li>
<li><p><strong>Fórmula:</strong> <span class="math display">\[I(x) = -\log(P(x))\]</span></p>
<ul>
<li><span class="math inline">\(x\)</span>: evento</li>
<li><span class="math inline">\(P(x)\)</span>: probabilidad de que ocurra el evento <span class="math inline">\(x\)</span></li>
<li><span class="math inline">\(\log\)</span>: la base del logaritmo puede ser 2 (unidad: bits), <span class="math inline">\(e\)</span> (unidad: nats), o 10, entre otras. En aprendizaje profundo, se suele usar el logaritmo natural (<span class="math inline">\(e\)</span>).</li>
</ul></li>
<li><p><strong>Explicación Intuitiva:</strong></p>
<ul>
<li><strong>Rarez:</strong> Cuanto menor sea la probabilidad de un evento (raro), mayor será su cantidad de información. Por ejemplo, “el sol sale por el este” es un hecho obvio y tiene poco contenido informativo, mientras que “gané el premio mayor de la lotería hoy” es un evento muy raro y tiene mucho contenido informativo.</li>
<li><strong>Reducción de Incertidumbre:</strong> La cantidad de información puede interpretarse como una medida de cuánto se reduce la incertidumbre antes del evento después de que este ocurre.</li>
</ul></li>
<li><p><strong>Propiedades:</strong></p>
<ul>
<li><span class="math inline">\(0 \le P(x) \le 1\)</span> por lo tanto, <span class="math inline">\(I(x) \ge 0\)</span>.</li>
<li>Si <span class="math inline">\(P(x) = 1\)</span> (evento seguro), entonces <span class="math inline">\(I(x) = 0\)</span>.</li>
<li>Cuanto menor sea <span class="math inline">\(P(x)\)</span>, mayor será <span class="math inline">\(I(x)\)</span>.</li>
<li>Para dos eventos independientes <span class="math inline">\(x\)</span> y <span class="math inline">\(y\)</span>, <span class="math inline">\(I(x, y) = I(x) + I(y)\)</span> (aditividad de la cantidad de información).</li>
</ul></li>
</ul>
</section>
<section id="cross-entropy" class="level3">
<h3 class="anchored" data-anchor-id="cross-entropy">2. Cross Entropy</h3>
<ul>
<li><p><strong>Definición:</strong> La entropía cruzada (Cross Entropy) es una medida que indica cuán diferentes son dos distribuciones de probabilidad <span class="math inline">\(P\)</span> y <span class="math inline">\(Q\)</span>. Si <span class="math inline">\(P\)</span> es la distribución verdadera y <span class="math inline">\(Q\)</span> es la distribución estimada, la entropía cruzada representa el número promedio de bits necesarios para representar <span class="math inline">\(P\)</span> utilizando <span class="math inline">\(Q\)</span>.</p></li>
<li><p><strong>Derivación:</strong></p>
<ol type="1">
<li><strong>Cantidad de Información:</strong> La cantidad de información del evento <span class="math inline">\(x\)</span> que sigue la distribución verdadera <span class="math inline">\(P\)</span>: <span class="math inline">\(I(x) = -\log P(x)\)</span></li>
<li><strong>Cantidad de Información Promedio (Entropía):</strong> La cantidad de información promedio (entropía) para la distribución verdadera <span class="math inline">\(P\)</span>: <span class="math inline">\(H(P) = -\sum_{x} P(x) \log P(x)\)</span></li>
<li><strong>Uso de Distribución Estimada:</strong> Al usar la distribución estimada <span class="math inline">\(Q\)</span> para representar la distribución verdadera <span class="math inline">\(P\)</span>, la cantidad de información para cada evento <span class="math inline">\(x\)</span>: <span class="math inline">\(-\log Q(x)\)</span></li>
<li><strong>Entropía Cruzada:</strong> La cantidad de información promedio al usar la distribución estimada <span class="math inline">\(Q\)</span> para representar la distribución verdadera <span class="math inline">\(P\)</span>: <span class="math display">\[H(P, Q) = -\sum_{x} P(x) \log Q(x)\]</span></li>
</ol></li>
<li><p><strong>Explicación Intuitiva:</strong></p>
<ul>
<li>Cuanto más similares sean <span class="math inline">\(P\)</span> y <span class="math inline">\(Q\)</span>, menor será la entropía cruzada.</li>
<li>Si <span class="math inline">\(P = Q\)</span>, la entropía cruzada alcanza su valor mínimo (entropía <span class="math inline">\(H(P)\)</span>).</li>
<li>Cuanto más diferentes sean <span class="math inline">\(P\)</span> y <span class="math inline">\(Q\)</span>, mayor será la entropía cruzada. Es decir, si la distribución estimada no refleja bien la distribución real, se produce una pérdida de información.</li>
</ul></li>
<li><p><strong>Binary Cross Entropy (BCE):</strong></p>
<ul>
<li>Se utiliza en problemas de clasificación binaria con dos clases (0 o 1).</li>
<li><span class="math inline">\(P = [p, 1-p]\)</span> (distribución de probabilidad de la clase real, donde <span class="math inline">\(p\)</span> es la probabilidad de la clase 1)</li>
<li><span class="math inline">\(Q = [q, 1-q]\)</span> (distribución de probabilidad de la clase predicha, donde <span class="math inline">\(q\)</span> es la probabilidad de predecir la clase 1)</li>
<li><span class="math display">\[H(P, Q) = -[p \log q + (1-p) \log (1-q)]\]</span></li>
</ul></li>
<li><p><strong>Categorical Cross Entropy (CCE):</strong></p>
<ul>
<li>Se utiliza en problemas de clasificación multiclase con múltiples clases.</li>
<li><span class="math inline">\(P = [p_1, p_2, ..., p_k]\)</span> (distribución de probabilidad real de la clase, <span class="math inline">\(p_i\)</span> es la probabilidad de la clase <span class="math inline">\(i\)</span>, one-hot encoding)</li>
<li><span class="math inline">\(Q = [q_1, q_2, ..., q_k]\)</span> (distribución de probabilidad predicha de la clase, <span class="math inline">\(q_i\)</span> es la probabilidad de predecir la clase <span class="math inline">\(i\)</span>, softmax)</li>
<li><span class="math display">\[H(P, Q) = -\sum_{i=1}^{k} p_i \log q_i\]</span></li>
</ul></li>
</ul>
</section>
<section id="cross-entropy-y-likelihood" class="level3">
<h3 class="anchored" data-anchor-id="cross-entropy-y-likelihood">3. Cross Entropy y Likelihood</h3>
<ul>
<li><strong>Likelihood (verosimilitud):</strong> La probabilidad de que los datos dados ocurran en un modelo específico (parámetros).</li>
<li><strong>Negative Log-Likelihood (NLL):</strong> El valor logarítmico negativo de la verosimilitud.</li>
<li><strong>Relación entre Cross Entropy y NLL:</strong>
<ul>
<li>En problemas de clasificación, cuando se considera la salida del modelo (distribución de probabilidad predicha) como <span class="math inline">\(Q\)</span> y las etiquetas reales (one-hot encoding) como <span class="math inline">\(P\)</span>, la Cross Entropy es igual a la Negative Log-Likelihood.</li>
<li>Minimizar la Cross Entropy es equivalente a maximizar la Likelihood (Estimación del Máximo de Verosimilitud, MLE).</li>
</ul></li>
<li><strong>Uso en Deep Learning:</strong>
<ul>
<li>En deep learning, utilizar la Cross Entropy como función de pérdida para problemas de clasificación equivale a entrenar el modelo para que su salida siga la distribución de las etiquetas reales (desde una perspectiva MLE).</li>
</ul></li>
</ul>
</section>
<section id="relación-entre-kl-divergence-y-cross-entropy" class="level3">
<h3 class="anchored" data-anchor-id="relación-entre-kl-divergence-y-cross-entropy">4. Relación entre KL-Divergence y Cross Entropy</h3>
<ul>
<li><p><strong>KL-Divergence (Divergencia Kullback-Leibler):</strong></p>
<ul>
<li>Otra manera de medir la diferencia entre dos distribuciones de probabilidad <span class="math inline">\(P\)</span> y <span class="math inline">\(Q\)</span> (no es una distancia, es asimétrica).</li>
<li>La KL-Divergence de <span class="math inline">\(P\)</span> a <span class="math inline">\(Q\)</span> representa la cantidad adicional de información necesaria para representar <span class="math inline">\(P\)</span> usando <span class="math inline">\(Q\)</span>.</li>
<li><span class="math display">\[D_{KL}(P||Q) = \sum_{x} P(x) \log \frac{P(x)}{Q(x)} = \sum_{x} P(x)[\log P(x) - \log Q(x)]\]</span></li>
</ul></li>
<li><p><strong>Relación entre KL-Divergence y Cross Entropy:</strong></p>
<p><span class="math display">\[D_{KL}(P||Q) = \sum_{x} P(x) \log P(x) - \sum_{x} P(x) \log Q(x) =  -\sum_{x} P(x) \log Q(x)  - (-\sum_{x} P(x) \log P(x))\]</span> <span class="math display">\[D_{KL}(P||Q) = H(P, Q) - H(P)\]</span></p>
<ul>
<li><p><span class="math inline">\(H(P,Q)\)</span>: Cross Entropy</p></li>
<li><p><span class="math inline">\(H(P)\)</span>: Entropy</p></li>
<li><p>La KL-Divergence es la diferencia entre la Cross Entropy y la Entropy de <span class="math inline">\(P\)</span>.</p></li>
<li><p>Cuando <span class="math inline">\(P\)</span> está fija, minimizar la Cross Entropy es equivalente a minimizar la KL-Divergence.</p></li>
</ul></li>
</ul>
</section>
<section id="relación-entre-mutual-information-y-conditional-entropy" class="level3">
<h3 class="anchored" data-anchor-id="relación-entre-mutual-information-y-conditional-entropy">5. Relación entre Mutual Information y Conditional Entropy</h3>
<ul>
<li><p><strong>Mutual Information (Información Mutua):</strong></p>
<ul>
<li>Una medida que indica cuánta información comparten dos variables aleatorias <span class="math inline">\(X\)</span> y <span class="math inline">\(Y\)</span>.</li>
<li>Indica cuánto se reduce la incertidumbre de <span class="math inline">\(Y\)</span> al conocer <span class="math inline">\(X\)</span> (o viceversa).</li>
<li><span class="math display">\[I(X;Y) = \sum_{x, y} P(x, y) \log \frac{P(x, y)}{P(x)P(y)}\]</span>
<ul>
<li><span class="math inline">\(P(x,y)\)</span>: distribución de probabilidad conjunta (Joint Probability Distribution)</li>
<li><span class="math inline">\(P(x)\)</span>, <span class="math inline">\(P(y)\)</span>: distribuciones de probabilidad marginales (Marginal Probability Distribution)</li>
</ul></li>
</ul></li>
<li><p><strong>Entropía Condicional (entropía condicional):</strong></p>
<ul>
<li>Representa la incertidumbre de la variable aleatoria <span class="math inline">\(X\)</span> dado que se conoce la variable aleatoria <span class="math inline">\(Y\)</span>. <span class="math display">\[H(X|Y) = -\sum_{y} P(y) \sum_{x} P(x|y) \log P(x|y) =  -\sum_{x,y} P(x,y) \log P(x|y)\]</span></li>
</ul></li>
<li><p><strong>Relación entre Información Mutua y Entropía Condicional</strong>: <span class="math display">\[I(X;Y) = H(X) - H(X|Y) = H(Y) - H(Y|X)\]</span></p>
<ul>
<li>La cantidad de información mutua entre <span class="math inline">\(X\)</span> y <span class="math inline">\(Y\)</span> es igual a la entropía de <span class="math inline">\(X\)</span> menos la entropía condicional de <span class="math inline">\(X\)</span> dado <span class="math inline">\(Y\)</span>.</li>
<li>Muestra cuánto disminuye la incertidumbre sobre <span class="math inline">\(X\)</span> al conocer <span class="math inline">\(Y\)</span>.</li>
</ul></li>
</ul>
</section>
<section id="divergencia-jensenshannon" class="level3">
<h3 class="anchored" data-anchor-id="divergencia-jensenshannon">6. Divergencia Jensen–Shannon</h3>
<ul>
<li><strong>Divergencia Jensen–Shannon (JSD):</strong>
<ul>
<li>Otra forma de medir la distancia entre dos distribuciones de probabilidad <span class="math inline">\(P\)</span> y <span class="math inline">\(Q\)</span>. A diferencia de la divergencia KL, es simétrica (symmetric) y acotada (entre 0 y 1).</li>
<li><span class="math display">\[JSD(P||Q) = \frac{1}{2}D_{KL}(P||M) + \frac{1}{2}D_{KL}(Q||M)\]</span>
<ul>
<li><span class="math inline">\(M = \frac{1}{2}(P + Q)\)</span>: distribución media de <span class="math inline">\(P\)</span> y <span class="math inline">\(Q\)</span></li>
</ul></li>
</ul></li>
<li><strong>Características:</strong>
<ul>
<li>Simetría: <span class="math inline">\(JSD(P||Q) = JSD(Q||P)\)</span></li>
<li>Acotación: <span class="math inline">\(0 \le JSD(P||Q) \le 1\)</span> (cuando se usa logaritmo base 2)</li>
<li>La raíz cuadrada de JSD satisface las condiciones de una función métrica.</li>
</ul></li>
</ul>
</section>
</section>
</div>
</div>
</section>
</section>
<section id="función-de-pérdida" class="level3">
<h3 class="anchored" data-anchor-id="función-de-pérdida">2.3.4 Función de pérdida</h3>
<p>La función de pérdida (Loss Function) es una función que mide cuánto difiere la predicción del modelo de aprendizaje automático de los valores reales. El objetivo del entrenamiento del modelo es encontrar los parámetros (pesos y sesgos) que minimicen el valor de esta función de pérdida. La elección de una función de pérdida adecuada tiene un gran impacto en el rendimiento del modelo, por lo tanto, debe seleccionarse cuidadosamente según el tipo de problema y las características de los datos.</p>
<section id="definición-de-la-función-de-pérdida" class="level4">
<h4 class="anchored" data-anchor-id="definición-de-la-función-de-pérdida">Definición de la función de pérdida</h4>
<p>En general, la función de pérdida <span class="math inline">\(L\)</span> se puede expresar como sigue cuando <span class="math inline">\(\theta\)</span> son los parámetros del modelo y <span class="math inline">\((x_i, y_i)\)</span> es un punto de datos. (Aquí, <span class="math inline">\(y_i\)</span> es el valor real y <span class="math inline">\(f(x_i; \theta)\)</span> es el valor predicho por el modelo)</p>
<p><span class="math inline">\(L(\theta) = \frac{1}{N} \sum_{i=1}^{N} l(y_i, f(x_i; \theta))\)</span></p>
<p><span class="math inline">\(N\)</span> es el número de puntos de datos, y <span class="math inline">\(l\)</span> es la función que representa la pérdida para un punto de datos individual (loss term).</p>
</section>
<section id="funciones-de-pérdida-principales" class="level4">
<h4 class="anchored" data-anchor-id="funciones-de-pérdida-principales">Funciones de pérdida principales</h4>
<p>A continuación se presentan las funciones de pérdida más comúnmente utilizadas en aprendizaje automático y aprendizaje profundo.</p>
<section id="error-cuadrático-medio-mean-squared-error-mse" class="level5">
<h5 class="anchored" data-anchor-id="error-cuadrático-medio-mean-squared-error-mse">1. Error cuadrático medio (Mean Squared Error, MSE)</h5>
<ul>
<li><strong>Fórmula:</strong> <span class="math inline">\(MSE = \frac{1}{N} \sum_{i=1}^N (y_i - \hat{y}_i)^2\)</span> (<span class="math inline">\(y_i\)</span>: valor real, <span class="math inline">\(\hat{y}_i\)</span>: valor predicho)</li>
<li><strong>Características:</strong>
<ul>
<li>Dado que se eleva al cuadrado el error, es sensible a los valores atípicos (outliers).</li>
<li>Es diferenciable y una función convexa, lo que facilita encontrar la solución óptima mediante métodos de descenso de gradiente.</li>
</ul></li>
<li><strong>Uso:</strong> Se utiliza principalmente en problemas de regresión.</li>
</ul>
</section>
<section id="error-absoluto-medio-mean-absolute-error-mae" class="level5">
<h5 class="anchored" data-anchor-id="error-absoluto-medio-mean-absolute-error-mae">2. Error absoluto medio (Mean Absolute Error, MAE)</h5>
<ul>
<li><strong>Fórmula:</strong> <span class="math inline">\(MAE = \frac{1}{N} \sum_{i=1}^N |y_i - \hat{y}_i|\)</span></li>
<li><strong>Características:</strong>
<ul>
<li>Es menos sensible a los valores atípicos que el MSE.</li>
<li>No es diferenciable en x=0, pero puede ser manejado por frameworks de aprendizaje profundo mediante diferenciación automática.</li>
</ul></li>
<li><strong>Uso:</strong> Se utiliza en problemas de regresión.</li>
</ul>
</section>
<section id="pérdida-de-entropía-cruzada-cross-entropy-loss" class="level5">
<h5 class="anchored" data-anchor-id="pérdida-de-entropía-cruzada-cross-entropy-loss">3. Pérdida de entropía cruzada (Cross-Entropy Loss)</h5>
<ul>
<li><strong>Fórmula:</strong>
<ul>
<li><strong>Clasificación binaria (Binary Classification):</strong> <span class="math inline">\(L = -\frac{1}{N} \sum_{i=1}^N [y_i \log(\hat{y}_i) + (1-y_i) \log(1-\hat{y}_i)]\)</span></li>
<li><strong>Clasificación multiclase (Multi-class Classification):</strong> <span class="math inline">\(L = -\frac{1}{N} \sum_{i=1}^N \sum_{c=1}^{C} y_{ic} \log(\hat{y}_{ic})\)</span> (<span class="math inline">\(C\)</span>: número de clases)</li>
</ul></li>
<li><strong>Características:</strong>
<ul>
<li>Tiende a converger más rápidamente en problemas de clasificación.</li>
<li>Se utiliza junto con la función de activación softmax en la capa de salida.</li>
</ul></li>
<li><strong>Uso:</strong> Problemas de clasificación (clasificación binaria, clasificación multiclase)</li>
</ul>
</section>
<section id="pérdida-del-borde-hinge-loss" class="level5">
<h5 class="anchored" data-anchor-id="pérdida-del-borde-hinge-loss">4. Pérdida del borde (Hinge Loss)</h5>
<ul>
<li><strong>Fórmula:</strong> <span class="math inline">\(L = \max(0, 1 - y \cdot f(x))\)</span> (<span class="math inline">\(y\)</span>: {-1, 1} clase real, <span class="math inline">\(f(x)\)</span>: valor predicho por el modelo)</li>
<li><strong>Características:</strong>
<ul>
<li>Maximiza el margen (margin) entre “correcto” y “incorrecto”.</li>
<li>No es diferenciable en x=1.</li>
</ul></li>
<li><strong>Uso:</strong> Se utiliza principalmente en problemas de clasificación binaria, como en las máquinas de vectores de soporte (SVM).</li>
</ul>
</section>
</section>
<section id="criterios-para-elegir-la-función-de-pérdida" class="level4">
<h4 class="anchored" data-anchor-id="criterios-para-elegir-la-función-de-pérdida">Criterios para elegir la función de pérdida</h4>
<ul>
<li><strong>Tipo de problema:</strong> La elección de la función de pérdida adecuada depende de si el problema es de regresión o clasificación.</li>
<li><strong>Características de los datos:</strong> Factores como la presencia de valores atípicos y el desequilibrio de clases pueden influir en la selección de la función de pérdida apropiada.</li>
<li><strong>Modelo</strong>: La elección de la función de pérdida también puede depender del modelo que se esté utilizando.</li>
</ul>
</section>
<section id="funciones-de-pérdida-adicionales" class="level4">
<h4 class="anchored">Funciones de pérdida adicionales</h4>
<ul>
<li><strong>Divergencia Kullback-Leibler (KLD):</strong> mide la diferencia entre dos distribuciones de probabilidad P y Q. Se utiliza principalmente en modelos generativos como el Variational Autoencoder (VAE).</li>
<li><strong>Focal Loss:</strong> una función de pérdida que ajusta la Cross-Entropy para funcionar bien con datos desequilibrados. Se utiliza principalmente en problemas de detección de objetos.</li>
<li><strong>Huber Loss:</strong> combina las características del MSE y el MAE, es robusto a los valores atípicos y diferenciable.</li>
<li><strong>Log-Cosh Loss:</strong> similar al Huber Loss, pero con la ventaja de ser dos veces diferenciable en todos los puntos.</li>
<li><strong>Contrastive Loss:</strong> utilizado en redes Siamesas, aprende incrustaciones que colocan pares de muestras similares cerca y pares de muestras no similares lejos entre sí.</li>
<li><strong>Triplet Loss:</strong> utiliza tres muestras: Anchor, Positive y Negative, para aprender incrustaciones que minimicen la distancia entre el Anchor y la muestra Positive mientras maximiza la distancia entre el Anchor y la muestra Negative.</li>
<li><strong>CTC Loss:</strong> una función de pérdida utilizada en reconocimiento de voz, reconocimiento de escritura, etc., cuando las longitudes de las secuencias de entrada y salida difieren.</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled" title="Haga clic para ver el contenido (deep dive: análisis detallado de la función de pérdida)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-10-contents" aria-controls="callout-10" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Haga clic para ver el contenido (deep dive: análisis detallado de la función de pérdida)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-10" class="callout-10-contents callout-collapse collapse">
<section id="análisis-profundo-de-la-función-de-pérdida" class="level3 callout-body-container callout-body">
<h3 class="anchored" data-anchor-id="análisis-profundo-de-la-función-de-pérdida">Análisis profundo de la función de pérdida</h3>
<section id="función-de-pérdida-y-estimación-de-máxima-verosimilitud-maximum-likelihood-estimation-mle" class="level4">
<h4 class="anchored" data-anchor-id="función-de-pérdida-y-estimación-de-máxima-verosimilitud-maximum-likelihood-estimation-mle">Función de pérdida y estimación de máxima verosimilitud (Maximum Likelihood Estimation, MLE)</h4>
<p>Muchos modelos de aprendizaje automático pueden explicarse desde la perspectiva de la estimación de máxima verosimilitud (MLE). El MLE es un método para encontrar los parámetros del modelo que mejor explican los datos observados. Si se asume que los datos son independientes e idénticamente distribuidos (i.i.d.), la función de verosimilitud se define como sigue.</p>
<p><span class="math inline">\(L(\theta) = P(D|\theta) = \prod_{i=1}^{N} P(y_i | x_i; \theta)\)</span></p>
<p>Aquí, <span class="math inline">\(D = \{(x_1, y_1), (x_2, y_2), ..., (x_N, y_N)\}\)</span> es el conjunto de datos de entrenamiento, <span class="math inline">\(\theta\)</span> son los parámetros del modelo. <span class="math inline">\(P(y_i | x_i; \theta)\)</span> es la probabilidad (o densidad de probabilidad) de que el modelo genere <span class="math inline">\(y_i\)</span> dado <span class="math inline">\(x_i\)</span>.</p>
<p>El objetivo del MLE es encontrar los parámetros <span class="math inline">\(\theta\)</span> que maximizan la función de verosimilitud <span class="math inline">\(L(\theta)\)</span>. En la práctica, es más conveniente computacionalmente maximizar la función de log-verosimilitud (log-likelihood function).</p>
<p><span class="math inline">\(\log L(\theta) = \sum_{i=1}^{N} \log P(y_i | x_i; \theta)\)</span></p>
<ul>
<li><p><strong>MSE y MLE:</strong> En el caso de un modelo de regresión lineal, si se asume que los errores siguen una distribución normal con media 0 y varianza <span class="math inline">\(\sigma^2\)</span>, entonces la MLE es equivalente a minimizar el MSE.</p>
<p><span class="math inline">\(P(y_i | x_i; \theta) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(y_i - f(x_i; \theta))^2}{2\sigma^2}\right)\)</span></p>
<p>La función de log-verosimilitud es la siguiente. <span class="math inline">\(\log L(\theta) = -\frac{N}{2}\log(2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^{N}(y_i - f(x_i;\theta))^2\)</span></p>
<p>Excluyendo las constantes, y asumiendo que <span class="math inline">\(\sigma^2\)</span> es constante, maximizar la función de log-verosimilitud es equivalente a minimizar el MSE.</p></li>
<li><p><strong>Cross-Entropy y MLE:</strong> En problemas de clasificación, los valores de salida <span class="math inline">\(\hat{y}_i\)</span> pueden interpretarse como parámetros de una distribución de Bernoulli (clasificación binaria) o multinomial (clasificación multiclase). En este caso, la MLE es equivalente a minimizar la Loss de Cross-Entropy.</p>
<ul>
<li><p><strong>Clasificación binaria (distribución de Bernoulli):</strong> Si <span class="math inline">\(\hat{y_i}\)</span> representa la probabilidad que el modelo predice para <span class="math inline">\(y_i=1\)</span>, <span class="math inline">\(P(y_i|x_i;\theta) = \hat{y_i}^{y_i} (1 - \hat{y_i})^{(1-y_i)}\)</span> Log-verosimilitud: <span class="math inline">\(\log L(\theta) = \sum_{i=1}^{N} [y_i \log(\hat{y}_i) + (1 - y_i)\log(1 - \hat{y}_i)]\)</span></p></li>
<li><p><strong>Clasificación multiclase (Distribución Categórica/Multinomial):</strong> <span class="math inline">\(P(y_i | x_i; \theta) = \prod_{j=1}^{C} \hat{y}_{ij}^{y_{ij}}\)</span> (codificación one-hot) Log-verosimilitud: <span class="math inline">\(\log L(\theta) = \sum_{i=1}^N \sum_{j=1}^C y_{ij} \log(\hat{y}_{ij})\)</span></p></li>
</ul>
<p>Por lo tanto, minimizar la Loss de Cross-Entropy es un proceso equivalente a encontrar los parámetros que mejor modelan la distribución de los datos según MLE.</p></li>
</ul>
</section>
<section id="funciones-de-pérdida-adicionales-kld-focal-loss" class="level4">
<h4 class="anchored" data-anchor-id="funciones-de-pérdida-adicionales-kld-focal-loss">Funciones de pérdida adicionales (KLD, Focal Loss)</h4>
<ul>
<li><p><strong>Divergencia Kullback-Leibler (KLD):</strong></p></li>
<li><p><strong>Descripción:</strong> Mide la diferencia entre dos distribuciones de probabilidad P y Q. P representa la distribución de los datos reales, y Q representa la distribución estimada por el modelo.</p>
<ul>
<li><strong>Fórmula:</strong> <span class="math inline">\(D_{KL}(P||Q) = \sum_{x} P(x) \log \frac{P(x)}{Q(x)}\)</span></li>
<li><strong>Características:</strong>
<ul>
<li>Asimétrica (asymmetric): <span class="math inline">\(D_{KL}(P||Q) \neq D_{KL}(Q||P)\)</span></li>
<li>Siempre mayor o igual a 0: <span class="math inline">\(D_{KL}(P||Q) \ge 0\)</span>, solo cuando <span class="math inline">\(P=Q\)</span> se tiene que <span class="math inline">\(D_{KL}(P||Q) = 0\)</span></li>
<li>Problemas de definición donde P(x) = 0</li>
</ul></li>
<li><strong>Relación con VAEs:</strong>
<ul>
<li>En los autoencoders variacionales (Variational Autoencoder, VAE), la divergencia KL se utiliza para hacer que la distribución a posteriori de las variables latentes sea similar a una distribución previa, como la normal.</li>
<li>La función de pérdida del VAE consta de una pérdida de reconstrucción y un término de divergencia KL.</li>
</ul></li>
</ul></li>
<li><p><strong>Focal Loss:</strong></p>
<ul>
<li><strong>Descripción:</strong> Se propuso para abordar problemas de desequilibrio de clases, especialmente entre ejemplos “fáciles” (easy examples) y ejemplos “difíciles” (hard examples), modificando la Cross-Entropy Loss.</li>
<li><strong>Fórmula:</strong> <span class="math inline">\(FL(p_t) = -\alpha_t (1 - p_t)^\gamma \log(p_t)\)</span>
<ul>
<li><span class="math inline">\(p_t\)</span>: probabilidad predicha por el modelo para la clase correcta</li>
<li><span class="math inline">\(\gamma\)</span>: parámetro de enfoque (<span class="math inline">\(\gamma \ge 0\)</span>, generalmente 2)</li>
<li><span class="math inline">\(\alpha_t\)</span>: pesos por clase (opcional)</li>
</ul></li>
<li><strong>Características:</strong>
<ul>
<li>Si <span class="math inline">\(\gamma = 0\)</span>, es igual a la Cross-Entropy Loss normal.</li>
<li>Si <span class="math inline">\(\gamma &gt; 0\)</span>, disminuye la pérdida de los ejemplos bien clasificados (<span class="math inline">\(p_t\)</span> alto) y mantiene alta la pérdida de los mal clasificados (<span class="math inline">\(p_t\)</span> bajo). Es decir, se centra más en los ejemplos difíciles durante el aprendizaje.</li>
<li>Se pueden ajustar los pesos por clase usando <span class="math inline">\(\alpha_t\)</span> (por ejemplo, dando un peso mayor a las clases con menos muestras).</li>
</ul></li>
<li><strong>Aplicación en detección de objetos:</strong>
<ul>
<li>En problemas de detección de objetos, las áreas de fondo (negative) son mucho más numerosas que las áreas de objeto (positive), lo que provoca un desequilibrio de clases grave.</li>
<li>El Focal Loss ayuda a mitigar este desequilibrio, haciendo que el modelo de detección de objetos se centre más en los objetos reales y no tanto en el fondo durante el aprendizaje.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="diferentes-funciones-de-pérdida-avanzado" class="level4">
<h4 class="anchored" data-anchor-id="diferentes-funciones-de-pérdida-avanzado">Diferentes funciones de pérdida (avanzado)</h4>
<ul>
<li><p><strong>Huber Loss:</strong> Es una función de pérdida que combina las ventajas del MSE y el MAE. Usa el error cuadrático cuando el error es menor a un valor específico (<span class="math inline">\(\delta\)</span>), y el error absoluto cuando el error es grande, lo que la hace robusta frente a valores atípicos y diferenciable.</p>
<p><span class="math inline">\(L_\delta(y, \hat{y}) = \begin{cases}
\frac{1}{2}(y - \hat{y})^2 &amp; \text{si } |y - \hat{y}| \le \delta \\
\delta(|y - \hat{y}| - \frac{1}{2}\delta) &amp; \text{en otro caso}
\end{cases}\)</span></p></li>
<li><p><strong>Log-Cosh Loss:</strong> Se define como <span class="math inline">\(\log(\cosh(y - \hat{y}))\)</span>. Similar al Huber Loss, es robusta frente a valores atípicos y tiene la ventaja de ser dos veces diferenciable en todos los puntos.</p></li>
<li><p><strong>Quantile Loss:</strong> Se utiliza para minimizar el error de predicción en un cuantil específico.</p></li>
<li><p><strong>Contrastive Loss, Triplet Loss:</strong> Se utilizan en redes Siamesas, redes Triplet, y se usan para ajustar la distancia entre pares/tripletas de muestras similares. (Consulte los documentos relevantes para más detalles)</p></li>
<li><p><strong>Connectionist Temporal Classification (CTC) Loss</strong>: Se utiliza cuando la alineación (alignment) entre secuencias de entrada y salida no es clara, como en el reconocimiento de voz y escritura.</p></li>
</ul>
</section>
<section id="guía-para-la-selección-de-funciones-de-pérdida-avanzado" class="level4">
<h4 class="anchored" data-anchor-id="guía-para-la-selección-de-funciones-de-pérdida-avanzado">Guía para la selección de funciones de pérdida (avanzado)</h4>
<ul>
<li><strong>Manejo de valores atípicos:</strong> Si hay muchos valores atípicos y se requiere robustez frente a ellos, puede considerar MAE, Huber Loss, Quantile Loss.</li>
<li><strong>Diferenciabilidad:</strong> Para la optimización basada en el descenso del gradiente, es necesario una función de pérdida diferenciable. Sin embargo, incluso con funciones no diferenciables como Hinge Loss y MAE, se pueden usar subgradientes (subdiferenciales) o la diferenciación automática de marcos de deep learning para resolverlo.</li>
<li><strong>Modelado probabilístico:</strong> Si desea interpretar las salidas del modelo como una distribución de probabilidad, Cross-Entropy Loss es adecuado.</li>
<li><strong>Desbalanceo de clases:</strong> En caso de un desbalanceo de clases severo, puede considerar Focal Loss, Weighted Cross-Entropy.</li>
<li><strong>Salidas múltiples</strong>: Si hay varias salidas y existe una correlación entre ellas, puede combinar las funciones de pérdida para cada salida.</li>
</ul>
<p>Las funciones de pérdida son un elemento crucial que determina el rendimiento de los modelos de deep learning. Se requiere la capacidad de seleccionar una función de pérdida adecuada considerando las características del problema, la distribución de los datos y la estructura del modelo, e incluso diseñar nuevas funciones de pérdida si es necesario.</p>
</section>
</section>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Haga clic para ver el contenido (deep dive: diseño de nuevas funciones de pérdida)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-11-contents" aria-controls="callout-11" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Haga clic para ver el contenido (deep dive: diseño de nuevas funciones de pérdida)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-11" class="callout-11-contents callout-collapse collapse">
<section id="diseño-de-nuevas-funciones-de-pérdida" class="level3 callout-body-container callout-body">
<h3 class="anchored" data-anchor-id="diseño-de-nuevas-funciones-de-pérdida">Diseño de nuevas funciones de pérdida</h3>
<p>Las funciones de pérdida existentes (MSE, Entropía Cruzada, etc.) no siempre son la mejor opción. Dependiendo de las exigencias específicas del problema, la distribución de los datos y la estructura del modelo, puede ser necesario diseñar nuevas funciones de pérdida. El diseño de nuevas funciones de pérdida es una parte importante de la investigación en deep learning y tiene el potencial de mejorar significativamente el rendimiento del modelo.</p>
<section id="casos-en-los-que-se-necesitan-nuevas-funciones-de-pérdida" class="level4">
<h4 class="anchored" data-anchor-id="casos-en-los-que-se-necesitan-nuevas-funciones-de-pérdida">Casos en los que se necesitan nuevas funciones de pérdida</h4>
<ul>
<li><strong>Estructura especial de los datos:</strong> Cuando los datos no siguen distribuciones comunes (Gaussiana, Bernoulli, etc.) o tienen una estructura especial (por ejemplo: orden, rareza, estructura jerárquica, estructura de grafo).</li>
<li><strong>Restricciones especiales del problema:</strong> Cuando se desea imponer restricciones específicas a las predicciones del modelo (por ejemplo: monotonicidad, rareza, equidad, robustez).</li>
<li><strong>Limitaciones de las funciones de pérdida existentes:</strong> Cuando las funciones de pérdida existentes no funcionan bien en un problema específico (por ejemplo: sensibilidad a los valores atípicos, desequilibrio de clases) o no reflejan adecuadamente el objetivo deseado. Cuando se desea optimizar directamente una métrica específica.</li>
<li><strong>Optimización multiobjetivo:</strong> Cuando es necesario combinar varias funciones de pérdida para optimizarlas simultáneamente (por ejemplo: equilibrar precisión predictiva y complejidad del modelo).</li>
<li><strong>Modelos generativos</strong>: Los modelos generativos tienen como objetivo aprender la distribución de los datos, por lo que requieren funciones de pérdida diferentes a las usadas en problemas de clasificación/regresión comunes.</li>
</ul>
</section>
<section id="principios-para-el-diseño-de-nuevas-funciones-de-pérdida" class="level4">
<h4 class="anchored" data-anchor-id="principios-para-el-diseño-de-nuevas-funciones-de-pérdida">Principios para el diseño de nuevas funciones de pérdida</h4>
<p>Al diseñar nuevas funciones de pérdida, se deben considerar los siguientes principios:</p>
<ol type="1">
<li><p><strong>Definición del problema y objetivos:</strong> Se debe definir claramente el problema que se desea resolver y el objetivo final del modelo. La función de pérdida es un elemento clave que define lo que el modelo debe aprender (por ejemplo: si solo se trata de aumentar la precisión de clasificación, mejorar las predicciones para una clase específica, ajustar la ratio de False Positive/False Negative, etc.).</p></li>
<li><p><strong>Validez matemática:</strong></p>
<ul>
<li><strong>Diferenciabilidad (Differentiability):</strong> Para la optimización basada en el descenso del gradiente, la función de pérdida debe ser diferenciable (casi) en todos los puntos. Si existen puntos no diferenciables, se deben poder usar subgradientes (subdiferenciales).</li>
<li><strong>Convexidad (Convexity):</strong> Si la función de pérdida es convexa, se puede garantizar que se encuentra el mínimo global. En el caso de funciones no convexas, se debe diseñar para encontrar buenos mínimos locales.</li>
<li><strong>Prevención del desvanecimiento/explotación del gradiente:</strong> Gradientes demasiado grandes o pequeños pueden hacer que el aprendizaje sea inestable. Se debe tener cuidado de que en situaciones específicas, como el problema “dying ReLU” o el desvanecimiento del gradiente con sigmoid/tanh, el gradiente no se haga 0 o muy pequeño.</li>
<li><strong>Invariancia a la escala</strong>: El valor de la función de pérdida no debe cambiar significativamente según la escala de los datos de entrada o de los parámetros.</li>
</ul></li>
<li><p><strong>Interpretabilidad:</strong> Si la función de pérdida tiene un significado intuitivo, puede ser útil para analizar y depurar el proceso de aprendizaje del modelo. Cada término (term) debe tener un rol y un significado claros. El significado e impacto de los hiperparámetros también deben ser claros.</p></li>
<li><p><strong>Eficiencia computacional:</strong> La función de pérdida se calcula en cada iteración y para todos (o mini-lotes) los puntos de datos, por lo que si el costo de cálculo es muy alto, la velocidad de aprendizaje puede disminuir significativamente.</p></li>
</ol>
</section>
<section id="metodología-para-el-diseño-de-nuevas-funciones-de-pérdida" class="level4">
<h4 class="anchored" data-anchor-id="metodología-para-el-diseño-de-nuevas-funciones-de-pérdida">Metodología para el diseño de nuevas funciones de pérdida</h4>
<ol type="1">
<li><p><strong>Modificación/Combinación de funciones de pérdida existentes:</strong></p>
<ul>
<li><strong>Adición de pesos:</strong> se asignan mayores pesos a ciertos puntos de datos, clases o salidas (por ejemplo: Weighted Cross-Entropy, Focal Loss).</li>
<li><strong>Adición de términos de regularización:</strong> se agregan términos de regularización para limitar la complejidad del modelo o fomentar ciertas propiedades (por ejemplo: L1 regularization, L2 regularization, Elastic Net). También se pueden agregar términos de regularización para suavizar las salidas.</li>
<li><strong>Combinación de múltiples funciones de pérdida:</strong> se combinan linealmente varias funciones de pérdida existentes o se combinan de otras maneras (por ejemplo: Multi-task learning).</li>
<li><strong>Label Smoothing Soft/Hard</strong>: la Regularización por Suavizado de Etiquetas evita que el modelo sea demasiado confiado en las respuestas correctas.</li>
</ul></li>
<li><p><strong>Diseño basado en modelado probabilístico:</strong></p>
<ul>
<li><strong>Estimación de Máxima Verosimilitud (MLE):</strong> se diseña la función de pérdida desde la perspectiva de estimar los parámetros de una distribución asumida para los datos (por ejemplo: MSE es MLE bajo la suposición de una distribución gaussiana, Cross-Entropy es MLE bajo la suposición de una distribución Bernoulli/multinomial).</li>
<li><strong>Inferencia Variacional:</strong> se diseña la función de pérdida (ELBO, Evidence Lower Bound) para aproximar una distribución posterior intractable usando métodos de inferencia aproximada (por ejemplo: Variational Autoencoder).</li>
<li><strong>Verosimilitud Implícita</strong>: en modelos generativos donde es difícil calcular la verosimilitud explícitamente, se utilizan métodos sin verosimilitud (por ejemplo: GAN).</li>
</ul></li>
<li><p><strong>Diseño de funciones de pérdida especializadas para problemas específicos:</strong></p>
<ul>
<li><strong>Función de Pérdida de Ranking:</strong> se diseña una función de pérdida adecuada para problemas de clasificación por ranking (por ejemplo: pairwise ranking loss, listwise ranking loss, margin ranking loss).</li>
<li><strong>Función de Pérdida de Detección de Objetos:</strong> en problemas de detección de objetos, se diseña una función de pérdida que considere la regresión del bounding box y la clasificación de clases simultáneamente (por ejemplo: las funciones de pérdida de YOLO, SSD, Faster R-CNN).</li>
<li><strong>Función de Pérdida de Segmentación:</strong> en problemas de segmentación de imágenes, se diseña una función de pérdida que prediga la clase de cada píxel y minimice la diferencia con el mapa de segmentación ground truth (por ejemplo: Dice Loss, IoU Loss, Tversky Loss).</li>
<li><strong>Función de Pérdida de Modelos Generativos:</strong> funciones de pérdida para generadores y discriminadores en modelos generativos como GAN, VAE (por ejemplo: Wasserstein distance, Adversarial Loss).</li>
<li><strong>Función de Pérdida de Aprendizaje Métrico</strong>: Contrastive Loss, Triplet Loss, N-pair Loss, etc.</li>
<li><strong>Función de Pérdida de Secuencia:</strong> CTC Loss, Cross-Entropy en modelos sequence-to-sequence, etc.</li>
<li><strong>Función de Pérdida de Datos de Grafo</strong>: funciones de pérdida utilizadas en Graph Neural Networks (clasificación de nodos, predicción de enlaces, clasificación de grafos, etc.)</li>
</ul></li>
</ol>
</section>
<section id="precauciones-al-diseñar-nuevas-funciones-de-pérdida" class="level4">
<h4 class="anchored" data-anchor-id="precauciones-al-diseñar-nuevas-funciones-de-pérdida">Precauciones al diseñar nuevas funciones de pérdida</h4>
<ul>
<li><strong>Complejidad excesiva:</strong> una función de pérdida demasiado compleja puede dificultar el aprendizaje y causar sobreajuste (overfitting). Es mejor comenzar con funciones de pérdida simples e incrementar gradualmente la complejidad.</li>
<li><strong>Ajuste de hiperparámetros:</strong> una nueva función de pérdida a menudo incluye hiperparámetros adicionales (por ejemplo, <span class="math inline">\(\gamma\)</span> en Focal Loss, pesos en combinaciones ponderadas). Es importante ajustar estos hiperparámetros adecuadamente y encontrar sus valores óptimos mediante técnicas como la validación cruzada (cross-validation).</li>
<li><strong>Fundamento teórico/empírico:</strong> al proponer una nueva función de pérdida, es necesario presentar un fundamento teórico (por ejemplo, características matemáticas específicas del problema, relación con el MLE) o empírico (por ejemplo, resultados experimentales) que explique por qué la función de pérdida funciona bien.</li>
</ul>
<p>Diseñar una nueva función de pérdida es un proceso creativo, pero también requiere un enfoque cuidadoso. Es importante comprender profundamente la naturaleza del problema, diseñar sobre principios matemáticos/estadísticos y validar el rendimiento a través de experimentos rigurosos.</p>
</section>
</section>
</div>
</div>
<p>En este capítulo hemos examinado las bases matemáticas del aprendizaje profundo. Hemos visto cómo los conceptos de diferentes campos, como el álgebra lineal, el cálculo, la probabilidad y estadística, y la teoría de la información, se utilizan en el diseño, el aprendizaje y el análisis de los modelos de aprendizaje profundo. Estas herramientas matemáticas son esenciales para comprender las complejas estructuras de redes neuronales, desarrollar algoritmos de aprendizaje eficientes, evaluar y mejorar el rendimiento del modelo. También desempeñan un papel importante en encontrar nuevas vías de avance en la investigación de aprendizaje profundo.</p>
</section>
</section>
</section>
<section id="ejercicios-de-práctica" class="level2">
<h2 class="anchored" data-anchor-id="ejercicios-de-práctica">Ejercicios de práctica</h2>
<section id="álgebra-lineal" class="level3">
<h3 class="anchored">1. Álgebra lineal</h3>
<section id="básico" class="level4">
<h4 class="anchored" data-anchor-id="básico">Básico</h4>
<ol type="1">
<li><p>Calcule el producto escalar (dot product) de los vectores <span class="math inline">\(\mathbf{a} = \begin{bmatrix} 1 \\ 2 \end{bmatrix}\)</span> y <span class="math inline">\(\mathbf{b} = \begin{bmatrix} 3 \\ 4 \end{bmatrix}\)</span>.</p></li>
<li><p>Calcule el producto <span class="math inline">\(\mathbf{Ab}\)</span> de la matriz <span class="math inline">\(\mathbf{A} = \begin{bmatrix} 1 &amp; 2 \\ 3 &amp; 4 \end{bmatrix}\)</span> y el vector <span class="math inline">\(\mathbf{b} = \begin{bmatrix} 5 \\ 6 \end{bmatrix}\)</span>.</p></li>
<li><p>Genere una matriz identidad (identity matrix) de tamaño 2x2.</p></li>
<li><p>Escriba las definiciones de la norma L1 y la norma L2 de un vector, y calcule la norma L1 y la norma L2 del vector <span class="math inline">\(\mathbf{v} = \begin{bmatrix} 3 \\ -4 \end{bmatrix}\)</span>.</p></li>
</ol>
</section>
<section id="aplicado" class="level4">
<h4 class="anchored" data-anchor-id="aplicado">Aplicado</h4>
<ol type="1">
<li><p>Encuentre los valores propios (eigenvalues) y vectores propios (eigenvectors) de la matriz <span class="math inline">\(\mathbf{A} = \begin{bmatrix} 2 &amp; 1 \\ 1 &amp; 2 \end{bmatrix}\)</span>.</p></li>
<li><p>Determine si existe la matriz inversa de la matriz dada, y si es así, calcule la inversa. <span class="math inline">\(\mathbf{A} = \begin{bmatrix} 1 &amp; 2 \\ 3 &amp; 4 \end{bmatrix}\)</span></p></li>
<li><p>Dada una transformación lineal <span class="math inline">\(T(\mathbf{x}) = \mathbf{Ax}\)</span>, explique cómo se transforman los vectores base <span class="math inline">\(\mathbf{e_1} = \begin{bmatrix} 1 \\ 0 \end{bmatrix}\)</span> y <span class="math inline">\(\mathbf{e_2} = \begin{bmatrix} 0 \\ 1 \end{bmatrix}\)</span>, y visualice el resultado. (Donde, <span class="math inline">\(\mathbf{A} = \begin{bmatrix} 2 &amp; -1 \\ 1 &amp; 1 \end{bmatrix}\)</span>)</p></li>
<li><p>Calcule el rango (rank) de la siguiente matriz. <span class="math inline">\(\mathbf{A} = \begin{bmatrix} 1 &amp; 2 &amp; 3 \\ 4 &amp; 5 &amp; 6 \\ 7 &amp; 8 &amp; 9 \end{bmatrix}\)</span></p></li>
</ol>
</section>
<section id="avanzado" class="level4">
<h4 class="anchored">Avanzado</h4>
<ol type="1">
<li><p>Escriba la definición de descomposición en valores singulares (Singular Value Decomposition, SVD) y realice la descomposición SVD de la matriz dada. <span class="math inline">\(\mathbf{A} = \begin{bmatrix} 1 &amp; 2 \\ 3 &amp; 4 \\ 5 &amp; 6 \end{bmatrix}\)</span></p></li>
<li><p>Explique el objetivo y el proceso del análisis de componentes principales (Principal Component Analysis, PCA) y realice un PCA en el conjunto de datos dado para reducir la dimensionalidad a una dimensión.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">2</span>], [<span class="dv">2</span>, <span class="dv">3</span>], [<span class="dv">3</span>, <span class="dv">4</span>], [<span class="dv">4</span>, <span class="dv">5</span>], [<span class="dv">5</span>, <span class="dv">6</span>]])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p>Encuentre las bases del espacio nulo (null space) y del espacio de columnas (column space) de la siguiente matriz. <span class="math inline">\(\mathbf{A} = \begin{bmatrix} 1 &amp; 2 &amp; 3 \\ 4 &amp; 5 &amp; 6 \\ 7 &amp; 8 &amp; 9 \end{bmatrix}\)</span></p></li>
<li><p>Escriba la definición de descomposición QR y realice la descomposición QR de la matriz dada. (La descomposición QR es un método numéricamente estable que se usa para encontrar soluciones a ecuaciones lineales o resolver problemas de valores propios.) <span class="math inline">\(\mathbf{A} = \begin{bmatrix} 1 &amp; 2 \\ 3 &amp; 4 \end{bmatrix}\)</span></p></li>
</ol>
<div class="callout callout-style-default callout-note callout-titled" title="Haga clic para ver el contenido (solución)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-12-contents" aria-controls="callout-12" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Haga clic para ver el contenido (solución)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-12" class="callout-12-contents callout-collapse collapse">
<section id="soluciones-a-los-ejercicios" class="level2 callout-body-container callout-body">
<h2 class="anchored" data-anchor-id="soluciones-a-los-ejercicios">Soluciones a los Ejercicios</h2>
<section id="álgebra-lineal-1" class="level3">
<h3 class="anchored" data-anchor-id="álgebra-lineal-1">1. Álgebra Lineal</h3>
<section id="básico-1" class="level4">
<h4 class="anchored" data-anchor-id="básico-1">Básico</h4>
<ol type="1">
<li><p><strong>Producto interno:</strong> <span class="math inline">\(\mathbf{a} \cdot \mathbf{b} = (1)(3) + (2)(4) = 3 + 8 = 11\)</span></p></li>
<li><p><strong>Producto matriz-vector:</strong> <span class="math inline">\(\mathbf{Ab} = \begin{bmatrix} 1 &amp; 2 \\ 3 &amp; 4 \end{bmatrix} \begin{bmatrix} 5 \\ 6 \end{bmatrix} = \begin{bmatrix} (1)(5) + (2)(6) \\ (3)(5) + (4)(6) \end{bmatrix} = \begin{bmatrix} 17 \\ 39 \end{bmatrix}\)</span></p></li>
<li><p><strong>Matriz identidad 2x2:</strong> <span class="math inline">\(\mathbf{I} = \begin{bmatrix} 1 &amp; 0 \\ 0 &amp; 1 \end{bmatrix}\)</span></p></li>
<li><p><strong>Normas L1, L2:</strong></p>
<ul>
<li>Norma L1 (Distancia de Manhattan): <span class="math inline">\(||\mathbf{v}||_1 = \sum_{i} |v_i|\)</span></li>
<li>Norma L2 (Distancia Euclidiana): <span class="math inline">\(||\mathbf{v}||_2 = \sqrt{\sum_{i} v_i^2}\)</span></li>
</ul>
<p><span class="math inline">\(\mathbf{v} = \begin{bmatrix} 3 \\ -4 \end{bmatrix}\)</span> <span class="math inline">\(||\mathbf{v}||_1 = |3| + |-4| = 3 + 4 = 7\)</span> <span class="math inline">\(||\mathbf{v}||_2 = \sqrt{(3)^2 + (-4)^2} = \sqrt{9 + 16} = \sqrt{25} = 5\)</span></p></li>
</ol>
</section>
<section id="aplicado-1" class="level4">
<h4 class="anchored" data-anchor-id="aplicado-1">Aplicado</h4>
<ol type="1">
<li><p><strong>Valores propios, vectores propios:</strong> <span class="math inline">\(\mathbf{A} = \begin{bmatrix} 2 &amp; 1 \\ 1 &amp; 2 \end{bmatrix}\)</span></p>
<ul>
<li><p><strong>Ecuación característica:</strong> <span class="math inline">\(\det(\mathbf{A} - \lambda\mathbf{I}) = 0\)</span> <span class="math inline">\((2-\lambda)^2 - (1)(1) = 0\)</span> <span class="math inline">\(\lambda^2 - 4\lambda + 3 = 0\)</span> <span class="math inline">\((\lambda - 3)(\lambda - 1) = 0\)</span> <span class="math inline">\(\lambda_1 = 3\)</span>, <span class="math inline">\(\lambda_2 = 1\)</span></p></li>
<li><p><strong>Vector propio (λ = 3):</strong> <span class="math inline">\((\mathbf{A} - 3\mathbf{I})\mathbf{v} = 0\)</span> <span class="math inline">\(\begin{bmatrix} -1 &amp; 1 \\ 1 &amp; -1 \end{bmatrix} \begin{bmatrix} x \\ y \end{bmatrix} = \begin{bmatrix} 0 \\ 0 \end{bmatrix}\)</span> <span class="math inline">\(x = y\)</span>, <span class="math inline">\(\mathbf{v_1} = \begin{bmatrix} 1 \\ 1 \end{bmatrix}\)</span> (o cualquier múltiplo constante)</p></li>
<li><p><strong>Vector propio (λ = 1):</strong> <span class="math inline">\((\mathbf{A} - \mathbf{I})\mathbf{v} = 0\)</span> <span class="math inline">\(\begin{bmatrix} 1 &amp; 1 \\ 1 &amp; 1 \end{bmatrix} \begin{bmatrix} x \\ y \end{bmatrix} = \begin{bmatrix} 0 \\ 0 \end{bmatrix}\)</span> <span class="math inline">\(x = -y\)</span>, <span class="math inline">\(\mathbf{v_2} = \begin{bmatrix} -1 \\ 1 \end{bmatrix}\)</span> (o cualquier múltiplo constante)</p></li>
</ul></li>
<li><p><strong>Matriz inversa:</strong> <span class="math inline">\(\mathbf{A} = \begin{bmatrix} 1 &amp; 2 \\ 3 &amp; 4 \end{bmatrix}\)</span></p></li>
</ol>
<ul>
<li><strong>Determinación de existencia:</strong> <span class="math inline">\(\det(\mathbf{A}) = (1)(4) - (2)(3) = 4 - 6 = -2 \neq 0\)</span>. Existe la matriz inversa.
<ul>
<li><strong>Cálculo de la matriz inversa:</strong> <span class="math inline">\(\mathbf{A}^{-1} = \frac{1}{\det(\mathbf{A})} \begin{bmatrix} 4 &amp; -2 \\ -3 &amp; 1 \end{bmatrix} = \frac{1}{-2} \begin{bmatrix} 4 &amp; -2 \\ -3 &amp; 1 \end{bmatrix} = \begin{bmatrix} -2 &amp; 1 \\ 1.5 &amp; -0.5 \end{bmatrix}\)</span></li>
</ul></li>
</ul>
<ol start="3" type="1">
<li><strong>Visualización de la transformación lineal:</strong>
<ul>
<li><span class="math inline">\(T(\mathbf{e_1}) = \mathbf{A}\mathbf{e_1} = \begin{bmatrix} 2 &amp; -1 \\ 1 &amp; 1 \end{bmatrix} \begin{bmatrix} 1 \\ 0 \end{bmatrix} = \begin{bmatrix} 2 \\ 1 \end{bmatrix}\)</span></li>
<li><span class="math inline">\(T(\mathbf{e_2}) = \mathbf{A}\mathbf{e_2} = \begin{bmatrix} 2 &amp; -1 \\ 1 &amp; 1 \end{bmatrix} \begin{bmatrix} 0 \\ 1 \end{bmatrix} = \begin{bmatrix} -1 \\ 1 \end{bmatrix}\)</span></li>
<li>Visualización: Se trazan en el plano de coordenadas las transformaciones de los vectores base originales <span class="math inline">\(\mathbf{e_1}\)</span>, <span class="math inline">\(\mathbf{e_2}\)</span> a <span class="math inline">\(\begin{bmatrix} 2 \\ 1 \end{bmatrix}\)</span>, <span class="math inline">\(\begin{bmatrix} -1 \\ 1 \end{bmatrix}\)</span> respectivamente.</li>
</ul></li>
<li><strong>Cálculo del rango:</strong> <span class="math inline">\(\mathbf{A} = \begin{bmatrix} 1 &amp; 2 &amp; 3 \\ 4 &amp; 5 &amp; 6 \\ 7 &amp; 8 &amp; 9 \end{bmatrix}\)</span> Al convertirlo a la forma escalonada por filas, dos filas tienen valores no nulos, por lo que el rango es 2. (La tercera fila puede expresarse como una combinación lineal de la primera y segunda filas)</li>
</ol>
</section>
<section id="ampliación" class="level4">
<h4 class="anchored" data-anchor-id="ampliación">Ampliación</h4>
<ol type="1">
<li><p><strong>SVD:</strong> <span class="math inline">\(\mathbf{A} = \mathbf{U\Sigma V^T}\)</span></p>
<ul>
<li><span class="math inline">\(\mathbf{U}\)</span>: Matriz ortogonal que tiene los vectores propios de <span class="math inline">\(\mathbf{A}\mathbf{A}^T\)</span> como columnas</li>
<li><span class="math inline">\(\mathbf{\Sigma}\)</span>: Matriz diagonal con los valores singulares (raíces cuadradas de los valores propios de <span class="math inline">\(\mathbf{A}\mathbf{A}^T\)</span>) en la diagonal principal</li>
<li><span class="math inline">\(\mathbf{V}\)</span>: Matriz ortogonal que tiene los vectores propios de <span class="math inline">\(\mathbf{A}^T\mathbf{A}\)</span> como columnas</li>
</ul>
<p>(Se omite el proceso de cálculo. Es posible calcularlo usando bibliotecas como NumPy: <code>U, S, V = np.linalg.svd(A)</code>)</p></li>
<li><p><strong>PCA:</strong></p>
<p>```python import numpy as np</p>
<p>data = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6]])</p>
<h1 id="centrar-los-datos-restar-la-media">1. Centrar los datos (restar la media)</h1>
<p>mean = np.mean(data, axis=0) centered_data = data - mean</p>
<h1 id="calcular-la-matriz-de-covarianza">2. Calcular la matriz de covarianza</h1>
<p>covariance_matrix = np.cov(centered_data.T)</p>
<h1 id="calcular-los-valores-propios-y-vectores-propios">3. Calcular los valores propios y vectores propios</h1>
<p>eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)</p>
<h1 id="seleccionar-componentes-principales-vector-propio-correspondiente-al-mayor-valor-propio">4. Seleccionar componentes principales (vector propio correspondiente al mayor valor propio)</h1>
<h1 id="ordenar-los-valores-propios-en-orden-descendente-y-seleccionar-el-vector-propio-correspondiente-al-mayor-valor-propio">Ordenar los valores propios en orden descendente y seleccionar el vector propio correspondiente al mayor valor propio</h1>
<p>sorted_indices = np.argsort(eigenvalues)[::-1] # Índices de ordenación descendente largest_eigenvector = eigenvectors[:, sorted_indices[0]] # 5. Proyección a una dimensión projected_data = centered_data.dot(largest_eigenvector)</p></li>
</ol>
<p>print(projected_data)</p>
<pre><code>
3. **Espacios nulo y columna:**
$\mathbf{A} = \begin{bmatrix} 1 &amp; 2 &amp; 3 \\ 4 &amp; 5 &amp; 6 \\ 7 &amp; 8 &amp; 9 \end{bmatrix}$

*   **Espacio nulo (Null Space):** Encontrar $\mathbf{x}$ que satisface $\mathbf{Ax} = 0$.
    Al transformar a forma escalonada reducida, la solución es:
    $\mathbf{x} = t\begin{bmatrix} 1 \\ -2 \\ 1 \end{bmatrix}$ (t es una constante arbitraria).
    Por lo tanto, la base del espacio nulo es $\begin{bmatrix} 1 \\ -2 \\ 1 \end{bmatrix}$

*   **Espacio columna (Column Space):** Espacio generado por las combinaciones lineales de los vectores columna de la matriz $\mathbf{A}$.
    Los vectores columna correspondientes a las columnas pivote en la forma escalonada reducida son bases.
    $\begin{bmatrix} 1 \\ 4 \\ 7 \end{bmatrix}$, $\begin{bmatrix} 2 \\ 5 \\ 8 \end{bmatrix}$

4. **Descomposición QR:**
$\mathbf{A} = \mathbf{QR}$
*   $\mathbf{Q}$: Matriz con vectores columna ortonormales
*   $\mathbf{R}$: Matriz triangular superior (upper triangular matrix)

(El proceso de cálculo puede usar el proceso de ortogonalización de Gram-Schmidt o bibliotecas como NumPy para calcular: `Q, R = np.linalg.qr(A)`)
:::

## Ejercicios de práctica

### 2 Cálculo y optimización

#### Básico

1.  Encuentre la derivada $f'(x)$ de la función $f(x) = x^3 - 6x^2 + 9x + 1$.

2.  Encuentre las derivadas parciales $\frac{\partial f}{\partial x}$ y $\frac{\partial f}{\partial y}$ de la función $f(x, y) = x^2y + 2xy^2$.

3.  Utilice la regla de la cadena para encontrar la derivada $f'(x)$ de la función $f(x) = \sin(x^2)$.

#### Aplicado

1.  Encuentre el gradiente $\nabla f$ de la función $f(x, y) = e^{x^2 + y^2}$ y calcule su valor en el punto (1, 1).

2.  Encuentre todos los puntos críticos de la función $f(x) = x^4 - 4x^3 + 4x^2$ y determine si cada uno es un máximo local, un mínimo local o un punto de silla.

3.  Encuentre la matriz jacobiana de la siguiente función:
    $f(x, y) = \begin{bmatrix} x^2 + y^2 \\ 2xy \end{bmatrix}$

#### Avanzado

1.  Utilice el método de los multiplicadores de Lagrange para encontrar los valores máximos y mínimos de la función $f(x, y) = xy$ sujeta a la restricción $g(x, y) = x^2 + y^2 - 1 = 0$.

2.  Utilice el método del descenso por gradiente para encontrar el mínimo de la función $f(x) = x^4 - 4x^3 + 4x^2$. (Valor inicial $x_0 = 3$, tasa de aprendizaje $\alpha = 0.01$, número de iteraciones 100)

3.  Expresione el gradiente $\nabla f$ de la función $f(\mathbf{x}) = \mathbf{x}^T \mathbf{A} \mathbf{x}$ en términos de $\mathbf{A}$ y $\mathbf{x}$. (Donde $\mathbf{A}$ es una matriz simétrica)

4.  Utilice el método de Newton para encontrar las raíces de la ecuación $x^3 - 2x - 5 = 0$.

::: {.callout-note collapse="true" title="Haga clic para ver el contenido (solución)"}
## Soluciones de problemas de práctica

### 2 Cálculo y optimización

#### Básico

1.  **Derivada:**
    $f(x) = x^3 - 6x^2 + 9x + 1$
    $f'(x) = 3x^2 - 12x + 9$

2.  **Derivadas parciales:**
    $f(x, y) = x^2y + 2xy^2$
    $\frac{\partial f}{\partial x} = 2xy + 2y^2$
    $\frac{\partial f}{\partial y} = x^2 + 4xy$

3.  **Regla de la cadena:**
    $f(x) = \sin(x^2)$
    $f'(x) = \cos(x^2) \cdot (2x) = 2x\cos(x^2)$

#### Aplicado

1.  **Gradiente:**
    $f(x, y) = e^{x^2 + y^2}$
    $\nabla f = \begin{bmatrix} \frac{\partial f}{\partial x} \\ \frac{\partial f}{\partial y} \end{bmatrix} = \begin{bmatrix} 2xe^{x^2 + y^2} \\ 2ye^{x^2 + y^2} \end{bmatrix}$
    $\nabla f(1, 1) = \begin{bmatrix} 2e^2 \\ 2e^2 \end{bmatrix}$

2.  **Puntos críticos, clasificación de valores extremos:**
    $f(x) = x^4 - 4x^3 + 4x^2$
    $f'(x) = 4x^3 - 12x^2 + 8x = 4x(x-1)(x-2)$
    Puntos críticos: $x = 0, 1, 2$

    $f''(x) = 12x^2 - 24x + 8$
    *   $f''(0) = 8 &gt; 0$: mínimo local
    *   $f''(1) = -4 &lt; 0$: máximo local
    *   $f''(2) = 8 &gt; 0$: mínimo local

3.  **Matriz jacobiana:**
    $f(x, y) = \begin{bmatrix} x^2 + y^2 \\ 2xy \end{bmatrix}$
    $\mathbf{J} = \begin{bmatrix} \frac{\partial f_1}{\partial x} &amp; \frac{\partial f_1}{\partial y} \\ \frac{\partial f_2}{\partial x} &amp; \frac{\partial f_2}{\partial y} \end{bmatrix} = \begin{bmatrix} 2x &amp; 2y \\ 2y &amp; 2x \end{bmatrix}$

#### Avanzado

1.  **Método de multiplicadores de Lagrange:**
    $L(x, y, \lambda) = xy - \lambda(x^2 + y^2 - 1)$
    $\frac{\partial L}{\partial x} = y - 2\lambda x = 0$
    $\frac{\partial L}{\partial y} = x - 2\lambda y = 0$
    $\frac{\partial L}{\partial \lambda} = x^2 + y^2 - 1 = 0$

    *   $x = \pm \frac{1}{\sqrt{2}}$, $y = \pm \frac{1}{\sqrt{2}}$, $\lambda = \pm \frac{1}{2}$
    *   Máximo: $f(\frac{1}{\sqrt{2}}, \frac{1}{\sqrt{2}}) = f(-\frac{1}{\sqrt{2}}, -\frac{1}{\sqrt{2}}) = \frac{1}{2}$
    *   Mínimo: $f(\frac{1}{\sqrt{2}}, -\frac{1}{\sqrt{2}}) = f(-\frac{1}{\sqrt{2}}, \frac{1}{\sqrt{2}}) = -\frac{1}{2}$

2.  **Descenso por gradiente:**

    ```python
    def gradient_descent(f, df, x0, alpha, iterations):
        x = x0
        for i in range(iterations):
            x = x - alpha * df(x)
        return x
    ```
f = lambda x: x**4 - 4*x**3 + 4*x**2
df = lambda x: 4*x**3 - 12*x**2 + 8*x

x_min = gradient_descent(f, df, 3, 0.01, 100)
print(x_min) # converge aproximadamente a 2</code></pre>
<ol start="3" type="1">
<li><p><strong>Gradiente (en forma de matriz):</strong> <span class="math inline">\(f(\mathbf{x}) = \mathbf{x}^T \mathbf{A} \mathbf{x}\)</span> <span class="math inline">\(\nabla f = (\mathbf{A} + \mathbf{A}^T)\mathbf{x}\)</span>. Como <span class="math inline">\(\mathbf{A}\)</span> es una matriz simétrica, <span class="math inline">\(\nabla f = 2\mathbf{A}\mathbf{x}\)</span></p></li>
<li><p><strong>Método de Newton:</strong> <span class="math inline">\(f(x) = x^3 - 2x - 5\)</span> <span class="math inline">\(f'(x) = 3x^2 - 2\)</span> <span class="math inline">\(x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)}\)</span></p></li>
</ol>
<div class="sourceCode" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> newton_method(f, df, x0, iterations):</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> x0</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(iterations):</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x <span class="op">-</span> f(x) <span class="op">/</span> df(x)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> <span class="kw">lambda</span> x: x<span class="op">**</span><span class="dv">3</span> <span class="op">-</span> <span class="dv">2</span><span class="op">*</span>x <span class="op">-</span> <span class="dv">5</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> <span class="kw">lambda</span> x: <span class="dv">3</span><span class="op">*</span>x<span class="op">**</span><span class="dv">2</span> <span class="op">-</span> <span class="dv">2</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>root <span class="op">=</span> newton_method(f, df, <span class="dv">2</span>, <span class="dv">5</span>) <span class="co"># valor inicial x0 = 2, 5 iteraciones</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(root)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
</section>
</div>
</div>
</section>
</section>
</section>
<section id="ejercicios-de-práctica-1" class="level2">
<h2 class="anchored" data-anchor-id="ejercicios-de-práctica-1">Ejercicios de práctica</h2>
<section id="probabilidad-y-estadística-1" class="level3">
<h3 class="anchored">3 Probabilidad y estadística</h3>
<section id="básico-2" class="level4">
<h4 class="anchored" data-anchor-id="básico-2">Básico</h4>
<ol type="1">
<li><p>Calcule la probabilidad de que aparezca cara dos veces cuando se lanza una moneda tres veces.</p></li>
<li><p>Calcule la probabilidad de que salga un número par cuando se lanza un dado.</p></li>
<li><p>Escriba la función de densidad de probabilidad (PDF) de una distribución normal y explique el significado de la media y la varianza.</p></li>
</ol>
</section>
<section id="aplicación" class="level4">
<h4 class="anchored" data-anchor-id="aplicación">Aplicación</h4>
<ol type="1">
<li><p>Explique el teorema de Bayes (Bayes’ theorem) y aplíquelo al siguiente problema.</p>
<ul>
<li>Si la prevalencia de una enfermedad es del 1% y la precisión de la prueba diagnóstica (sensibilidad y especificidad) es del 99%, ¿cuál es la probabilidad de que realmente se tenga la enfermedad si el resultado de la prueba es positivo?</li>
</ul></li>
<li><p>Explique el concepto de estimación de máxima verosimilitud (Maximum Likelihood Estimation, MLE) y calcule el MLE para la probabilidad de que aparezca cara cuando se lanza una moneda cinco veces y cae tres veces.</p></li>
<li><p>Escriba la definición de valor esperado (expectation) y escriba las fórmulas para calcular el valor esperado de variables aleatorias discretas y continuas, respectivamente.</p></li>
</ol>
</section>
<section id="avanzado-1" class="level4">
<h4 class="anchored">Avanzado</h4>
<ol type="1">
<li><p>Escriba la definición de entropía (entropy) y calcule la entropía para la siguiente distribución de probabilidad.</p>
<ul>
<li>P(X=1) = 0.5, P(X=2) = 0.25, P(X=3) = 0.25</li>
</ul></li>
<li><p>Si la distribución conjunta de probabilidad (joint probability distribution) de dos variables aleatorias X e Y es la siguiente, calcule la información mutua (mutual information) I(X;Y).</p>
<pre><code>P(X=0, Y=0) = 0.1, P(X=0, Y=1) = 0.2
P(X=1, Y=0) = 0.3, P(X=1, Y=1) = 0.4</code></pre></li>
<li><p>Si las distribuciones de probabilidad P y Q son las siguientes, calcule la divergencia KL (Kullback-Leibler divergence) <span class="math inline">\(D_{KL}(P||Q)\)</span>.</p>
<ul>
<li>P(X=1) = 0.6, P(X=2) = 0.4</li>
<li>Q(X=1) = 0.8, Q(X=2) = 0.2</li>
</ul></li>
<li><p>Escriba la función de masa de probabilidad (PMF) de la distribución de Poisson y dé un ejemplo de cuándo se utiliza.</p></li>
</ol>
<div class="callout callout-style-default callout-note callout-titled" title="Haga clic para ver el contenido (solución)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-13-contents" aria-controls="callout-13" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Haga clic para ver el contenido (solución)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-13" class="callout-13-contents callout-collapse collapse">
<section id="soluciones-de-ejercicios" class="level2 callout-body-container callout-body">
<h2 class="anchored" data-anchor-id="soluciones-de-ejercicios">Soluciones de Ejercicios</h2>
<section id="probabilidad-y-estadística-2" class="level3">
<h3 class="anchored" data-anchor-id="probabilidad-y-estadística-2">3 Probabilidad y Estadística</h3>
<section id="básico-3" class="level4">
<h4 class="anchored" data-anchor-id="básico-3">Básico</h4>
<ol type="1">
<li><p><strong>Lanzamiento de Moneda:</strong> Probabilidad = (Número de casos en los que caen 2 caras en 3 lanzamientos) * (Probabilidad de cara)^2 * (Probabilidad de cruz)^1 = 3C2 * (1/2)^2 * (1/2)^1 = 3 * (1/4) * (1/2) = 3/8</p></li>
<li><p><strong>Lanzamiento de Dados:</strong> Probabilidad = (Número de casos en los que cae un número par) / (Número total de casos) = 3 / 6 = 1/2</p></li>
<li><p><strong>Distribución Normal:</strong> <span class="math inline">\(f(x) = \frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}\)</span></p>
<ul>
<li><span class="math inline">\(\mu\)</span>: Media (centro de la distribución)</li>
<li><span class="math inline">\(\sigma\)</span>: Desviación estándar (dispersión de la distribución)</li>
</ul></li>
</ol>
</section>
<section id="aplicaciones" class="level4">
<h4 class="anchored" data-anchor-id="aplicaciones">Aplicaciones</h4>
<ol type="1">
<li><p><strong>Teorema de Bayes:</strong> <span class="math inline">\(P(A|B) = \frac{P(B|A)P(A)}{P(B)}\)</span></p>
<ul>
<li><span class="math inline">\(P(A)\)</span>: Probabilidad de tener una enfermedad (probabilidad a priori) = 0.01</li>
<li><span class="math inline">\(P(B|A)\)</span>: Probabilidad de que la prueba sea positiva si se tiene la enfermedad (sensibilidad) = 0.99</li>
<li><span class="math inline">\(P(B|\neg A)\)</span>: Probabilidad de que la prueba sea positiva si no se tiene la enfermedad (1 - especificidad) = 0.01 (asumiendo una especificidad de 0.99)</li>
<li><span class="math inline">\(P(B)\)</span>: Probabilidad de que la prueba sea positiva = <span class="math inline">\(P(B|A)P(A) + P(B|\neg A)P(\neg A) = (0.99)(0.01) + (0.01)(0.99) = 0.0198\)</span></li>
</ul>
<p><span class="math inline">\(P(A|B) = \frac{(0.99)(0.01)}{0.0198} = 0.5\)</span> (50%)</p></li>
<li><p><strong>Estimación de Máxima Verosimilitud (MLE):</strong></p></li>
</ol>
<ul>
<li>Función de verosimilitud: <span class="math inline">\(L(p) = p^3 (1-p)^2\)</span> (p es la probabilidad de que caiga cara)
<ul>
<li>Derivada: <span class="math inline">\(\frac{dL}{dp} = 3p^2(1-p)^2 - 2p^3(1-p)\)</span></li>
<li>Igualando a cero y resolviendo para p, se obtiene <span class="math inline">\(p = \frac{3}{5}\)</span></li>
</ul></li>
</ul>
<ol start="3" type="1">
<li><strong>Divergencia de Kullback-Leibler:</strong> <span class="math inline">\(D_{KL}(P||Q) = \sum_{x} P(x) \log \frac{P(x)}{Q(x)}\)</span></li>
</ol>
</section>
<section id="avanzado-2" class="level4">
<h4 class="anchored" data-anchor-id="avanzado-2">Avanzado</h4>
<ol type="1">
<li><p><strong>Entropía:</strong> Entropía es una medida de la incertidumbre, desorden o cantidad de información en una distribución de probabilidad. <span class="math inline">\(H(P) = -\sum_{x} P(x) \log P(x)\)</span> (la base del logaritmo suele ser 2 o el logaritmo natural e)</p>
<p><span class="math inline">\(H(P) = -(0.5 \log 0.5 + 0.25 \log 0.25 + 0.25 \log 0.25)\)</span> (usando logaritmos de base 2) <span class="math inline">\(H(P) \approx 1.5\)</span> bits</p></li>
<li><p><strong>Información Mutua:</strong> <span class="math inline">\(I(X;Y) = \sum_{x}\sum_{y} P(x,y) \log \frac{P(x,y)}{P(x)P(y)}\)</span></p>
<ul>
<li><span class="math inline">\(P(X=0) = 0.1 + 0.2 = 0.3\)</span></li>
<li><span class="math inline">\(P(X=1) = 0.3 + 0.4 = 0.7\)</span></li>
<li><span class="math inline">\(P(Y=0) = 0.1 + 0.3 = 0.4\)</span></li>
<li><span class="math inline">\(P(Y=1) = 0.2 + 0.4 = 0.6\)</span></li>
</ul>
<p><span class="math inline">\(I(X;Y) = (0.1)\log\frac{0.1}{(0.3)(0.4)} + (0.2)\log\frac{0.2}{(0.3)(0.6)} + (0.3)\log\frac{0.3}{(0.7)(0.4)} + (0.4)\log\frac{0.4}{(0.7)(0.6)}\)</span> <span class="math inline">\(I(X;Y) \approx 0.0867\)</span> (usando logaritmos de base 2)</p></li>
<li><p><strong>Divergencia KL:</strong> <span class="math inline">\(D_{KL}(P||Q) = \sum_{x} P(x) \log \frac{P(x)}{Q(x)}\)</span> <span class="math inline">\(D_{KL}(P||Q) = 0.6 \log \frac{0.6}{0.8} + 0.4 \log \frac{0.4}{0.2} \approx 0.083\)</span></p></li>
<li><p><strong>Distribución de Poisson:</strong></p>
<ul>
<li><strong>Función de masa de probabilidad (PMF):</strong> <span class="math inline">\(P(X=k) = \frac{\lambda^k e^{-\lambda}}{k!}\)</span> (<span class="math inline">\(k\)</span> es el número de ocurrencias, <span class="math inline">\(\lambda\)</span> es la tasa media de ocurrencia por unidad de tiempo/espacio)</li>
<li><strong>Ejemplos de uso</strong>:
<ul>
<li>Número de llamadas recibidas en un centro de llamadas durante un período específico</li>
<li>Número de accidentes de tráfico ocurridos en una zona específica</li>
<li>Número de errores tipográficos encontrados en un libro</li>
<li>Número de visitantes que acceden a un sitio web</li>
<li>Desintegración radiactiva, mutaciones genéticas</li>
</ul></li>
</ul></li>
</ol>
</section>
</section>
</section>
</div>
</div>
</section>
</section>
</section>
<section id="referencias" class="level2">
<h2 class="anchored" data-anchor-id="referencias">Referencias</h2>
<section id="materiales-esenciales-de-referencia" class="level4">
<h4 class="anchored" data-anchor-id="materiales-esenciales-de-referencia">Materiales esenciales de referencia</h4>
<ol type="1">
<li><strong>Linear Algebra and Its Applications (Gilbert Strang, 4th Edition)</strong>:
<ul>
<li>Este es un libro de texto que cubre los conceptos básicos y aplicaciones del álgebra lineal. Explica claramente el contenido esencial necesario para el aprendizaje profundo.</li>
<li><a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/">Curso de Álgebra Lineal de Gilbert Strang (MIT OCW)</a></li>
</ul></li>
<li><strong>Calculus (James Stewart, 8th Edition)</strong>:
<ul>
<li>Este libro de texto explica detalladamente los principios básicos del cálculo. Proporciona el conocimiento previo necesario para comprender los algoritmos de optimización en el aprendizaje profundo.</li>
</ul></li>
<li><strong>Probability and Statistics for Engineering and the Sciences (Jay L. Devore, 9th Edition)</strong>:
<ul>
<li>Este libro de texto explica los conceptos básicos de probabilidad y estadística junto con aplicaciones ingenieriles. Ayuda a comprender la modelización probabilística y la inferencia de incertidumbre en el aprendizaje profundo.</li>
</ul></li>
<li><strong>Pattern Recognition and Machine Learning (Christopher Bishop)</strong>:
<ul>
<li>Este es un libro de texto clásico sobre reconocimiento de patrones y aprendizaje automático. Aborda a fondo los temas teóricos del aprendizaje profundo, como la modelización probabilística, la inferencia bayesiana y la teoría de la información.</li>
</ul></li>
<li><strong>The Elements of Statistical Learning (Trevor Hastie, Robert Tibshirani, Jerome Friedman)</strong>:
<ul>
<li>Este libro de texto explica claramente los conceptos clave de la teoría del aprendizaje estadístico. Es útil para comprender el rendimiento generalizador y los problemas de sobreajuste en los modelos de aprendizaje profundo.</li>
<li><a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://hastie.su.domains/ElemStatLearn/">The Elements of Statistical Learning (PDF gratuito)</a></li>
</ul></li>
<li><strong>Deep Learning (Ian Goodfellow, Yoshua Bengio, Aaron Courville)</strong>:
<ul>
<li>Este es un libro de texto que abarca los conceptos básicos y las técnicas más recientes del aprendizaje profundo. Introduce brevemente la base matemática necesaria para el aprendizaje profundo.</li>
<li><a href="https://www.deeplearningbook.org/">Deep Learning Book (PDF gratuito)</a></li>
</ul></li>
<li><strong>Understanding Machine Learning: From Theory to Algorithms (Shai Shalev-Shwartz, Shai Ben-David)</strong>:
<ul>
<li>Este libro de texto proporciona una base sólida en la teoría del aprendizaje automático. Explica conceptos importantes para comprender el rendimiento generalizador de los modelos de aprendizaje profundo, como la teoría PAC, la dimensión VC y el compromiso sesgo-varianza.</li>
</ul></li>
<li><strong>Information Theory, Inference, and Learning Algorithms (David J.C. MacKay)</strong>:
<ul>
<li>Este libro de texto explica los principios del aprendizaje automático centrados en la teoría de la información y la inferencia bayesiana. Ayuda a comprender la interpretación probabilística y los modelos generativos en el aprendizaje profundo.</li>
<li><a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=http://www.inference.org.uk/itprnn/book.pdf">Information Theory, Inference, and Learning Algorithms (PDF gratuito)</a></li>
</ul></li>
<li><strong>Mathematics for Machine Learning (Marc Peter Deisenroth, A. Aldo Faisal, and Cheng Soon Ong)</strong>
<ul>
<li>Este libro de texto aborda ampliamente los conocimientos matemáticos necesarios para el aprendizaje automático.</li>
</ul></li>
<li><strong>Matrix Computations (Gene H. Golub, Charles F. Van Loan, 4th Edition)</strong>:
<ul>
<li>Este libro de texto trata exhaustivamente métodos numéricos relacionados con operaciones de matrices. Proporciona el conocimiento necesario para implementar y mejorar los algoritmos de optimización en el aprendizaje profundo.</li>
</ul></li>
<li><strong>Linear Algebra and Its Applications (Gilbert Strang, 4th Edition)</strong>:
<ul>
<li>Libro de texto que aborda los conceptos básicos y aplicaciones del álgebra lineal. Explica claramente el contenido esencial para el aprendizaje profundo. - <a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/">Curso de Álgebra Lineal de Gilbert Strang (MIT OCW)</a></li>
</ul></li>
<li><strong>Calculus (James Stewart, 8th Edition)</strong>:
<ul>
<li>Libro de texto que explica detalladamente los principios básicos del cálculo. Proporciona el conocimiento de fondo necesario para comprender los algoritmos de optimización en el aprendizaje profundo.</li>
</ul></li>
<li><strong>Probability and Statistics for Engineering and the Sciences (Jay L. Devore, 9th Edition)</strong>:
<ul>
<li>Libro de texto que explica los conceptos básicos de probabilidad y estadística junto con sus aplicaciones ingenieriles. Ayuda a comprender la modelización probabilística y la inferencia de incertidumbre en el aprendizaje profundo.</li>
</ul></li>
<li><strong>Pattern Recognition and Machine Learning (Christopher Bishop)</strong>:
<ul>
<li>Libro de texto clásico sobre reconocimiento de patrones y aprendizaje automático. Aborda profundamente los conceptos teóricos del aprendizaje profundo, incluyendo modelización probabilística, inferencia bayesiana e información teórica.</li>
</ul></li>
<li><strong>The Elements of Statistical Learning (Trevor Hastie, Robert Tibshirani, Jerome Friedman)</strong>:
<ul>
<li>Libro de texto que explica claramente los conceptos clave de la teoría del aprendizaje estadístico. Es útil para comprender el rendimiento generalizado y los problemas de sobreajuste en los modelos de aprendizaje profundo. - <a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://hastie.su.domains/ElemStatLearn/">The Elements of Statistical Learning (Free PDF)</a></li>
</ul></li>
<li><strong>Deep Learning (Ian Goodfellow, Yoshua Bengio, Aaron Courville)</strong>:
<ul>
<li>Libro de texto que abarca exhaustivamente los conceptos básicos y las tecnologías más recientes del aprendizaje profundo. Introduce brevemente la base matemática necesaria para el aprendizaje profundo. - <a href="https://www.deeplearningbook.org/">Libro de Aprendizaje Profundo (Free PDF)</a></li>
</ul></li>
<li><strong>Understanding Machine Learning: From Theory to Algorithms (Shai Shalev-Shwartz, Shai Ben-David)</strong>:
<ul>
<li>Libro de texto que establece firmemente los fundamentos teóricos del aprendizaje automático. Explica conceptos importantes para comprender el rendimiento generalizado de los modelos de aprendizaje profundo, como la teoría PAC, la dimensión VC y el trade-off sesgo-varianza.</li>
</ul></li>
<li><strong>Information Theory, Inference, and Learning Algorithms (David J.C. MacKay)</strong>:
<ul>
<li>Libro de texto que explica los principios del aprendizaje automático centrados en la teoría de la información y la inferencia bayesiana. Ayuda a comprender la interpretación probabilística y los modelos generativos en el aprendizaje profundo. - <a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=http://www.inference.org.uk/itprnn/book.pdf">Information Theory, Inference, and Learning Algorithms (Free PDF)</a></li>
</ul></li>
<li><strong>Mathematics for Machine Learning (Marc Peter Deisenroth, A. Aldo Faisal, y Cheng Soon Ong)</strong>
<ul>
<li>Aborda ampliamente el conocimiento matemático necesario para el aprendizaje automático.</li>
</ul></li>
<li><strong>Matrix Computations (Gene H. Golub, Charles F. Van Loan, 4th Edition)</strong>: - Es un libro de texto que trata profundamente los métodos numéricos relacionados con las operaciones matriciales. Proporciona el conocimiento necesario para implementar y mejorar el rendimiento de los algoritmos de optimización en deep learning.</li>
</ol>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>