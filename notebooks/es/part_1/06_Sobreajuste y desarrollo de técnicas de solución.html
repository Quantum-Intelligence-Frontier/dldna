<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>sobreajuste-y-desarrollo-de-técnicas-de-solución – Deep Learning DNA: Surviving Architectures and Essential Principles</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-f507c7d0488cb7630e20aad62ad8c2aa.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script>window.MathJax = {loader: {load: ['[tex]/boldsymbol']},tex: {packages: {'[+]': ['boldsymbol']}}};</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../notebooks/es/part_1/01_El inicio del aprendizaje profundo.html">part_1</a></li><li class="breadcrumb-item"><a href="../../../notebooks/es/part_1/06_Sobreajuste y desarrollo de técnicas de solución.html">6. Sobreajuste y desarrollo de técnicas de solución</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../../">Español</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Language</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index_de.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Deutsch</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index_en.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">English</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index_es.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Español</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">한국어</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index_zh.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">中文</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/00_Introducción.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introducción</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">part_1</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/01_El inicio del aprendizaje profundo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1. El inicio del aprendizaje profundo</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/02_Matemáticas de deep learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2. Matemáticas de deep learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/03_marco de aprendizaje profundo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3. marco de aprendizaje profundo</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/04_función de activación.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4. función de activación</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/05_Optimización y visualización.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5. Optimización y visualización</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/06_Sobreajuste y desarrollo de técnicas de solución.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">6. Sobreajuste y desarrollo de técnicas de solución</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/07_Evolución de las redes neuronales convolucionales.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">7. Evolución de las redes neuronales convolucionales</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/08_El nacimiento del transformer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8. El nacimiento del transformer</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/09_La evolución del transformer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">9. La evolución del transformer</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/10_Multimodal deep learning: el inicio de la fusión multisensorial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">10. Multimodal deep learning: el inicio de la fusión multisensorial</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/11_Multimodal deep learning: inteligencia más allá de los límites.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">11. Multimodal deep learning: inteligencia más allá de los límites</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">la vanguardia del deep learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/la vanguardia del deep learning/01_SLM: pequeño pero poderoso modelo de lenguaje.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1. SLM: pequeño pero poderoso modelo de lenguaje</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/la vanguardia del deep learning/02_conducción autónoma.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2. conducción autónoma</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#capítulo-sobreajuste-y-el-desarrollo-de-técnicas-para-resolverlo" id="toc-capítulo-sobreajuste-y-el-desarrollo-de-técnicas-para-resolverlo" class="nav-link active" data-scroll-target="#capítulo-sobreajuste-y-el-desarrollo-de-técnicas-para-resolverlo">6 Capítulo Sobreajuste y el desarrollo de técnicas para resolverlo</a>
  <ul class="collapse">
  <li><a href="#comprensión-del-sobreajuste" id="toc-comprensión-del-sobreajuste" class="nav-link" data-scroll-target="#comprensión-del-sobreajuste">6.1 Comprensión del Sobreajuste</a></li>
  <li><a href="#técnicas-de-regularización" id="toc-técnicas-de-regularización" class="nav-link" data-scroll-target="#técnicas-de-regularización">6.2 Técnicas de regularización</a>
  <ul class="collapse">
  <li><a href="#regularización-l1-l2" id="toc-regularización-l1-l2" class="nav-link" data-scroll-target="#regularización-l1-l2">6.2.1 Regularización L1, L2</a></li>
  <li><a href="#aplicación-de-l1-y-l2-regularización-en-pytorch" id="toc-aplicación-de-l1-y-l2-regularización-en-pytorch" class="nav-link" data-scroll-target="#aplicación-de-l1-y-l2-regularización-en-pytorch">6.2.2 Aplicación de L1 y L2 regularización en PyTorch</a></li>
  <li><a href="#aplicación-de-l1-y-l2-regulación-en-pytorch" id="toc-aplicación-de-l1-y-l2-regulación-en-pytorch" class="nav-link" data-scroll-target="#aplicación-de-l1-y-l2-regulación-en-pytorch">6.2.2 Aplicación de L1 y L2 regulación en PyTorch</a></li>
  <li><a href="#análisis-del-efecto-de-la-regularización-en-el-plano-de-pérdida" id="toc-análisis-del-efecto-de-la-regularización-en-el-plano-de-pérdida" class="nav-link" data-scroll-target="#análisis-del-efecto-de-la-regularización-en-el-plano-de-pérdida">6.2.3 Análisis del efecto de la regularización en el plano de pérdida</a></li>
  </ul></li>
  <li><a href="#dropout-드롭아웃" id="toc-dropout-드롭아웃" class="nav-link" data-scroll-target="#dropout-드롭아웃">6.3 Dropout (드롭아웃)</a>
  <ul class="collapse">
  <li><a href="#principio-del-dropout" id="toc-principio-del-dropout" class="nav-link" data-scroll-target="#principio-del-dropout">6.3.1 Principio del dropout</a></li>
  <li><a href="#implementación-del-dropout-en-pytorch" id="toc-implementación-del-dropout-en-pytorch" class="nav-link" data-scroll-target="#implementación-del-dropout-en-pytorch">6.3.2 Implementación del dropout en PyTorch</a></li>
  </ul></li>
  <li><a href="#normalización-por-lotes-batch-normalization" id="toc-normalización-por-lotes-batch-normalization" class="nav-link" data-scroll-target="#normalización-por-lotes-batch-normalization">6.4 Normalización por lotes (batch normalization)</a>
  <ul class="collapse">
  <li><a href="#concepto-y-efectos-de-la-normalización-por-lotes" id="toc-concepto-y-efectos-de-la-normalización-por-lotes" class="nav-link" data-scroll-target="#concepto-y-efectos-de-la-normalización-por-lotes">6.4.1 Concepto y efectos de la normalización por lotes</a></li>
  <li><a href="#implementación-de-la-normalización-por-lotes-en-pytorch" id="toc-implementación-de-la-normalización-por-lotes-en-pytorch" class="nav-link" data-scroll-target="#implementación-de-la-normalización-por-lotes-en-pytorch">6.4.2 Implementación de la normalización por lotes en PyTorch</a></li>
  <li><a href="#aplicación-en-el-seguimiento-estadístico-y-la-inferencia" id="toc-aplicación-en-el-seguimiento-estadístico-y-la-inferencia" class="nav-link" data-scroll-target="#aplicación-en-el-seguimiento-estadístico-y-la-inferencia">6.4.3 Aplicación en el seguimiento estadístico y la inferencia</a></li>
  </ul></li>
  <li><a href="#optimización-de-hiperparámetros" id="toc-optimización-de-hiperparámetros" class="nav-link" data-scroll-target="#optimización-de-hiperparámetros">6.5 Optimización de hiperparámetros</a>
  <ul class="collapse">
  <li><a href="#comparación-de-metodologías-de-optimización" id="toc-comparación-de-metodologías-de-optimización" class="nav-link" data-scroll-target="#comparación-de-metodologías-de-optimización">6.5.1 Comparación de metodologías de optimización</a></li>
  <li><a href="#optimización-con-bayes-opt" id="toc-optimización-con-bayes-opt" class="nav-link" data-scroll-target="#optimización-con-bayes-opt">6.5.2 Optimización con Bayes-Opt</a></li>
  <li><a href="#optimización-con-botorch" id="toc-optimización-con-botorch" class="nav-link" data-scroll-target="#optimización-con-botorch">6.5.3 Optimización con BoTorch</a></li>
  </ul></li>
  <li><a href="#procesos-gaussianos" id="toc-procesos-gaussianos" class="nav-link" data-scroll-target="#procesos-gaussianos">6.6 Procesos Gaussianos</a>
  <ul class="collapse">
  <li><a href="#fundamentos-matemáticos-para-el-manejo-de-la-incertidumbre" id="toc-fundamentos-matemáticos-para-el-manejo-de-la-incertidumbre" class="nav-link" data-scroll-target="#fundamentos-matemáticos-para-el-manejo-de-la-incertidumbre">6.6.1 Fundamentos matemáticos para el manejo de la incertidumbre</a></li>
  <li><a href="#aplicaciones-modernas" id="toc-aplicaciones-modernas" class="nav-link" data-scroll-target="#aplicaciones-modernas">6.6.2 Aplicaciones modernas</a></li>
  <li><a href="#aprendizaje-de-núcleos-profundos-deep-kernel-learning" id="toc-aprendizaje-de-núcleos-profundos-deep-kernel-learning" class="nav-link" data-scroll-target="#aprendizaje-de-núcleos-profundos-deep-kernel-learning">6.6.3 Aprendizaje de núcleos profundos (Deep Kernel Learning)</a></li>
  </ul></li>
  <li><a href="#ejercicios-de-práctica" id="toc-ejercicios-de-práctica" class="nav-link" data-scroll-target="#ejercicios-de-práctica">Ejercicios de práctica</a>
  <ul class="collapse">
  <li><a href="#problemas-básicos" id="toc-problemas-básicos" class="nav-link" data-scroll-target="#problemas-básicos">Problemas básicos</a></li>
  <li><a href="#problemas-aplicados" id="toc-problemas-aplicados" class="nav-link" data-scroll-target="#problemas-aplicados">Problemas aplicados</a></li>
  <li><a href="#problemas-avanzados" id="toc-problemas-avanzados" class="nav-link" data-scroll-target="#problemas-avanzados">Problemas avanzados</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../notebooks/es/part_1/01_El inicio del aprendizaje profundo.html">part_1</a></li><li class="breadcrumb-item"><a href="../../../notebooks/es/part_1/06_Sobreajuste y desarrollo de técnicas de solución.html">6. Sobreajuste y desarrollo de técnicas de solución</a></li></ol></nav></header>




<p><a href="https://colab.research.google.com/github/Quantum-Intelligence-Frontier/dldna/blob/main/notebooks/es/part_1/06_sobreajuste_y_el_desarrollo_de_técnicas_de_resolución.ipynb" target="_parent"> <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Abrir en Colab"> </a></p>
<section id="capítulo-sobreajuste-y-el-desarrollo-de-técnicas-para-resolverlo" class="level1">
<h1>6 Capítulo Sobreajuste y el desarrollo de técnicas para resolverlo</h1>
<blockquote class="blockquote">
<p>“La simplicidad es la sofisticación suprema.” - Leonardo da Vinci</p>
</blockquote>
<p>Los modelos de deep learning tienen una poderosa capacidad para representar funciones complejas a través de numerosos parámetros. Sin embargo, esta capacidad a veces puede ser un <em>doble filo</em>. Cuando el modelo se ajusta excesivamente a los datos de entrenamiento, se produce el fenómeno de <strong>sobreajuste (overfitting)</strong>, donde el rendimiento de predicción en nuevos datos disminuye.</p>
<p>Desde que el algoritmo de retropropagación fue revisado en 1986, el sobreajuste ha sido un desafío constante para los investigadores de deep learning. Inicialmente, se abordaba reduciendo el tamaño del modelo o aumentando la cantidad de datos de entrenamiento. Sin embargo, estos métodos tenían limitaciones, ya que restringían la capacidad expresiva del modelo o presentaban dificultades en la recopilación de datos. La aparición de AlexNet en 2012 marcó el inicio de una nueva era para el deep learning, pero también resaltó la gravedad del problema de sobreajuste. AlexNet tenía muchos más parámetros que los modelos anteriores, lo que aumentaba el riesgo de sobreajuste. A medida que la escala de los modelos de deep learning creció exponencialmente, el problema de sobreajuste se convirtió en un tema central de investigación.</p>
<p>En este capítulo, exploraremos la esencia del sobreajuste y examinaremos las diversas técnicas que han evolucionado para abordarlo. Al igual que los exploradores que mapean territorios desconocidos, los investigadores de deep learning han buscado constantemente nuevas formas para superar el desafío del sobreajuste.</p>
<section id="comprensión-del-sobreajuste" class="level2">
<h2 class="anchored" data-anchor-id="comprensión-del-sobreajuste">6.1 Comprensión del Sobreajuste</h2>
<p>El sobreajuste fue mencionado por primera vez en las obras de William Hopkins en 1670, pero en su sentido moderno comenzó con una referencia en <em>Quarterly Review of Biology</em> en 1935: “Hacer un análisis multivariante de 6 variables con solo 13 observaciones parece un sobreajuste”. A partir de la década de 1950, se empezó a estudiar sistemáticamente en estadística, y fue particularmente importante en el contexto del análisis de series temporales en el artículo “Tests of Fit in Time Series” de 1952.</p>
<p>El problema de sobreajuste en deep learning tomó un nuevo rumbo con la aparición de AlexNet en 2012. AlexNet era una red neuronal a gran escala con aproximadamente 60 millones de parámetros, lo que representaba un salto significativo respecto a los modelos anteriores. A medida que la escala de los modelos de deep learning creció exponencialmente, el problema de sobreajuste se volvió más grave. Por ejemplo, los modernos modelos de lenguaje a gran escala (LLM) tienen billones de parámetros, lo que hace que prevenir el sobreajuste sea una tarea crucial en el diseño del modelo.</p>
<p>Para abordar estos desafíos, se propusieron soluciones innovadoras como dropout (2014) y batch normalization (2015), y recientemente se han investigado métodos más sofisticados para detectar y prevenir el sobreajuste utilizando historiales de entrenamiento (2024). En particular, en modelos a gran escala, se utilizan estrategias diversas que van desde técnicas tradicionales como early stopping hasta ensembles learning y data augmentation.</p>
<p>Vamos a entender intuitivamente el fenómeno de sobreajuste a través de un ejemplo simple. Aplicaremos polinomios (polynomial) de diferentes grados (degree) a datos de una función seno (sine) con ruido.</p>
<div id="cell-2" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install dldna[colab] <span class="co"># in Colab</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip install dldna[all] # in your local</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>load_ext autoreload</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>autoreload <span class="dv">2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="cell-3" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Noisy sin graph</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> real_func(x):</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> np.sin(x) <span class="op">+</span> np.random.uniform(<span class="op">-</span><span class="fl">0.2</span>, <span class="fl">0.2</span>, <span class="bu">len</span>(x))</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> y</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Create x data from 40 to 320 degrees.  Use a step value to avoid making it too dense.</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.array([np.pi<span class="op">/</span><span class="dv">180</span> <span class="op">*</span> i <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">40</span>, <span class="dv">320</span>, <span class="dv">4</span>)])</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> real_func(x)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span>x, y<span class="op">=</span>y, label<span class="op">=</span><span class="st">'real function'</span>)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot with 1st, 3rd, and 21th degree polynomials.  </span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> deg <span class="kw">in</span> [<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">21</span>]:  </span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the coefficients for the corresponding degree using polyfit, and create the estimated function using poly1d.</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>    params <span class="op">=</span> np.polyfit(x, y, deg) <span class="co"># Get the parameter values</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># print(f" {deg} params = {params}")</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> np.poly1d(params) <span class="co"># Get the line function</span></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>    sns.lineplot(x<span class="op">=</span>x, y<span class="op">=</span>p(x), color<span class="op">=</span><span class="ss">f"C</span><span class="sc">{</span>deg<span class="sc">}</span><span class="ss">"</span>, label<span class="op">=</span><span class="ss">f"deg = </span><span class="sc">{</span>deg<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>The autoreload extension is already loaded. To reload it, use:
  %reload_ext autoreload</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/tmp/ipykernel_1362795/2136320363.py:25: RankWarning: Polyfit may be poorly conditioned
  params = np.polyfit(x, y, deg) # Get the parameter values</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="06_Sobreajuste y desarrollo de técnicas de solución_files/figure-html/cell-3-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>El siguiente código genera datos de una función senoidal con ruido y ajusta (fitting) estos datos usando polinomios de 1º, 3º y 21º grado.</p>
<ul>
<li><p><strong>Función de 1º grado (deg = 1):</strong> no sigue la tendencia general de los datos y se muestra en forma de línea simple. Esto demuestra un estado de <em>subajuste (underfitting)</em> donde el modelo no expresa suficientemente la complejidad de los datos.</p></li>
<li><p><strong>Función de 3º grado (deg = 3):</strong> captura relativamente bien el patrón básico de los datos, mostrando una curva suave que no se ve demasiado afectada por el ruido.</p></li>
<li><p><strong>Función de 21º grado (deg = 21):</strong> sigue excesivamente incluso el ruido en los datos de entrenamiento, mostrando un estado de <em>sobreajuste (overfitting)</em> donde el modelo está demasiado optimizado para los datos de entrenamiento.</p></li>
</ul>
<p>Así, si la complejidad del modelo (en este caso, el grado del polinomio) es demasiado baja, ocurre subajuste; si es demasiado alta, ocurre sobreajuste. Lo que buscamos finalmente es un modelo que se generalice bien no solo a los datos de entrenamiento sino también a nuevos datos, es decir, la función de aproximación más cercana a la función senoidal real.</p>
<p>El sobreajuste ocurre cuando la complejidad del modelo (capacidad) es relativamente alta en comparación con la cantidad de datos de entrenamiento. Las redes neuronales tienen un gran número de parámetros y una alta capacidad de expresión, por lo que son particularmente vulnerables al sobreajuste. El sobreajuste también puede ocurrir cuando los datos de entrenamiento son insuficientes o contienen mucho ruido. El sobreajuste se caracteriza por las siguientes características:</p>
<ul>
<li>La pérdida (loss) en los <strong>datos de entrenamiento</strong> sigue disminuyendo.</li>
<li>La pérdida en los <strong>datos de validación</strong> disminuye inicialmente, pero a partir de un cierto punto comienza a aumentar.</li>
<li>Esto es debido a que el modelo aprende incluso el ruido y los detalles finos de los datos de entrenamiento, especializándose excesivamente en ellos.</li>
</ul>
<p>En resumen, un modelo sobreajustado muestra un alto rendimiento en los datos de entrenamiento pero un bajo rendimiento predictivo en nuevos datos reales. Para prevenir este sobreajuste, examinaremos detalladamente técnicas como la regularización L1/L2, el dropout y la normalización por lotes.</p>
</section>
<section id="técnicas-de-regularización" class="level2">
<h2 class="anchored" data-anchor-id="técnicas-de-regularización">6.2 Técnicas de regularización</h2>
<blockquote class="blockquote">
<p><strong>Desafío:</strong> ¿Cuál es un método para mejorar el rendimiento de generalización mientras se controla eficazmente la complejidad del modelo?</p>
<p><strong>Angustia del investigador:</strong> Reducir el tamaño del modelo para evitar el sobreajuste puede limitar su capacidad de expresión, y simplemente aumentar los datos de entrenamiento no siempre es posible. Se necesitaba un método que imponga restricciones a la estructura del modelo o al proceso de aprendizaje para prevenir una optimización excesiva de los datos de entrenamiento y mejorar el rendimiento predictivo en nuevos datos.</p>
</blockquote>
<section id="regularización-l1-l2" class="level3">
<h3 class="anchored" data-anchor-id="regularización-l1-l2">6.2.1 Regularización L1, L2</h3>
<p>Entre las técnicas de regularización (regularization) más utilizadas en redes neuronales se encuentran la regularización L1 y L2. L1 se refiere a Lasso, mientras que L2 se refiere a Ridge (regresión lineal).</p>
<p>También conocidas como regresión Ridge y regresión Lasso, cada una introduce un término de penalización para limitar el movimiento de los parámetros. Las diferencias características entre ambos métodos se pueden resumir en la siguiente tabla.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 27%">
<col style="width: 38%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="header">
<th>Característica</th>
<th>Regresión Ridge (Ridge Regression)</th>
<th>Regresión Lasso (Lasso Regression)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Tipo de penalización</td>
<td>Aplica una penalización L2. El término de penalización es el producto de la suma de los cuadrados de los parámetros por un valor alfa.</td>
<td>Aplica una penalización L1. El término de penalización es el producto de la suma de los valores absolutos de los parámetros por un valor alfa.</td>
</tr>
<tr class="even">
<td>Efecto en los parámetros</td>
<td>Suprime los parámetros con grandes valores, llevándolos a ser cercanos a cero, pero no exactamente cero</td>
<td>Cuando el valor de alfa es grande, puede hacer que algunos parámetros sean exactamente cero, creando un modelo más simple</td>
</tr>
<tr class="odd">
<td>Efecto general</td>
<td>Todos los parámetros se conservan. Por lo tanto, incluso los parámetros con menor impacto permanecen.</td>
<td>Solo quedan los parámetros relevantes, lo que confiere propiedades selectivas y permite explicar modelos complejos de manera más simple.</td>
</tr>
<tr class="even">
<td>Características de optimización</td>
<td>Menos sensible a valores ideales en comparación con Lasso.</td>
<td>Es sensible a valores ideales debido al término de penalización absoluto.</td>
</tr>
</tbody>
</table>
<p>La expresión matemática es la siguiente.</p>
<ul>
<li><p>Función objetivo de Ridge (Ridge Regression Objective Function)</p>
<p>“Función objetivo modificada de Ridge” = (función de regresión lineal no modificada) + <span class="math inline">\(\alpha \cdot \sum (\text{parámetro})^2\)</span></p>
<p><span class="math inline">\(f_{\beta} = \sum_{i=1}^{M} (y_i - \hat{y}_i)^2 + \alpha \sum_{j} \beta_{j}^2\)</span></p>
<p>Aquí, <span class="math inline">\(\beta\)</span> es el vector de parámetros (pesos) que se desea encontrar. <span class="math inline">\(\alpha \sum_{j} \beta_{j}^2\)</span> se conoce como término de penalización o término de regularización. <span class="math inline">\(\alpha\)</span> es un hiperparámetro que ajusta la magnitud del término de regularización. La fórmula para encontrar los parámetros es:</p>
<p><span class="math inline">\(\beta = \underset{\beta}{\operatorname{argmin}} \left( \sum_{i=1}^{M} (y_i - \hat{y}_i)^2 + \alpha \sum_{j} \beta_{j}^2 \right)\)</span></p></li>
<li><p>Función objetivo de Lasso (Lasso Regression Objective Function)</p>
<p>“Función objetivo modificada de Lasso” = (función de regresión lineal no modificada) + $ || $</p>
<p><span class="math inline">\(f_{\beta} = \sum_{i=1}^{M} (y_i - \hat{y}_i)^2 + \alpha \sum_{j} |\beta_{j}|\)</span> <span class="math inline">\(\beta = \underset{\beta}{\operatorname{argmin}} \left( \sum_{i=1}^{M} (y_i - \hat{y}_i)^2 + \alpha \sum_{j} |\beta_j| \right)\)</span></p></li>
</ul>
<p>El uso de la penalización de la suma de cuadrados de los parámetros, conocido como L2, es comúnmente llamado atenuación de peso (weight decay) en redes neuronales. Vamos a examinar cómo difiere el uso de regresión Ridge (L2) del regresión lineal simple utilizando un modelo implementado en sklearn. Para esto, es necesario aumentar la dimensionalidad de los datos de entrada x según el grado. Usaremos una función utilitaria simple para crear estos datos.</p>
<div id="cell-6" class="cell" data-execution_count="15">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_x_powered(x, p<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    size <span class="op">=</span> <span class="bu">len</span>(x)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The shape of the created x will be (data size, degree)</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    new_x <span class="op">=</span> np.zeros((size, p))</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> s <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(x)): <span class="co"># Iterate over data size</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> d <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, p<span class="op">+</span><span class="dv">1</span>): <span class="co"># Iterate over degrees</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>            new_x[s][d<span class="op">-</span><span class="dv">1</span>] <span class="op">=</span> x[s]<span class="op">**</span>d <span class="co"># Raise x to the power of the degree.</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> new_x</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's take a quick look at how it works.</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>deg <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.array([np.pi<span class="op">/</span><span class="dv">180</span> <span class="op">*</span> i <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">20</span>, <span class="dv">35</span>, <span class="dv">5</span>)])</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> real_func(x)  <span class="co"># real_func는 이전 코드에 정의되어 있다고 가정</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"x = </span><span class="sc">{</span>x<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>new_x <span class="op">=</span> get_x_powered(x, p<span class="op">=</span>deg)</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"new_x = </span><span class="sc">{</span>new_x<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>x = [0.34906585 0.43633231 0.52359878]
new_x = [[0.34906585 0.12184697 0.04253262]
 [0.43633231 0.19038589 0.08307151]
 [0.52359878 0.27415568 0.14354758]]</code></pre>
</div>
</div>
<p>Debido a que es de tercer orden, los valores de <span class="math inline">\(x\)</span> aumentan a <span class="math inline">\(x^2, x^3\)</span>. Por ejemplo, 0.3490, 0.1218 (el cuadrado de 0.3490), 0.04253 (el cubo de 0.3490) son ejemplos de esto. Si fuera de décimo orden, se generarían datos hasta <span class="math inline">\(x^{10}\)</span>. El valor alfa del término de penalización puede tomar valores desde 0 hasta infinito. Cuanto mayor sea el valor alfa, mayor será la intensidad de la regularización. Fijaremos el grado en 13 y compararemos las funciones de regresión lineal y de regresión ridge mientras variamos el valor alfa.</p>
<div id="cell-8" class="cell" data-execution_count="18">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Ridge</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> PolynomialFeatures</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> make_pipeline</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a noisy sine wave (increased noise)</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> real_func(x):</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.sin(x) <span class="op">+</span> np.random.normal(<span class="dv">0</span>, <span class="fl">0.4</span>, <span class="bu">len</span>(x))  <span class="co"># Increased noise</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Create x data (narrower range)</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.array([np.pi <span class="op">/</span> <span class="dv">180</span> <span class="op">*</span> i <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">40</span>, <span class="dv">280</span>, <span class="dv">8</span>)])  <span class="co"># Narrower range, larger step</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> real_func(x)</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Degree of the polynomial</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>deg <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a><span class="co"># List of alpha values to compare (adjusted)</span></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>alpha_list <span class="op">=</span> [<span class="fl">0.0</span>, <span class="fl">0.1</span>, <span class="dv">10</span>]  <span class="co"># Adjusted alpha values</span></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>cols <span class="op">=</span> <span class="bu">len</span>(alpha_list)</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>fig, axes_list <span class="op">=</span> plt.subplots(<span class="dv">1</span>, cols, figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">5</span>))  <span class="co"># Adjusted figure size</span></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, alpha <span class="kw">in</span> <span class="bu">enumerate</span>(alpha_list):</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>    axes <span class="op">=</span> axes_list[i]</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot the original data</span></span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>    sns.scatterplot(ax<span class="op">=</span>axes, x<span class="op">=</span>x, y<span class="op">=</span>y, label<span class="op">=</span><span class="st">'real function'</span>, s<span class="op">=</span><span class="dv">50</span>)  <span class="co"># Increased marker size</span></span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot linear regression</span></span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>    params <span class="op">=</span> np.polyfit(x, y, deg)</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> np.poly1d(params)</span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>    sns.lineplot(ax<span class="op">=</span>axes, x<span class="op">=</span>x, y<span class="op">=</span>p(x), label<span class="op">=</span><span class="ss">f"LR deg = </span><span class="sc">{</span>deg<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ridge regression (using Pipeline, solver='auto')</span></span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> make_pipeline(PolynomialFeatures(degree<span class="op">=</span>deg), Ridge(alpha<span class="op">=</span>alpha, solver<span class="op">=</span><span class="st">'auto'</span>))</span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>    model.fit(x.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>), y)  <span class="co"># Reshape x for pipeline</span></span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> model.predict(x.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)) <span class="co"># Reshape x for prediction</span></span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>    sns.lineplot(ax<span class="op">=</span>axes, x<span class="op">=</span>x, y<span class="op">=</span>y_pred, label<span class="op">=</span><span class="ss">f"Ridge alpha=</span><span class="sc">{</span>alpha<span class="sc">:0.1e}</span><span class="ss"> deg=</span><span class="sc">{</span>deg<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a>    axes.set_title(<span class="ss">f"Alpha = </span><span class="sc">{</span>alpha<span class="sc">:0.1e}</span><span class="ss">"</span>)</span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a>    axes.set_ylim(<span class="op">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span>)  <span class="co"># Limit y-axis range</span></span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>    axes.legend()</span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="06_Sobreajuste y desarrollo de técnicas de solución_files/figure-html/cell-5-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>El gráfico muestra el resultado de ajustar datos de una función seno con ruido utilizando un polinomio de grado 10, mostrando los resultados de la regresión Ridge con diferentes valores de <code>alpha</code> (fuerza de regularización). Dado que el rango de datos es estrecho y el ruido es alto, es fácil producir overfitting incluso a bajo grado.</p>
<ul>
<li><strong>Alpha = 0.0:</strong> La regresión Ridge se vuelve igual a la regresión lineal de mínimos cuadrados ordinarios, y un polinomio de grado 10 sigue el ruido en los datos de entrenamiento, mostrando una forma de overfitting muy ondulada.</li>
<li><strong>Alpha = 0.1:</strong> Se aplica una regularización débil, lo que reduce las ondulaciones en comparación con <code>alpha=0</code>, pero aún es sensible al ruido y dista de la función seno.</li>
<li><strong>Alpha = 10:</strong> Con una fuerte regularización, la curva se vuelve mucho más suave, representando bien la tendencia general de los datos (la función seno). Esto demuestra que la regularización L2 (regresión Ridge) controla eficazmente el overfitting.</li>
</ul>
<p>Seleccionar un valor adecuado de <code>alpha</code> permite controlar la complejidad del modelo y mejorar su rendimiento en generalización. La regularización L2 es útil para estabilizar el modelo al hacer que los pesos sean cercanos a 0.</p>
<p>El modelo <code>sklearn.linear_model.Ridge</code> puede utilizar diferentes métodos de optimización según el <code>solver</code> seleccionado. En particular, cuando el rango de datos es estrecho y hay mucho ruido, como en este ejemplo, los solvers <code>'svd'</code> o <code>'cholesky'</code> pueden ser más estables, por lo que se debe tener cuidado al elegir el <code>solver</code> (en el código se especifica <code>'cholesky'</code>).</p>
</section>
<section id="aplicación-de-l1-y-l2-regularización-en-pytorch" class="level3">
<h3 class="anchored" data-anchor-id="aplicación-de-l1-y-l2-regularización-en-pytorch">6.2.2 Aplicación de L1 y L2 regularización en PyTorch</h3>
<p>PyTorch y Keras difieren en la forma de implementar la regularización L1 y L2. Keras permite agregar términos de regularización directamente a cada capa (<code>kernel_regularizer</code>, <code>bias_regularizer</code>).</p>
</section>
<section id="aplicación-de-l1-y-l2-regulación-en-pytorch" class="level3">
<h3 class="anchored" data-anchor-id="aplicación-de-l1-y-l2-regulación-en-pytorch">6.2.2 Aplicación de L1 y L2 regulación en PyTorch</h3>
<p>PyTorch y Keras tienen diferencias en la forma de implementar la regulación L1 y L2. Keras soporta agregar términos de regulación directamente a cada capa (como <code>kernel_regularizer</code>, <code>bias_regularizer</code>).</p>
<div id="cell-10" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># In Keras, you can specify regularization when declaring a layer.</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>keras.layers.Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">'relu'</span>,</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>                    kernel_regularizer<span class="op">=</span>regularizers.l2(<span class="fl">0.01</span>),</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>                    input_shape<span class="op">=</span>(<span class="dv">784</span>,))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Mientras tanto, PyTorch aplica la regularización L2 configurando la decadencia de peso (weight decay) en el optimizador (optimizer), y la regularización L1 generalmente se implementa a través de una función de pérdida personalizada.</p>
<div id="cell-12" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> custom_loss(outputs, targets, model, lambda_l1<span class="op">=</span><span class="fl">0.01</span>, lambda_l2<span class="op">=</span><span class="fl">0.01</span>,):</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    mse_loss <span class="op">=</span> nn.MSELoss()(outputs, targets)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    l1_loss <span class="op">=</span> <span class="fl">0.</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    l2_loss <span class="op">=</span> <span class="fl">0.</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> param <span class="kw">in</span> model.parameters():</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>        l1_loss <span class="op">+=</span> torch.<span class="bu">sum</span>(torch.<span class="bu">abs</span>(param)) <span class="co"># Take the absolute value of the parameters.</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>        l2_loss <span class="op">+=</span> torch.<span class="bu">sum</span>(param <span class="op">**</span> <span class="dv">2</span>)  <span class="co"># Square the parameters.</span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>    total_loss <span class="op">=</span> mse_loss <span class="op">+</span> lambda_l1 <span class="op">*</span> l1_loss <span class="op">+</span> lambda_l2 <span class="op">*</span> l2_loss <span class="co"># Add L1 and L2 penalty terms to the loss.</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> total_loss</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Example usage within a training loop (not runnable as is)</span></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a><span class="co"># for inputs, targets in dataloader:</span></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a><span class="co">#     # ... (rest of the training loop)</span></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a><span class="co">#     loss = custom_loss(outputs, targets, model)</span></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a><span class="co">#     loss.backward()</span></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ... (rest of the training loop)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Como en el ejemplo anterior, se puede definir una función <code>custom_loss</code> para aplicar tanto la regularización L1 como L2. Sin embargo, generalmente se configura el <code>weight_decay</code>, que corresponde a la regularización L2, en el optimizador. Sin embargo, los optimizadores Adam y SGD implementan el peso de decadencia ligeramente diferente a la regularización L2. La regularización L2 tradicional añade un término cuadrático de parámetros a la función de pérdida.</p>
<p><span class="math inline">\(L_{n+1} = L_{n} + \frac{ \lambda }{2} \sum w^2\)</span></p>
<p>La derivada de esto con respecto a los parámetros es la siguiente:</p>
<p><span class="math inline">\(\frac{\partial L_{n+1}}{\partial w} = \frac{\partial L_{n}}{\partial w} +\lambda w\)</span></p>
<p>SGD y Adam implementan esto añadiendo directamente el término <span class="math inline">\(\lambda w\)</span> al gradiente. El código de SGD en <code>chapter_05/optimizers/</code> es el siguiente.</p>
<div id="cell-14" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="va">self</span>.weight_decay <span class="op">!=</span> <span class="dv">0</span>:</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    grad <span class="op">=</span> grad.add(p, alpha<span class="op">=</span><span class="va">self</span>.weight_decay)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Este método no produce exactamente el mismo efecto que agregar un término de regularización L2 a la función de pérdida cuando se combina con momentum o tasas de aprendizaje adaptativas.</p>
<p><strong>Separación del Decaimiento de Peso en AdamW (Decoupled Weight Decay)</strong></p>
<p>En el artículo “Fixing Weight Decay Regularization in Adam” publicado en ICLR 2017 (https://arxiv.org/abs/1711.05101), se destacó que la atenuación de pesos en el optimizador Adam funciona de manera diferente a la regularización L2, y se propuso el optimizador AdamW para corregir este problema. En AdamW, el decaimiento de peso se separa del ajuste de gradiente y se aplica directamente durante la etapa de actualización de parámetros. El código está en el mismo basic.py.</p>
<div id="cell-16" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># PyTorch AdamW weght decay</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> weight_decay <span class="op">!=</span> <span class="dv">0</span>:</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    param.data.mul_(<span class="dv">1</span> <span class="op">-</span> lr <span class="op">*</span> weight_decay)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>AdamW multiplica los valores de los parámetros por 1 - lr * weight_decay.</p>
<ul>
<li><strong>Decaimiento de pesos en el Adam original</strong>: En la etapa de actualización de gradientes, el término de decaimiento de pesos (<span class="math inline">\(\lambda w\)</span>) se considera junto con la tasa de aprendizaje (<span class="math inline">\(lr\)</span>) y otros términos de ajuste de gradiente (por ejemplo, momentum). Esto puede hacer que el efecto del decaimiento de pesos varíe según la tasa de aprendizaje y la configuración de otros hiperparámetros.</li>
<li><strong>Decaimiento de pesos en AdamW</strong>: El decaimiento de pesos se aplica por separado en la etapa de actualización de parámetros, lo que lo hace menos dependiente de la tasa de aprendizaje u otros hiperparámetros. Es decir, el efecto del decaimiento de pesos es más predecible y consistente.</li>
</ul>
<p>En conclusión, el enfoque de AdamW se acerca más a una implementación precisa de la regularización L2. Llamar al decaimiento de pesos en SGD, Adam como regularización L2 se debe a razones históricas y efectos similares, pero estrictamente es más preciso verlo como una técnica de regularización separada, y AdamW clarifica esta diferencia para ofrecer un mejor rendimiento.</p>
</section>
<section id="análisis-del-efecto-de-la-regularización-en-el-plano-de-pérdida" class="level3">
<h3 class="anchored">6.2.3 Análisis del efecto de la regularización en el plano de pérdida</h3>
<p>Para comprender visualmente el impacto de la regularización L1 y L2 en el aprendizaje del modelo, utilizaremos la técnica de visualización del plano de pérdida (loss surface) introducida en el Capítulo 4. Compararemos los cambios en el plano de pérdida entre el caso sin regularización y el caso con regularización L2, observando cómo varía la posición de la solución óptima según la intensidad de la regularización (<code>weight_decay</code>).</p>
<div id="cell-19" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sys</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_05.visualization.loss_surface <span class="im">import</span> xy_perturb_loss,  hessian_eigenvectors, visualize_loss_surface </span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_04.utils.data <span class="im">import</span> get_dataset, get_device   </span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_04.utils.metrics <span class="im">import</span> load_model  </span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.utils.data <span class="im">as</span> data_utils</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span>  DataLoader</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> get_device()  <span class="co"># Get the device (CPU or CUDA)</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>train_dataset, test_dataset <span class="op">=</span> get_dataset()  <span class="co"># Load the datasets.  </span></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>act_name <span class="op">=</span> <span class="st">"ReLU"</span></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>model_file <span class="op">=</span> <span class="ss">f"SimpleNetwork-</span><span class="sc">{</span>act_name<span class="sc">}</span><span class="ss">.pth"</span></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>small_dataset <span class="op">=</span> data_utils.Subset(test_dataset, torch.arange(<span class="dv">0</span>, <span class="dv">256</span>))  <span class="co"># Use a subset of the test dataset</span></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>data_loader <span class="op">=</span> DataLoader(small_dataset, batch_size<span class="op">=</span><span class="dv">256</span>, shuffle<span class="op">=</span><span class="va">True</span>)  <span class="co"># Create a data loader</span></span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>loss_func <span class="op">=</span> nn.CrossEntropyLoss()  <span class="co"># Define the loss function</span></span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the trained model.</span></span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>trained_model, _ <span class="op">=</span> load_model(model_file<span class="op">=</span>model_file, path<span class="op">=</span><span class="st">"./tmp/opts/ReLU"</span>) <span class="co"># 4장의 load_model 사용</span></span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>trained_model <span class="op">=</span> trained_model.to(device)  <span class="co"># Move the model to the device</span></span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>top_n <span class="op">=</span> <span class="dv">2</span>  <span class="co"># Number of top eigenvalues/eigenvectors to compute</span></span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>top_eigenvalues, top_eigenvectors <span class="op">=</span>  hessian_eigenvectors(model<span class="op">=</span>trained_model, loss_func<span class="op">=</span>loss_func, data_loader<span class="op">=</span>data_loader, top_n<span class="op">=</span>top_n, is_cuda<span class="op">=</span><span class="va">True</span>)  <span class="co"># 5장의 함수 사용</span></span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>d_min ,d_max, d_num <span class="op">=</span> <span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">50</span>  <span class="co"># Define the range and number of points for the grid</span></span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>lambda1, lambda2 <span class="op">=</span> np.linspace(d_min, d_max, d_num).astype(np.float32), np.linspace(d_min, d_max, d_num).astype(np.float32)  <span class="co"># Create the grid of lambda values</span></span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>x, y, z <span class="op">=</span> xy_perturb_loss(model<span class="op">=</span>trained_model, top_eigenvectors<span class="op">=</span>top_eigenvectors, data_loader<span class="op">=</span>data_loader, loss_func<span class="op">=</span>loss_func, lambda1<span class="op">=</span>lambda1, lambda2<span class="op">=</span>lambda2, device<span class="op">=</span>device) <span class="co"># 5장의 함수 사용</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Se crea una función de aproximación con <code>xy_perturb_loss</code> y luego se vuelven a introducir (x, y) en esa función de aproximación para calcular un nuevo valor de z. La razón por la que se hace esto es porque si se trazan las líneas de contorno utilizando los valores obtenidos con <code>xy_perturb_loss</code>, como se muestra en el Capítulo 5, el punto mínimo puede variar ligeramente, lo que causa que el optimizador converja a un punto ligeramente diferente. Ahora, en lugar de mostrar toda la trayectoria por la que fluye el optimizador, solo se comparan los puntos más bajos finales mientras se aumenta el valor de amortiguación <code>weight_decay</code>.</p>
<div id="cell-21" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim  <span class="co"># Import optim</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader, Subset</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="co"># 5장, 4장 함수들 import</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_05.visualization.loss_surface <span class="im">import</span> (</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    hessian_eigenvectors,</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>    xy_perturb_loss,</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>    visualize_loss_surface</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_04.utils.data <span class="im">import</span> get_dataset, get_device</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_04.utils.metrics <span class="im">import</span> load_model</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_05.visualization.gaussian_loss_surface <span class="im">import</span> (</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>    get_opt_params,</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>    train_loss_surface,</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>    gaussian_func <span class="co"># gaussian_func 추가.</span></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> get_device()</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>_, test_dataset <span class="op">=</span> get_dataset(dataset<span class="op">=</span><span class="st">"FashionMNIST"</span>) </span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>small_dataset <span class="op">=</span> Subset(test_dataset, torch.arange(<span class="dv">0</span>, <span class="dv">256</span>))</span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>data_loader <span class="op">=</span> DataLoader(small_dataset, batch_size<span class="op">=</span><span class="dv">256</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>loss_func <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>act_name <span class="op">=</span> <span class="st">"ReLU"</span> <span class="co"># Tanh로 실험하려면 이 부분을 변경</span></span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>model_file <span class="op">=</span> <span class="ss">f"SimpleNetwork-</span><span class="sc">{</span>act_name<span class="sc">}</span><span class="ss">.pth"</span></span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a>trained_model, _ <span class="op">=</span> load_model(model_file<span class="op">=</span>model_file, path<span class="op">=</span><span class="st">"./tmp/opts/ReLU"</span>) </span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a>trained_model <span class="op">=</span> trained_model.to(device)</span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a>top_n <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a>top_eigenvalues, top_eigenvectors <span class="op">=</span> hessian_eigenvectors(</span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>trained_model,</span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a>    loss_func<span class="op">=</span>loss_func,</span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a>    data_loader<span class="op">=</span>data_loader,</span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a>    top_n<span class="op">=</span>top_n,</span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a>    is_cuda<span class="op">=</span><span class="va">True</span></span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a>d_min, d_max, d_num <span class="op">=</span> <span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">30</span> <span class="co"># 5장의 30을 사용</span></span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a>lambda1 <span class="op">=</span> np.linspace(d_min, d_max, d_num).astype(np.float32)</span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a>lambda2 <span class="op">=</span> np.linspace(d_min, d_max, d_num).astype(np.float32)</span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a>x, y, z <span class="op">=</span> xy_perturb_loss(</span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>trained_model,</span>
<span id="cb13-49"><a href="#cb13-49" aria-hidden="true" tabindex="-1"></a>    top_eigenvectors<span class="op">=</span>top_eigenvectors,</span>
<span id="cb13-50"><a href="#cb13-50" aria-hidden="true" tabindex="-1"></a>    data_loader<span class="op">=</span>data_loader,</span>
<span id="cb13-51"><a href="#cb13-51" aria-hidden="true" tabindex="-1"></a>    loss_func<span class="op">=</span>loss_func,</span>
<span id="cb13-52"><a href="#cb13-52" aria-hidden="true" tabindex="-1"></a>    lambda1<span class="op">=</span>lambda1,</span>
<span id="cb13-53"><a href="#cb13-53" aria-hidden="true" tabindex="-1"></a>    lambda2<span class="op">=</span>lambda2,</span>
<span id="cb13-54"><a href="#cb13-54" aria-hidden="true" tabindex="-1"></a>    device<span class="op">=</span>device <span class="co"># device 추가</span></span>
<span id="cb13-55"><a href="#cb13-55" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb13-56"><a href="#cb13-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-57"><a href="#cb13-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-58"><a href="#cb13-58" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Optimization and Visualization ---</span></span>
<span id="cb13-59"><a href="#cb13-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-60"><a href="#cb13-60" aria-hidden="true" tabindex="-1"></a><span class="co"># Find the parameters that best fit the data.</span></span>
<span id="cb13-61"><a href="#cb13-61" aria-hidden="true" tabindex="-1"></a>popt, _, offset <span class="op">=</span> get_opt_params(x, y, z)  <span class="co"># offset 사용</span></span>
<span id="cb13-62"><a href="#cb13-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-63"><a href="#cb13-63" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Optimal parameters: </span><span class="sc">{</span>popt<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-64"><a href="#cb13-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-65"><a href="#cb13-65" aria-hidden="true" tabindex="-1"></a><span class="co"># Get a new z using the optimized surface function (Gaussian).</span></span>
<span id="cb13-66"><a href="#cb13-66" aria-hidden="true" tabindex="-1"></a><span class="co"># No need for global g_offset, we can use the returned offset.</span></span>
<span id="cb13-67"><a href="#cb13-67" aria-hidden="true" tabindex="-1"></a>z_fitted <span class="op">=</span> gaussian_func((x, y), <span class="op">*</span>popt,offset) <span class="co"># offset을 더해야 함.</span></span>
<span id="cb13-68"><a href="#cb13-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-69"><a href="#cb13-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-70"><a href="#cb13-70" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> [(x, y, z_fitted)]  <span class="co"># Use z_fitted</span></span>
<span id="cb13-71"><a href="#cb13-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-72"><a href="#cb13-72" aria-hidden="true" tabindex="-1"></a>axes <span class="op">=</span> visualize_loss_surface(data, act_name<span class="op">=</span>act_name, color<span class="op">=</span><span class="st">"C0"</span>, size<span class="op">=</span><span class="dv">6</span>, levels<span class="op">=</span><span class="dv">80</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, plot_3d<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb13-73"><a href="#cb13-73" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> axes[<span class="dv">0</span>]</span>
<span id="cb13-74"><a href="#cb13-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-75"><a href="#cb13-75" aria-hidden="true" tabindex="-1"></a><span class="co"># Train with different weight decays and plot trajectories.</span></span>
<span id="cb13-76"><a href="#cb13-76" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> n, weight_decay <span class="kw">in</span> <span class="bu">enumerate</span>([<span class="fl">0.0</span>, <span class="fl">6.0</span>, <span class="fl">10.0</span>, <span class="fl">18.0</span>, <span class="fl">20.0</span>]):</span>
<span id="cb13-77"><a href="#cb13-77" aria-hidden="true" tabindex="-1"></a><span class="co"># for n, weight_decay in enumerate([0.0]):  # For faster testing</span></span>
<span id="cb13-78"><a href="#cb13-78" aria-hidden="true" tabindex="-1"></a>    points_sgd_m <span class="op">=</span> train_loss_surface(</span>
<span id="cb13-79"><a href="#cb13-79" aria-hidden="true" tabindex="-1"></a>        <span class="kw">lambda</span> params: optim.SGD(params, lr<span class="op">=</span><span class="fl">0.1</span>, momentum<span class="op">=</span><span class="fl">0.7</span>, weight_decay<span class="op">=</span>weight_decay),</span>
<span id="cb13-80"><a href="#cb13-80" aria-hidden="true" tabindex="-1"></a>        [d_min, d_max],</span>
<span id="cb13-81"><a href="#cb13-81" aria-hidden="true" tabindex="-1"></a>        <span class="dv">200</span>,</span>
<span id="cb13-82"><a href="#cb13-82" aria-hidden="true" tabindex="-1"></a>        (<span class="op">*</span>popt, offset) <span class="co"># unpack popt and offset</span></span>
<span id="cb13-83"><a href="#cb13-83" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb13-84"><a href="#cb13-84" aria-hidden="true" tabindex="-1"></a>    ax.plot(</span>
<span id="cb13-85"><a href="#cb13-85" aria-hidden="true" tabindex="-1"></a>        points_sgd_m[<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>],</span>
<span id="cb13-86"><a href="#cb13-86" aria-hidden="true" tabindex="-1"></a>        points_sgd_m[<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>],</span>
<span id="cb13-87"><a href="#cb13-87" aria-hidden="true" tabindex="-1"></a>        color<span class="op">=</span><span class="ss">f"C</span><span class="sc">{</span>n<span class="sc">}</span><span class="ss">"</span>,</span>
<span id="cb13-88"><a href="#cb13-88" aria-hidden="true" tabindex="-1"></a>        marker<span class="op">=</span><span class="st">"o"</span>,</span>
<span id="cb13-89"><a href="#cb13-89" aria-hidden="true" tabindex="-1"></a>        markersize<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb13-90"><a href="#cb13-90" aria-hidden="true" tabindex="-1"></a>        zorder<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb13-91"><a href="#cb13-91" aria-hidden="true" tabindex="-1"></a>        label<span class="op">=</span><span class="ss">f"wd=</span><span class="sc">{</span>weight_decay<span class="sc">:0.1f}</span><span class="ss">"</span></span>
<span id="cb13-92"><a href="#cb13-92" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb13-93"><a href="#cb13-93" aria-hidden="true" tabindex="-1"></a>    ax.ticklabel_format(axis<span class="op">=</span><span class="st">'both'</span>, style<span class="op">=</span><span class="st">'scientific'</span>, scilimits<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">0</span>))</span>
<span id="cb13-94"><a href="#cb13-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-95"><a href="#cb13-95" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb13-96"><a href="#cb13-96" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Function parameters = [ 4.59165436  0.34582255 -0.03204057 -1.09810435  1.54530407]
Optimal parameters: [ 4.59165436  0.34582255 -0.03204057 -1.09810435  1.54530407]

train_loss_surface: SGD
SGD: Iter=1 loss=4.7671 w=[-0.8065, 0.9251]
SGD: Iter=200 loss=1.9090 w=[0.3458, -0.0320]

train_loss_surface: SGD
SGD: Iter=1 loss=4.7671 w=[-0.2065, 0.3251]
SGD: Iter=200 loss=1.9952 w=[0.1327, -0.0077]

train_loss_surface: SGD
SGD: Iter=1 loss=4.7671 w=[0.1935, -0.0749]
SGD: Iter=200 loss=2.0293 w=[0.0935, -0.0051]

train_loss_surface: SGD
SGD: Iter=1 loss=4.7671 w=[0.9935, -0.8749]
SGD: Iter=200 loss=2.0641 w=[0.0587, -0.0030]

train_loss_surface: SGD
SGD: Iter=1 loss=4.7671 w=[1.1935, -1.0749]
SGD: Iter=200 loss=2.0694 w=[0.0537, -0.0027]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="06_Sobreajuste y desarrollo de técnicas de solución_files/figure-html/cell-11-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Como se puede ver en la figura, cuanto mayor es la regulación L2 (weight decay), más lejos del punto mínimo de la función de pérdida llega el optimizador. Esto se debe a que la regulación L2 previene que los pesos sean demasiado grandes, lo cual ayuda a evitar el sobreajuste del modelo.</p>
<p>La regulación L1 crea un modelo disperso (sparse model) al hacer que algunos pesos sean 0. Es útil cuando se desea reducir la complejidad del modelo y eliminar características innecesarias. Por otro lado, la regulación L1 no reduce los pesos completamente a 0, sino que mantiene todos los pesos pequeños. La regulación L2 generalmente muestra una convergencia más estable y, debido a que disminuye gradualmente los pesos, también se conoce como ‘regulación suave’.</p>
<p>La regulación L1 y la regulación L2 se aplican de manera diferente según las características del problema, los datos y el objetivo del modelo. Aunque generalmente se usa más la regulación L2, es aconsejable probar ambas regularizaciones en diferentes situaciones y ver cuál ofrece un mejor rendimiento. Además, también se puede considerar la regularización Elastic Net, que combina las regularizaciones L1 y L2.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Haga clic para ver el contenido (deep dive: Regularización Elastic Net - la armonía entre L1 y L2)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Haga clic para ver el contenido (deep dive: Regularización Elastic Net - la armonía entre L1 y L2)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<section id="regulación-elastic-net---armonía-entre-l1-y-l2" class="level2 callout-body-container callout-body">
<h2 class="anchored" data-anchor-id="regulación-elastic-net---armonía-entre-l1-y-l2">Regulación Elastic Net - Armonía entre L1 y L2</h2>
<p>Elastic Net es un método de regularización que combina la regulación L1 y la regulación L2. Tomando las ventajas de cada regulación y compensando sus desventajas, se puede crear un modelo más flexible y efectivo.</p>
<p><strong>Núcleo:</strong></p>
<ul>
<li><strong>Regulación L1 (Lasso):</strong> Limita la suma de los valores absolutos de los pesos. Crea un modelo <em>disperso (sparse)</em> al hacer que algunos pesos sean <em>exactamente 0</em>. Tiene un efecto de selección de características, eliminando características innecesarias y simplificando el modelo.</li>
<li><strong>Regulación L2 (Ridge):</strong> Limita la suma de los cuadrados de los pesos. Mantiene todos los pesos <em>pequeños</em> para prevenir el sobreajuste del modelo. La convergencia es estable y reduce suavemente los pesos.</li>
<li><strong>Elastic Net:</strong> Aplica <em>simultáneamente</em> la regulación L1 y L2. Se pueden obtener los efectos de ambas regulaciones.</li>
</ul>
<p><strong>Fórmula:</strong></p>
<p>La función de costo de Elastic Net se expresa de la siguiente manera.</p>
<p><span class="math inline">\(Cost = Loss + \lambda_1 \sum_{i} |w_i| + \lambda_2 \sum_{i} (w_i)^2\)</span></p>
<ul>
<li><code>Loss</code>: La función de pérdida del modelo original (ej: MSE, Cross-Entropy)</li>
<li><code>λ₁</code>: Hiperparámetro que controla la intensidad de la regulación L1</li>
<li><code>λ₂</code>: Hiperparámetro que controla la intensidad de la regulación L2</li>
<li><code>wᵢ</code>: Los pesos del modelo</li>
</ul>
<p><strong>Ventajas:</strong></p>
<ul>
<li><strong>Selección de características + prevención de sobreajuste:</strong> Se pueden obtener los efectos de selección de características de la regulación L1 y la prevención de sobreajuste de la regulación L2.</li>
<li><strong>Tratamiento de características altamente correlacionadas:</strong> La regulación L1 tiende a seleccionar una sola característica de un conjunto de características altamente correlacionadas y hacer que las demás sean 0. Elastic Net alivia este problema a través de la regulación L2, tendiendo a <em>seleccionar o eliminar juntas</em> las características altamente correlacionadas.</li>
<li><strong>Flexibilidad:</strong> Se puede ajustar el <code>λ₁</code> y el <code>λ₂</code> para equilibrar la proporción de la regulación L1 y L2. Si <code>λ₁=0</code>, se obtiene la regulación L2 (Ridge); si <code>λ₂=0</code>, se obtiene la regulación L1 (Lasso).</li>
</ul>
<p><strong>Desventajas:</strong></p>
<ul>
<li><strong>Ajuste de hiperparámetros:</strong> Se deben ajustar dos hiperparámetros, <code>λ₁</code> y <code>λ₂</code>, lo que puede ser más complejo que ajustar solo uno para la regulación L1 o L2.</li>
<li><strong>Costo computacional:</strong> Al calcular simultáneamente la regulación L1 y L2, el costo computacional puede aumentar ligeramente (no es un gran problema en el aprendizaje automático moderno).</li>
</ul>
<p><strong>Cuándo aplicar:</strong></p>
<ul>
<li>Cuando se tienen muchas características y se espera que solo algunas sean importantes (cuando se necesita selección de características)</li>
<li>Cuando las características están altamente correlacionadas</li>
<li>Cuando no está claro si la regulación L1 o L2 es mejor (cuando se desea probar ambas)</li>
<li>Para prevenir el sobreajuste mientras se crea un modelo que sea <em>disperso</em> en cierto grado</li>
</ul>
<p><strong>Resumen:</strong> Elastic Net es un método de regularización poderoso que combina las ventajas de L1 y L2. Aunque requiere ajuste de hiperparámetros, puede mostrar un buen rendimiento en una variedad de problemas.</p>
</section>
</div>
</div>
</section>
</section>
<section id="dropout-드롭아웃" class="level2">
<h2 class="anchored" data-anchor-id="dropout-드롭아웃">6.3 Dropout (드롭아웃)</h2>
<section id="principio-del-dropout" class="level3">
<h3 class="anchored" data-anchor-id="principio-del-dropout">6.3.1 Principio del dropout</h3>
<p>El dropout es uno de los métodos de regularización más poderosos para prevenir el sobreajuste en las redes neuronales. Durante el proceso de aprendizaje, se desactivan (dropout) aleatoriamente algunas neuronas para evitar que ciertas neuronas o combinaciones de neuronas dependan excesivamente de los datos de entrenamiento. Esto tiene un efecto similar al aprendizaje en conjunto, donde varias personas aprenden diferentes partes y luego colaboran para resolver el problema. Se induce a cada neurona a aprender características importantes de manera independiente, lo que mejora el rendimiento general del modelo. Generalmente se aplica a las capas completamente conectadas (fully connected layer), y la tasa de desactivación se establece entre 20% y 50%. El dropout solo se aplica durante el entrenamiento, mientras que en la inferencia se utilizan todas las neuronas.</p>
</section>
<section id="implementación-del-dropout-en-pytorch" class="level3">
<h3 class="anchored" data-anchor-id="implementación-del-dropout-en-pytorch">6.3.2 Implementación del dropout en PyTorch</h3>
<p>En PyTorch, el dropout puede implementarse de manera simple de la siguiente manera.</p>
<div id="cell-25" class="cell" data-execution_count="9">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Dropout(nn.Module):</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, dropout_rate):</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(Dropout, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout_rate <span class="op">=</span> dropout_rate</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.training:</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>            mask <span class="op">=</span> torch.bernoulli(torch.ones_like(x) <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> <span class="va">self</span>.dropout_rate)) <span class="op">/</span> (<span class="dv">1</span> <span class="op">-</span> <span class="va">self</span>.dropout_rate)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> x <span class="op">*</span> mask</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> x</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Usage example.  Drops out 0.5 (50%).</span></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>dropout <span class="op">=</span> Dropout(dropout_rate<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Example input data</span></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>inputs <span class="op">=</span> torch.randn(<span class="dv">1000</span>, <span class="dv">100</span>)</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Forward pass (during training)</span></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>dropout.train()</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>outputs_train <span class="op">=</span> dropout(inputs)</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Forward pass (during inference)</span></span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>dropout.<span class="bu">eval</span>()</span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>outputs_test <span class="op">=</span> dropout(inputs)</span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Input shape:"</span>, inputs.shape)</span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Training output shape:"</span>, outputs_train.shape)</span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test output shape"</span>, outputs_test.shape)</span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Dropout rate (should be close to 0.5):"</span>, <span class="dv">1</span> <span class="op">-</span> torch.count_nonzero(outputs_train) <span class="op">/</span> outputs_train.numel())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Input shape: torch.Size([1000, 100])
Training output shape: torch.Size([1000, 100])
Test output shape torch.Size([1000, 100])
Dropout rate (should be close to 0.5): tensor(0.4997)</code></pre>
</div>
</div>
<p>La implementación es muy simple. Se multiplica el valor de <code>mask</code> por el tensor de entrada para desactivar una proporción determinada de neuronas. La capa de dropout no tiene parámetros aprendibles separados, simplemente convierte en 0 aleatoriamente parte de la entrada. En redes neuronales prácticas, las capas de dropout se insertan entre otras capas (por ejemplo, capas lineales, capas de convolución) para su uso. El dropout elimina aleatoriamente neuronas durante el entrenamiento, pero utiliza todas las neuronas durante la inferencia. Para ajustar la escala de los valores de salida durante el entrenamiento y la inferencia, se utiliza el método de <em>dropout invertido</em>. El dropout invertido realiza un escalado anticipado dividiendo por (1 - dropout_rate) durante el entrenamiento, lo que permite usar directamente los valores sin operaciones adicionales durante la inferencia. De esta manera, se puede obtener un efecto similar al del aprendizaje conjunto durante la inferencia, es decir, promediando varios sub-redes parciales (sub-networks), mientras también se mejora la eficiencia computacional.</p>
<p>Vamos a examinar qué tan efectivo es el dropout utilizando gráficos con datos simples. El código fuente está en <code>chapter_06/plot_dropout.py</code>, y aunque es importante, no lo presentaremos aquí por brevedad. Los comentarios detallados hacen que ver el código sea sencillo. Al graficar los resultados, se puede observar que el modelo con dropout (azul) tiene una precisión de prueba significativamente mayor.</p>
<div id="cell-27" class="cell" data-execution_count="11">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_06.plot_dropout <span class="im">import</span> plot_dropout_effect</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>plot_dropout_effect()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="06_Sobreajuste y desarrollo de técnicas de solución_files/figure-html/cell-13-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>La precisión de entrenamiento del modelo con dropout (With Dropout) es menor que la del modelo sin dropout (Without Dropout), pero la precisión de validación es mayor. Esto significa que el dropout reduce el sobreajuste a los datos de entrenamiento y mejora el rendimiento de generalización del modelo.</p>
</section>
</section>
<section id="normalización-por-lotes-batch-normalization" class="level2">
<h2 class="anchored" data-anchor-id="normalización-por-lotes-batch-normalization">6.4 Normalización por lotes (batch normalization)</h2>
<section id="concepto-y-efectos-de-la-normalización-por-lotes" class="level3">
<h3 class="anchored" data-anchor-id="concepto-y-efectos-de-la-normalización-por-lotes">6.4.1 Concepto y efectos de la normalización por lotes</h3>
<p>La normalización por lotes es un método que, además de actuar como regularización, aumenta la estabilidad de los datos durante el entrenamiento. La normalización por lotes fue propuesta por primera vez en 2015 por Ioffe y Szegedy en su artículo [referencia 2]. En el aprendizaje profundo, ocurre un fenómeno denominado cambio interno de covariables (internal covariate shift), donde la distribución de los valores de activación cambia a medida que los datos pasan por cada capa. Esto ralentiza el entrenamiento y hace que el modelo sea inestable (se necesitan más pasos de cálculo debido al cambio en la distribución). Este problema se agrava especialmente cuando hay más capas. La normalización por lotes mitiga este problema normalizando los datos a nivel de mini lote.</p>
<p>La idea central de la normalización por lotes es normalizar los datos a nivel de mini lote. El siguiente código ilustra esto de manera sencilla.</p>
<div id="cell-30" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the mean and variance of the mini-batch</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>batch_mean <span class="op">=</span> x.mean(dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>batch_var <span class="op">=</span> x.var(dim<span class="op">=</span><span class="dv">0</span>, unbiased<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform normalization</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>x_norm <span class="op">=</span> (x <span class="op">-</span> batch_mean) <span class="op">/</span> torch.sqrt(batch_var <span class="op">+</span> epsilon)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply scale and shift parameters</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> gamma <span class="op">*</span> x_norm <span class="op">+</span> beta</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Generalmente, la normalización por lotes utiliza la varianza y la media de los datos dentro de un solo lote de entrenamiento para ajustar adecuadamente la distribución de todos los datos. Primero se realiza la normalización y luego se aplican parámetros de escala y desplazamiento en cierto grado. El gamma anterior es el parámetro de escala y beta es el parámetro de desplazamiento. Es conveniente pensar simplemente en <span class="math inline">\(y = ax + b\)</span>. Epsilon, utilizado durante la normalización, es un valor constante muy pequeño (1e-5 o 1e-7) común en análisis numérico. Se utiliza para garantizar la estabilidad numérica. La normalización por lotes proporciona los siguientes efectos adicionales:</p>
<ul>
<li><strong>Aumento de la velocidad de aprendizaje</strong>: Estabiliza la distribución de los valores de activación de cada capa, mitigando el problema del desvanecimiento/explotación del gradiente y permitiendo el uso de tasas de aprendizaje más altas.</li>
<li><strong>Reducción de la dependencia de la inicialización</strong>: Reduce la sensibilidad a la inicialización de pesos, facilitando el inicio del proceso de aprendizaje.</li>
<li><strong>Efecto regularizador</strong>: Al calcular estadísticas por lotes, tiene un efecto similar al de agregar ruido, lo que ayuda a prevenir el sobreajuste (overfitting). Su eficacia se mejora cuando se usa junto con Dropout.</li>
</ul>
<p>Vamos a crear datos aleatorios con dos características y comparar gráficamente los casos en los que se aplica la normalización pura y los que incluyen parámetros de escala y desplazamiento. A través de la visualización, será fácil comprender el significado numérico de la normalización en un lote de entrenamiento.</p>
<div id="cell-32" class="cell" data-execution_count="21">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate data</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.random.rand(<span class="dv">50</span>, <span class="dv">2</span>) <span class="op">*</span> <span class="dv">10</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Batch normalization (including scaling parameters)</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> batch_normalize(x, epsilon<span class="op">=</span><span class="fl">1e-5</span>, gamma<span class="op">=</span><span class="fl">1.0</span>, beta<span class="op">=</span><span class="fl">0.0</span>):</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>    mean <span class="op">=</span> x.mean(axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>    var <span class="op">=</span> x.var(axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>    x_norm <span class="op">=</span> (x <span class="op">-</span> mean) <span class="op">/</span> np.sqrt(var <span class="op">+</span> epsilon)</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>    x_scaled <span class="op">=</span> gamma <span class="op">*</span> x_norm <span class="op">+</span> beta</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x_norm, mean, x_scaled</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform normalization (gamma=1.0, beta=0.0 is pure normalization)</span></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>x_norm, mean, x_norm_scaled <span class="op">=</span> batch_normalize(x, gamma<span class="op">=</span><span class="fl">1.0</span>, beta<span class="op">=</span><span class="fl">0.0</span>)</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform normalization and scaling (apply gamma=2.0, beta=1.0)</span></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>_, _, x_scaled <span class="op">=</span> batch_normalize(x, gamma<span class="op">=</span><span class="fl">2.0</span>, beta<span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Set Seaborn style</span></span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>sns.set_style(<span class="st">"whitegrid"</span>)</span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>sns.set_context(<span class="st">"notebook"</span>, font_scale<span class="op">=</span><span class="fl">1.2</span>)</span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualization</span></span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2, ax3) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">18</span>, <span class="dv">5</span>))</span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Original data</span></span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span>x[:, <span class="dv">0</span>], y<span class="op">=</span>x[:, <span class="dv">1</span>], ax<span class="op">=</span>ax1, color<span class="op">=</span><span class="st">'royalblue'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a>ax1.scatter(mean[<span class="dv">0</span>], mean[<span class="dv">1</span>], color<span class="op">=</span><span class="st">'red'</span>, marker<span class="op">=</span><span class="st">'*'</span>, s<span class="op">=</span><span class="dv">200</span>, label<span class="op">=</span><span class="st">'Mean'</span>)</span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>ax1.<span class="bu">set</span>(title<span class="op">=</span><span class="st">'Original Data'</span>,</span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>        xlabel<span class="op">=</span><span class="st">'Feature 1'</span>,</span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a>        ylabel<span class="op">=</span><span class="st">'Feature 2'</span>,</span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a>        xlim<span class="op">=</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dv">12</span>),</span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a>        ylim<span class="op">=</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dv">12</span>))</span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a>ax1.legend()</span>
<span id="cb19-38"><a href="#cb19-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-39"><a href="#cb19-39" aria-hidden="true" tabindex="-1"></a><span class="co"># After normalization (gamma=1, beta=0)</span></span>
<span id="cb19-40"><a href="#cb19-40" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span>x_norm[:, <span class="dv">0</span>], y<span class="op">=</span>x_norm[:, <span class="dv">1</span>], ax<span class="op">=</span>ax2, color<span class="op">=</span><span class="st">'crimson'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb19-41"><a href="#cb19-41" aria-hidden="true" tabindex="-1"></a>ax2.scatter(<span class="dv">0</span>, <span class="dv">0</span>, color<span class="op">=</span><span class="st">'blue'</span>, marker<span class="op">=</span><span class="st">'*'</span>, s<span class="op">=</span><span class="dv">200</span>, label<span class="op">=</span><span class="st">'Mean (0,0)'</span>)</span>
<span id="cb19-42"><a href="#cb19-42" aria-hidden="true" tabindex="-1"></a>ax2.axhline(y<span class="op">=</span><span class="dv">0</span>, color<span class="op">=</span><span class="st">'k'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb19-43"><a href="#cb19-43" aria-hidden="true" tabindex="-1"></a>ax2.axvline(x<span class="op">=</span><span class="dv">0</span>, color<span class="op">=</span><span class="st">'k'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb19-44"><a href="#cb19-44" aria-hidden="true" tabindex="-1"></a>ax2.<span class="bu">set</span>(title<span class="op">=</span><span class="st">'After Normalization (γ=1, β=0)'</span>,</span>
<span id="cb19-45"><a href="#cb19-45" aria-hidden="true" tabindex="-1"></a>        xlabel<span class="op">=</span><span class="st">'Normalized Feature 1'</span>,</span>
<span id="cb19-46"><a href="#cb19-46" aria-hidden="true" tabindex="-1"></a>        ylabel<span class="op">=</span><span class="st">'Normalized Feature 2'</span>,</span>
<span id="cb19-47"><a href="#cb19-47" aria-hidden="true" tabindex="-1"></a>        xlim<span class="op">=</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dv">12</span>),</span>
<span id="cb19-48"><a href="#cb19-48" aria-hidden="true" tabindex="-1"></a>        ylim<span class="op">=</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dv">12</span>))</span>
<span id="cb19-49"><a href="#cb19-49" aria-hidden="true" tabindex="-1"></a>ax2.legend()</span>
<span id="cb19-50"><a href="#cb19-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-51"><a href="#cb19-51" aria-hidden="true" tabindex="-1"></a><span class="co"># After scaling and shifting (gamma=2, beta=1)</span></span>
<span id="cb19-52"><a href="#cb19-52" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span>x_scaled[:, <span class="dv">0</span>], y<span class="op">=</span>x_scaled[:, <span class="dv">1</span>], ax<span class="op">=</span>ax3, color<span class="op">=</span><span class="st">'green'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb19-53"><a href="#cb19-53" aria-hidden="true" tabindex="-1"></a>ax3.scatter(<span class="dv">1</span>, <span class="dv">1</span>, color<span class="op">=</span><span class="st">'purple'</span>, marker<span class="op">=</span><span class="st">'*'</span>, s<span class="op">=</span><span class="dv">200</span>, label<span class="op">=</span><span class="st">'New Mean'</span>)</span>
<span id="cb19-54"><a href="#cb19-54" aria-hidden="true" tabindex="-1"></a>ax3.axhline(y<span class="op">=</span><span class="dv">1</span>, color<span class="op">=</span><span class="st">'k'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb19-55"><a href="#cb19-55" aria-hidden="true" tabindex="-1"></a>ax3.axvline(x<span class="op">=</span><span class="dv">1</span>, color<span class="op">=</span><span class="st">'k'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb19-56"><a href="#cb19-56" aria-hidden="true" tabindex="-1"></a>ax3.<span class="bu">set</span>(title<span class="op">=</span><span class="st">'After Scale &amp; Shift (γ=2, β=1)'</span>,</span>
<span id="cb19-57"><a href="#cb19-57" aria-hidden="true" tabindex="-1"></a>        xlabel<span class="op">=</span><span class="st">'Scaled Feature 1'</span>,</span>
<span id="cb19-58"><a href="#cb19-58" aria-hidden="true" tabindex="-1"></a>        ylabel<span class="op">=</span><span class="st">'Scaled Feature 2'</span>,</span>
<span id="cb19-59"><a href="#cb19-59" aria-hidden="true" tabindex="-1"></a>        xlim<span class="op">=</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dv">12</span>),</span>
<span id="cb19-60"><a href="#cb19-60" aria-hidden="true" tabindex="-1"></a>        ylim<span class="op">=</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dv">12</span>))</span>
<span id="cb19-61"><a href="#cb19-61" aria-hidden="true" tabindex="-1"></a>ax3.legend()</span>
<span id="cb19-62"><a href="#cb19-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-63"><a href="#cb19-63" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb19-64"><a href="#cb19-64" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb19-65"><a href="#cb19-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-66"><a href="#cb19-66" aria-hidden="true" tabindex="-1"></a><span class="co"># Print statistics</span></span>
<span id="cb19-67"><a href="#cb19-67" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Original Data Statistics:"</span>)</span>
<span id="cb19-68"><a href="#cb19-68" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Mean: </span><span class="sc">{</span>mean<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-69"><a href="#cb19-69" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Variance: </span><span class="sc">{</span>x<span class="sc">.</span>var(axis<span class="op">=</span><span class="dv">0</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-70"><a href="#cb19-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-71"><a href="#cb19-71" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Normalized Data Statistics (γ=1, β=0):"</span>)</span>
<span id="cb19-72"><a href="#cb19-72" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Mean: </span><span class="sc">{</span>x_norm<span class="sc">.</span>mean(axis<span class="op">=</span><span class="dv">0</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-73"><a href="#cb19-73" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Variance: </span><span class="sc">{</span>x_norm<span class="sc">.</span>var(axis<span class="op">=</span><span class="dv">0</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-74"><a href="#cb19-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-75"><a href="#cb19-75" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Scaled Data Statistics (γ=2, β=1):"</span>)</span>
<span id="cb19-76"><a href="#cb19-76" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Mean: </span><span class="sc">{</span>x_scaled<span class="sc">.</span>mean(axis<span class="op">=</span><span class="dv">0</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-77"><a href="#cb19-77" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Variance: </span><span class="sc">{</span>x_scaled<span class="sc">.</span>var(axis<span class="op">=</span><span class="dv">0</span>)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="06_Sobreajuste y desarrollo de técnicas de solución_files/figure-html/cell-15-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Original Data Statistics:
Mean: [4.40716778 4.99644709]
Variance: [8.89458134 8.45478364]

Normalized Data Statistics (γ=1, β=0):
Mean: [-2.70894418e-16 -3.59712260e-16]
Variance: [0.99999888 0.99999882]

Scaled Data Statistics (γ=2, β=1):
Mean: [1. 1.]
Variance: [3.9999955  3.99999527]</code></pre>
</div>
</div>
<p>En seed(42) es común ver el valor de inicialización aleatoria establecido en 42. Esta es una práctica habitual entre los programadores, aunque se puede usar cualquier otro número. El 42 es un número que aparece en la novela “La guía del autoestopista galáctico” de Douglas Adams como “la respuesta a la vida, el universo y todo lo demás”. Por esta razón, se utiliza comúnmente en el código de ejemplo y entre los programadores.</p>
</section>
<section id="implementación-de-la-normalización-por-lotes-en-pytorch" class="level3">
<h3 class="anchored">6.4.2 Implementación de la normalización por lotes en PyTorch</h3>
<p>En PyTorch, la implementación generalmente implica insertar una capa de normalización por lotes en las capas de la red neuronal. A continuación se muestra un ejemplo.</p>
<div id="cell-35" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SimpleNet(nn.Module):</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.network <span class="op">=</span> nn.Sequential(</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">784</span>, <span class="dv">256</span>),</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm1d(<span class="dv">256</span>),  <span class="co"># 배치 정규화 층</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">256</span>, <span class="dv">10</span>)</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.network(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>En PyTorch, la implementación de la normalización por lotes simplificada a partir del código fuente original es como sigue. Al igual que en el capítulo anterior, esto se ha implementado de manera concisa con fines educativos.</p>
<div id="cell-37" class="cell" data-execution_count="23">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> BatchNorm1d(nn.Module):</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_features, eps<span class="op">=</span><span class="fl">1e-5</span>, momentum<span class="op">=</span><span class="fl">0.1</span>):</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_features <span class="op">=</span> num_features</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.eps <span class="op">=</span> eps</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.momentum <span class="op">=</span> momentum</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Trainable parameters</span></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.gamma <span class="op">=</span> nn.Parameter(torch.ones(num_features))  <span class="co"># scale</span></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.beta <span class="op">=</span> nn.Parameter(torch.zeros(num_features))  <span class="co"># shift</span></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Running statistics to be tracked</span></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.register_buffer(<span class="st">'running_mean'</span>, torch.zeros(num_features))</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.register_buffer(<span class="st">'running_var'</span>, torch.ones(num_features))</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.training:</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Calculate mini-batch statistics</span></span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>            batch_mean <span class="op">=</span> x.mean(dim<span class="op">=</span><span class="dv">0</span>)  <span class="co"># Mean per channel</span></span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a>            batch_var <span class="op">=</span> x.var(dim<span class="op">=</span><span class="dv">0</span>, unbiased<span class="op">=</span><span class="va">False</span>)  <span class="co"># Variance per channel</span></span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Update running statistics (important)</span></span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.running_mean <span class="op">=</span> (<span class="dv">1</span> <span class="op">-</span> <span class="va">self</span>.momentum) <span class="op">*</span> <span class="va">self</span>.running_mean <span class="op">+</span> <span class="va">self</span>.momentum <span class="op">*</span> batch_mean</span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.running_var <span class="op">=</span> (<span class="dv">1</span> <span class="op">-</span> <span class="va">self</span>.momentum) <span class="op">*</span> <span class="va">self</span>.running_var <span class="op">+</span> <span class="va">self</span>.momentum <span class="op">*</span> batch_var</span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Normalize</span></span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a>            x_norm <span class="op">=</span> (x <span class="op">-</span> batch_mean) <span class="op">/</span> torch.sqrt(batch_var <span class="op">+</span> <span class="va">self</span>.eps)</span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true" tabindex="-1"></a>            <span class="co"># During inference, use the stored statistics</span></span>
<span id="cb22-34"><a href="#cb22-34" aria-hidden="true" tabindex="-1"></a>            x_norm <span class="op">=</span> (x <span class="op">-</span> <span class="va">self</span>.running_mean) <span class="op">/</span> torch.sqrt(<span class="va">self</span>.running_var <span class="op">+</span> <span class="va">self</span>.eps)</span>
<span id="cb22-35"><a href="#cb22-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-36"><a href="#cb22-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply scale and shift</span></span>
<span id="cb22-37"><a href="#cb22-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.gamma <span class="op">*</span> x_norm <span class="op">+</span> <span class="va">self</span>.beta</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>La parte más diferente con respecto a la implementación básica es la actualización de las estadísticas durante la ejecución. Durante el entrenamiento, se acumula el movimiento de las estadísticas del mini-lote (media y varianza) para finalmente poder conocer la media y varianza totales. Para seguir este movimiento, se utiliza una media móvil exponencial (Exponential Moving Average) con un momento (valor predeterminado 0.1). Al utilizar esta media y varianza obtenidas durante el entrenamiento en la inferencia, se aplica una varianza y desviación precisas a los datos de inferencia, garantizando la consistencia entre el aprendizaje y la inferencia.</p>
<p>Por supuesto, esta implementación es muy simplificada para fines educativos. La ubicación del código de referencia es (https://github.com/pytorch/pytorch/blob/main/torch/nn/modules/batchnorm.py). La implementación real de BatchNorm1d es mucho más compleja. Esto se debe a que, en frameworks como PyTorch y TensorFlow, además de la lógica básica, incluyen diversas optimizaciones como CUDA, optimización de gradientes, manejo de diferentes configuraciones, integración con C/C++, entre otros.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Haga clic para ver el contenido (análisis detallado de la derivación matemática y el proceso de retropropagación de la normalización por lotes)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Haga clic para ver el contenido (análisis detallado de la derivación matemática y el proceso de retropropagación de la normalización por lotes)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<section id="derivación-de-la-fórmula-y-análisis-detallado-del-proceso-de-retropropagación-de-la-normalización-por-lotes" class="level2 callout-body-container callout-body">
<h2 class="anchored" data-anchor-id="derivación-de-la-fórmula-y-análisis-detallado-del-proceso-de-retropropagación-de-la-normalización-por-lotes">Derivación de la fórmula y análisis detallado del proceso de retropropagación de la normalización por lotes</h2>
<p>La normalización por lotes (Batch Normalization, BN) se ha establecido como una de las técnicas clave en el aprendizaje de modelos de deep learning desde que fue propuesta por Ioffe &amp; Szegedy en 2015. BN normaliza las entradas de cada capa para acelerar la velocidad de aprendizaje, mitigar los problemas de desvanecimiento/explotación del gradiente y proporcionar cierto efecto de regularización. En este deep dive, examinaremos detalladamente el proceso de propagación hacia adelante y retropropagación de BN, y analizaremos sus efectos matemáticamente.</p>
<section id="derivación-de-la-fórmula-de-propagación-hacia-adelante-forward-pass-de-la-normalización-por-lotes" class="level3">
<h3 class="anchored" data-anchor-id="derivación-de-la-fórmula-de-propagación-hacia-adelante-forward-pass-de-la-normalización-por-lotes">Derivación de la fórmula de propagación hacia adelante (Forward Pass) de la normalización por lotes</h3>
<p>La normalización por lotes se realiza en unidades de mini-lotes (mini-batches). Si consideramos el tamaño del mini-lote como <span class="math inline">\(B\)</span> y la dimensión de las características (features) como <span class="math inline">\(D\)</span>, los datos de entrada del mini-lote se pueden representar como una matriz <span class="math inline">\(\mathbf{X}\)</span> de tamaño <span class="math inline">\(B \times D\)</span>. BN se realiza independientemente para cada dimensión de las características, por lo que consideraremos solo las operaciones para una dimensión de característica en particular.</p>
<ol type="1">
<li><p><strong>Cálculo de la media del mini-lote:</strong></p>
<p><span class="math inline">\(\mu_B = \frac{1}{B} \sum_{i=1}^{B} x_i\)</span></p>
<p>Aquí, <span class="math inline">\(x_i\)</span> representa el valor de la característica correspondiente al <span class="math inline">\(i\)</span>-ésimo ejemplo en el mini-lote.</p></li>
<li><p><strong>Cálculo de la varianza del mini-lote:</strong></p>
<p><span class="math inline">\(\sigma_B^2 = \frac{1}{B} \sum_{i=1}^{B} (x_i - \mu_B)^2\)</span></p></li>
<li><p><strong>Normalización:</strong></p>
<p><span class="math inline">\(\hat{x_i} = \frac{x_i - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}}\)</span></p>
<p>Aquí, <span class="math inline">\(\epsilon\)</span> es una pequeña constante para evitar que el denominador sea cero.</p></li>
<li><p><strong>Escalado y desplazamiento (Scale and Shift):</strong></p>
<p><span class="math inline">\(y_i = \gamma \hat{x_i} + \beta\)</span></p>
<p>Aquí, <span class="math inline">\(\gamma\)</span> y <span class="math inline">\(\beta\)</span> son parámetros aprendibles que se encargan del escalado y el desplazamiento, respectivamente. Estos parámetros juegan un papel en restaurar la capacidad de representación de los datos normalizados.</p></li>
</ol>
</section>
<section id="derivación-de-la-fórmula-de-retropropagación-backward-pass-de-la-normalización-por-lotes---incluyendo-gráfico-de-cálculo" class="level3">
<h3 class="anchored" data-anchor-id="derivación-de-la-fórmula-de-retropropagación-backward-pass-de-la-normalización-por-lotes---incluyendo-gráfico-de-cálculo">Derivación de la fórmula de retropropagación (Backward Pass) de la normalización por lotes - incluyendo gráfico de cálculo</h3>
<p>La retropropagación de la normalización por lotes implica calcular las derivadas de la función de pérdida con respecto a cada parámetro utilizando la regla de la cadena. Este proceso se puede visualizar a través de un gráfico de cálculo, que se muestra a continuación. (Aquí se representa brevemente mediante ASCII art)</p>
<pre><code>     x_i   --&gt;   [-]   --&gt;   [/]   --&gt;   [*]   --&gt;   [+]   --&gt;   y_i
      |          ^          ^          ^          ^
      |          |          |          |          |
      |          |          |          |          +---&gt; beta
      |          |          |          +---&gt; gamma
      |          |          +---&gt; sqrt(...) + epsilon
      |          +---&gt; mu_B, sigma_B^2</code></pre>
<ul>
<li><span class="math inline">\(x_i\)</span>: entrada</li>
<li><span class="math inline">\([-]\)</span>: resta (<span class="math inline">\(x_i - \mu_B\)</span>)</li>
<li><span class="math inline">\([/]\)</span>: división (<span class="math inline">\((x_i - \mu_B) / \sqrt{\sigma_B^2 + \epsilon}\)</span>)</li>
<li><span class="math inline">\([*]\)</span>: multiplicación (<span class="math inline">\(\gamma \hat{x_i}\)</span>)</li>
<li><span class="math inline">\([+]\)</span>: suma (<span class="math inline">\(\gamma \hat{x_i} + \beta\)</span>)</li>
<li><span class="math inline">\(y_i\)</span>: salida</li>
<li><span class="math inline">\(\mu_B\)</span>: media</li>
<li><span class="math inline">\(\sigma_B^2\)</span>: varianza</li>
<li><span class="math inline">\(\epsilon\)</span>: pequeño número para evitar que el denominador sea cero</li>
<li><span class="math inline">\(\gamma, \beta\)</span>: parámetros de aprendizaje Ahora, calculemos el backpropagation paso a paso. Denotemos la función de pérdida como <span class="math inline">\(\mathcal{L}\)</span> y supongamos que se nos da <span class="math inline">\(\frac{\partial \mathcal{L}}{\partial y_i}\)</span>.</li>
</ul>
<ol type="1">
<li><p><strong>Cálculo de <span class="math inline">\(\frac{\partial \mathcal{L}}{\partial \beta}\)</span> y <span class="math inline">\(\frac{\partial \mathcal{L}}{\partial \gamma}\)</span>:</strong></p>
<p><span class="math inline">\(\frac{\partial \mathcal{L}}{\partial \beta} = \sum_{i=1}^{B} \frac{\partial \mathcal{L}}{\partial y_i} \cdot \frac{\partial y_i}{\partial \beta} = \sum_{i=1}^{B} \frac{\partial \mathcal{L}}{\partial y_i}\)</span></p>
<p><span class="math inline">\(\frac{\partial \mathcal{L}}{\partial \gamma} = \sum_{i=1}^{B} \frac{\partial \mathcal{L}}{\partial y_i} \cdot \frac{\partial y_i}{\partial \gamma} = \sum_{i=1}^{B} \frac{\partial \mathcal{L}}{\partial y_i} \cdot \hat{x_i}\)</span></p></li>
<li><p><strong>Cálculo de <span class="math inline">\(\frac{\partial \mathcal{L}}{\partial \hat{x_i}}\)</span>:</strong></p>
<p><span class="math inline">\(\frac{\partial \mathcal{L}}{\partial \hat{x_i}} = \frac{\partial \mathcal{L}}{\partial y_i} \cdot \frac{\partial y_i}{\partial \hat{x_i}} = \frac{\partial \mathcal{L}}{\partial y_i} \cdot \gamma\)</span></p></li>
<li><p><strong>Cálculo de <span class="math inline">\(\frac{\partial \mathcal{L}}{\partial \sigma_B^2}\)</span>:</strong></p>
<p><span class="math inline">\(\frac{\partial \mathcal{L}}{\partial \sigma_B^2} = \sum_{i=1}^{B} \frac{\partial \mathcal{L}}{\partial \hat{x_i}} \cdot \frac{\partial \hat{x_i}}{\partial \sigma_B^2} = \sum_{i=1}^{B} \frac{\partial \mathcal{L}}{\partial \hat{x_i}} \cdot (x_i - \mu_B) \cdot (-\frac{1}{2})(\sigma_B^2 + \epsilon)^{-3/2}\)</span></p></li>
<li><p><strong>Cálculo de <span class="math inline">\(\frac{\partial \mathcal{L}}{\partial \mu_B}\)</span>:</strong></p>
<p><span class="math inline">\(\frac{\partial \mathcal{L}}{\partial \mu_B} = \sum_{i=1}^{B} \frac{\partial \mathcal{L}}{\partial \hat{x_i}} \cdot \frac{\partial \hat{x_i}}{\partial \mu_B} + \frac{\partial \mathcal{L}}{\partial \sigma_B^2} \cdot \frac{\partial \sigma_B^2}{\partial \mu_B}  = \sum_{i=1}^{B} \frac{\partial \mathcal{L}}{\partial \hat{x_i}} \cdot \frac{-1}{\sqrt{\sigma_B^2 + \epsilon}} + \frac{\partial \mathcal{L}}{\partial \sigma_B^2} \cdot (-2)\frac{1}{B}\sum_{i=1}^B (x_i-\mu_B)\)</span></p>
<p>Dado que <span class="math inline">\(\sum_{i=1}^B (x_i - \mu_B) = 0\)</span> <span class="math inline">\(\frac{\partial \mathcal{L}}{\partial \mu_B} =  \sum_{i=1}^{B} \frac{\partial \mathcal{L}}{\partial \hat{x_i}} \cdot \frac{-1}{\sqrt{\sigma_B^2 + \epsilon}}\)</span></p></li>
<li><p><strong>Cálculo de <span class="math inline">\(\frac{\partial \mathcal{L}}{\partial x_i}\)</span>:</strong></p>
<p><span class="math inline">\(\frac{\partial \mathcal{L}}{\partial x_i} = \frac{\partial \mathcal{L}}{\partial \hat{x_i}} \cdot \frac{\partial \hat{x_i}}{\partial x_i} + \frac{\partial \mathcal{L}}{\partial \mu_B} \cdot \frac{\partial \mu_B}{\partial x_i}  + \frac{\partial \mathcal{L}}{\partial \sigma_B^2} \cdot \frac{\partial \sigma_B^2}{\partial x_i} = \frac{\partial \mathcal{L}}{\partial \hat{x_i}} \cdot \frac{1}{\sqrt{\sigma_B^2 + \epsilon}} + \frac{\partial \mathcal{L}}{\partial \mu_B} \cdot \frac{1}{B} +  \frac{\partial \mathcal{L}}{\partial \sigma_B^2} \cdot \frac{2}{B}(x_i - \mu_B)\)</span></p></li>
</ol>
</section>
<section id="explicación-de-cómo-la-normalización-por-lotes-mitiga-el-problema-de-desvanecimientoestallido-del-gradiente" class="level3">
<h3 class="anchored" data-anchor-id="explicación-de-cómo-la-normalización-por-lotes-mitiga-el-problema-de-desvanecimientoestallido-del-gradiente">Explicación de cómo la normalización por lotes mitiga el problema de desvanecimiento/estallido del gradiente</h3>
<p>La normalización por lotes evita que las entradas a las funciones de activación se sesguen hacia valores extremos al normalizar las entradas en cada capa. Esto ayuda a mitigar el problema de desvanecimiento/estallido del gradiente, que ocurre en funciones de activación como la sigmoide o tanh.</p>
<ul>
<li><p><strong>Problema de desvanecimiento del gradiente:</strong> Cuando las entradas a una función de activación son muy grandes o pequeñas, la pendiente de esa función se acerca a 0, lo que provoca que el gradiente se desvanezca durante la retropropagación. La normalización por lotes mantiene las entradas de la función de activación en un rango adecuado al normalizarlas con media 0 y varianza 1, mitigando así el problema de desvanecimiento del gradiente.</p></li>
<li><p><strong>Problema de estallido del gradiente:</strong> Cuando las entradas a una función de activación son muy grandes, la pendiente se vuelve extremadamente grande. La normalización por lotes limita el rango de entrada, mitigando también el problema de estallido del gradiente.</p></li>
</ul>
</section>
<section id="cálculo-y-uso-del-promedio-móvil-running-mean-running-variance-durante-la-inferencia-en-la-normalización-por-lotes" class="level3">
<h3 class="anchored" data-anchor-id="cálculo-y-uso-del-promedio-móvil-running-mean-running-variance-durante-la-inferencia-en-la-normalización-por-lotes">Cálculo y uso del promedio móvil (running mean, running variance) durante la inferencia en la normalización por lotes</h3>
<p>Durante el entrenamiento, la normalización por lotes calcula la media y varianza para cada mini-lote. Sin embargo, durante la inferencia se necesitan estimaciones de la media y varianza del conjunto completo de datos de entrenamiento. Para esto, la normalización por lotes calcula el promedio móvil (running mean) y la varianza móvil (running variance) durante el proceso de entrenamiento.</p>
<ul>
<li><p><strong>Cálculo del promedio móvil:</strong></p>
<p><span class="math inline">\(\text{running\_mean} = (1 - \text{momentum}) \times \text{running\_mean} + \text{momentum} \times \mu_B\)</span></p></li>
<li><p><strong>Cálculo de la varianza móvil:</strong></p>
<p><span class="math inline">\(\text{running\_var} = (1 - \text{momentum}) \times \text{running\_var} + \text{momentum} \times \sigma_B^2\)</span></p></li>
</ul>
<p>Aquí, <code>momentum</code> es un hiperparámetro que generalmente se establece en valores pequeños como 0.1 o 0.01.</p>
<p>Durante la inferencia, se utilizan los <code>running_mean</code> y <code>running_var</code> calculados durante el entrenamiento para normalizar las entradas.</p>
</section>
<section id="comparación-de-la-normalización-por-lotes-con-otras-técnicas-de-normalización-normalización-por-capa-normalización-por-instancia-normalización-por-grupo" class="level3">
<h3 class="anchored" data-anchor-id="comparación-de-la-normalización-por-lotes-con-otras-técnicas-de-normalización-normalización-por-capa-normalización-por-instancia-normalización-por-grupo">Comparación de la normalización por lotes con otras técnicas de normalización (Normalización por capa, Normalización por instancia, Normalización por grupo)</h3>
<ul>
<li><p><strong>Normalización por lotes (Batch Normalization, BN):</strong> utiliza las estadísticas entre las muestras dentro de un lote. Se ve afectada por el tamaño del lote y es difícil aplicarla a RNN.</p></li>
<li><p><strong>Normalización por capa (Layer Normalization, LN):</strong> usa las estadísticas sobre la dimensión de características para cada muestra. No se ve afectada por el tamaño del lote y es fácil aplicarla a RNN.</p></li>
<li><p><strong>Normalización por instancia (Instance Normalization, IN):</strong> calcula las estadísticas independientemente para cada muestra y cada canal. Se utiliza principalmente en tareas de generación de imágenes como la transferencia de estilo (style transfer).</p></li>
<li><p><strong>Normalización por grupo (Group Normalization, GN):</strong> divide los canales en grupos y calcula las estadísticas dentro de cada grupo. Puede usarse como una alternativa a BN cuando el tamaño del lote es pequeño.</p></li>
</ul>
<p>Cada técnica de normalización tiene sus propias ventajas y desventajas dependiendo de la situación, por lo que se debe elegir la técnica adecuada según las características del problema y la arquitectura del modelo.</p>
</section>
</section>
</div>
</div>
</section>
<section id="aplicación-en-el-seguimiento-estadístico-y-la-inferencia" class="level3">
<h3 class="anchored" data-anchor-id="aplicación-en-el-seguimiento-estadístico-y-la-inferencia">6.4.3 Aplicación en el seguimiento estadístico y la inferencia</h3>
</section>
</section>
<section id="optimización-de-hiperparámetros" class="level2">
<h2 class="anchored" data-anchor-id="optimización-de-hiperparámetros">6.5 Optimización de hiperparámetros</h2>
<p>La optimización de hiperparámetros tiene un impacto muy importante en el rendimiento del modelo. Su importancia comenzó a ser conocida desde la década de 1990. A finales de los años 90, se descubrió que en las máquinas de vectores de soporte (SVM), incluso para modelos idénticos, los parámetros de la función kernel (C, gamma, etc.) desempeñaban un papel decisivo en el rendimiento. Alrededor del 2015, se demostró que la optimización bayesiana producía resultados mejores que el ajuste manual, lo que se convirtió en una base fundamental para los métodos de ajuste automatizado (automated tuning) como Google AutoML (2017).</p>
<section id="comparación-de-metodologías-de-optimización" class="level3">
<h3 class="anchored" data-anchor-id="comparación-de-metodologías-de-optimización">6.5.1 Comparación de metodologías de optimización</h3>
<p>Existen varios métodos para optimizar hiperparámetros. Los más representativos son:</p>
<ol type="1">
<li><p><strong>Búsqueda en cuadrícula (Grid Search):</strong> Es el método más básico, donde se especifican listas de valores posibles para cada hiperparámetro y se intentan todas las combinaciones de estos valores. Es útil cuando el número de hiperparámetros es pequeño y el rango de valores que puede tomar cada parámetro está limitado, pero debido a que se deben probar todas las combinaciones, el costo computacional es muy alto. Es adecuado para modelos simples o cuando el espacio de exploración es muy pequeño.</p></li>
<li><p><strong>Búsqueda aleatoria (Random Search):</strong> Se generan combinaciones seleccionando valores aleatorios para cada hiperparámetro y se evalúa el rendimiento del modelo entrenado con estas combinaciones. Si algunos hiperparámetros tienen un impacto significativo en el rendimiento, puede ser más efectivo que la búsqueda en cuadrícula. (Bergstra &amp; Bengio, 2012)</p></li>
<li><p><strong>Optimización bayesiana (Bayesian Optimization):</strong> Selecciona <em>inteligentemente</em> las siguientes combinaciones de hiperparámetros para probar basándose en resultados previos y utilizando un modelo probabilístico (generalmente un proceso gaussiano). Elige el punto que maximiza la función de adquisición (acquisition function) como el siguiente punto a explorar. Dado que explora eficientemente el espacio de búsqueda de hiperparámetros, puede encontrar mejores combinaciones con menos intentos en comparación con la búsqueda en cuadrícula o la búsqueda aleatoria.</p></li>
</ol>
<p>Además, existen otros métodos como los algoritmos evolutivos (Evolutionary Algorithms) basados en algoritmos genéticos y la optimización basada en gradientes (Gradient-based Optimization).</p>
<p>A continuación se presenta un ejemplo de cómo optimizar los hiperparámetros de un modelo de red neuronal simple utilizando optimización bayesiana.</p>
</section>
<section id="optimización-con-bayes-opt" class="level3">
<h3 class="anchored" data-anchor-id="optimización-con-bayes-opt">6.5.2 Optimización con Bayes-Opt</h3>
<p>La optimización bayesiana comenzó a recibir atención desde la década de 2010. En particular, tras la publicación del artículo “Practical Bayesian Optimization of Machine Learning Algorithms” en 2015, ganó una ventaja significativa al seleccionar <em>inteligentemente</em> los siguientes parámetros a explorar basándose en resultados previos.</p>
<p>La optimización bayesiana se repite principalmente en tres etapas:</p>
<ol type="1">
<li><strong>Muestreo inicial (Initialization):</strong> Se seleccionan combinaciones de hiperparámetros aleatoriamente y se entrena el modelo para evaluar su rendimiento, un número de veces especificado por <code>init_points</code>.</li>
<li><strong>Construcción del modelo sustituto (Surrogate Model):</strong> Se construye un modelo sustituto (generalmente un proceso gaussiano) que modela la relación entre los hiperparámetros y el rendimiento basándose en los resultados experimentales hasta ahora.</li>
<li><strong>Optimización de la función de adquisición (Acquisition Function):</strong> Se selecciona la combinación de hiperparámetros más prometedora para probar a continuación, utilizando la función de adquisición, que se basa en la información actual (el modelo sustituto) para equilibrar entre “exploración” y “explotación”.</li>
<li>Se repiten las etapas 2-3.</li>
</ol>
<div id="cell-42" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_04.models.base <span class="im">import</span> SimpleNetwork  </span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_04.utils.data <span class="im">import</span> get_data_loaders, get_device  </span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> bayes_opt <span class="im">import</span> BayesianOptimization</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_04.experiments.model_training <span class="im">import</span> train_model, eval_loop  </span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_simple_net(hidden_layers, learning_rate, batch_size, epochs):</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Trains a SimpleNetwork model with given hyperparameters.</span></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a><span class="co">       Uses CIFAR100 dataset and train_model from Chapter 4.</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> get_device()  <span class="co"># Use the utility function to get device</span></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get data loaders for CIFAR100</span></span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>    train_loader, test_loader <span class="op">=</span> get_data_loaders(dataset<span class="op">=</span><span class="st">"CIFAR100"</span>, batch_size<span class="op">=</span>batch_size)</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Instantiate the model with specified activation and hidden layers.</span></span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># CIFAR100 images are 3x32x32, so the input size is 3*32*32 = 3072.</span></span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> SimpleNetwork(act_func<span class="op">=</span>nn.ReLU(), input_shape<span class="op">=</span><span class="dv">3</span><span class="op">*</span><span class="dv">32</span><span class="op">*</span><span class="dv">32</span>, hidden_shape<span class="op">=</span>hidden_layers, num_labels<span class="op">=</span><span class="dv">100</span>).to(device)</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Optimizer: Use Adam</span></span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> optim.Adam(model.parameters(), lr<span class="op">=</span>learning_rate)</span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Train the model using the training function from Chapter 4</span></span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> train_model(model, train_loader, test_loader, device, optimizer<span class="op">=</span>optimizer, epochs<span class="op">=</span>epochs, save_dir<span class="op">=</span><span class="st">"./tmp/tune"</span>,</span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>                         retrain<span class="op">=</span><span class="va">True</span>) <span class="co"># retrain=True로 설정</span></span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Return the final test accuracy</span></span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> results[<span class="st">'test_accuracies'</span>][<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-34"><a href="#cb24-34" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_wrapper(learning_rate, batch_size, hidden1, hidden2):</span>
<span id="cb24-35"><a href="#cb24-35" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Wrapper function for Bayesian optimization."""</span></span>
<span id="cb24-36"><a href="#cb24-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> train_simple_net(</span>
<span id="cb24-37"><a href="#cb24-37" aria-hidden="true" tabindex="-1"></a>        hidden_layers<span class="op">=</span>[<span class="bu">int</span>(hidden1), <span class="bu">int</span>(hidden2)],</span>
<span id="cb24-38"><a href="#cb24-38" aria-hidden="true" tabindex="-1"></a>        learning_rate<span class="op">=</span>learning_rate,</span>
<span id="cb24-39"><a href="#cb24-39" aria-hidden="true" tabindex="-1"></a>        batch_size<span class="op">=</span><span class="bu">int</span>(batch_size),</span>
<span id="cb24-40"><a href="#cb24-40" aria-hidden="true" tabindex="-1"></a>        epochs<span class="op">=</span><span class="dv">10</span></span>
<span id="cb24-41"><a href="#cb24-41" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb24-42"><a href="#cb24-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-43"><a href="#cb24-43" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> optimize_hyperparameters():</span>
<span id="cb24-44"><a href="#cb24-44" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Runs hyperparameter optimization."""</span></span>
<span id="cb24-45"><a href="#cb24-45" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set the parameter ranges to be optimized.</span></span>
<span id="cb24-46"><a href="#cb24-46" aria-hidden="true" tabindex="-1"></a>    pbounds <span class="op">=</span> {</span>
<span id="cb24-47"><a href="#cb24-47" aria-hidden="true" tabindex="-1"></a>        <span class="st">"learning_rate"</span>: (<span class="fl">1e-4</span>, <span class="fl">1e-2</span>),</span>
<span id="cb24-48"><a href="#cb24-48" aria-hidden="true" tabindex="-1"></a>        <span class="st">"batch_size"</span>: (<span class="dv">64</span>, <span class="dv">256</span>),</span>
<span id="cb24-49"><a href="#cb24-49" aria-hidden="true" tabindex="-1"></a>        <span class="st">"hidden1"</span>: (<span class="dv">64</span>, <span class="dv">512</span>),  <span class="co"># First hidden layer</span></span>
<span id="cb24-50"><a href="#cb24-50" aria-hidden="true" tabindex="-1"></a>        <span class="st">"hidden2"</span>: (<span class="dv">32</span>, <span class="dv">256</span>)   <span class="co"># Second hidden layer</span></span>
<span id="cb24-51"><a href="#cb24-51" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb24-52"><a href="#cb24-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-53"><a href="#cb24-53" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a Bayesian optimization object.</span></span>
<span id="cb24-54"><a href="#cb24-54" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> BayesianOptimization(</span>
<span id="cb24-55"><a href="#cb24-55" aria-hidden="true" tabindex="-1"></a>        f<span class="op">=</span>train_wrapper,</span>
<span id="cb24-56"><a href="#cb24-56" aria-hidden="true" tabindex="-1"></a>        pbounds<span class="op">=</span>pbounds,</span>
<span id="cb24-57"><a href="#cb24-57" aria-hidden="true" tabindex="-1"></a>        random_state<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb24-58"><a href="#cb24-58" aria-hidden="true" tabindex="-1"></a>        allow_duplicate_points<span class="op">=</span><span class="va">True</span></span>
<span id="cb24-59"><a href="#cb24-59" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb24-60"><a href="#cb24-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-61"><a href="#cb24-61" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Run optimization</span></span>
<span id="cb24-62"><a href="#cb24-62" aria-hidden="true" tabindex="-1"></a>    optimizer.maximize(</span>
<span id="cb24-63"><a href="#cb24-63" aria-hidden="true" tabindex="-1"></a>        init_points<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb24-64"><a href="#cb24-64" aria-hidden="true" tabindex="-1"></a>        n_iter<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb24-65"><a href="#cb24-65" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb24-66"><a href="#cb24-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-67"><a href="#cb24-67" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Print the best parameters and accuracy</span></span>
<span id="cb24-68"><a href="#cb24-68" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Best parameters found:"</span>)</span>
<span id="cb24-69"><a href="#cb24-69" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Learning Rate: </span><span class="sc">{</span>optimizer<span class="sc">.</span><span class="bu">max</span>[<span class="st">'params'</span>][<span class="st">'learning_rate'</span>]<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb24-70"><a href="#cb24-70" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Batch Size: </span><span class="sc">{</span><span class="bu">int</span>(optimizer.<span class="bu">max</span>[<span class="st">'params'</span>][<span class="st">'batch_size'</span>])<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb24-71"><a href="#cb24-71" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Hidden Layer 1: </span><span class="sc">{</span><span class="bu">int</span>(optimizer.<span class="bu">max</span>[<span class="st">'params'</span>][<span class="st">'hidden1'</span>])<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb24-72"><a href="#cb24-72" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Hidden Layer 2: </span><span class="sc">{</span><span class="bu">int</span>(optimizer.<span class="bu">max</span>[<span class="st">'params'</span>][<span class="st">'hidden2'</span>])<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb24-73"><a href="#cb24-73" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Best accuracy: </span><span class="sc">{</span>optimizer<span class="sc">.</span><span class="bu">max</span>[<span class="st">'target'</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb24-74"><a href="#cb24-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-75"><a href="#cb24-75" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">"__main__"</span>:</span>
<span id="cb24-76"><a href="#cb24-76" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Starting hyperparameter optimization..."</span>)</span>
<span id="cb24-77"><a href="#cb24-77" aria-hidden="true" tabindex="-1"></a>    optimize_hyperparameters()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>El siguiente ejemplo utiliza el paquete <code>BayesOpt</code> para realizar la optimización de hiperparámetros. El objetivo es entrenar <code>SimpleNetwork</code> (definido en el Capítulo 4) utilizando el conjunto de datos CIFAR100. La función <code>train_wrapper</code> actúa como la función objetivo (objective function) que <code>BayesOpt</code> utilizará, entrenando el modelo con una combinación dada de hiperparámetros y devolviendo la precisión final del test.</p>
<p><code>pbounds</code> especifica el rango de búsqueda para cada hiperparámetro. En <code>optimizer.maximize</code>, <code>init_points</code> es el número de búsquedas aleatorias iniciales, y <code>n_iter</code> es el número de iteraciones de optimización bayesiana. Por lo tanto, el número total de experimentos es <code>init_points + n_iter</code>.</p>
<p>Al explorar hiperparámetros, hay varios puntos a considerar:</p>
<ol type="1">
<li><strong>Rango de parámetros:</strong> Un rango demasiado amplio puede aumentar el tiempo de búsqueda, mientras que un rango demasiado estrecho puede hacer que se pierda el óptimo. Generalmente, la tasa de aprendizaje se establece en una escala logarítmica (1e-4 ~ 1e-2), y el número de neuronas se configura en múltiplos de potencias de 2.</li>
<li><strong>Número de iteraciones:</strong> El número total de intentos generalmente se establece en aproximadamente (número de parámetros) x 20, lo cual ha demostrado dar buenos resultados empíricamente. En el ejemplo anterior, con 4 parámetros, un total de 14 intentos (init_points=4, n_iter=10) puede ser algo bajo. Para obtener mejores resultados, se puede considerar aumentar <code>n_iter</code>.</li>
</ol>
</section>
<section id="optimización-con-botorch" class="level3">
<h3 class="anchored" data-anchor-id="optimización-con-botorch">6.5.3 Optimización con BoTorch</h3>
<p>Recientemente, el framework BoTorch ha ganado atención en el campo de la optimización de hiperparámetros de deep learning. BoTorch es un framework de optimización bayesiana basado en PyTorch desarrollado por FAIR (Facebook AI Research, ahora Meta AI) en 2019. Bayes-Opt es una biblioteca de optimización bayesiana más antigua, que ha estado en desarrollo desde 2016 y se utiliza ampliamente debido a su interfaz intuitiva y simple (API estilo scikit-learn).</p>
<p>Las ventajas y desventajas de las dos bibliotecas son claras.</p>
<ul>
<li><strong>BoTorch:</strong>
<ul>
<li><strong>Ventajas:</strong> Integración con modelos de deep learning, aceleración GPU, alta eficiencia de muestreo, diversas técnicas avanzadas de optimización bayesiana (multi-fidelity, multi-task, optimización bajo restricciones, etc.), soporte para diferenciación automática y otras funcionalidades especializadas en la optimización de hiperparámetros de modelos de deep learning. Es particularmente adecuado para modelos a gran escala, espacios de parámetros de alta dimensión y experimentos con altos costos computacionales.</li>
<li><strong>Desventajas:</strong> Requiere más aprendizaje en comparación con Bayes-Opt y la configuración inicial puede ser compleja.</li>
</ul></li>
<li><strong>Bayes-Opt:</strong>
<ul>
<li><strong>Ventajas:</strong> Proporciona una API simple e intuitiva que facilita su uso. La instalación es sencilla y cuenta con abundantes tutoriales y ejemplos de código.</li>
<li><strong>Desventajas:</strong> En comparación con BoTorch, carece de funciones avanzadas y la integración con modelos de deep learning es menos fluida. El rendimiento puede disminuir en problemas a gran escala o de alta dimensión.</li>
</ul></li>
</ul>
<p>Por lo tanto, para problemas simples o la creación rápida de prototipos, se recomienda Bayes-Opt; mientras que para la optimización compleja de hiperparámetros de modelos de deep learning, problemas a gran escala o de alta dimensión y técnicas avanzadas de optimización bayesiana (por ejemplo, multi-task, optimización con restricciones), es preferible usar BoTorch.</p>
<p>Para utilizar BoTorch, a diferencia de Bayes-Opt, es necesario comprender algunos conceptos clave necesarios para la configuración inicial (modelos surrogados, normalización de datos de entrada, funciones de adquisición).</p>
<ol type="1">
<li><p><strong>Modelo Surrogate:</strong></p>
<p>El modelo surrogate es un modelo que aproxima la función objetivo real (en este caso, la precisión de validación del modelo de deep learning). Generalmente se utiliza el proceso gaussiano (GP). El GP se usa para predecir resultados rápidamente y a bajo costo en lugar de la costosa función objetivo real. BoTorch ofrece los siguientes modelos GP:</p>
<ul>
<li><code>SingleTaskGP</code>: Es el modelo de proceso gaussiano más básico. Es adecuado para problemas de optimización de un solo objetivo (single-objective) y es efectivo con conjuntos de datos relativamente pequeños, de 1000 puntos o menos.</li>
<li><code>MultiTaskGP</code>: Se usa cuando se necesita optimizar varias funciones objetivas simultáneamente (optimización multi-objetivo). Por ejemplo, puede optimizar tanto la precisión del modelo como el tiempo de inferencia.</li>
<li><code>SAASBO</code> (Sparsity-Aware Adaptive Subspace Bayesian Optimization): Es un modelo especializado para espacios de parámetros de alta dimensión. Asume que existe una dispersión en los espacios de alta dimensión y realiza búsquedas eficientes.</li>
</ul></li>
<li><p><strong>Normalización de datos de entrada:</strong></p>
<p>El proceso gaussiano es sensible a la escala de los datos, por lo que es importante normalizar los datos de entrada (hiperparámetros). Generalmente, todos los hiperparámetros se transforman al rango [0, 1]. BoTorch proporciona las transformaciones <code>Normalize</code> y <code>Standardize</code>.</p></li>
<li><p><strong>Función de Adquisición (Acquisition Function):</strong> La función de adquisición se basa en un modelo proxy (GP) para determinar la próxima combinación de hiperparámetros a probar. La función de adquisición juega el papel de equilibrar entre “exploración” y “explotación”. BoTorch proporciona las siguientes funciones de adquisición.</p></li>
</ol>
<ul>
<li><code>ExpectedImprovement (EI)</code>: Es una de las funciones de adquisición más comunes. Considera la probabilidad de obtener un resultado mejor que el óptimo actual y el grado de mejora.</li>
<li><code>LogExpectedImprovement (LogEI)</code>: Es una versión logarítmica transformada del EI. Es numéricamente más estable y responde con mayor sensibilidad a pequeños cambios.</li>
<li><code>UpperConfidenceBound (UCB)</code>: Una función de adquisición que pone más énfasis en la exploración. Explora activamente las regiones de alta incertidumbre.</li>
<li><code>ProbabilityOfImprovement (PI)</code>: Indica la probabilidad de mejorar el valor óptimo actual.</li>
<li><code>qExpectedImprovement (qEI)</code>: También conocido como q-batch EI, se utiliza para optimización paralela. Selecciona múltiples candidatos a la vez.</li>
<li><code>qNoisyExpectedImprovement (qNEI)</code>: q-batch Noisy EI. Se usa en entornos ruidosos.</li>
</ul>
<p>El código completo está en <code>package/botorch_optimization.py</code>. Puede ejecutarse directamente desde la línea de comandos. El código completo incluye comentarios detallados, por lo que aquí solo se explicarán las partes importantes de cada código.</p>
<div id="cell-45" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, max_trials: <span class="bu">int</span> <span class="op">=</span> <span class="dv">80</span>, init_samples: <span class="bu">int</span> <span class="op">=</span> <span class="dv">10</span>):</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.param_bounds <span class="op">=</span> torch.tensor([</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>        [<span class="fl">1e-4</span>, <span class="fl">64.0</span>, <span class="fl">32.0</span>, <span class="fl">32.0</span>],      <span class="co"># 최소값</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>        [<span class="fl">1e-2</span>, <span class="fl">256.0</span>, <span class="fl">512.0</span>, <span class="fl">512.0</span>]    <span class="co"># 최대값</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>    ], dtype<span class="op">=</span>torch.float64)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>En la parte de inicialización, se establecen los valores mínimos y máximos de cada hiperparámetro. <code>max_trials</code> es el número total de intentos, e <code>init_samples</code> es el número de experimentos aleatorios iniciales (equivalente a <code>init_points</code> en Bayes-Opt). <code>init_samples</code> generalmente se configura como 2 o 3 veces el número de parámetros. En el ejemplo anterior, hay 4 hiperparámetros, por lo que un valor adecuado sería entre 8 y 12. Se utiliza <code>torch.float64</code> para asegurar la estabilidad numérica. La optimización bayesiana, especialmente los procesos gaussianos, utilizan descomposición de Cholesky en el cálculo de matrices de kernel, y durante este proceso, <code>float32</code> puede generar errores debido a problemas de precisión.</p>
<div id="cell-47" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tune(<span class="va">self</span>):</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 가우시안 프로세스 모델 학습</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> SingleTaskGP(configs, accuracies)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>    mll <span class="op">=</span> ExactMarginalLogLikelihood(model.likelihood, model)</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>    fit_gpytorch_mll(mll)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Se utiliza un modelo proxy basado en procesos gaussianos llamado <code>SingleTaskGP</code>. <code>ExactMarginalLogLikelihood</code> es la función de pérdida utilizada para el entrenamiento del modelo, y <code>fit_gpytorch_mll</code> entrena el modelo utilizando esta función de pérdida.</p>
<div id="cell-49" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>acq_func <span class="op">=</span> LogExpectedImprovement(</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>    model, </span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>    best_f<span class="op">=</span>accuracies.<span class="bu">max</span>().item()</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Se utiliza la función de adquisición <code>LogExpectedImprovement</code>. Debido al uso del logaritmo, es numéricamente estable y responde sensiblemente a pequeños cambios.</p>
<div id="cell-51" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>candidate, _ <span class="op">=</span> optimize_acqf(                                   <span class="co"># 획득 함수 최적화로 다음 실험할 파라미터 선택</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>    acq_func, bounds<span class="op">=</span>bounds,                                    <span class="co"># 획득 함수와 파라미터 범위 지정</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>    q<span class="op">=</span><span class="dv">1</span>,                                                        <span class="co"># 한 번에 하나의 설정만 선택</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    num_restarts<span class="op">=</span><span class="dv">10</span>,                                            <span class="co"># 최적화 재시작 횟수</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>    raw_samples<span class="op">=</span><span class="dv">512</span>                                             <span class="co"># 초기 샘플링 수</span></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><code>optimize_acqf</code> es una función que optimiza la función de adquisición para seleccionar la combinación de hiperparámetros (<code>candidate</code>) a experimentar a continuación.</p>
<ul>
<li><code>q=1</code>: solo selecciona un candidato a la vez (no es una optimización en q-batch).</li>
<li><code>num_restarts=10</code>: durante cada paso de optimización, se repite 10 veces desde diferentes puntos de inicio para evitar caer en mínimos locales.</li>
<li><code>raw_samples=512</code>: se extraen 512 muestras del proceso gaussiano para estimar el valor de la función de adquisición.</li>
</ul>
<p><code>num_restarts</code> y <code>raw_samples</code> tienen un impacto significativo en el equilibrio entre exploración y explotación en la optimización bayesiana. <code>num_restarts</code> determina la exhaustividad de la optimización, mientras que <code>raw_samples</code> afecta a la precisión de la estimación de la función de adquisición. Cuanto mayores sean estos valores, mayor será el costo computacional, pero también aumentará la probabilidad de obtener mejores resultados. En general, se pueden usar los siguientes valores:</p>
<ul>
<li>Ejecución rápida: <code>num_restarts=5</code>, <code>raw_samples=256</code></li>
<li>Equilibrio: <code>num_restarts=10</code>, <code>raw_samples=512</code></li>
<li>Foco en precisión: <code>num_restarts=20</code>, <code>raw_samples=1024</code></li>
</ul>
<div id="cell-53" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_06.botorch_optimizer <span class="im">import</span> run_botorch_optimization</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>run_botorch_optimization(max_trials<span class="op">=</span><span class="dv">80</span>, init_samples<span class="op">=</span><span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><strong>Resultado</strong> Dataset : FashionMNIST Épocas : 20 Experimentos iniciales : 5 veces Experimentos de repetición : 80 veces</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Parámetro óptimo</th>
<th>Bayes-Opt</th>
<th>Botorch</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Tasa de aprendizaje</td>
<td>6e-4</td>
<td>1e-4</td>
</tr>
<tr class="even">
<td>Tamaño del lote</td>
<td>173</td>
<td>158</td>
</tr>
<tr class="odd">
<td>hid 1</td>
<td>426</td>
<td>512</td>
</tr>
<tr class="even">
<td>hid 2</td>
<td>197</td>
<td>512</td>
</tr>
<tr class="odd">
<td>Precisión</td>
<td>0.7837</td>
<td>0.8057</td>
</tr>
</tbody>
</table>
<p>Es una comparación simple, pero la precisión de BoTorch es mayor. Para búsquedas de optimización simples se recomienda Bayes-Opt y para exploraciones especializadas se recomienda BoTorch.</p>
</section>
</section>
<section id="procesos-gaussianos" class="level2">
<h2 class="anchored" data-anchor-id="procesos-gaussianos">6.6 Procesos Gaussianos</h2>
<blockquote class="blockquote">
<p><strong>Desafío:</strong> ¿Cuál es el método para cuantificar la incertidumbre de las predicciones del modelo y utilizarla para aprender activamente?</p>
<p><strong>Reflexión del investigador:</strong> Los modelos de aprendizaje profundo tradicionales proporcionan estimaciones puntuales (point estimates) como resultados de predicción, pero en aplicaciones reales es muy importante conocer la incertidumbre de las predicciones. Por ejemplo, un automóvil autónomo debe saber qué tan incierta es su predicción sobre el próximo movimiento de un peatón para poder conducir de manera segura. Los procesos Gaussianos han sido una herramienta poderosa basada en la teoría Bayesiana para cuantificar la incertidumbre de las predicciones, pero tienen la desventaja de ser computacionalmente complejos y difíciles de aplicar a conjuntos de datos grandes.</p>
</blockquote>
<p>Los Procesos Gaussianos (Gaussian Process, GP) son modelos clave en el aprendizaje Bayesiano que proporcionan predicciones con conciencia de incertidumbre. Anteriormente, vimos brevemente cómo los procesos Gaussianos se utilizan como modelo sustituto (surrogate model) en la optimización Bayesiana; aquí, exploraremos más detalladamente los principios fundamentales y la importancia de los procesos Gaussianos.</p>
<p>Un GP se define como una “distribución de probabilidad sobre un conjunto de valores de función”. A diferencia de una función determinista <span class="math inline">\(y = f(x)\)</span> que predice un solo valor de salida para una entrada dada, un GP no predice un solo valor de salida <span class="math inline">\(y\)</span> para una entrada dada <span class="math inline">\(x\)</span>, sino una <em>distribución</em> de posibles valores de salida. Por ejemplo, en lugar de predecir con certeza “la temperatura máxima mañana será 25 grados”, podría predecir “hay una probabilidad del 95% de que la temperatura máxima mañana esté entre 23 y 27 grados”. Si estás conduciendo en bicicleta hacia casa, el camino general ya está decidido, pero cada vez puede variar. Se necesita un tipo de predicción que incluya incertidumbre, no una predicción determinista.</p>
<p>La base matemática para manejar predicciones con incertidumbre se encuentra en la distribución normal (distribución Gaussiana) propuesta por el matemático del siglo XIX, Gauss. Sobre esta base, los procesos Gaussianos se desarrollaron en la década de 1940. En ese momento, durante la Segunda Guerra Mundial, los científicos tenían que manejar datos inciertos como nunca antes, incluyendo el procesamiento de señales de radar, descifrado de códigos y análisis meteorológico. Un ejemplo notable es el trabajo de Norbert Wiener para mejorar la precisión del cañón antiaéreo al predecir la futura posición de los aviones. Wiener concibió un “proceso Wiener” que veía el movimiento de los aviones como un proceso estocástico, donde la incertidumbre era fundamental. En 1951, Daniel Krige aplicó los procesos Gaussianos para predecir la distribución de vetas minerales. Hasta los años 70, los estadísticos sistematizaron las aplicaciones de los procesos Gaussianos en estadística espacial, diseño de experimentos computacionales y optimización Bayesiana en el aprendizaje automático. Hoy en día, desempeñan un papel crucial en casi todos los campos que manejan incertidumbre, incluyendo la inteligencia artificial, robótica y predicción climática. En particular, en el aprendizaje profundo, los procesos Gaussianos con kernels profundos a través del aprendizaje meta (meta-learning) han recibido atención reciente y muestran un rendimiento destacado en campos como la predicción de características moleculares.</p>
<p>Hoy en día, los procesos Gaussianos se utilizan en una amplia gama de campos, incluyendo inteligencia artificial, robótica y modelización climática. En particular, en el aprendizaje profundo, recientemente han destacado los procesos Gaussianos con kernels profundos a través del aprendizaje meta (meta-learning) y la predicción de características moleculares.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Haga clic para ver el contenido (profundización: fundamentos matemáticos de los procesos gaussianos y sus aplicaciones en machine learning)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Haga clic para ver el contenido (profundización: fundamentos matemáticos de los procesos gaussianos y sus aplicaciones en machine learning)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<section id="fundamentos-matemáticos-del-proceso-gaussiano-y-aplicaciones-en-el-aprendizaje-automático" class="level2 callout-body-container callout-body">
<h2 class="anchored" data-anchor-id="fundamentos-matemáticos-del-proceso-gaussiano-y-aplicaciones-en-el-aprendizaje-automático">Fundamentos matemáticos del proceso gaussiano y aplicaciones en el aprendizaje automático</h2>
<p>El proceso gaussiano (Gaussian Process, GP) es un modelo probabilístico basado en métodos de núcleo (kernel method), que se utiliza ampliamente para problemas de regresión y clasificación. El GP tiene la ventaja de definir una distribución sobre las funciones mismas, lo que permite cuantificar la incertidumbre en las predicciones. En este profundización detallada, exploramos los fundamentos matemáticos del proceso gaussiano desde la distribución normal multivariante (multivariate normal distribution) hasta la perspectiva de procesos estocásticos (stochastic process), y examinamos diversas aplicaciones en el aprendizaje automático.</p>
<section id="distribución-normal-multivariante-multivariate-normal-distribution" class="level3">
<h3 class="anchored" data-anchor-id="distribución-normal-multivariante-multivariate-normal-distribution">1. Distribución normal multivariante (Multivariate Normal Distribution)</h3>
<p>El primer paso para entender los procesos gaussianos es comprender la distribución normal multivariante. Un vector aleatorio <span class="math inline">\(\mathbf{x} = (x_1, x_2, ..., x_d)^T\)</span> de dimensión <span class="math inline">\(d\)</span> que sigue una distribución normal multivariante significa que tiene la siguiente función de densidad de probabilidad (probability density function).</p>
<p><span class="math inline">\(p(\mathbf{x}) = \frac{1}{(2\pi)^{d/2}|\mathbf{\Sigma}|^{1/2}} \exp\left(-\frac{1}{2}(\mathbf{x} - \boldsymbol{\mu})^T \mathbf{\Sigma}^{-1} (\mathbf{x} - \boldsymbol{\mu})\right)\)</span></p>
<p>Donde <span class="math inline">\(\boldsymbol{\mu} \in \mathbb{R}^d\)</span> es el vector de medias, y <span class="math inline">\(\mathbf{\Sigma} \in \mathbb{R}^{d \times d}\)</span> es la matriz de covarianza (covariance matrix). La matriz de covarianza debe ser una matriz definida positiva (positive definite).</p>
<p><strong>Propiedades clave:</strong></p>
<ul>
<li><p><strong>Transformación lineal:</strong> La transformación lineal de una variable aleatoria que sigue una distribución normal multivariante también seguirá una distribución normal multivariante. Es decir, si <span class="math inline">\(\mathbf{x} \sim \mathcal{N}(\boldsymbol{\mu}, \mathbf{\Sigma})\)</span> y <span class="math inline">\(\mathbf{y} = \mathbf{A}\mathbf{x} + \mathbf{b}\)</span>, entonces <span class="math inline">\(\mathbf{y} \sim \mathcal{N}(\mathbf{A}\boldsymbol{\mu} + \mathbf{b}, \mathbf{A}\mathbf{\Sigma}\mathbf{A}^T)\)</span>.</p></li>
<li><p><strong>Distribución condicional (Conditional Distribution):</strong> La distribución condicional de una distribución normal multivariante también sigue una distribución normal. Si dividimos <span class="math inline">\(\mathbf{x}\)</span> en <span class="math inline">\(\mathbf{x} = (\mathbf{x}_1, \mathbf{x}_2)^T\)</span> y las medias y matrices de covarianza se dividen como:</p>
<p><span class="math inline">\(\boldsymbol{\mu} = \begin{pmatrix} \boldsymbol{\mu}_1 \\ \boldsymbol{\mu}_2 \end{pmatrix}, \quad \mathbf{\Sigma} = \begin{pmatrix} \mathbf{\Sigma}_{11} &amp; \mathbf{\Sigma}_{12} \\ \mathbf{\Sigma}_{21} &amp; \mathbf{\Sigma}_{22} \end{pmatrix}\)</span></p>
<p>La distribución condicional de <span class="math inline">\(\mathbf{x}_2\)</span> dado <span class="math inline">\(\mathbf{x}_1\)</span> es:</p>
<p><span class="math inline">\(p(\mathbf{x}_2 | \mathbf{x}_1) = \mathcal{N}(\boldsymbol{\mu}_{2|1}, \mathbf{\Sigma}_{2|1})\)</span></p>
<p><span class="math inline">\(\boldsymbol{\mu}_{2|1} = \boldsymbol{\mu}_2 + \mathbf{\Sigma}_{21}\mathbf{\Sigma}_{11}^{-1}(\mathbf{x}_1 - \boldsymbol{\mu}_1)\)</span> <span class="math inline">\(\mathbf{\Sigma}_{2|1} = \mathbf{\Sigma}_{22} - \mathbf{\Sigma}_{21}\mathbf{\Sigma}_{11}^{-1}\mathbf{\Sigma}_{12}\)</span></p></li>
<li><p><strong>Distribución marginal (Marginal Distribution):</strong> La distribución marginal de una distribución normal multivariante también sigue una distribución normal. Dado el particionamiento anterior, la distribución marginal de <span class="math inline">\(\mathbf{x}_1\)</span> es la siguiente. <span class="math inline">\(p(\mathbf{x}_1) = \mathcal{N}(\boldsymbol{\mu_1}, \mathbf{\Sigma}_{11})\)</span></p></li>
</ul>
</section>
<section id="definición-del-proceso-gaussiano-y-su-interpretación-desde-una-perspectiva-de-procesos-estocásticos" class="level3">
<h3 class="anchored" data-anchor-id="definición-del-proceso-gaussiano-y-su-interpretación-desde-una-perspectiva-de-procesos-estocásticos">2. Definición del proceso gaussiano y su interpretación desde una perspectiva de procesos estocásticos</h3>
<p>El proceso gaussiano es una distribución de probabilidad sobre <em>funciones</em>. Es decir, que una función <span class="math inline">\(f(x)\)</span> siga un proceso gaussiano significa que el vector de valores de la función <span class="math inline">\((f(x_1), f(x_2), ..., f(x_n))^T\)</span> para cualquier conjunto finito de puntos de entrada <span class="math inline">\(\{x_1, x_2, ..., x_n\}\)</span> sigue una distribución normal multivariante.</p>
<p><strong>Definición:</strong> Un proceso gaussiano se define por la función media (mean function) <span class="math inline">\(m(x)\)</span> y la función de covarianza (o kernel function) <span class="math inline">\(k(x, x')\)</span>.</p>
<p><span class="math inline">\(f(x) \sim \mathcal{GP}(m(x), k(x, x'))\)</span></p>
<ul>
<li><strong>Función media:</strong> <span class="math inline">\(m(x) = \mathbb{E}[f(x)]\)</span></li>
<li><strong>Función de covarianza:</strong> <span class="math inline">\(k(x, x') = \mathbb{E}[(f(x) - m(x))(f(x') - m(x'))]\)</span></li>
</ul>
<p><strong>Perspectiva del proceso estocástico (Stochastic Process):</strong> Un proceso gaussiano es un tipo de proceso estocástico que asigna una variable aleatoria al conjunto índice (aquí, el espacio de entrada). En un proceso gaussiano, estas variables aleatorias siguen una distribución normal conjunta.</p>
</section>
<section id="el-papel-de-la-función-kernel-y-introducción-a-diferentes-funciones-kernel" class="level3">
<h3 class="anchored" data-anchor-id="el-papel-de-la-función-kernel-y-introducción-a-diferentes-funciones-kernel">3. El papel de la función kernel y introducción a diferentes funciones kernel</h3>
<p>La función kernel es uno de los elementos más importantes en un proceso gaussiano. La función kernel representa la similitud entre dos entradas <span class="math inline">\(x\)</span> y <span class="math inline">\(x'\)</span>, y determina las propiedades del proceso gaussiano.</p>
<p><strong>Roles clave:</strong></p>
<ul>
<li><strong>Definición de covarianza:</strong> La función kernel define la covarianza entre los valores de la función. Es decir, <span class="math inline">\(k(x, x')\)</span> representa la covarianza entre <span class="math inline">\(f(x)\)</span> y <span class="math inline">\(f(x')\)</span>.</li>
<li><strong>Determinación de suavidad (Smoothness):</strong> La función kernel determina la suavidad de las funciones generadas. Por ejemplo, el kernel RBF genera funciones infinitamente diferenciables, mientras que el kernel Matern permite controlar la diferenciabilidad.</li>
<li><strong>Positividad definida (Positive Definiteness):</strong> Para ser una función de covarianza válida, la función kernel debe cumplir con la positividad definida. Es decir, la matriz kernel generada a partir de cualquier conjunto de puntos de entrada debe ser una matriz positiva definida.</li>
</ul>
<p><strong>Diferentes funciones kernel:</strong></p>
<ul>
<li><p><strong>Kernel RBF (Radial Basis Function) (o kernel Exponencial Cuadrático):</strong></p>
<p><span class="math inline">\(k(x, x') = \sigma^2 \exp\left(-\frac{\|x - x'\|^2}{2l^2}\right)\)</span></p>
<ul>
<li><span class="math inline">\(\sigma^2\)</span>: varianza</li>
<li><span class="math inline">\(l\)</span>: escala de longitud (length scale)</li>
<li>Genera funciones muy suaves.</li>
</ul></li>
<li><p><strong>Kernel Matern:</strong></p>
<p><span class="math inline">\(k(x, x') = \sigma^2 \frac{2^{1-\nu}}{\Gamma(\nu)}\left(\sqrt{2\nu}\frac{\|x - x'\|}{l}\right)^\nu K_\nu\left(\sqrt{2\nu}\frac{\|x - x'\|}{l}\right)\)</span></p></li>
<li><p><span class="math inline">\(\nu\)</span>: parámetro de suavidad (smoothness parameter)</p></li>
<li><p><span class="math inline">\(K_\nu\)</span>: función de Bessel modificada (modified Bessel function)</p></li>
<li><p>Se utilizan principalmente valores semienteros (half-integer) como <span class="math inline">\(\nu = 1/2, 3/2, 5/2\)</span>.</p></li>
<li><p>A medida que <span class="math inline">\(\nu\)</span> aumenta, se acerca al núcleo RBF.</p></li>
<li><p><strong>Núcleo periódico (Periodic):</strong></p>
<p><span class="math inline">\(k(x, x') = \sigma^2 \exp\left(-\frac{2\sin^2(\pi|x-x'|/p)}{l^2}\right)\)</span></p>
<ul>
<li><span class="math inline">\(p\)</span> : período</li>
</ul></li>
<li><p><strong>Núcleo lineal (Linear):</strong></p>
<p><span class="math inline">\(k(x,x') = \sigma_b^2 + \sigma_v^2(x - c)(x' -c)\)</span></p></li>
</ul>
</section>
<section id="resolución-de-problemas-de-regresión-y-clasificación-utilizando-procesos-gaussianos" class="level3">
<h3 class="anchored" data-anchor-id="resolución-de-problemas-de-regresión-y-clasificación-utilizando-procesos-gaussianos">4. Resolución de problemas de regresión y clasificación utilizando procesos gaussianos</h3>
<p><strong>Regresión:</strong></p>
<p>La regresión con procesos gaussianos consiste en predecir la salida <span class="math inline">\(f(\mathbf{x}_*)\)</span> para una nueva entrada <span class="math inline">\(\mathbf{x}_*\)</span> basada en los datos de entrenamiento <span class="math inline">\(\mathcal{D} = \{(\mathbf{x}_i, y_i)\}_{i=1}^n\)</span>. Se combina la distribución previa (prior distribution) del proceso gaussiano con los datos de entrenamiento para calcular la distribución posterior (posterior distribution), a partir de la cual se obtiene la distribución predictiva (predictive distribution).</p>
<ul>
<li><strong>Distribución previa:</strong> <span class="math inline">\(f(\mathbf{x}) \sim \mathcal{GP}(0, k(\mathbf{x}, \mathbf{x}'))\)</span> (se asume una función media de 0 por conveniencia)</li>
<li><strong>Datos de entrenamiento:</strong> <span class="math inline">\(\mathbf{y} = (y_1, y_2, ..., y_n)^T\)</span></li>
<li><strong>Matriz del núcleo:</strong> <span class="math inline">\(\mathbf{K} = k(\mathbf{X}, \mathbf{X})\)</span>, donde <span class="math inline">\(\mathbf{X} = [\mathbf{x}_1, \mathbf{x}_2, ..., \mathbf{x}_n]\)</span></li>
<li><strong>Distribución predictiva:</strong> <span class="math inline">\(p(f(\mathbf{x}_*) | \mathbf{y}, \mathbf{X}, \mathbf{x}_*) = \mathcal{N}(\mu_*, \sigma_*^2)\)</span>
<ul>
<li><span class="math inline">\(\mu_* = \mathbf{k}_*^T \mathbf{K}^{-1} \mathbf{y}\)</span></li>
<li><span class="math inline">\(\sigma_*^2 = k(\mathbf{x}_*, \mathbf{x}_*) - \mathbf{k}_*^T \mathbf{K}^{-1} \mathbf{k}_*\)</span></li>
<li><span class="math inline">\(\mathbf{k}_* = [k(\mathbf{x}_*, \mathbf{x}_1), k(\mathbf{x}_*, \mathbf{x}_2), ..., k(\mathbf{x}_*, \mathbf{x}_n)]^T\)</span></li>
</ul></li>
</ul>
<p><strong>Clasificación:</strong></p>
<p>La clasificación con procesos gaussianos implica modelar la función latente (latent function) <span class="math inline">\(f(\mathbf{x})\)</span> como un proceso gaussiano y definir las probabilidades de clasificación a través de esta función latente. Por ejemplo, en problemas de clasificación binaria, se utilizan funciones logísticas o probit para convertir los valores de la función latente en probabilidades.</p>
<ul>
<li><strong>Función latente:</strong> <span class="math inline">\(f(\mathbf{x}) \sim \mathcal{GP}(0, k(\mathbf{x}, \mathbf{x}'))\)</span></li>
<li><strong>Clasificación binaria:</strong> <span class="math inline">\(p(y = 1 | f(\mathbf{x})) = \sigma(f(\mathbf{x}))\)</span> (donde <span class="math inline">\(\sigma\)</span> es la función logística)</li>
</ul>
<p>En problemas de clasificación, como la distribución posterior no tiene una forma cerrada, se utilizan métodos de inferencia aproximada como la aproximación de Laplace o la inferencia variacional. ### 5. Ventajas y desventajas del proceso gaussiano y comparación con el aprendizaje profundo</p>
<p><strong>Ventajas:</strong></p>
<ul>
<li><strong>Cuantificación de la incertidumbre:</strong> proporciona la incertidumbre de las predicciones en forma de varianza predictiva.</li>
<li><strong>Eficiencia de datos:</strong> puede ofrecer un buen rendimiento con una cantidad relativamente pequeña de datos.</li>
<li><strong>Flexibilidad en la selección del kernel:</strong> se pueden usar diversas funciones de kernel para diseñar un modelo adecuado a las características del problema.</li>
<li><strong>Interpretación bayesiana:</strong> se interpreta naturalmente dentro del marco bayesiano.</li>
</ul>
<p><strong>Desventajas:</strong></p>
<ul>
<li><strong>Complejidad computacional:</strong> tiene una complejidad computacional de <span class="math inline">\(O(n^3)\)</span> en función del tamaño <span class="math inline">\(n\)</span> de los datos de entrenamiento. (debido al cálculo de la matriz inversa)</li>
<li><strong>Selección del modelo:</strong> es importante y puede ser difícil elegir la función de kernel y los hiperparámetros adecuados.</li>
<li><strong>Entradas de alta dimensión:</strong> el rendimiento puede disminuir en espacios de entrada de alta dimensión.</li>
</ul>
<p><strong>Comparación con el aprendizaje profundo:</strong></p>
<ul>
<li><strong>Requisitos de datos:</strong> los modelos de aprendizaje profundo generalmente requieren una cantidad mucho mayor de datos que el proceso gaussiano.</li>
<li><strong>Costo computacional:</strong> los modelos de aprendizaje profundo requieren un alto costo computacional para el entrenamiento, pero la inferencia es relativamente rápida. El proceso gaussiano puede ser rápido en el entrenamiento (cuando hay pocos datos), pero la inferencia tiene un costo computacional que aumenta con el tamaño de los datos.</li>
<li><strong>Incertidumbre:</strong> generalmente, los modelos de aprendizaje profundo no proporcionan incertidumbre en las predicciones. (aunque existen excepciones como el aprendizaje profundo bayesiano).</li>
<li><strong>Expresividad:</strong> los modelos de aprendizaje profundo pueden representar funciones muy complejas, mientras que la expresividad del proceso gaussiano está limitada por la función de kernel.</li>
<li><strong>Interpretabilidad</strong>: el proceso gaussiano puede explicitar las suposiciones del modelo a través de la función de kernel y proporciona una cuantificación de la incertidumbre en los resultados de predicción.</li>
</ul>
<p>Recientemente, se están investigando modelos que combinan el aprendizaje profundo y el proceso gaussiano (por ejemplo, Deep Kernel Learning).</p>
</section>
</section>
</div>
</div>
<section id="fundamentos-matemáticos-para-el-manejo-de-la-incertidumbre" class="level3">
<h3 class="anchored" data-anchor-id="fundamentos-matemáticos-para-el-manejo-de-la-incertidumbre">6.6.1 Fundamentos matemáticos para el manejo de la incertidumbre</h3>
<p>Generalmente pensamos en una función como una sola línea, pero los procesos gaussianos la consideran un “conjunto de varias líneas posibles”. Matemáticamente, esto se expresa de la siguiente manera:</p>
<p><span class="math inline">\(f(t) \sim \mathcal{GP}(m(t), k(t,t'))\)</span></p>
<p>Tomando el ejemplo de la posición de una bicicleta, <span class="math inline">\(m(t)\)</span> es la función media que indica “probablemente seguirá esta ruta”. <span class="math inline">\(k(t,t')\)</span> es la función de covarianza (o kernel) que muestra “hasta qué punto las posiciones en diferentes momentos están relacionadas”. Hay varios kernels típicos. Uno de los kernels más utilizados es el RBF (Función Base Radial).</p>
<p><span class="math inline">\(k(t,t') = \sigma^2 \exp\left(-\frac{(t-t')^2}{2l^2}\right)\)</span></p>
<p>Esta fórmula es muy intuitiva. Cuanto más cerca estén dos momentos <span class="math inline">\(t\)</span> y <span class="math inline">\(t'\)</span>, mayor será el valor; cuanto más lejos estén, menor será el valor. Es como si “si sabemos nuestra posición actual, podemos predecir bastante bien la posición en un corto tiempo después, pero no tanto para un futuro lejano”.</p>
<p>Si consideramos que <span class="math inline">\(K\)</span> es RBF y vemos un ejemplo práctico. Imagina que tienes un servicio de bicicletas compartidas (o vehículos autónomos también serviría). Queremos estimar la ruta completa de una bicicleta basándonos solo en algunas observaciones GPS.</p>
<p><strong>Fórmula básica para la predicción</strong></p>
<p><span class="math inline">\(f_* | X, y, X_* \sim \mathcal{N}(\mu_*, \Sigma_*)\)</span></p>
<p>Esta fórmula expresa que “basándonos en nuestros registros GPS (<span class="math inline">\(X\)</span>, <span class="math inline">\(y\)</span>), la posición de la bicicleta en los momentos desconocidos (<span class="math inline">\(X_*\)</span>) sigue una distribución normal con media <span class="math inline">\(\mu_*\)</span> y varianza <span class="math inline">\(\Sigma_*\)</span>”.</p>
<p><strong>Cálculo de la predicción de la posición</strong></p>
<p><span class="math inline">\(\mu_* = K_*K^{-1}y\)</span></p>
<p>Esta fórmula muestra cómo predecir la posición de la bicicleta. <span class="math inline">\(K_*\)</span> representa la “correlación temporal” entre los momentos a predecir y los momentos registrados por GPS; <span class="math inline">\(K^{-1}\)</span> ajusta el “peso” considerando las relaciones entre los registros de GPS, y <span class="math inline">\(y\)</span> son las posiciones reales registradas por GPS. Por ejemplo, para predecir la posición a las 2:15 p.m.: 1. Consideramos los registros GPS a las 2:00 p.m. y 2:30 p.m. 2. Y ajustamos el peso basándonos en la consistencia de esos registros.</p>
<p><strong>Efecto de la incertidumbre según los datos</strong> La incertidumbre en la predicción varía según la cantidad de datos GPS: 1. En intervalos con muchos registros GPS: baja incertidumbre - <span class="math inline">\(K_*\)</span> es grande y hay muchos datos, por lo que <span class="math inline">\(K_*K^{-1}K_*^T\)</span> también es grande - Por tanto, <span class="math inline">\(\Sigma_*\)</span> es pequeño y la estimación de la ruta es precisa. 2. En intervalos con pocos registros GPS: alta incertidumbre - <span class="math inline">\(K_*\)</span> es pequeño y hay pocos datos, por lo que <span class="math inline">\(K_*K^{-1}K_*^T\)</span> también es pequeño - Por tanto, <span class="math inline">\(\Sigma_*\)</span> es grande y la incertidumbre en la estimación de la ruta es alta.</p>
<p>En resumen, cuanto más densos sean los datos en intervalos de tiempo, mayor será el valor de <span class="math inline">\(K\)</span>, lo que reduce la incertidumbre.</p>
<p>Veamos un ejemplo para entender mejor cómo se predice la ruta de una bicicleta.</p>
<div id="cell-58" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 시각화 스타일 설정</span></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>sns.set_style(<span class="st">"whitegrid"</span>)</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">'font.size'</span>] <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 데이터셋 1: 5개 관측점</span></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>time1 <span class="op">=</span> np.array([<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">8</span>, <span class="dv">10</span>]).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>position1 <span class="op">=</span> np.array([<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">4</span>])</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a><span class="co"># 데이터셋 2: 8개 관측점</span></span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>time2 <span class="op">=</span> np.array([<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">8</span>, <span class="dv">10</span>]).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>position2 <span class="op">=</span> np.array([<span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">2.5</span>, <span class="fl">1.5</span>, <span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">4</span>])  <span class="co"># 더 큰 변동성 추가</span></span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a><span class="co"># 예측할 시간점 생성: 0~10분 구간을 100개로 분할</span></span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>time_pred <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">100</span>).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a><span class="co"># RBF 커널 함수 정의</span></span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> kernel(T1, T2, l<span class="op">=</span><span class="fl">2.0</span>):</span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>    sqdist <span class="op">=</span> np.<span class="bu">sum</span>(T1<span class="op">**</span><span class="dv">2</span>, <span class="dv">1</span>).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>) <span class="op">+</span> np.<span class="bu">sum</span>(T2<span class="op">**</span><span class="dv">2</span>, <span class="dv">1</span>) <span class="op">-</span> <span class="dv">2</span> <span class="op">*</span> np.dot(T1, T2.T)</span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.exp(<span class="op">-</span><span class="fl">0.5</span> <span class="op">*</span> sqdist <span class="op">/</span> l<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a><span class="co"># 가우시안 프로세스 예측 함수</span></span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> predict_gp(time, position, time_pred):</span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a>    K <span class="op">=</span> kernel(time, time)</span>
<span id="cb30-28"><a href="#cb30-28" aria-hidden="true" tabindex="-1"></a>    K_star <span class="op">=</span> kernel(time_pred, time)</span>
<span id="cb30-29"><a href="#cb30-29" aria-hidden="true" tabindex="-1"></a>    K_star_star <span class="op">=</span> kernel(time_pred, time_pred)</span>
<span id="cb30-30"><a href="#cb30-30" aria-hidden="true" tabindex="-1"></a>    mu_star <span class="op">=</span> K_star.dot(np.linalg.inv(K)).dot(position)</span>
<span id="cb30-31"><a href="#cb30-31" aria-hidden="true" tabindex="-1"></a>    sigma_star <span class="op">=</span> K_star_star <span class="op">-</span> K_star.dot(np.linalg.inv(K)).dot(K_star.T)</span>
<span id="cb30-32"><a href="#cb30-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> mu_star, sigma_star</span>
<span id="cb30-33"><a href="#cb30-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-34"><a href="#cb30-34" aria-hidden="true" tabindex="-1"></a><span class="co"># 두 데이터셋에 대한 예측 수행</span></span>
<span id="cb30-35"><a href="#cb30-35" aria-hidden="true" tabindex="-1"></a>mu1, sigma1 <span class="op">=</span> predict_gp(time1, position1, time_pred)</span>
<span id="cb30-36"><a href="#cb30-36" aria-hidden="true" tabindex="-1"></a>mu2, sigma2 <span class="op">=</span> predict_gp(time2, position2, time_pred)</span>
<span id="cb30-37"><a href="#cb30-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-38"><a href="#cb30-38" aria-hidden="true" tabindex="-1"></a><span class="co"># 2개의 서브플롯 생성</span></span>
<span id="cb30-39"><a href="#cb30-39" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">16</span>, <span class="dv">4</span>))</span>
<span id="cb30-40"><a href="#cb30-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-41"><a href="#cb30-41" aria-hidden="true" tabindex="-1"></a><span class="co"># 첫 번째 그래프 (5개 데이터)</span></span>
<span id="cb30-42"><a href="#cb30-42" aria-hidden="true" tabindex="-1"></a>ax1.fill_between(time_pred.flatten(),</span>
<span id="cb30-43"><a href="#cb30-43" aria-hidden="true" tabindex="-1"></a>                mu1 <span class="op">-</span> <span class="dv">2</span><span class="op">*</span>np.sqrt(np.diag(sigma1)),</span>
<span id="cb30-44"><a href="#cb30-44" aria-hidden="true" tabindex="-1"></a>                mu1 <span class="op">+</span> <span class="dv">2</span><span class="op">*</span>np.sqrt(np.diag(sigma1)),</span>
<span id="cb30-45"><a href="#cb30-45" aria-hidden="true" tabindex="-1"></a>                color<span class="op">=</span><span class="st">'blue'</span>, alpha<span class="op">=</span><span class="fl">0.2</span>, label<span class="op">=</span><span class="st">'95</span><span class="sc">% c</span><span class="st">onfidence interval'</span>)</span>
<span id="cb30-46"><a href="#cb30-46" aria-hidden="true" tabindex="-1"></a>ax1.plot(time_pred, mu1, <span class="st">'b-'</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>, label<span class="op">=</span><span class="st">'Predicted path'</span>)</span>
<span id="cb30-47"><a href="#cb30-47" aria-hidden="true" tabindex="-1"></a>ax1.plot(time1, position1, <span class="st">'ro'</span>, markersize<span class="op">=</span><span class="dv">6</span>, label<span class="op">=</span><span class="st">'GPS records'</span>)</span>
<span id="cb30-48"><a href="#cb30-48" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">'Time (min)'</span>)</span>
<span id="cb30-49"><a href="#cb30-49" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">'Position (km)'</span>)</span>
<span id="cb30-50"><a href="#cb30-50" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">'Route Estimation (5 GPS points)'</span>)</span>
<span id="cb30-51"><a href="#cb30-51" aria-hidden="true" tabindex="-1"></a>ax1.legend(fontsize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb30-52"><a href="#cb30-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-53"><a href="#cb30-53" aria-hidden="true" tabindex="-1"></a><span class="co"># 두 번째 그래프 (8개 데이터)</span></span>
<span id="cb30-54"><a href="#cb30-54" aria-hidden="true" tabindex="-1"></a>ax2.fill_between(time_pred.flatten(),</span>
<span id="cb30-55"><a href="#cb30-55" aria-hidden="true" tabindex="-1"></a>                mu2 <span class="op">-</span> <span class="dv">2</span><span class="op">*</span>np.sqrt(np.diag(sigma2)),</span>
<span id="cb30-56"><a href="#cb30-56" aria-hidden="true" tabindex="-1"></a>                mu2 <span class="op">+</span> <span class="dv">2</span><span class="op">*</span>np.sqrt(np.diag(sigma2)),</span>
<span id="cb30-57"><a href="#cb30-57" aria-hidden="true" tabindex="-1"></a>                color<span class="op">=</span><span class="st">'blue'</span>, alpha<span class="op">=</span><span class="fl">0.2</span>, label<span class="op">=</span><span class="st">'95</span><span class="sc">% c</span><span class="st">onfidence interval'</span>)</span>
<span id="cb30-58"><a href="#cb30-58" aria-hidden="true" tabindex="-1"></a>ax2.plot(time_pred, mu2, <span class="st">'b-'</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>, label<span class="op">=</span><span class="st">'Predicted path'</span>)</span>
<span id="cb30-59"><a href="#cb30-59" aria-hidden="true" tabindex="-1"></a>ax2.plot(time2, position2, <span class="st">'ro'</span>, markersize<span class="op">=</span><span class="dv">6</span>, label<span class="op">=</span><span class="st">'GPS records'</span>)</span>
<span id="cb30-60"><a href="#cb30-60" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">'Time (min)'</span>)</span>
<span id="cb30-61"><a href="#cb30-61" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">'Position (km)'</span>)</span>
<span id="cb30-62"><a href="#cb30-62" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">'Route Estimation (8 GPS points)'</span>)</span>
<span id="cb30-63"><a href="#cb30-63" aria-hidden="true" tabindex="-1"></a>ax2.legend(fontsize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb30-64"><a href="#cb30-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-65"><a href="#cb30-65" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb30-66"><a href="#cb30-66" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="06_Sobreajuste y desarrollo de técnicas de solución_files/figure-html/cell-24-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>El siguiente código es un ejemplo de la estimación de rutas de bicicleta utilizando procesos gaussianos (GP) en dos escenarios (5 puntos de observación, 8 puntos de observación). En cada gráfico, la línea sólida azul representa la ruta media predicha, y el área sombreada azul muestra el intervalo de confianza del 95%.</p>
<ul>
<li><strong>Cuando hay pocos datos</strong> (gráfico izquierdo): Debido a que los registros GPS son dispersos, la incertidumbre en las predicciones (el ancho del intervalo de confianza) es alta.</li>
<li><strong>Cuando hay muchos datos</strong> (gráfico derecho): Con registros GPS más densos, la incertidumbre en las predicciones disminuye y la ruta predicha se aproxima más a la ruta real.</li>
</ul>
<p>De esta manera, los GP no solo proporcionan resultados de predicción, sino también su incertidumbre, lo que los hace útiles en diversos campos donde es necesario considerar la incertidumbre en el proceso de toma de decisiones (por ejemplo: conducción autónoma, control de robots, diagnóstico médico).</p>
</section>
<section id="aplicaciones-modernas" class="level3">
<h3 class="anchored" data-anchor-id="aplicaciones-modernas">6.6.2 Aplicaciones modernas</h3>
<p>Los procesos gaussianos se aplican en diversas áreas científicas e ingenierísticas, como el control de robots, la optimización de redes de sensores, la predicción de estructuras moleculares, la modelación climática y el análisis de datos astrofísicos. En el campo del aprendizaje automático (machine learning), una aplicación representativa es la optimización de hiperparámetros, como se ha discutido anteriormente. Otro campo representativo que requiere predicciones con incertidumbre es la conducción autónoma de vehículos. Se predice la futura posición del vehículo relativo y en los intervalos de mayor incertidumbre, se conduce de manera más defensiva. Además, se aplican ampliamente en el campo médico para predecir cambios en el estado del paciente, y en los mercados financieros para predecir precios de acciones y gestionar riesgos basados en la incertidumbre. Recientemente, las aplicaciones de GP están siendo activamente investigadas en campos como el aprendizaje por refuerzo (reinforcement learning), la combinación con modelos generativos en el aprendizaje profundo (deep learning), la inferencia causal y el aprendizaje meta (meta-learning).</p>
</section>
<section id="aprendizaje-de-núcleos-profundos-deep-kernel-learning" class="level3">
<h3 class="anchored" data-anchor-id="aprendizaje-de-núcleos-profundos-deep-kernel-learning">6.6.3 Aprendizaje de núcleos profundos (Deep Kernel Learning)</h3>
<p>El aspecto más importante de los procesos gaussianos es el kernel (función de covarianza). El aprendizaje profundo tiene una ventaja en aprender representaciones a partir de datos. La combinación eficiente de la capacidad predictiva de GP y la capacidad de aprendizaje de representaciones del aprendizaje profundo es una dirección de investigación natural. Un método representativo es el Aprendizaje de Núcleos Profundos (Deep Kernel Learning, DKL), que utiliza redes neuronales para aprender directamente el kernel a partir de los datos en lugar de predefinir un kernel como el RBF.</p>
<p>La estructura general del DKL es la siguiente:</p>
<ol type="1">
<li><strong>Extracción de características (Feature Extraction)</strong>: Los datos de entrada pasan primero por una red neuronal profunda (generalmente una CNN o una Transformer) para convertirse en vectores de características de baja dimensión.</li>
<li><strong>Cálculo del núcleo (Kernel Computation)</strong>: Se utiliza la función kernel del proceso gaussiano (por ejemplo, el kernel RBF) con los vectores de características extraídos como entrada para calcular la matriz de kernel.</li>
<li><strong>Proceso gaussiano (Gaussian Process)</strong>: Se entrena un modelo de proceso gaussiano utilizando la matriz de kernel calculada y los datos de entrenamiento, y se realiza una predicción (media y varianza) para nuevas entradas. El DKL tiene la ventaja de poder aprender simultáneamente representaciones útiles a partir de los datos y la similitud entre los datos mediante redes neuronales. Esto permite realizar predicciones que consideran la incertidumbre en datos complejos (por ejemplo, imágenes, gráficos, texto).</li>
</ol>
<p>El DKL se utiliza en diversos campos. * <strong>Clasificación de imágenes (Image Classification)</strong>: Se utilizan CNN para extraer características de las imágenes y GP para realizar la clasificación. * <strong>Clasificación de grafos (Graph Classification)</strong>: Se usan redes neuronales de grafos (GNN) para extraer características de la estructura del grafo y GP para realizar la clasificación del grafo. * <strong>Predicción de propiedades moleculares (Molecular Property Prediction)</strong>: Acepta gráficos moleculares como entrada y predice las propiedades de la molécula (por ejemplo, solubilidad, toxicidad). * <strong>Predicción de series temporales (Time Series Forecasting)</strong>: Se utilizan RNN para extraer características de los datos de serie temporal y GP para predecir valores futuros. Aquí se ejecutará un simple ejemplo de DKL y en la parte 2 se explorarán más detalles y casos de aplicación.</p>
<p><strong>Redes de núcleos profundas</strong></p>
<p>Primero, definimos las redes de núcleos profundas. Las redes de núcleos son redes neuronales que aprenden funciones de núcleo. Esta red neuronal recibe datos de entrada y produce representaciones de características. Estas representaciones de características se utilizan para calcular la matriz de núcleo.</p>
<div id="cell-60" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.distributions <span class="im">import</span> Normal</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Set seed for reproducibility</span></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">42</span>)</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a neural network to learn the kernel</span></span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DeepKernel(nn.Module):</span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_dim, hidden_dim, output_dim):</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(DeepKernel, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc1 <span class="op">=</span> nn.Linear(input_dim, hidden_dim)</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc2 <span class="op">=</span> nn.Linear(hidden_dim, hidden_dim)</span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc3 <span class="op">=</span> nn.Linear(hidden_dim, output_dim)</span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.activation <span class="op">=</span> nn.ReLU()</span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.activation(<span class="va">self</span>.fc1(x))</span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.activation(<span class="va">self</span>.fc2(x))</span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.fc3(x)  <span class="co"># No activation on the final layer</span></span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>La entrada de una red neuronal de kernel profundo es típicamente un tensor 2D, donde la primera dimensión es el tamaño del lote y la segunda dimensión es la dimensión de los datos de entrada. La salida es un tensor 2D de forma (tamaño del lote, dimensión de representación de características).</p>
<p><strong>Definición de la capa GP</strong></p>
<p>La capa GP recibe la salida de la red de kernel profundo, calcula la matriz de kernel y determina la distribución predictiva.</p>
<div id="cell-62" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the Gaussian Process layer</span></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> GaussianProcessLayer(nn.Module):</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_dim, num_data):</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(GaussianProcessLayer, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_dim <span class="op">=</span> num_dim</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_data <span class="op">=</span> num_data</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lengthscale <span class="op">=</span> nn.Parameter(torch.ones(num_dim))  <span class="co"># Length-scale for each dimension</span></span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.noise_var <span class="op">=</span> nn.Parameter(torch.ones(<span class="dv">1</span>))  <span class="co"># Noise variance</span></span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.outputscale <span class="op">=</span> nn.Parameter(torch.ones(<span class="dv">1</span>))  <span class="co"># Output scale</span></span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, y):</span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate the kernel matrix (using RBF kernel)</span></span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>        dist_matrix <span class="op">=</span> torch.cdist(x, x)  <span class="co"># Pairwise distances between inputs</span></span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a>        kernel_matrix <span class="op">=</span> <span class="va">self</span>.outputscale <span class="op">*</span> torch.exp(<span class="op">-</span><span class="fl">0.5</span> <span class="op">*</span> dist_matrix<span class="op">**</span><span class="dv">2</span> <span class="op">/</span> <span class="va">self</span>.lengthscale<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a>        kernel_matrix <span class="op">+=</span> <span class="va">self</span>.noise_var <span class="op">*</span> torch.eye(<span class="va">self</span>.num_data)</span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate the predictive distribution (using Cholesky decomposition)</span></span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a>        L <span class="op">=</span> torch.linalg.cholesky(kernel_matrix)</span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a>        alpha <span class="op">=</span> torch.cholesky_solve(y.unsqueeze(<span class="op">-</span><span class="dv">1</span>), L)  <span class="co"># Add unsqueeze for correct shape</span></span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true" tabindex="-1"></a>        predictive_mean <span class="op">=</span> torch.matmul(kernel_matrix, alpha).squeeze(<span class="op">-</span><span class="dv">1</span>) <span class="co"># Remove extra dimension</span></span>
<span id="cb32-25"><a href="#cb32-25" aria-hidden="true" tabindex="-1"></a>        v <span class="op">=</span> torch.linalg.solve_triangular(L, kernel_matrix, upper<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb32-26"><a href="#cb32-26" aria-hidden="true" tabindex="-1"></a>        predictive_var <span class="op">=</span> kernel_matrix <span class="op">-</span> torch.matmul(v.T, v)</span>
<span id="cb32-27"><a href="#cb32-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-28"><a href="#cb32-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-29"><a href="#cb32-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> predictive_mean, predictive_var</span>
<span id="cb32-30"><a href="#cb32-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-31"><a href="#cb32-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> predictive_mean, predictive_var</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>La entrada de la capa GP es un tensor 2D de forma (tamaño del lote, dimensión de representación de características). La salida es una tupla que incluye la media y la varianza predichas. Para el cálculo de la matriz kernel se utiliza el kernel RBF, y para calcular la distribución predictiva se aprovecha la descomposición de Cholesky (Cholesky decomposition) para mejorar la eficiencia computacional. <code>y.unsqueeze(-1)</code> y <code>.squeeze(-1)</code> se utilizan para ajustar las dimensiones entre y y la matriz kernel.</p>
<div id="cell-64" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 데이터를 생성</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">100</span>)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.sin(x) <span class="op">+</span> <span class="fl">0.1</span> <span class="op">*</span> np.random.randn(<span class="dv">100</span>)</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 데이터를 텐서로 변환</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>x_tensor <span class="op">=</span> torch.tensor(x, dtype<span class="op">=</span>torch.float32).unsqueeze(<span class="op">-</span><span class="dv">1</span>)  <span class="co"># (100,) -&gt; (100, 1)</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>y_tensor <span class="op">=</span> torch.tensor(y, dtype<span class="op">=</span>torch.float32)  <span class="co"># (100,)</span></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 딥 커널과 GP 레이어를 초기화</span></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>deep_kernel <span class="op">=</span> DeepKernel(input_dim<span class="op">=</span><span class="dv">1</span>, hidden_dim<span class="op">=</span><span class="dv">50</span>, output_dim<span class="op">=</span><span class="dv">1</span>)  <span class="co"># output_dim=1로 수정</span></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>gp_layer <span class="op">=</span> GaussianProcessLayer(num_dim<span class="op">=</span><span class="dv">1</span>, num_data<span class="op">=</span><span class="bu">len</span>(x))</span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a><span class="co"># 손실 함수와 최적화기를 정의</span></span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> nn.MSELoss()  <span class="co"># Use MSE loss</span></span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.Adam(<span class="bu">list</span>(deep_kernel.parameters()) <span class="op">+</span> <span class="bu">list</span>(gp_layer.parameters()), lr<span class="op">=</span><span class="fl">0.01</span>)</span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>num_epochs <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a><span class="co"># 모델을 학습</span></span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a>    optimizer.zero_grad()</span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a>    kernel_output <span class="op">=</span> deep_kernel(x_tensor)</span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a>    predictive_mean, _ <span class="op">=</span> gp_layer(kernel_output, y_tensor) <span class="co"># predictive_var는 사용 안함</span></span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(predictive_mean, y_tensor)  <span class="co"># Use predictive_mean here</span></span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a>    optimizer.step()</span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(epoch <span class="op">%</span> <span class="dv">10</span> <span class="op">==</span> <span class="dv">0</span>):</span>
<span id="cb33-28"><a href="#cb33-28" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">, Loss: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb33-29"><a href="#cb33-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-30"><a href="#cb33-30" aria-hidden="true" tabindex="-1"></a><span class="co"># 예측을 수행</span></span>
<span id="cb33-31"><a href="#cb33-31" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb33-32"><a href="#cb33-32" aria-hidden="true" tabindex="-1"></a>    kernel_output <span class="op">=</span> deep_kernel(x_tensor)</span>
<span id="cb33-33"><a href="#cb33-33" aria-hidden="true" tabindex="-1"></a>    predictive_mean, predictive_var <span class="op">=</span> gp_layer(kernel_output, y_tensor)</span>
<span id="cb33-34"><a href="#cb33-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-35"><a href="#cb33-35" aria-hidden="true" tabindex="-1"></a><span class="co"># 결과를 시각화</span></span>
<span id="cb33-36"><a href="#cb33-36" aria-hidden="true" tabindex="-1"></a>sns.<span class="bu">set</span>()</span>
<span id="cb33-37"><a href="#cb33-37" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb33-38"><a href="#cb33-38" aria-hidden="true" tabindex="-1"></a>plt.plot(x, y, <span class="st">'bo'</span>, label<span class="op">=</span><span class="st">'Training Data'</span>)</span>
<span id="cb33-39"><a href="#cb33-39" aria-hidden="true" tabindex="-1"></a>plt.plot(x, predictive_mean.numpy(), <span class="st">'r-'</span>, label<span class="op">=</span><span class="st">'Predictive Mean'</span>)</span>
<span id="cb33-40"><a href="#cb33-40" aria-hidden="true" tabindex="-1"></a>plt.fill_between(x, predictive_mean.numpy() <span class="op">-</span> <span class="fl">1.96</span> <span class="op">*</span> np.sqrt(predictive_var.numpy().diagonal()),</span>
<span id="cb33-41"><a href="#cb33-41" aria-hidden="true" tabindex="-1"></a>                 predictive_mean.numpy() <span class="op">+</span> <span class="fl">1.96</span> <span class="op">*</span> np.sqrt(predictive_var.numpy().diagonal()),</span>
<span id="cb33-42"><a href="#cb33-42" aria-hidden="true" tabindex="-1"></a>                 alpha<span class="op">=</span><span class="fl">0.2</span>, label<span class="op">=</span><span class="st">'95% CI'</span>)</span>
<span id="cb33-43"><a href="#cb33-43" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb33-44"><a href="#cb33-44" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1, Loss: 4.3467857893837725e-13
Epoch 11, Loss: 3.1288711313699757e-13
Epoch 21, Loss: 3.9212150236903054e-13
Epoch 31, Loss: 4.184870765894244e-13
Epoch 41, Loss: 2.9785689973499396e-13
Epoch 51, Loss: 3.8607078688482344e-13
Epoch 61, Loss: 3.9107123572454383e-13
Epoch 71, Loss: 2.359286811054462e-13
Epoch 81, Loss: 3.4729958167147024e-13
Epoch 91, Loss: 2.7600995490886793e-13</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/tmp/ipykernel_1408185/2425174321.py:40: RuntimeWarning: invalid value encountered in sqrt
  plt.fill_between(x, predictive_mean.numpy() - 1.96 * np.sqrt(predictive_var.numpy().diagonal()),
/tmp/ipykernel_1408185/2425174321.py:41: RuntimeWarning: invalid value encountered in sqrt
  predictive_mean.numpy() + 1.96 * np.sqrt(predictive_var.numpy().diagonal()),</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="06_Sobreajuste y desarrollo de técnicas de solución_files/figure-html/cell-27-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>El aprendizaje del modelo utiliza la función de pérdida de error cuadrático medio (Mean Squared Error, MSE) y el optimizador Adam para aprender simultáneamente los parámetros de la red neuronal profunda y la capa GP.</p>
<section id="posibilidades-y-limitaciones-del-dkl" class="level4">
<h4 class="anchored" data-anchor-id="posibilidades-y-limitaciones-del-dkl">6.6.4 Posibilidades y limitaciones del DKL</h4>
<p>El ejemplo anterior muestra las ideas básicas detrás del aprendizaje de núcleos profundos (Deep Kernel Learning, DKL). Se utiliza un modelo de aprendizaje profundo (<code>DeepKernel</code> clase) para extraer características de los datos de entrada, y estas características se utilizan para calcular el kernel de un proceso gaussiano (GP). Luego, se usa el GP para calcular la media y la varianza (incertidumbre) de las predicciones. De esta manera, DKL combina la capacidad de aprendizaje representativo del aprendizaje profundo con la capacidad de estimación de incertidumbre del GP, lo que permite hacer predicciones confiables incluso en datos complejos.</p>
<p><strong>Posibilidades del DKL:</strong></p>
<ul>
<li><strong>Eficiencia de datos:</strong> Los GPs tienden a funcionar bien incluso cuando los datos son escasos. DKL combina la potente capacidad de extracción de características del aprendizaje profundo con la eficiencia en datos del GP, lo que permite obtener un buen rendimiento incluso con pocos datos.</li>
<li><strong>Estimación de incertidumbre:</strong> DKL puede cuantificar la incertidumbre de las predicciones. Esto es muy útil en aplicaciones donde la seguridad es crucial (por ejemplo, diagnóstico médico, conducción autónoma).</li>
<li><strong>Flexibilidad:</strong> DKL se puede aplicar a diversos tipos de datos (imágenes, texto, gráficos, etc.). Se puede elegir libremente la arquitectura de la red neuronal para diseñar un extractor de características adecuado al problema.</li>
<li><strong>Combinación con optimización bayesiana:</strong> DKL se puede combinar con la optimización bayesiana para afinar eficientemente los hiperparámetros del modelo.</li>
</ul>
<p><strong>Limitaciones del DKL:</strong></p>
<ul>
<li><strong>Costo computacional:</strong> Los GPs siguen siendo costosos en términos de cálculo. En particular, a medida que aumenta el tamaño de los datos de entrenamiento, la matriz del kernel se hace más grande y el cálculo se vuelve más difícil.</li>
<li><strong>Diseño de redes neuronales:</strong> El rendimiento de DKL depende en gran medida del diseño del extractor de características (red neuronal). Elegir una arquitectura de red neuronal apropiada sigue siendo un problema complicado.</li>
<li><strong>Comprensión teórica insuficiente:</strong> El análisis teórico de DKL aún está en sus primeras etapas. Se necesitan más investigaciones para entender por qué DKL funciona bien y bajo qué condiciones muestra un buen rendimiento.</li>
</ul>
</section>
<section id="conclusión" class="level4">
<h4 class="anchored" data-anchor-id="conclusión">Conclusión</h4>
<p>En este capítulo hemos examinado diversas técnicas para abordar el problema del sobreajuste en los modelos de aprendizaje profundo. El sobreajuste ocurre cuando un modelo de aprendizaje profundo se especializa excesivamente en los datos de entrenamiento y su rendimiento en la predicción de nuevos datos disminuye. Esto puede ocurrir cuando el modelo es demasiado complejo, hay pocos datos de entrenamiento, o los datos contienen mucho ruido. Prevenir el sobreajuste es una tarea crucial para aplicar modelos de aprendizaje profundo a problemas reales.</p>
<p>Las técnicas presentadas en este capítulo abordan el problema del sobreajuste de diferentes formas:</p>
<ul>
<li><strong>Regularización:</strong> Se aplica una penalización a la complejidad del modelo para evitar que los pesos sean demasiado grandes. (L1, L2, Elastic Net)</li>
<li><strong>Dropout:</strong> Durante el entrenamiento, se eliminan aleatoriamente neuronas para evitar que el modelo dependa de neuronas o combinaciones específicas.</li>
<li><strong>Normalización por lotes:</strong> Se normalizan las entradas de cada capa para estabilizar y acelerar el aprendizaje.</li>
<li><strong>Optimización de hiperparámetros:</strong> Se utilizan métodos como la optimización bayesiana para encontrar combinaciones de hiperparámetros que optimicen el rendimiento del modelo.</li>
<li><strong>Procesos gaussianos, aprendizaje de núcleos profundos</strong>: Se modela explícitamente la incertidumbre para hacer predicciones más confiables. La combinación adecuada de estas técnicas y su ajuste según las características del problema es una de las habilidades más importantes de un ingeniero de deep learning. No existe una única solución “perfecta para todos los casos” y se debe buscar el mejor método a través de experimentación y análisis. La investigación en deep learning continúa avanzando rápidamente y es probable que surjan nuevas técnicas para abordar el sobreajuste.</li>
</ul>
</section>
</section>
</section>
<section id="ejercicios-de-práctica" class="level2">
<h2 class="anchored" data-anchor-id="ejercicios-de-práctica">Ejercicios de práctica</h2>
<section id="problemas-básicos" class="level3">
<h3 class="anchored" data-anchor-id="problemas-básicos">Problemas básicos</h3>
<ol type="1">
<li>Explique los conceptos de sobreajuste (overfitting) y subajuste (underfitting), y describa cómo cada fenómeno afecta el rendimiento del modelo.</li>
<li>Explique las diferencias entre la regularización L1 y L2, y describa cómo cada tipo de regularización afecta los pesos del modelo.</li>
<li>Explique el principio de funcionamiento del dropout y cómo ayuda a prevenir el sobreajuste.</li>
<li>Explique el concepto de normalización por lotes (batch normalization) y describa qué beneficios proporciona para el entrenamiento de modelos de deep learning.</li>
<li>Describa los cambios en el gráfico mientras se modifican las funciones lambda en la función custom_loss dada.</li>
<li>Defina las normas L1 y L2.</li>
<li>Explique cómo se calculan la media y la varianza en la fórmula de normalización por lotes, y cómo estas se utilizan en el proceso de normalización.</li>
</ol>
</section>
<section id="problemas-aplicados" class="level3">
<h3 class="anchored" data-anchor-id="problemas-aplicados">Problemas aplicados</h3>
<ol type="1">
<li>Entrene un modelo de regresión polinomial (polynomial regression) en un conjunto de datos dado y observe los fenómenos de sobreajuste y subajuste mientras varía el grado del polinomio. (Escriba código Python)</li>
<li>Cree un modelo de red neuronal simple, aplique regularización L1 o L2 y observe cómo cambian los pesos del modelo; compare los cambios en el rendimiento según la intensidad de la regularización. (Escriba código Python)</li>
<li>Entrene modelos de red neuronal con diferentes tasas de dropout y compare las pérdidas de entrenamiento/validación y la precisión para cada tasa. (Escriba código Python)</li>
<li>Compare la velocidad de aprendizaje y la estabilidad de convergencia del modelo de red neuronal mientras añade o elimina capas de normalización por lotes. (Escriba código Python)</li>
<li>Utilice el método de multiplicadores de Lagrange para derivar las condiciones óptimas de una función de pérdida con regularización L1 y L2 aplicadas.</li>
<li>Derive el proceso de retropropagación (backpropagation) en la normalización por lotes y explique cómo ayuda a mitigar el problema del desvanecimiento del gradiente.</li>
</ol>
</section>
<section id="problemas-avanzados" class="level3">
<h3 class="anchored">Problemas avanzados</h3>
<ol type="1">
<li>Visualice los efectos de la regularización L1 y L2 sobre la superficie de pérdida y explique el significado geométrico de cada tipo de regularización. (Escriba código Python)</li>
<li>Interprete el dropout desde la perspectiva del aprendizaje por ensamblaje (ensemble learning) y explique cómo se puede utilizar para estimar la incertidumbre del modelo.</li>
<li>Compare diferentes técnicas de optimización de hiperparámetros (búsqueda en cuadrícula, búsqueda aleatoria, optimización bayesiana, etc.) y describa las ventajas y desventajas de cada técnica.</li>
<li>Implemente la idea central de la optimización bayesiana para encontrar el valor óptimo de una función simple sin usar BoTorch. (Escriba código Python, se permite el uso de bibliotecas)</li>
<li>Explique los principios básicos del proceso gaussiano (Gaussian Process) y cómo realiza predicciones que incluyen incertidumbre.</li>
<li>Explique las condiciones que debe satisfacer la función kernel en un proceso gaussiano y demuestre que el kernel RBF satisface estas condiciones.</li>
<li>Explique el papel de la función de adquisición (acquisition function) en la optimización bayesiana, derive la fórmula de la función de adquisición Expected Improvement (EI) y explique su significado.</li>
</ol>
<div class="callout callout-style-default callout-note callout-titled" title="Haga clic para ver el contenido (soluciones de los ejercicios)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Haga clic para ver el contenido (soluciones de los ejercicios)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<section id="soluciones-de-ejercicios" class="level2 callout-body-container callout-body">
<h2 class="anchored" data-anchor-id="soluciones-de-ejercicios">Soluciones de Ejercicios</h2>
<section id="problemas-básicos-1" class="level3">
<h3 class="anchored" data-anchor-id="problemas-básicos-1">Problemas Básicos</h3>
<ol type="1">
<li><strong>Sobreajuste/Subajuste:</strong>
<ul>
<li><strong>Sobreajuste (Overfitting):</strong> El modelo se ajusta demasiado bien a los datos de entrenamiento, lo que resulta en un rendimiento (rendimiento de generalización) inferior en nuevos datos (datos de validación/prueba). Muestra un alto rendimiento en los datos de entrenamiento pero un bajo rendimiento en los datos de validación/prueba.</li>
<li><strong>Subajuste (Underfitting):</strong> El modelo es demasiado simple y no logra aprender adecuadamente los patrones de los datos de entrenamiento. Muestra un bajo rendimiento en los datos de entrenamiento, validación y prueba.</li>
</ul></li>
<li><strong>Regularización L1/L2:</strong>
<ul>
<li><strong>Regularización L1 (Lasso):</strong> Añade la suma de los valores absolutos de los pesos a la función de pérdida. <span class="math inline">\(\lambda \sum_{i} |w_i|\)</span> Hace que algunos pesos sean exactamente 0, lo que tiene un efecto de selección de características (feature selection).</li>
<li><strong>Regularización L2 (Ridge):</strong> Añade la suma de los cuadrados de los pesos a la función de pérdida. <span class="math inline">\(\lambda \sum_{i} (w_i)^2\)</span> Reduce los pesos hacia 0, pero no los hace exactamente 0.</li>
</ul></li>
<li><strong>Dropout:</strong>
<ul>
<li><strong>Principio de funcionamiento:</strong> Durante el proceso de entrenamiento, desactiva aleatoriamente algunos neuronas (hace que sus salidas sean 0).</li>
<li><strong>Prevención del sobreajuste:</strong> Al aprender con diferentes combinaciones de neuronas cada vez, evita la dependencia en ciertas neuronas y produce un efecto de aprendizaje por ensamble.</li>
</ul></li>
<li><strong>Normalización por lotes:</strong>
<ul>
<li><strong>Concepto:</strong> Normaliza las entradas de cada capa para que tengan una media de 0 y una varianza de 1.</li>
<li><strong>Ventajas:</strong> Mejora la velocidad de entrenamiento, mitiga el problema del desvanecimiento/explosión del gradiente, permite el uso de tasas de aprendizaje más altas y tiene un efecto de regularización ligero.</li>
</ul></li>
<li><strong>Cambio de <code>lambda</code> en <code>custom_loss</code>:</strong>
<ul>
<li><strong>Aumento de <code>lambda</code>:</strong> Aumenta la influencia del término de regularización. Los pesos se reducen, el modelo se simplifica y aumenta la posibilidad de subajuste.</li>
<li><strong>Disminución de <code>lambda</code>:</strong> Reduce la influencia del término de regularización. Los pesos aumentan, el modelo se vuelve más complejo y aumenta la posibilidad de sobreajuste.</li>
</ul></li>
<li><strong>Normas L1/L2:</strong>
<ul>
<li><strong>Norma L1:</strong> Suma de los valores absolutos de los elementos del vector. <span class="math inline">\(\| \mathbf{x} \|_1 = \sum_{i=1}^{n} |x_i|\)</span></li>
<li><strong>Norma L2:</strong> Raíz cuadrada de la suma de los cuadrados de los elementos del vector. <span class="math inline">\(\| \mathbf{x} \|_2 = \sqrt{\sum_{i=1}^{n} x_i^2}\)</span></li>
</ul></li>
<li><strong>Normalización por lotes:</strong>
<ul>
<li><strong>Media (μ):</strong> Media de las muestras dentro de un lote. <span class="math inline">\(\mu = \frac{1}{m} \sum_{i=1}^{m} x_i\)</span></li>
<li><strong>Varianza (σ²):</strong> Varianza de las muestras dentro de un lote. <span class="math inline">\(\sigma^2 = \frac{1}{m} \sum_{i=1}^{m} (x_i - \mu)^2\)</span></li>
<li><strong>Normalización:</strong> <span class="math inline">\(x_{\text{norm}} = \frac{x_i - \mu}{\sqrt{\sigma^2 + \epsilon}}\)</span> (ε es una pequeña constante para evitar la división por 0)</li>
</ul></li>
</ol>
</section>
<section id="problemas-de-aplicación" class="level3">
<h3 class="anchored" data-anchor-id="problemas-de-aplicación">Problemas de Aplicación</h3>
<ol type="1">
<li><p><strong>Regresión Polinomial:</strong> (código omitido) Si el grado es demasiado alto, puede ocurrir sobreajuste; si es demasiado bajo, puede ocurrir subajuste.</p></li>
<li><p><strong>Regularización L1/L2:</strong> (código omitido) Cuanto mayor sea la intensidad de regularización (<code>lambda</code>), más pequeños serán los pesos y se observarán cambios en el rendimiento.</p></li>
<li><p><strong>Tasa de Dropout:</strong> (código omitido) Una tasa de dropout adecuada puede prevenir el sobreajuste y mejorar el rendimiento. Una tasa demasiado alta puede causar subajuste.</p></li>
<li><p><strong>Normalización por lotes:</strong> (código omitido) Al agregar normalización por lotes, la velocidad de entrenamiento aumenta y tiende a converger de manera más estable.</p></li>
<li><p><strong>Método de los multiplicadores de Lagrange:</strong></p>
<ul>
<li><strong>Regularización L2:</strong> <span class="math inline">\(L(\mathbf{w}, \lambda) = \text{Loss}(\mathbf{w}) + \lambda (\|\mathbf{w}\|_2^2 - c)  \rightarrow  \nabla_\mathbf{w}L = \nabla_\mathbf{w}\text{Loss}(\mathbf{w}) + 2\lambda\mathbf{w} = 0\)</span></li>
<li><strong>Regularización L1:</strong> <span class="math inline">\(L(\mathbf{w}, \lambda) = \text{Loss}(\mathbf{w}) + \lambda (\|\mathbf{w}\|_1 - c)  \rightarrow  \nabla_\mathbf{w}L = \nabla_\mathbf{w}\text{Loss}(\mathbf{w}) + \lambda \cdot \text{sign}(\mathbf{w}) = 0\)</span> (sign(w) es el signo de w)</li>
</ul></li>
<li><p><strong>Retropropagación del batch normalization:</strong> (omitiendo la derivación) La normalización por lotes normaliza las entradas de cada capa para mitigar los problemas de desvanecimiento y explosión de gradientes, estabilizando así el aprendizaje.</p></li>
</ol>
</section>
<section id="problemas-avanzados-1" class="level3">
<h3 class="anchored" data-anchor-id="problemas-avanzados-1">Problemas avanzados</h3>
<ol type="1">
<li><p><strong>Visualización del plano de pérdida:</strong> (omitiendo el código) La regularización L1 genera restricciones en forma de rombo, mientras que la regularización L2 genera restricciones circulares, lo que resulta en soluciones óptimas formadas en diferentes ubicaciones.</p></li>
<li><p><strong>Ensamblaje de dropout:</strong> El dropout tiene un efecto similar al aprendizaje por ensamblaje al entrenar con diferentes estructuras de red cada vez. Durante la predicción, se utilizan todos los neuronas (sin dropout) para realizar una predicción promedio. La incertidumbre de las predicciones puede estimarse mediante el dropout de Monte Carlo.</p></li>
<li><p><strong>Técnicas de optimización de hiperparámetros:</strong></p>
<ul>
<li><strong>Búsqueda en cuadrícula:</strong> Intenta todas las combinaciones posibles. Es muy costoso computacionalmente.</li>
<li><strong>Búsqueda aleatoria:</strong> Prueba combinaciones aleatorias. Puede ser más eficiente que la búsqueda en cuadrícula.</li>
<li><strong>Optimización bayesiana:</strong> Utiliza un modelo probabilístico basado en resultados previos de búsqueda para determinar el siguiente punto a explorar. Es eficiente.</li>
</ul></li>
<li><p><strong>Implementación de optimización bayesiana:</strong> (omitiendo el código) Se implementa utilizando un modelo sustituto (surrogate model, por ejemplo, proceso gaussiano) y una función de adquisición (acquisition function, por ejemplo, Expected Improvement).</p></li>
<li><p><strong>Proceso gaussiano:</strong> Es una distribución de probabilidad sobre funciones. Utiliza una función kernel para definir la covarianza entre valores de función. Calcula la distribución a posteriori basada en datos observados, proporcionando la media y variancia (incertidumbre) de las predicciones.</p></li>
<li><p><strong>Condiciones de la función kernel:</strong> Debe ser positiva semidefinida (positive semi-definite). La matriz kernel generada para cualquier conjunto de puntos de entrada debe ser una matriz positiva semidefinida (positive semi-definite matrix). El kernel RBF satisface esta condición. (omitiendo la prueba)</p></li>
<li><p><strong>Función de adquisición:</strong> Se utiliza en optimización bayesiana para seleccionar el siguiente punto a explorar. Expected Improvement (EI) considera tanto la probabilidad de obtener un resultado mejor que el óptimo actual como la magnitud de esa mejora para seleccionar el próximo punto de exploración. (omitiendo la derivación de la fórmula)</p></li>
</ol>
</section>
</section>
</div>
</div>
<ol type="1">
<li><strong>Dropout: A Simple Way to Prevent Neural Networks from Overfitting</strong> (Srivastava et al., 2014): Artículo original que explica el concepto y efectos del dropout. (<a href="https://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf">https://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf</a>)</li>
<li><strong>Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</strong> (Ioffe &amp; Szegedy, 2015): Artículo original que explica el concepto y efectos de la normalización por lotes. (<a href="https://arxiv.org/abs/1502.03167">https://arxiv.org/abs/1502.03167</a>)</li>
<li><strong>Deep Learning</strong> (Goodfellow et al., 2016): Libro de texto sobre aprendizaje profundo. El capítulo 7 “Regularization for Deep Learning” trata detalladamente el tema del overfitting y las técnicas de regularización. (<a href="http://www.deeplearningbook.org/">http://www.deeplearningbook.org/</a>)</li>
<li><strong>Understanding the difficulty of training deep feedforward neural networks</strong> (Glorot &amp; Bengio, 2010): Explica las dificultades de entrenamiento en los modelos iniciales de aprendizaje profundo y la importancia de la inicialización de pesos. (<a href="http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf">http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf</a>)</li>
<li><strong>Regularization techniques for deep learning: A survey</strong> (Kukacka et al., 2017): Artículo que compara y analiza de manera integral diversas técnicas de regularización.</li>
<li><strong>A Tutorial on Bayesian Optimization</strong> (Frazier, 2018): Tutorial que explica los conceptos básicos y aplicaciones de la optimización bayesiana. (<a href="https://arxiv.org/abs/1807.02811">https://arxiv.org/abs/1807.02811</a>)</li>
<li><strong>Bayesian Optimization</strong> (Garnett, 2023): Libro de texto completo sobre optimización bayesiana (<a href="https://www.bayesoptbook.com/">https://www.bayesoptbook.com/</a>)</li>
<li><strong>Gaussian Processes for Machine Learning</strong> (Rasmussen &amp; Williams, 2006): Libro de texto que aborda los principios básicos y aplicaciones en aprendizaje automático de los procesos gaussianos. (<a href="http://www.gaussianprocess.org/gpml/">http://www.gaussianprocess.org/gpml/</a>)</li>
<li><strong>Deep Kernel Learning</strong> (Wilson et al., 2016): Artículo que explica el concepto y métodos del aprendizaje de kernels profundos. (<a href="https://arxiv.org/abs/1511.02222">https://arxiv.org/abs/1511.02222</a>)</li>
<li><strong>Hands-On Machine Learning with Scikit-Learn, Keras &amp; TensorFlow</strong> (Aurélien Géron, 2019): Libro de texto práctico sobre aprendizaje automático y aprendizaje profundo. Explica el overfitting y las técnicas de regularización con ejemplos de código reales.</li>
<li><strong>Adam: A Method for Stochastic Optimization</strong> (Kingma &amp; Ba, 2014) (<a href="https://arxiv.org/abs/1412.6980">https://arxiv.org/abs/1412.6980</a>): Artículo sobre el optimizador Adam</li>
<li><strong>Decoupled Weight Decay Regularization</strong> (Loshchilov &amp; Hutter, 2017) (<a href="https://arxiv.org/abs/1711.05101">https://arxiv.org/abs/1711.05101</a>): Artículo sobre AdamW</li>
<li><strong>Dropout: A Simple Way to Prevent Neural Networks from Overfitting</strong> (Srivastava et al., 2014): Artículo original que explica el concepto y los efectos del dropout. (<a href="https://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf">https://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf</a>) 2. <strong>Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</strong> (Ioffe &amp; Szegedy, 2015): Artículo original que explica el concepto y los efectos de la normalización por lotes. (<a href="https://arxiv.org/abs/1502.03167">https://arxiv.org/abs/1502.03167</a>) 3. <strong>Deep Learning</strong> (Goodfellow et al., 2016): Libro de texto de deep learning. El capítulo 7 “Regularization for Deep Learning” trata detalladamente el sobreajuste y las técnicas de regularización. (<a href="http://www.deeplearningbook.org/">http://www.deeplearningbook.org/</a>) 4. <strong>Understanding the difficulty of training deep feedforward neural networks</strong> (Glorot &amp; Bengio, 2010): Explica las dificultades en el entrenamiento de modelos de deep learning iniciales y la importancia de los métodos de inicialización de pesos. (<a href="http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf">http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf</a>) 5. <strong>Regularization techniques for deep learning: A survey</strong> (Kukacka et al., 2017): Artículo que compara y analiza de manera integral diversas técnicas de regularización. 6. <strong>A Tutorial on Bayesian Optimization</strong> (Frazier, 2018): Tutorial que explica los conceptos básicos y las aplicaciones de la optimización bayesiana. (<a href="https://arxiv.org/abs/1807.02811">https://arxiv.org/abs/1807.02811</a>) 7. <strong>Bayesian Optimization</strong> (Garnett, 2023): Libro de texto integral sobre la optimización bayesiana (<a href="https://www.bayesoptbook.com/">https://www.bayesoptbook.com/</a>) 8. <strong>Gaussian Processes for Machine Learning</strong> (Rasmussen &amp; Williams, 2006): Libro de texto que trata los principios básicos y las aplicaciones de machine learning de los procesos gaussianos. (<a href="http://www.gaussianprocess.org/gpml/">http://www.gaussianprocess.org/gpml/</a>) 9. <strong>Deep Kernel Learning</strong> (Wilson et al., 2016): Artículo que explica el concepto y los métodos del aprendizaje de núcleos profundos. (<a href="https://arxiv.org/abs/1511.02222">https://arxiv.org/abs/1511.02222</a>) 10. <strong>Hands-On Machine Learning with Scikit-Learn, Keras &amp; TensorFlow</strong> (Aurélien Géron, 2019): Libro de texto práctico sobre machine learning y deep learning. Explica el sobreajuste y las técnicas de regularización con ejemplos de código reales. 11. <strong>Adam: A Method for Stochastic Optimization</strong> (Kingma &amp; Ba, 2014) (<a href="https://arxiv.org/abs/1412.6980">https://arxiv.org/abs/1412.6980</a>): Artículo sobre el optimizador Adam 12. <strong>Decoupled Weight Decay Regularization</strong> (Loshchilov &amp; Hutter, 2017) (<a href="https://arxiv.org/abs/1711.05101">https://arxiv.org/abs/1711.05101</a>): Paper sobre AdamW</li>
</ol>
<p>Traducción:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Título</strong></th>
<th><strong>Contenido</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Ejemplo de texto</td>
<td>Este es un ejemplo de texto que debe traducirse, pero las expresiones matemáticas como <span class="math inline">\(E = mc^2\)</span> y las tablas deben mantenerse intactas.</td>
</tr>
</tbody>
</table>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>