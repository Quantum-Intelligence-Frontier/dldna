{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Quantum-Intelligence-Frontier/dldna/blob/main/notebooks/es/part_1/03_marco_de_aprendizaje_profundo.ipynb\" target=\"_parent\">\n",
    "<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Abrir en Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Marco de aprendizaje profundo\n",
    "\n",
    "> \"La herramienta es tan buena como el que la hace.\" - *Anónimo, pero a menudo citado por von Neumann*\n",
    "\n",
    "El desarrollo de los marcos en la historia del aprendizaje profundo ha sido muy importante. Después del éxito de AlexNet en 2012, han surgido varios marcos. A través de Caffe, Theano, Torch7 y otros, actualmente PyTorch y TensorFlow son los más utilizados.\n",
    "\n",
    "A principios de la década de 2010, el aprendizaje profundo comenzó a mostrar resultados sorprendentes en varios campos, como el reconocimiento de imágenes y el reconocimiento de voz, superando las tecnologías existentes. Sin embargo, entrenar y desplegar modelos de aprendizaje profundo todavía era una tarea difícil. Esto se debía a que había que implementar directamente la configuración de redes neuronales, el cálculo de gradientes, la aceleración GPU y otros aspectos. Esta complejidad elevaba las barreras de entrada para la investigación en aprendizaje profundo y ralentizaba el ritmo de la investigación. Para abordar estos problemas, surgieron los marcos de aprendizaje profundo. Estos marcos proporcionan API de alto nivel y herramientas para construir, entrenar y desplegar modelos de redes neuronales, simplificando y acelerando el proceso de desarrollo. En sus primeras etapas, frameworks como Theano, Caffe y Torch se popularizaron y fueron ampliamente utilizados en la academia y la industria.\n",
    "\n",
    "En 2015, Google lanzó TensorFlow como software de código abierto, lo que trajo grandes cambios al ecosistema de marcos de aprendizaje profundo. TensorFlow ganó rápidamente popularidad gracias a su arquitectura flexible, potentes herramientas de visualización y soporte para el entrenamiento distribuido a gran escala. En 2017, Facebook presentó PyTorch, estableciendo otro hito importante. PyTorch ofrecía un grafo de cálculo dinámico, una interfaz intuitiva y excelentes capacidades de depuración, lo que llevó a su rápida difusión entre los investigadores.\n",
    "\n",
    "Actualmente, los marcos de aprendizaje profundo han trascendido el papel de simples herramientas para convertirse en infraestructura esencial para la investigación y desarrollo de aprendizaje profundo. Proporcionan funciones clave como diferenciación automática, aceleración GPU, paralelización de modelos y entrenamiento distribuido, acelerando así el desarrollo de nuevos modelos y algoritmos. Además, la competencia y colaboración entre los marcos están impulsando aún más el avance del ecosistema de aprendizaje profundo.\n",
    "\n",
    "\n",
    "## 3.1 PyTorch\n",
    "\n",
    "PyTorch es un marco de aprendizaje automático de código abierto basado en la biblioteca Torch, utilizado para aplicaciones como visión por computadora y procesamiento de lenguaje natural. Fue desarrollado como el marco principal por el laboratorio de investigación de IA de Facebook (FAIR) en 2016, reimplemementando Torch7 en Python. Debido a su grafo de cálculo dinámico y capacidades intuitivas de depuración, ganó rápidamente popularidad entre los investigadores. Aunque hay otros marcos como TensorFlow, JAX y Caffe, PyTorch se ha convertido en el estándar de facto en la investigación. Muchos nuevos modelos a menudo se lanzan con implementaciones de PyTorch.\n",
    "\n",
    "Una vez que se es competente en un marco, también puede ser una buena estrategia aprovechar las ventajas de otros marcos. Por ejemplo, se pueden utilizar las pipelines de preprocesamiento de datos de TensorFlow o las transformaciones funcionales de JAX junto con PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dldna[colab] # in Colab\n",
    "# !pip install dldna[all] # in your local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cu124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7352f02b33f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Print PyTorch version\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "torch.manual_seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando se genera un número aleatorio, al configurar el valor inicial de la semilla se pueden obtener los mismos números aleatorios cada vez. Esto es comúnmente utilizado en la investigación para garantizar resultados consistentes en entrenamientos repetitivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Objeto Tensor\n",
    "\n",
    "> **Desafío**: ¿Cómo se pueden realizar eficientemente operaciones de matrices a gran escala utilizando GPU?\n",
    ">\n",
    "> **Dilema del investigador**: A medida que el tamaño de los modelos de aprendizaje profundo aumentaba, aprender y hacer inferencia con solo CPU llevaba demasiado tiempo. Las GPU estaban especializadas en cálculos paralelos y eran adecuadas para el aprendizaje profundo, pero la programación de GPU era compleja y difícil. Se necesitaba una herramienta que abstrajera y automatizara las operaciones de GPU para que los investigadores de aprendizaje profundo pudieran utilizarlas fácilmente.\n",
    "\n",
    "El tensor es la estructura de datos básica en PyTorch. Desde la aparición de CUDA en 2006, las operaciones de GPU se han convertido en el núcleo del aprendizaje profundo, y los tensores están diseñados para realizar estas operaciones de manera eficiente. Un tensor es un arreglo multidimensional que generaliza escalares, vectores y matrices. En el aprendizaje profundo, las dimensiones de los datos (rango del tensor) son muy variadas. Por ejemplo, una imagen se representa como un tensor de 4 dimensiones (lote, canal, altura, anchura), y el lenguaje natural se representa como un tensor de 3 dimensiones (lote, longitud de secuencia, dimensión de incrustación). Como se vio en el Capítulo 2, es importante poder transformar y procesar estas dimensiones con flexibilidad.\n",
    "\n",
    "Puedes declarar un tensor de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.1210e-44,  0.0000e+00,  0.0000e+00,  4.1369e-41],\n",
      "         [ 1.8796e-17,  0.0000e+00,  2.8026e-45,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,         nan,         nan],\n",
      "         [ 6.3058e-44,  4.7424e+30,  1.4013e-45,  1.3563e-19]],\n",
      "\n",
      "        [[ 1.0089e-43,  0.0000e+00,  1.1210e-44,  0.0000e+00],\n",
      "         [-8.8105e+09,  4.1369e-41,  1.8796e-17,  0.0000e+00]]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Create a 3x2x4 tensor with random values\n",
    "a = torch.Tensor(3, 2, 4)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También se pueden inicializar tensores a partir de datos existentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of d: <class 'list'>\n",
      "Tensor a:\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "Type of a: <class 'torch.Tensor'>\n",
      "Type of d_np: <class 'numpy.ndarray'>\n",
      "Tensor b (from_numpy):\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "Tensor c (from np array using torch.Tensor):\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "Modified d_np:\n",
      "[[100   2]\n",
      " [  3   4]]\n",
      "Tensor b (from_numpy) after modifying d_np:\n",
      "tensor([[100,   2],\n",
      "        [  3,   4]])\n",
      "Tensor c (copy) after modifying d_np:\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "# From a Python list\n",
    "d = [[1, 2], [3, 4]]\n",
    "print(f\"Type of d: {type(d)}\")\n",
    "\n",
    "a = torch.Tensor(d)  # Creates a *copy*\n",
    "print(f\"Tensor a:\\n{a}\")\n",
    "print(f\"Type of a: {type(a)}\")\n",
    "\n",
    "# From a NumPy array\n",
    "d_np = np.array(d)\n",
    "print(f\"Type of d_np: {type(d_np)}\")\n",
    "\n",
    "b = torch.from_numpy(d_np) # Shares memory with d_np (zero-copy)\n",
    "print(f\"Tensor b (from_numpy):\\n{b}\")\n",
    "\n",
    "\n",
    "c = torch.Tensor(d_np)  # Creates a *copy*\n",
    "print(f\"Tensor c (from np array using torch.Tensor):\\n{c}\")\n",
    "\n",
    "# Example of memory sharing with torch.from_numpy\n",
    "d_np[0, 0] = 100\n",
    "print(f\"Modified d_np:\\n{d_np}\")\n",
    "print(f\"Tensor b (from_numpy) after modifying d_np:\\n{b}\")\n",
    "print(f\"Tensor c (copy) after modifying d_np:\\n{c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No es lo mismo que se vean iguales cuando se imprimen. `d` es un objeto de lista de Python y los tensores pueden ser creados a partir de diversas estructuras de datos. La interacción con matrices NumPy es particularmente eficiente. Sin embargo, dado que los objetos de lista y las matrices NumPy no admiten GPU, la conversión a tensores es esencial para operaciones de gran escala. *Un punto importante* es entender la diferencia entre `torch.Tensor(data)` y `torch.from_numpy(data)`. El primero *siempre* crea una copia, mientras que el segundo crea una *vista* que comparte memoria con la matriz NumPy original (copia cero cuando sea posible). Si se modifica la matriz NumPy, también cambia el tensor creado por `from_numpy` y viceversa.\n",
    "\n",
    "Hay muchas maneras de inicializar tensores. La importancia de los métodos de inicialización ha sido destacada desde el artículo de Hinton en 2006 y se han desarrollado diversas estrategias de inicialización. Las funciones básicas de inicialización son las siguientes:\n",
    "\n",
    "*   `torch.zeros`: inicializa con ceros.\n",
    "*   `torch.ones`: inicializa con unos.\n",
    "*   `torch.rand`: inicializa con números aleatorios de una distribución uniforme entre 0 y 1.\n",
    "*   `torch.randn`: inicializa con números aleatorios de una distribución normal estándar (media 0, varianza 1).\n",
    "*   `torch.arange`: inicializa secuencialmente como n, n+1, n+2, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random tensor (uniform):\n",
      "tensor([[0.5349, 0.1988, 0.6592],\n",
      "        [0.6569, 0.2328, 0.4251]])\n",
      "Random tensor (normal):\n",
      "tensor([[-1.2514, -1.8841,  0.4457],\n",
      "        [-0.7068, -1.5750, -0.6318]])\n",
      "Ones tensor:\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "Zeros tensor:\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2, 3)\n",
    "\n",
    "rand_t = torch.rand(shape)     # Uniform distribution [0, 1)\n",
    "randn_t = torch.randn(shape)   # Standard normal distribution\n",
    "ones_t = torch.ones(shape)\n",
    "zeros_t = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random tensor (uniform):\\n{rand_t}\")\n",
    "print(f\"Random tensor (normal):\\n{randn_t}\")\n",
    "print(f\"Ones tensor:\\n{ones_t}\")\n",
    "print(f\"Zeros tensor:\\n{zeros_t}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch admite más de 100 operaciones de tensor, y todas ellas pueden ejecutarse en GPU. Los tensores se crean básicamente en la memoria de CPU, por lo que para usar GPU, es necesario moverlos explícitamente usando la función `to()`. Mover tensores grandes entre CPU y GPU tiene un costo considerable, por lo que una gestión cuidadosa de la memoria es esencial. En el entrenamiento de deep learning práctico, el ancho de banda de memoria de la GPU tiene un impacto decisivo en el rendimiento. Por ejemplo, al entrenar modelos de transformador, cuanto mayor sea la memoria de GPU, más grande será el tamaño del lote que se puede usar, lo que mejora la eficiencia del entrenamiento. Sin embargo, la memoria de alta banda es muy costosa de producir y constituye una parte significativa del precio de la GPU. La diferencia en rendimiento entre las operaciones de tensor de CPU y GPU es particularmente notable en operaciones que se pueden paralelizar, como la multiplicación de matrices. Por esta razón, en el deep learning moderno son esenciales los aceleradores dedicados como GPU, TPU, NPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU computation time = 2.34 seconds\n",
      "GPU computation time = 0.14 seconds\n",
      "GPU is 16.2 times faster.\n"
     ]
    }
   ],
   "source": [
    "# Device setting\n",
    "if torch.cuda.is_available():\n",
    "    tensor = zeros_t.to(\"cuda\")\n",
    "    device = \"cuda:0\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print('GPU not available')\n",
    "\n",
    "# CPU/GPU performance comparison\n",
    "import time\n",
    "\n",
    "# CPU operation\n",
    "x = torch.rand(10000, 10000)\n",
    "start = time.time()\n",
    "torch.matmul(x, x)\n",
    "cpu_time = time.time() - start\n",
    "print(f\"CPU computation time = {cpu_time:3.2f} seconds\")\n",
    "\n",
    "# GPU operation\n",
    "if device != \"cpu\":\n",
    "    x = x.to(device)\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    start.record()\n",
    "    torch.matmul(x, x)\n",
    "    end.record()\n",
    "    torch.cuda.synchronize()  # Wait for all operations to complete\n",
    "    gpu_time = start.elapsed_time(end) / 1000  # Convert milliseconds to seconds\n",
    "    print(f\"GPU computation time = {gpu_time:3.2f} seconds\")\n",
    "    print(f\"GPU is {cpu_time / gpu_time:3.1f} times faster.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La conversión entre NumPy y tensores se implementa de manera muy eficiente. En particular, como vimos anteriormente, al usar `torch.from_numpy()`, la memoria se comparte sin necesidad de copiarla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy array: [[1 1]\n",
      " [2 3]]\n",
      "Tensor: tensor([[1, 1],\n",
      "        [2, 3]])\n",
      "NumPy array from Tensor: [[1 1]\n",
      " [2 3]]\n"
     ]
    }
   ],
   "source": [
    "np_a = np.array([[1, 1], [2, 3]])\n",
    "tensor_a = torch.from_numpy(np_a)\n",
    "np_b = tensor_a.numpy() # Shares memory.  If tensor_a is on CPU.\n",
    "\n",
    "print(f\"NumPy array: {np_a}\")\n",
    "print(f\"Tensor: {tensor_a}\")\n",
    "print(f\"NumPy array from Tensor: {np_b}\") #if tensor_a is on CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando se convierte un tensor a NumPy, el tensor debe estar en la CPU. Si el tensor está en la GPU, primero debe moverse a la CPU usando `.cpu()`. Las propiedades básicas de un tensor son `shape`, `dtype`, `device`, y a través de estas se puede verificar la forma del tensor y su ubicación de almacenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape = torch.Size([2, 3])\n",
      "Data type = torch.float32\n",
      "Device = cpu\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(2, 3)\n",
    "print(f\"Shape = {a.shape}\")\n",
    "print(f\"Data type = {a.dtype}\")\n",
    "print(f\"Device = {a.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El indexado y el slicing utilizan la misma sintaxis que NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor a:\n",
      "tensor([[0.2069, 0.8296, 0.4973],\n",
      "        [0.9265, 0.8386, 0.6611],\n",
      "        [0.5329, 0.7822, 0.0975]])\n",
      "First row: tensor([0.2069, 0.8296, 0.4973])\n",
      "First column: tensor([0.2069, 0.9265, 0.5329])\n",
      "Last column: tensor([0.4973, 0.6611, 0.0975])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(3, 3)\n",
    "print(f\"Tensor a:\\n{a}\")\n",
    "print(f\"First row: {a[0]}\")\n",
    "print(f\"First column: {a[:, 0]}\")\n",
    "print(f\"Last column: {a[..., -1]}\")  # Equivalent to a[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Operaciones\n",
    "\n",
    "PyTorch admite casi todas las operaciones de NumPy. La tradición de operaciones en matrices multidimensionales, que comenzó con el lenguaje APL en 1964, se ha transmitido a través de NumPy hasta PyTorch. Puede consultar la lista completa de operaciones soportadas en la documentación oficial de PyTorch ([documentación de PyTorch]([https://pytorch.org/docs/stable/tensors.html)).\n",
    "\n",
    "El cambio de forma de tensores es una de las operaciones más frecuentemente utilizadas en redes neuronales. Se puede cambiar la dimensión de un tensor mediante la función `view()`, manteniendo el número total de elementos. La función `permute()` reordena las dimensiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
      "x: tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "y: tensor([[ 0,  4,  8],\n",
      "        [ 1,  5,  9],\n",
      "        [ 2,  6, 10],\n",
      "        [ 3,  7, 11]])\n",
      "b shape: torch.Size([2, 3, 5])\n",
      "z shape: torch.Size([5, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(12)\n",
    "print(f\"a: {a}\")\n",
    "\n",
    "x = a.view(3, 4)  # Reshape to 3x4\n",
    "print(f\"x: {x}\")\n",
    "\n",
    "y = x.permute(1, 0)  # Swap dimensions 0 and 1\n",
    "print(f\"y: {y}\")\n",
    "\n",
    "b = torch.randn(2, 3, 5)\n",
    "print(f\"b shape: {b.shape}\")\n",
    "\n",
    "z = b.permute(2, 0, 1)  # Change dimension order to (2, 0, 1)\n",
    "print(f\"z shape: {z.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las operaciones de matriz son fundamentales en el aprendizaje profundo, y PyTorch proporciona varias funciones para operaciones con matrices.\n",
    "\n",
    "1.  `torch.matmul`: realiza operaciones de matriz generales. Dependiendo de las dimensiones, funciona de la siguiente manera.\n",
    "    *   1D × 1D: producto escalar (dot product)\n",
    "    *   2D × 2D: multiplicación de matrices\n",
    "    *   1D × 2D: agrega una dimensión a la primera matriz y luego realiza la multiplicación de matrices\n",
    "    *   N-D × M-D: realiza broadcasting y luego la multiplicación de matrices\n",
    "2.  `torch.mm`: operación de multiplicación de matrices pura (sin soporte para broadcasting)\n",
    "3.  `torch.bmm`: multiplicación de matrices con dimensión de lote ((b, i, k) × (b, k, j) → (b, i, j))\n",
    "4.  `torch.einsum`: operaciones de tensores usando la notación de suma de Einstein. Permite expresar operaciones de tensores complejas de manera concisa. (Consulte \"Teoría Profunda\" para más detalles)\n",
    "    -   `torch.einsum('ij,jk->ik', a, b)`: producto de las matrices a y b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "Y: tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "X @ Y = tensor([[20, 23, 26, 29],\n",
      "        [56, 68, 80, 92]])\n",
      "X @ Y (using einsum) = tensor([[20, 23, 26, 29],\n",
      "        [56, 68, 80, 92]])\n",
      "a: tensor([0, 1])\n",
      "b: tensor([0, 1])\n",
      "a @ b = 1\n",
      "a: tensor([0, 1])\n",
      "B: tensor([[0, 1],\n",
      "        [2, 3]])\n",
      "a @ B = tensor([2, 3])\n",
      "X @ b shape = torch.Size([3])\n",
      "X: tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5]],\n",
      "\n",
      "        [[ 6,  7,  8],\n",
      "         [ 9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14],\n",
      "         [15, 16, 17]]])\n",
      "Y: tensor([[[ 0,  1],\n",
      "         [ 2,  3],\n",
      "         [ 4,  5]],\n",
      "\n",
      "        [[ 6,  7],\n",
      "         [ 8,  9],\n",
      "         [10, 11]],\n",
      "\n",
      "        [[12, 13],\n",
      "         [14, 15],\n",
      "         [16, 17]]])\n",
      "X @ Y shape: torch.Size([3, 2, 2])\n",
      "X @ Y: tensor([[[ 10,  13],\n",
      "         [ 28,  40]],\n",
      "\n",
      "        [[172, 193],\n",
      "         [244, 274]],\n",
      "\n",
      "        [[550, 589],\n",
      "         [676, 724]]])\n",
      "X: tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5]],\n",
      "\n",
      "        [[ 6,  7,  8],\n",
      "         [ 9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14],\n",
      "         [15, 16, 17]]])\n",
      "Y: tensor([[0, 1],\n",
      "        [2, 3],\n",
      "        [4, 5]])\n",
      "X @ Y shape: torch.Size([3, 2, 2])\n",
      "X @ Y: tensor([[[ 10,  13],\n",
      "         [ 28,  40]],\n",
      "\n",
      "        [[ 46,  67],\n",
      "         [ 64,  94]],\n",
      "\n",
      "        [[ 82, 121],\n",
      "         [100, 148]]])\n",
      "X @ Y (using einsum) = tensor([[20, 23, 26, 29],\n",
      "        [56, 68, 80, 92]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(6)\n",
    "b = torch.arange(12)\n",
    "\n",
    "X = a.view(2, 3)\n",
    "Y = b.view(3, 4)\n",
    "print(f\"X: {X}\")\n",
    "print(f\"Y: {Y}\")\n",
    "\n",
    "# matmul (2,3) X (3,4) -> (2, 4)\n",
    "print(f\"X @ Y = {torch.matmul(X, Y)}\")\n",
    "\n",
    "# Using torch.einsum for matrix multiplication\n",
    "einsum_result = torch.einsum('ij,jk->ik', X, Y)\n",
    "print(f\"X @ Y (using einsum) = {einsum_result}\")\n",
    "\n",
    "\n",
    "a = torch.arange(2)\n",
    "b = torch.arange(2)\n",
    "print(f\"a: {a}\")\n",
    "print(f\"b: {b}\")\n",
    "\n",
    "# Vector x Vector operation\n",
    "print(f\"a @ b = {torch.matmul(a, b)}\")\n",
    "\n",
    "# 1D tensor (vector), 2D tensor (matrix) operation\n",
    "# (2) x (2,2) is treated as (1,2) x (2,2) for matrix multiplication.\n",
    "# Result: (1,2) x (2,2) -> (1,2)\n",
    "b = torch.arange(4)\n",
    "B = b.view(2, 2)\n",
    "print(f\"a: {a}\")\n",
    "print(f\"B: {B}\")\n",
    "print(f\"a @ B = {torch.matmul(a, B)}\")\n",
    "\n",
    "# Matrix x Vector operation\n",
    "X = torch.randn(3, 4)\n",
    "b = torch.randn(4)\n",
    "print(f\"X @ b shape = {torch.matmul(X, b).size()}\")\n",
    "\n",
    "# Batched matrix x Batched matrix\n",
    "# The leading batch dimension is maintained.\n",
    "# The 2nd and 3rd dimensions are treated as matrices for multiplication.\n",
    "X = torch.arange(18).view(3, 2, 3)\n",
    "Y = torch.arange(18).view(3, 3, 2)\n",
    "print(f\"X: {X}\")\n",
    "print(f\"Y: {Y}\")\n",
    "# Batch dimension remains the same, and (2,3)x(3,2) -> (2,2)\n",
    "print(f\"X @ Y shape: {torch.matmul(X, Y).size()}\")\n",
    "print(f\"X @ Y: {torch.matmul(X, Y)}\")\n",
    "\n",
    "# Batched matrix x Broadcasted matrix\n",
    "X = torch.arange(18).view(3, 2, 3)\n",
    "Y = torch.arange(6).view(3, 2)\n",
    "print(f\"X: {X}\")\n",
    "print(f\"Y: {Y}\")\n",
    "# The second matrix lacks a batch dimension.\n",
    "# It's broadcasted to match the batch dimension of the first matrix (repeated 3 times).\n",
    "print(f\"X @ Y shape: {torch.matmul(X, Y).size()}\")\n",
    "print(f\"X @ Y: {torch.matmul(X, Y)}\")\n",
    "\n",
    "\n",
    "# Using torch.einsum for matrix multiplication\n",
    "X = torch.arange(6).view(2, 3)\n",
    "Y = torch.arange(12).view(3, 4)\n",
    "einsum_result = torch.einsum('ij,jk->ik', X, Y)  # Equivalent to torch.matmul(X, Y)\n",
    "print(f\"X @ Y (using einsum) = {einsum_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.einsum` utiliza la notación de Einstein para expresar operaciones de tensores. `'ij,jk->ik'` significa que se deben multiplicar las dimensiones `(i, j)` del tensor `X` con las dimensiones `(j, k)` del tensor `Y` para generar un resultado de dimensión `(i, k)`. Esto produce el mismo resultado que la multiplicación de matrices `torch.matmul(X, Y)`. `einsum` también admite varias otras operaciones, incluyendo transposición, suma, producto interno, producto externo y multiplicación de matrices por lotes. Para más detalles, consulte la documentación de PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other einsum examples\n",
    "\n",
    "# Transpose\n",
    "a = torch.randn(2, 3)\n",
    "b = torch.einsum('ij->ji', a)  # Swap dimensions\n",
    "\n",
    "# Sum of all elements\n",
    "a = torch.randn(2, 3)\n",
    "b = torch.einsum('ij->', a)  # Sum all elements\n",
    "\n",
    "# Batch matrix multiplication\n",
    "a = torch.randn(3, 2, 5)\n",
    "b = torch.randn(3, 5, 3)\n",
    "c = torch.einsum('bij,bjk->bik', a, b) # Batch matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-note collapse=\"true\" title=\"Haga clic para ver el contenido (análisis detallado: notación de Einstein y torch.einsum)\"}\n",
    "## Notación de Einstein y torch.einsum\n",
    "\n",
    "### Notación de Einstein (Einstein Notation)\n",
    "\n",
    "La notación de Einstein (o Convención de Suma de Einstein) es un método de notación introducido por Albert Einstein en 1916 para describir la teoría general de la relatividad. Originalmente se diseñó para simplificar las expresiones matemáticas en física, especialmente en la teoría de la relatividad, pero gracias a su comodidad y expresividad, es ampliamente utilizada en diversos campos que manejan operaciones con tensores.\n",
    "\n",
    "**Idea central:**\n",
    "\n",
    "  * **Los índices repetidos implican suma:** cuando un índice aparece dos veces en un término, se implica que se suman todos los valores posibles de ese índice. Se omite el símbolo de suma explícito ($\\sum$) para simplificar la notación.\n",
    "  * **Índices libres y ficticios:**\n",
    "      * **Índice libre (free index):** índice que aparece en el tensor resultante. Aparece una vez por término.\n",
    "      * **Índice ficticio (dummy index):** índice sobre el cual se realiza la suma. Aparece dos veces en un término. (índice de suma, índice ligado)\n",
    "\n",
    "**Reglas básicas**\n",
    "\n",
    "1.  **Si un mismo índice aparece dos veces en un término, se suman los valores correspondientes a ese índice.**\n",
    "2.  **Los índices libres determinan las dimensiones del tensor resultante.**\n",
    "3.  **Los índices ficticios solo se utilizan para cálculos internos y no aparecen en el resultado.**\n",
    "4.  **Las letras de los índices pueden elegirse arbitrariamente, pero es recomendable mantener la consistencia para evitar confusiones.** (por convención se usan $i, j, k, l, m, n$)\n",
    "5.  **La flecha ($\\rightarrow$) a la izquierda** representa los tensores de entrada, y **a la derecha** el tensor de salida.\n",
    "\n",
    "**Ejemplos**\n",
    "\n",
    "  * **Producto escalar (dot product):** $a_i b_i$ (equivalente a $\\sum_i a_i b_i$)\n",
    "  * **Multiplicación de matrices (matrix multiplication):** $A_{ij} B_{jk} = C_{ik}$ (equivalente a $\\sum_j A_{ij}B_{jk}$)\n",
    "  * **Transposición (transpose):** $A_{ij} = B_{ji}$ (B es la transpuesta de A)\n",
    "  * **Traza (trace):** $A_{ii}$ (equivalente a $\\sum_i A_{ii}$)\n",
    "  * **Producto exterior (outer product):** $a_i b_j = C_{ij}$\n",
    "  * **Multiplicación elemento por elemento (element-wise multiplication):** $A_{ij}B_{ij} = C_{ij}$ (producto de Hadamard)\n",
    "\n",
    "**Ejemplos de uso en deep learning**\n",
    "* **Multiplicación de matrices por lotes (batched matrix multiplication):** $A\\_{bij} B\\_{bjk} = C\\_{bik}$ ($b$: dimensión del lote)\n",
    "  * **Mecanismo de atención (attention mechanism):** $e\\_{ij} = Q\\_{ik} K\\_{jk}$, $a\\_{ij} = \\text{softmax}(e\\_{ij})$, $v\\_{i} = a\\_{ij} V\\_{j}$ ($Q$: consulta, $K$: clave, $V$: valor)\n",
    "  * **Transformación bilineal (bilinear transformation):** $x\\_i W\\_{ijk} y\\_j = z\\_k$\n",
    "  * **Convolución multidimensional (convolution):** $I\\_{b,c,i,j} \\* F\\_{o,c,k,l} = O\\_{b,o,i',j'}$ ($b$: lote, $c$: canales de entrada, $o$: canales de salida, $i, j$: dimensiones espaciales de entrada, $k, l$: dimensiones espaciales del filtro)\n",
    "  * **Normalización por lotes (Batch Normalization):** $\\gamma\\_c \\* \\frac{x\\_{b,c,h,w} - \\mu\\_c}{\\sigma\\_c} + \\beta\\_c$ ($c$: dimensión de canal, $b$: lote, $h$: altura, $w$: anchura)\n",
    "  * **Actualización del estado oculto de RNN**: $h\\_t = \\tanh(W\\_{ih}x\\_t + b\\_{ih} + W\\_{hh}h\\_{t-1} + b\\_{hh})$ ($h$: oculto, $x$: entrada, $W$: peso, $b$: sesgo)\n",
    "  * **Actualización del estado de celda de LSTM**: $c\\_t = f\\_t \\* c\\_{t-1} + i\\_t \\* \\tilde{c}\\_t$ ($c$: estado de celda, $f$: puerta de olvido, $i$: puerta de entrada, $\\tilde{c}\\_t$: estado de celda candidato)\n",
    "\n",
    "### torch.einsum\n",
    "\n",
    "`torch.einsum` es una función en PyTorch que realiza operaciones de tensores utilizando la notación de Einstein. `einsum` es el acrónimo de \"Einstein summation\".\n",
    "\n",
    "**Uso:**\n",
    "\n",
    "```python\n",
    "torch.einsum(equation, *operands)\n",
    "```\n",
    "\n",
    "  * `equation`: cadena de caracteres en notación de Einstein. Tiene forma `'ij,jk->ik'`.\n",
    "  * `*operands`: tensores que participan en la operación (argumentos variables).\n",
    "\n",
    "**Ventajas**\n",
    "\n",
    "  * **Concisión:** permite expresar operaciones complejas de tensores en una sola línea de código.\n",
    "  * **Legibilidad:** la notación de Einstein clarifica el significado de las operaciones de tensores.\n",
    "  * **Flexibilidad:** facilita combinar diversas operaciones de tensores para definir nuevas operaciones.\n",
    "  * **Optimización:** PyTorch optimiza automáticamente las operaciones `einsum` para realizar cálculos eficientes. Puede ser más rápido que operaciones implementadas manualmente, utilizando rutinas optimizadas de bibliotecas como BLAS, cuBLAS y ajustando el orden de las operaciones.\n",
    "  * **Compatibilidad con diferenciación automática**: las operaciones definidas con `einsum` son completamente compatibles con el sistema de diferenciación automática de PyTorch.\n",
    "\n",
    "**Ejemplos de torch.einsum:**\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "# Multiplicación de matrices\n",
    "A = torch.randn(3, 4)\n",
    "B = torch.randn(4, 5)\n",
    "C = torch.einsum('ij,jk->ik', A, B)  # C = A @ B\n",
    "\n",
    "# Transposición\n",
    "A = torch.randn(3, 4)\n",
    "B = torch.einsum('ij->ji', A)  # B = A.T\n",
    "\n",
    "# Suma de la diagonal\n",
    "A = torch.randn(3, 3)\n",
    "trace = torch.einsum('ii->', A)  # trace = torch.trace(A)\n",
    "```\n",
    "# multiplicación de matrices por lotes\n",
    "A = torch.randn(2, 3, 4)\n",
    "B = torch.randn(2, 4, 5)\n",
    "C = torch.einsum('bij,bjk->bik', A, B) # C = torch.bmm(A, B)\n",
    "\n",
    "# producto exterior\n",
    "a = torch.randn(3)\n",
    "b = torch.randn(4)\n",
    "C = torch.einsum('i,j->ij', a, b) # C = torch.outer(a, b)\n",
    "\n",
    "# multiplicación elemento por elemento\n",
    "A = torch.randn(2,3)\n",
    "B = torch.randn(2,3)\n",
    "C = torch.einsum('ij,ij->ij', A, B) # C = A * B\n",
    "\n",
    "# transformación bilineal\n",
    "x = torch.randn(3)\n",
    "W = torch.randn(5, 3, 4)\n",
    "y = torch.randn(4)\n",
    "z = torch.einsum('i,ijk,j->k', x, W, y) # z_k = sum_i sum_j x_i * W_{ijk} * y_j\n",
    "\n",
    "# reducción de tensores multidimensionales\n",
    "tensor = torch.randn(3, 4, 5, 6)\n",
    "result = torch.einsum('...ij->...i', tensor)  # suma sobre las últimas dos dimensiones\n",
    "```\n",
    "\n",
    "**`torch.einsum` vs. otros operadores:**\n",
    "\n",
    "| Operación               | `torch.einsum`           | Otros métodos                                   |\n",
    "| :---------------------- | :----------------------- | :------------------------------------------ |\n",
    "| multiplicación de matrices | `'ij,jk->ik'`           | `torch.matmul(A, B)` o `A @ B`          |\n",
    "| transposición            | `'ij->ji'`               | `torch.transpose(A, 0, 1)` o `A.T`        |\n",
    "| traza                    | `'ii->'`                 | `torch.trace(A)`                            |\n",
    "| multiplicación de matrices por lotes | `'bij,bjk->bik'`        | `torch.bmm(A, B)`                           |\n",
    "| producto interno         | `'i,i->'`                | `torch.dot(a, b)`                            |\n",
    "| producto exterior        | `'i,j->ij'`              | `torch.outer(a, b)`                          |\n",
    "| multiplicación elemento por elemento | `'ij,ij->ij'`          | `A * B`                                      |\n",
    "| reducción de tensores (sum, mean, etc.) | `'ijk->i'` (ejemplo)      | `torch.sum(A, dim=(1, 2))`                   |\n",
    "\n",
    "**Limitaciones de `torch.einsum`**\n",
    "\n",
    "  * **Curva de aprendizaje inicial:** Para usuarios no familiarizados con la notación de Einstein, puede ser un poco difícil al principio.\n",
    "  * **Legibilidad en operaciones complejas:** En casos muy complejos, la cadena `einsum` puede volverse larga y menos legible. En estos casos, es recomendable dividir la operación en varios pasos o utilizar comentarios.\n",
    "  * **Imposibilidad de expresar todas las operaciones:** Dado que `einsum` se basa en operaciones de álgebra lineal, no se pueden expresar directamente operaciones no lineales (por ejemplo: `max`, `min`, `sort`) ni operaciones condicionales. En estos casos, es necesario usar otras funciones de PyTorch.\n",
    "\n",
    "**Optimización de `einsum` (`torch.compile`)**\n",
    "`torch.compile` (PyTorch 2.0 o superior) puede optimizar aún más las operaciones `einsum`. `compile` realiza diversas optimizaciones a través de la compilación JIT (Just-In-Time), analizando el código, fusionando operaciones de tensores y optimizando patrones de acceso a memoria.\n",
    "\n",
    "```python\n",
    "import torch\n",
    "# Disponible en PyTorch 2.0 o superior\n",
    "\n",
    "@torch.compile\n",
    "def my_einsum_function(a, b):\n",
    "    return torch.einsum('ij,jk->ik', a, b)\n",
    "\n",
    "# Se compila al llamar por primera vez, y se ejecuta el código optimizado en llamadas posteriores\n",
    "result = my_einsum_function(torch.randn(10, 20), torch.randn(20, 30))\n",
    "\n",
    "```\n",
    "\n",
    "**Conclusión:**\n",
    "\n",
    "La notación de Einstein y `torch.einsum` son herramientas poderosas para expresar y calcular operaciones tensoriales complejas en el aprendizaje profundo de manera concisa y eficiente. Aunque puede parecer extraño al principio, una vez que te familiarices con ellas, puedes mejorar significativamente la legibilidad y eficiencia del código. En particular, cuando se trata de modelos de aprendizaje profundo complejos como los modelos Transformer, donde hay muchas operaciones tensoriales, su valor es evidente. Usarlas junto con `torch.compile` puede mejorar aún más el rendimiento.\n",
    "\n",
    "**Referencias:**\n",
    "\n",
    "1.  **Notación de Einstein:** [https://en.wikipedia.org/wiki/Einstein\\_notation](https://www.google.com/url?sa=E&source=gmail&q=https://en.wikipedia.org/wiki/Einstein_notation)\n",
    "2.  **Documentación de `torch.einsum`:** [https://pytorch.org/docs/stable/generated/torch.einsum.html](https://www.google.com/url?sa=E&source=gmail&q=https://pytorch.org/docs/stable/generated/torch.einsum.html)\n",
    "3.  **Introducción básica a NumPy's einsum:** [https://ajcr.net/Basic-guide-to-einsum/](https://www.google.com/url?sa=E&source=gmail&q=https://ajcr.net/Basic-guide-to-einsum/)\n",
    "4.  **Einsum is All You Need - Einstein Summation in Deep Learning:** [https://rockt.github.io/2018/04/30/einsum](https://www.google.com/url?sa=E&source=gmail&q=https://rockt.github.io/2018/04/30/einsum)\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 Grafo de cálculo para operaciones de gradiente\n",
    "\n",
    "La diferenciación automática (Automatic Differentiation) se ha estado investigando desde la década de 1970, pero ha recibido mucha atención desde el desarrollo del aprendizaje profundo después de 2015. PyTorch implementa la diferenciación automática a través de grafos de cálculo dinámicos (dynamic computation graph), lo cual es una implementación práctica de la regla de la cadena (chain rule) que se examinó en el Capítulo 2.\n",
    "\n",
    "La diferenciación automática de PyTorch puede rastrear y almacenar los gradientes en cada paso de cálculo. Para esto, es necesario declarar explícitamente el seguimiento de gradientes en los tensores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.requires_grad (default): False\n",
      "a.requires_grad (after setting to True): True\n",
      "x.requires_grad (declared at creation): True\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn((2,))\n",
    "print(f\"a.requires_grad (default): {a.requires_grad}\")  # False (default)\n",
    "\n",
    "a.requires_grad_(True)  # In-place modification\n",
    "print(f\"a.requires_grad (after setting to True): {a.requires_grad}\")  # True\n",
    "\n",
    "# Declare during creation\n",
    "x = torch.arange(2, dtype=torch.float32, requires_grad=True)\n",
    "print(f\"x.requires_grad (declared at creation): {x.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo, consideremos la siguiente función de pérdida simple. (Figura 3-1, ver versión anterior)\n",
    "\n",
    "$$y = \\frac {1}{N}\\displaystyle\\sum_{i}^{N} \\{(x_i - 1)^2 + 4) \\}$$\n",
    "\n",
    "Las operaciones sobre $x_i$ pueden expresarse secuencialmente como $a_i = x_i - 1$, $b_i = a_i^2$, $c_i = b_i + 4$, $y = \\frac{1}{N}\\sum_{i=1}^{N} c_i$. \n",
    "\n",
    "Vamos a realizar las operaciones en la dirección forward y backward para esta ecuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 4.5\n",
      "x.grad = tensor([-1.,  0.])\n"
     ]
    }
   ],
   "source": [
    "a = x - 1\n",
    "b = a**2\n",
    "c = b + 4\n",
    "y = c.mean()\n",
    "\n",
    "print(f\"y = {y}\")\n",
    "\n",
    "# Perform backward operation\n",
    "y.backward()\n",
    "\n",
    "# Print the gradient of x (x.grad)\n",
    "print(f\"x.grad = {x.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La traducción del texto es la siguiente:\n",
    "\n",
    "Calcular las gradientes de cada paso mediante fórmulas se muestra a continuación.\n",
    "\n",
    "$\\frac{\\partial a_i}{\\partial x_i} = 1, \\frac{\\partial b_i}{\\partial a_i} = 2 \\cdot a_i, \\frac{\\partial c_i}{\\partial b_i} = 1,  \\frac{\\partial y}{\\partial c_i} = \\frac{1}{N}$\n",
    "\n",
    "Por lo tanto, por la regla de la cadena:\n",
    "\n",
    "$\\frac{\\partial y}{\\partial x_i} = \\frac{\\partial y}{\\partial  c_i}\\frac{\\partial c_i}{\\partial b_i}\\frac{\\partial b_i}{\\partial a_i}\\frac{\\partial a_i}{\\partial x_i} =  \\frac{1}{N} \\cdot 1 \\cdot 2 \\cdot a_i \\cdot 1 = \\frac{2}{N}a_i = \\frac{2}{N}(x_i - 1)$\n",
    "\n",
    "Dado que $x_i$ está en el intervalo \\[0, 1] y N=2 (número de elementos de x), $\\frac{\\partial y}{\\partial x_i}  = [-0.5, 0.5]$. Esto coincide con los resultados de la diferenciación automática de PyTorch.\n",
    "\n",
    "PyTorch implementa modernamente el concepto de diferenciación automática que ha sido investigado desde la década de 1970. En particular, la creación dinámica de gráficos de cálculo y las funciones de seguimiento de gradientes son muy útiles. Sin embargo, a veces es necesario desactivar estas funciones de diferenciación automática."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z.requires_grad: True\n",
      "z.requires_grad (inside no_grad): False\n",
      "z_det.requires_grad: False\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 4)\n",
    "w = torch.randn(4, 2)\n",
    "b = torch.randn(2)\n",
    "\n",
    "# If gradient tracking is needed\n",
    "z = torch.matmul(x, w) + b\n",
    "z.requires_grad_(True)  # Can also be set using requires_grad_()\n",
    "print(f\"z.requires_grad: {z.requires_grad}\")\n",
    "\n",
    "# Disable gradient tracking method 1: Using 'with' statement\n",
    "with torch.no_grad():\n",
    "    z = torch.matmul(x, w) + b\n",
    "    print(f\"z.requires_grad (inside no_grad): {z.requires_grad}\")\n",
    "\n",
    "# Disable gradient tracking method 2: Using detach()\n",
    "z_det = z.detach()\n",
    "print(f\"z_det.requires_grad: {z_det.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La desactivación del rastreo de gradientes es particularmente útil en los siguientes casos:\n",
    "\n",
    "1.  **Durante la inferencia**: para ahorrar memoria y costos computacionales cuando solo se necesita el paso forward.\n",
    "2.  **Ajuste fino (Fine-tuning)**: cuando se actualizan solo ciertos parámetros y se mantienen fijos los demás.\n",
    "3.  **Optimización del rendimiento**: como el paso backward conlleva costos adicionales de memoria y computación, se desactiva cuando no es necesario.\n",
    "\n",
    "En particular, en el ajuste fino de grandes modelos de lenguaje, es común mantener la mayoría de los parámetros fijos y actualizar solo algunos, por lo que la activación selectiva del rastreo de gradientes es una característica muy importante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.4 Carga de datos\n",
    "\n",
    "La carga de datos es un elemento clave en el aprendizaje profundo. Hasta principios de la década de 2000, cada equipo de investigación utilizaba su propio método de procesamiento de datos, pero con la aparición de conjuntos de datos a gran escala como ImageNet en 2009, surgió la necesidad de un sistema estandarizado para cargar datos.\n",
    "\n",
    "PyTorch proporciona dos clases clave para separar el procesamiento de datos y la lógica de entrenamiento.\n",
    "\n",
    "1. `torch.utils.data.Dataset`: Proporciona una interfaz coherente para acceder a los datos y las etiquetas. Debe implementar los métodos `__len__` y `__getitem__`.\n",
    "2. `torch.utils.data.DataLoader`: Proporciona un mecanismo eficiente de carga de datos en lotes (batch). Envuelve un `Dataset` para automatizar la generación de mini-lotes, el mezclado, la carga paralela de datos, etc.\n",
    "\n",
    "A continuación se presenta un ejemplo de generación de datos aleatorios utilizando la distribución Dirichlet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data (a):\n",
      "[[0.46073711 0.01119455 0.28991657 0.11259078 0.12556099]\n",
      " [0.07331166 0.43554042 0.1243009  0.13339224 0.23345478]]\n",
      "Labels (b):\n",
      "[[1 0 0 0 0]\n",
      " [0 1 0 0 0]]\n",
      "Number of data samples = 100\n",
      "Data at index 0 = (tensor([1.4867e-01, 1.6088e-01, 1.2207e-02, 3.6049e-02, 1.1054e-04, 8.1160e-02,\n",
      "        2.9811e-02, 1.9398e-01, 4.9448e-02, 2.8769e-01]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1]))\n",
      "Data type = <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "\n",
    "# Initialize with Dirichlet distribution\n",
    "a = np.random.dirichlet(np.ones(5), size=2)\n",
    "b = np.zeros_like(a)\n",
    "# Generate label values\n",
    "b = (a == a.max(axis=1)[:, None]).astype(int)\n",
    "\n",
    "print(f\"Data (a):\\n{a}\")\n",
    "print(f\"Labels (b):\\n{b}\")\n",
    "\n",
    "\n",
    "# Create a custom Dataset class by inheriting from PyTorch's Dataset.\n",
    "class RandomData(data.Dataset):\n",
    "    def __init__(self, feature, length):\n",
    "        super().__init__()\n",
    "        self.feature = feature\n",
    "        self.length = length\n",
    "        self.generate_data()\n",
    "\n",
    "    def generate_data(self):\n",
    "        x = np.random.dirichlet(np.ones(self.feature), size=self.length)\n",
    "        y = (x == x.max(axis=1)[:, None]).astype(int)  # One-hot encoding\n",
    "\n",
    "        self.data = x  # numpy object\n",
    "        self.label = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Return data and label as torch tensors\n",
    "        return torch.tensor(self.data[index], dtype=torch.float32), torch.tensor(self.label[index], dtype=torch.int64)\n",
    "\n",
    "\n",
    "dataset = RandomData(feature=10, length=100)\n",
    "print(f\"Number of data samples = {len(dataset)}\")\n",
    "print(f\"Data at index 0 = {dataset[0]}\")\n",
    "print(f\"Data type = {type(dataset[0][0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataLoader` proporciona varias funciones para el procesamiento por lotes. Los parámetros principales son los siguientes.\n",
    "\n",
    "*   `batch_size`: número de muestras por lote\n",
    "*   `shuffle`: aleatorización del orden de los datos (generalmente se establece en `True` durante el entrenamiento)\n",
    "*   `num_workers`: número de procesos para la carga de datos en paralelo\n",
    "*   `drop_last`: indicar si se descarta o no el último lote incompleto (se descarta si es `True`)\n",
    "\n",
    "Se lee los datos del `Dataset` utilizando `__getitem__`, y se convierte el resultado en un objeto tensor. En particular, la configuración de `num_workers` es importante al procesar conjuntos de datos grandes de imágenes o videos. Sin embargo, para conjuntos de datos pequeños, puede ser más eficiente usar un solo proceso. Si se establece un valor demasiado alto para `num_workers`, puede generar overhead, por lo que es importante encontrar el valor adecuado. (Generalmente se prueban valores como el número de núcleos o el doble del número de núcleos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st batch training data = tensor([[3.3120e-02, 1.4274e-01, 9.7984e-02, 1.9628e-03, 6.8926e-02, 3.4525e-01,\n",
      "         4.6966e-02, 6.0947e-02, 4.2738e-02, 1.5937e-01],\n",
      "        [8.0707e-02, 4.9181e-02, 3.1863e-02, 1.4238e-02, 1.6089e-02, 1.7980e-01,\n",
      "         1.7544e-01, 1.3465e-01, 1.6361e-01, 1.5442e-01],\n",
      "        [4.2364e-02, 3.3635e-02, 2.0840e-01, 1.6919e-02, 4.5977e-02, 6.5791e-02,\n",
      "         1.8726e-01, 1.0325e-01, 2.2029e-01, 7.6117e-02],\n",
      "        [1.4867e-01, 1.6088e-01, 1.2207e-02, 3.6049e-02, 1.1054e-04, 8.1160e-02,\n",
      "         2.9811e-02, 1.9398e-01, 4.9448e-02, 2.8769e-01]]), \n",
      " Data shape = torch.Size([4, 10])\n",
      "1st batch label data = tensor([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]), \n",
      " Data shape = torch.Size([4, 10])\n",
      "1st batch label data type = <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "data_loader = data.DataLoader(dataset, batch_size=4, shuffle=True, num_workers=0)\n",
    "\n",
    "# Read one batch.\n",
    "train_x, train_y = next(iter(data_loader))\n",
    "\n",
    "print(f\"1st batch training data = {train_x}, \\n Data shape = {train_x.shape}\")\n",
    "print(f\"1st batch label data = {train_y}, \\n Data shape = {train_y.shape}\")\n",
    "print(f\"1st batch label data type = {type(train_y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch proporciona paquetes especializados para el procesamiento de datos específicos del dominio. Desde que el aprendizaje profundo se expandió a diversos campos después de 2016, surgió la necesidad de procesamiento de datos especializado en cada dominio.\n",
    "\n",
    "*   `torchvision`: visión por computadora\n",
    "*   `torchaudio`: procesamiento de audio\n",
    "*   `torchtext`: procesamiento del lenguaje natural\n",
    "\n",
    "Fashion-MNIST es un conjunto de datos publicado por Zalando Research en 2017, diseñado para reemplazar a MNIST. La composición del conjunto de datos es la siguiente.\n",
    "\n",
    "*   Datos de entrenamiento: 60,000\n",
    "*   Datos de prueba: 10,000\n",
    "*   Tamaño de las imágenes: 28x28 en escala de grises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data mean: tensor([0.2860]), std: tensor([0.3530])\n",
      "Label: 5\n",
      "Label map: Sandal\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "import seaborn_image as isns\n",
    "import matplotlib.pyplot as plt # Added for visualization\n",
    "\n",
    "\n",
    "# Function to calculate mean and std of the dataset\n",
    "def calculate_mean_std(dataset):\n",
    "    dataloader = DataLoader(dataset, batch_size=len(dataset), shuffle=False)\n",
    "    data, _ = next(iter(dataloader))\n",
    "    mean = data.mean(axis=(0, 2, 3))  # Calculate mean across channel dimension\n",
    "    std = data.std(axis=(0, 2, 3))    # Calculate std across channel dimension\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "# Datasets.  Note:  We *don't* apply Normalize here yet.\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    root=\"data\", train=True, download=True, transform=ToTensor()\n",
    ")\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root=\"data\", train=False, download=True, transform=ToTensor()\n",
    ")\n",
    "\n",
    "# Calculate mean and std for normalization\n",
    "train_mean, train_std = calculate_mean_std(train_dataset)\n",
    "print(f\"Train data mean: {train_mean}, std: {train_std}\")\n",
    "\n",
    "# Now define transforms *with* normalization\n",
    "transform = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize(train_mean, train_std)  # Use calculated mean and std\n",
    "])\n",
    "\n",
    "# Re-create datasets with the normalization transform\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    root=\"data\", train=True, download=True, transform=transform\n",
    ")\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root=\"data\", train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "\n",
    "# Check one training data sample.\n",
    "sample_idx = torch.randint(len(train_dataset), size=(1,)).item()\n",
    "img, label = train_dataset[sample_idx]  # Use a random index\n",
    "\n",
    "print(f\"Label: {label}\")\n",
    "\n",
    "# Manually create a label map\n",
    "labels_map = {\n",
    "    0: \"T-shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "\n",
    "print(f\"Label map: {labels_map[label]}\")\n",
    "\n",
    "# Plot using seaborn-image.\n",
    "isns.imgplot(img.squeeze())  # Squeeze to remove channel dimension for grayscale\n",
    "plt.title(f\"Label: {labels_map[label]}\") # Add title to plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Define data loaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False) # No need to shuffle test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.5 Transformación de datos (Transform)\n",
    "\n",
    "La transformación de datos es un proceso de preprocesamiento muy importante en el aprendizaje profundo. Desde el éxito de AlexNet en 2012, la ampliación de datos (Data Augmentation) se ha convertido en un factor clave para mejorar el rendimiento del modelo. PyTorch proporciona una variedad de herramientas para estos tipos de transformaciones. `transforms.Compose` permite aplicar varias transformaciones secuencialmente. Además, con la función `Lambda`, es fácil implementar transformaciones personalizadas.\n",
    "\n",
    "La transformación de datos es muy importante para mejorar el rendimiento de generalización del modelo. En particular, en el campo de la visión por computadora, la ampliación de datos a través de diversas transformaciones se ha convertido en una práctica estándar. El caso de la transformación `Normalize` es un paso esencial para estabilizar el entrenamiento del modelo, ya que estandariza los datos.\n",
    "\n",
    "Para aplicar la transformación `Normalize`, es necesario conocer la media (mean) y la desviación estándar (standard deviation) del conjunto de datos. El código para calcular esto es el siguiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data mean: tensor([0.2860]), std: tensor([0.3530])\n",
      "Transformed image shape: torch.Size([1, 18, 18])\n",
      "Transformed image min/max: -0.8102576732635498, 2.022408962249756\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "import PIL\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "\n",
    "# Calculate mean and std of the dataset\n",
    "def calculate_mean_std(dataset):\n",
    "    dataloader = DataLoader(dataset, batch_size=len(dataset), shuffle=False) # Load all data at once\n",
    "    data, _ = next(iter(dataloader))\n",
    "    # For grayscale images, calculate mean and std over height, width dimensions (0, 2, 3)\n",
    "    # For RGB images, the calculation would be over (0, 1, 2)\n",
    "    mean = data.mean(dim=(0, 2, 3))  # Calculate mean across batch and spatial dimensions\n",
    "    std = data.std(dim=(0, 2, 3))    # Calculate std across batch and spatial dimensions\n",
    "    return mean, std\n",
    "\n",
    "# --- Example usage with FashionMNIST ---\n",
    "# 1.  Create dataset *without* normalization first:\n",
    "train_dataset_for_calc = datasets.FashionMNIST(\n",
    "    root=\"data\", train=True, download=True, transform=transforms.ToTensor()  # Only ToTensor\n",
    ")\n",
    "\n",
    "# 2. Calculate mean and std:\n",
    "train_mean, train_std = calculate_mean_std(train_dataset_for_calc)\n",
    "print(f\"Train data mean: {train_mean}, std: {train_std}\")\n",
    "\n",
    "\n",
    "# 3.  *Now* create the dataset with normalization:\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(train_mean, train_std)  # Use calculated mean and std\n",
    "])\n",
    "\n",
    "# Example of defining a custom transform using Lambda\n",
    "def crop_image(image: PIL.Image.Image) -> PIL.Image.Image:\n",
    "    # Original image is assumed to be 28x28.\n",
    "    left, top, width, height = 5, 5, 18, 18 # Example crop parameters\n",
    "    return transforms.functional.crop(image, top=top, left=left, width=width, height=height)\n",
    "\n",
    "# Compose transforms, including the custom one and normalization.\n",
    "transform_with_crop = transforms.Compose([\n",
    "    transforms.Lambda(crop_image), # Custom cropping\n",
    "    transforms.ColorJitter(),\n",
    "    transforms.RandomInvert(),\n",
    "    transforms.ToTensor(), # Must be *before* Normalize\n",
    "    transforms.Normalize(train_mean, train_std) # Use calculated mean and std\n",
    "])\n",
    "\n",
    "train_dataset_transformed = datasets.FashionMNIST(root=\"data\", train=True, download=True, transform=transform_with_crop)\n",
    "# Get one sample to check the transformation.\n",
    "sample_img, sample_label = train_dataset_transformed[0]\n",
    "print(f\"Transformed image shape: {sample_img.shape}\")\n",
    "print(f\"Transformed image min/max: {sample_img.min()}, {sample_img.max()}\") # Check normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el código se genera primero un conjunto de datos al que solo se le aplica la transformación `ToTensor()` para calcular la media y la desviación estándar. Luego, utilizando los valores calculados, se define la transformación final que incluye la normalización `Normalize`. También se incluye un ejemplo de cómo añadir una función personalizada `crop_image` a la cadena de transformaciones usando una función `Lambda`. `ToTensor()` debe aplicarse *antes* de `Normalize`. `ToTensor()` convierte imágenes en el rango \\[0, 255] a tensores en el rango \\[0, 1], y `Normalize` normaliza estos datos en el rango \\[0, 1] para que tengan una media de 0 y una desviación estándar de 1. Es común aplicar el aumento de datos solo a los datos de entrenamiento y no a los datos de validación/prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.6 Modelo\n",
    "\n",
    "La implementación de modelos de redes neuronales ha evolucionado de diversas maneras desde la década de 1980. PyTorch adoptó un enfoque de implementación orientada a objetos desde su lanzamiento en 2016, lo cual se logra a través de `nn.Module`. Este enfoque mejoró significativamente la reutilización y escalabilidad de los modelos.\n",
    "\n",
    "Las clases de modelo se implementan heredando de `nn.Module` y generalmente incluyen los siguientes métodos:\n",
    "\n",
    "*   `__init__()`: define e inicializa los componentes del red neuronal (capas, funciones de activación, etc.).\n",
    "*   `forward()`: recibe datos de entrada, realiza la operación de propagación hacia adelante del modelo y devuelve la salida (logits o predicciones).\n",
    "*   (opcional) `training_step()`, `validation_step()`, `test_step()`: cuando se utilizan con bibliotecas como PyTorch Lightning, definen el comportamiento en cada paso de entrenamiento/validación/prueba.\n",
    "*   (opcional) otros métodos definidos por el usuario: se pueden agregar métodos adicionales para realizar funciones específicas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (network_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class SimpleNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()  # Or super(SimpleNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.network_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)  # Flatten the image data into a 1D array\n",
    "        logits = self.network_stack(x)\n",
    "        return logits\n",
    "\n",
    "# Move model to the appropriate device (CPU or GPU)\n",
    "model = SimpleNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función logit tiene varios significados.\n",
    "\n",
    "*   Significado matemático: es una función que convierte probabilidades en el rango \\[0, 1] a números reales en el rango \\[−∞, ∞].\n",
    "*   Significado en aprendizaje profundo: es la salida cruda (sin normalizar) de una red neuronal.\n",
    "\n",
    "En problemas de clasificación multiclase, comúnmente se aplica la función `softmax` al final para convertir los valores a probabilidades que se puedan comparar con las etiquetas. En este caso, el logit es la entrada de la función `softmax`.\n",
    "\n",
    "Se crea un modelo a partir de una clase y se transfiere a un `device`. Si existe una GPU, el modelo se carga en la memoria de la GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits: tensor([[ 0.0464, -0.0368,  0.0447, -0.0640, -0.0253,  0.0242,  0.0378, -0.1139,\n",
      "          0.0005,  0.0299]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Prediction probabilities: tensor([[0.1052, 0.0968, 0.1050, 0.0942, 0.0979, 0.1029, 0.1043, 0.0896, 0.1005,\n",
      "         0.1035]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "Predicted class: tensor([0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(x)  # Don't call forward() directly!  Call the *model* object.\n",
    "prediction = nn.Softmax(dim=1)(logits)  # Convert logits to probabilities\n",
    "y_label = prediction.argmax(1) # Get the predicted class\n",
    "\n",
    "print(f\"Logits: {logits}\")\n",
    "print(f\"Prediction probabilities: {prediction}\")\n",
    "print(f\"Predicted class: {y_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante tener en cuenta que no se debe llamar directamente al método `forward()` del modelo. En su lugar, cuando se llama al objeto de modelo como una función (`model(x)`), `forward()` se ejecuta automáticamente y se integra con el sistema de diferenciación automática de PyTorch. El método `__call__` del objeto de modelo invoca a `forward()` y realiza tareas adicionales necesarias (como hooks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.7 Entrenamiento\n",
    "\n",
    "> **Desafío**: ¿Cómo se pueden entrenar eficientemente modelos complejos con conjuntos de datos a gran escala?\n",
    ">\n",
    "> **Angustia del investigador**: El rendimiento de los modelos de aprendizaje profundo se ve fuertemente influenciado por la cantidad y calidad de los datos, así como por la complejidad del modelo. Sin embargo, entrenar modelos con conjuntos de datos a gran escala requería mucho tiempo y recursos de computación. Estabilizar el proceso de entrenamiento, prevenir el sobreajuste y encontrar los hiperparámetros óptimos eran problemas difíciles. Para abordar estos desafíos, se necesitaban algoritmos de aprendizaje eficientes, técnicas de optimización y bucles de entrenamiento automatizados.\n",
    "\n",
    "Una vez que se han preparado los datos y el modelo para el entrenamiento, se realiza el entrenamiento práctico. Para convertir una red neuronal en un buen aproximador (approximator), es necesario actualizar iterativamente sus parámetros. Se define una función de error (loss function) que calcula la diferencia entre las etiquetas y las predicciones, y se selecciona un optimizador para actualizar continuamente los parámetros y reducir el error.\n",
    "\n",
    "El proceso de entrenamiento sigue estos pasos:\n",
    "\n",
    "1. Inicialización del conjunto de datos y del cargador de datos (data loader)\n",
    "2. Carga de datos por lotes\n",
    "3. Cálculo de las predicciones a través de la propagación hacia adelante\n",
    "4. Cálculo del error a través de la función de pérdida\n",
    "5. Cálculo de los gradientes a través de la retropropagación\n",
    "6. Actualización de los parámetros a través del optimizador\n",
    "\n",
    "Se llama época (epoch) a una iteración completa sobre todo el conjunto de datos, y este proceso se repite durante varias épocas en lo que se conoce como bucle de entrenamiento.\n",
    "\n",
    "##### Hiperparámetros\n",
    "El entrenamiento requiere tres hiperparámetros clave:\n",
    "\n",
    "- Número de épocas (epoch): Determina cuántas veces se repetirá la época. Generalmente es mejor detenerse justo antes del sobreajuste.\n",
    "- Tamaño del lote: El número de datos de entrenamiento que pasarán a través del modelo en una sola vez. Pasar todo el conjunto de datos puede ser irrealista debido a las limitaciones de memoria de GPU y el aumento exponencial del tiempo de cálculo matricial. Se actualizan gradualmente los parámetros del modelo con subconjuntos de datos para aproximar el valor óptimo. Si el tamaño del lote es demasiado pequeño, las variaciones pueden ser demasiado volátiles y dificultar la aproximación al mínimo.\n",
    "- Tasa de aprendizaje: Ajusta la escala de los valores a actualizar. Puede compararse con el tamaño de paso en un proceso de búsqueda gradual. Generalmente tiene un valor pequeño. En el siguiente capítulo, se explorará la relación entre la tasa de aprendizaje y el optimizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3가지 초매개변수\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "learning_rate = 1e-3 # 최적화기를 위해 앞서 지정했음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bucle de Entrenamiento\n",
    "\n",
    "El bucle de entrenamiento se lleva a cabo en dos etapas por cada época.\n",
    "1. Etapa de entrenamiento: optimización de parámetros\n",
    "2. Etapa de validación: evaluación del rendimiento\n",
    "\n",
    "Desde la introducción de la normalización por lotes en 2015, ha sido importante distinguir entre los modos train() y eval(). En el modo eval(), las operaciones de entrenamiento específicas como la normalización por lotes o el dropout se desactivan para mejorar la velocidad de inferencia.\n",
    "\n",
    "##### Función de Pérdida\n",
    "\n",
    "La función de pérdida es un elemento crucial en el aprendizaje de redes neuronales. Desde el modelo de neurona de McCulloch-Pitts en 1943, se han propuesto diversas funciones de pérdida. En particular, la introducción del cross-entropy (entropía cruzada) a partir de la teoría de la información en 1989 marcó un punto de inflexión importante en el desarrollo del aprendizaje profundo.\n",
    "\n",
    "##### Binary Cross-Entropy (BCE)\n",
    "\n",
    "El BCE, que se utiliza principalmente en clasificación binaria, está definido como sigue:\n",
    "\n",
    "$$\\mathcal{L} = - \\sum_{i} [y_i \\log{x_i} + (1-y_i)\\log{(1-x_i)}] $$\n",
    "\n",
    "Aquí, $y$ es la etiqueta real y $x$ es el valor predicho por el modelo, ambos con un rango de [0, 1].\n",
    "\n",
    "PyTorch proporciona varias funciones de pérdida.\n",
    "\n",
    "*   `nn.MSELoss`: para problemas de regresión (Error Cuadrático Medio)\n",
    "*   `nn.NLLLoss`: logaritmo negativo de la verosimilitud\n",
    "*   `nn.CrossEntropyLoss`: combinación de `LogSoftmax` y `NLLLoss`\n",
    "*   `nn.BCEWithLogitsLoss`: integración de una capa sigmoide y BCE para mayor estabilidad numérica\n",
    "\n",
    "En particular, `nn.BCEWithLogitsLoss` es notable por integrar una capa sigmoide y BCE para mayor estabilidad numérica. El uso de la función log tiene las siguientes ventajas (descritas con más detalle en el Capítulo 2):\n",
    "\n",
    "1.  Mitiga cambios bruscos en los valores numéricos\n",
    "2.  Convierte multiplicaciones en sumas, mejorando la eficiencia computacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optimizador\n",
    "\n",
    "Los algoritmos de optimización comenzaron con el método de descenso del gradiente (Gradient Descent) básico de la década de 1950 y lograron un gran avance con la aparición de Adam en 2014. `torch.optim` proporciona varios optimizadores, y actualmente Adam y AdamW son los más utilizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the optimizer.\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Learning rate scheduler (optional, but often beneficial)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el código anterior, se agregó un programador de tasa de aprendizaje utilizando `torch.optim.lr_scheduler.StepLR`. Reduce la tasa de aprendizaje multiplicándola por `gamma` cada `step_size` épocas. La programación de la tasa de aprendizaje puede tener un gran impacto en la velocidad y estabilidad del entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bucle de Entrenamiento (Training Loop)\n",
    "\n",
    "Vamos a configurar un bucle de entrenamiento que se ejecuta iterativamente sobre el conjunto de datos. Un epoch generalmente consta de dos partes: entrenamiento y validación.\n",
    "\n",
    "1.  **Bucle de Entrenamiento**: Optimizamos los parámetros utilizando el conjunto de datos de entrenamiento.\n",
    "2.  **Bucle de Validación**: Verificamos cómo cambia el rendimiento del modelo utilizando el conjunto de datos de prueba (validación).\n",
    "\n",
    "Durante el entrenamiento, se puede configurar el modo del modelo en `train` y `eval`. Esto se puede considerar como un tipo de interruptor. La distinción entre los modos `train()` y `eval()` se volvió importante con la introducción de la normalización por lotes en 2015. En el modo `eval()`, se desactivan operaciones de entrenamiento específicas como la normalización por lotes o el dropout para mejorar la velocidad de inferencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# TensorBoard writer setup\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')\n",
    "\n",
    "\n",
    "def train_loop(model, data_loader, loss_fn, optimizer, epoch):  # Added epoch for logging\n",
    "\n",
    "    model.train()  # Set the model to training mode\n",
    "\n",
    "    size = len(data_loader.dataset)  # Total number of data samples\n",
    "    num_batches = len(data_loader)\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_count, (input_data, label_data) in enumerate(data_loader):\n",
    "        # Move data to the GPU (if available).\n",
    "        input_data = input_data.to(device)\n",
    "        label_data = label_data.to(device)\n",
    "\n",
    "        # Compute predictions\n",
    "        preds = model(input_data)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(preds, label_data)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()  # Perform backpropagation\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()  # Zero the gradients before next iteration\n",
    "\n",
    "        if batch_count % 100 == 0:\n",
    "            loss, current = loss.item(), batch_count * batch_size + len(input_data)\n",
    "            # print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    avg_train_loss = total_loss / num_batches\n",
    "    return avg_train_loss\n",
    "\n",
    "\n",
    "def eval_loop(model, data_loader, loss_fn):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    correct, test_loss = 0.0, 0.0\n",
    "\n",
    "    size = len(data_loader.dataset)  # Total data size\n",
    "    num_batches = len(data_loader)  # Number of batches\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation within this block\n",
    "        for input_data, label_data in data_loader:  # No need for enumerate as count is not used\n",
    "            # Move data to GPU (if available).\n",
    "            input_data = input_data.to(device)\n",
    "            label_data = label_data.to(device)\n",
    "\n",
    "            # Compute predictions\n",
    "            preds = model(input_data)\n",
    "\n",
    "            test_loss += loss_fn(preds, label_data).item()\n",
    "            correct += (preds.argmax(1) == label_data).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "\n",
    "    # print(f\"\\n Test Result \\n Accuracy: {(100 * correct):>0.1f}%, Average loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss, correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Proceso de entrenamiento completo\n",
    "\n",
    "El proceso de entrenamiento completo repite el entrenamiento y la validación en cada época. Se usa `tqdm` para mostrar visualmente el progreso, y TensorBoard para registrar los cambios en la tasa de aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84baac2d3bc14a3b960d258d62b7996a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Epoch: 0, Train Loss: 1.5232, Test Loss: 0.9543, Test Accuracy: 0.71%, LR: 0.001000\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Epoch: 1, Train Loss: 0.7920, Test Loss: 0.7059, Test Accuracy: 0.76%, LR: 0.001000\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Epoch: 2, Train Loss: 0.6442, Test Loss: 0.6208, Test Accuracy: 0.78%, LR: 0.001000\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Epoch: 3, Train Loss: 0.5790, Test Loss: 0.5757, Test Accuracy: 0.79%, LR: 0.001000\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Epoch: 4, Train Loss: 0.5383, Test Loss: 0.5440, Test Accuracy: 0.80%, LR: 0.001000\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Progress bar utility\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "epochs = 5  # Reduced for demonstration\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    train_loss = train_loop(model, train_dataloader, loss_fn, optimizer, epoch)\n",
    "    test_loss, correct = eval_loop(model, test_dataloader, loss_fn)\n",
    "\n",
    "    # Log training and validation metrics to TensorBoard\n",
    "    writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "    writer.add_scalar('Loss/test', test_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/test', correct, epoch)\n",
    "    writer.add_scalar('Learning Rate', optimizer.param_groups[0]['lr'], epoch) # Log learning rate\n",
    "\n",
    "    print(f'Epoch: {epoch}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {correct:.2f}%, LR: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "    scheduler.step()  # Update learning rate.  Place *after* logging.\n",
    "\n",
    "print(\"Done!\")\n",
    "writer.close() # Close TensorBoard Writer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este ciclo de entrenamiento-validación se ha establecido como una práctica estándar en el entrenamiento de deep learning desde la década de 1990. En particular, la etapa de validación desempeña un papel crucial en el monitoreo del sobreajuste y en la determinación del early stopping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.8 Guardado y lectura de modelos\n",
    "\n",
    "El guardado de modelos es una parte muy importante en la práctica del aprendizaje profundo. Se pueden guardar los modelos entrenados para cargarlos nuevamente más tarde y reutilizarlos, o para desplegarlos en diferentes entornos (por ejemplo, servidores, dispositivos móviles). PyTorch proporciona dos métodos principales de guardado.\n",
    "\n",
    "##### Guardar solo pesos\n",
    "\n",
    "Los parámetros aprendidos del modelo (pesos y sesgos) se almacenan en un diccionario Python llamado `state_dict`. El `state_dict` es una estructura que asigna cada capa (layer) a los tensores de parámetros correspondientes. Este método tiene la ventaja de que permite cargar pesos incluso si la estructura del modelo cambia, por lo que generalmente se recomienda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_112013/3522135054.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_saved_weights.load_state_dict(torch.load('model_weights.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5459668265935331, 0.8036)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model weights\n",
    "torch.save(model.state_dict(), 'model_weights.pth')\n",
    "\n",
    "# Load weights\n",
    "model_saved_weights = SimpleNetwork()  # Create an empty model with the same architecture\n",
    "model_saved_weights.load_state_dict(torch.load('model_weights.pth'))\n",
    "model_saved_weights.to(device) # Don't forget to move to the correct device!\n",
    "model_saved_weights.eval() # Set to evaluation mode\n",
    "\n",
    "# Check performance (assuming eval_loop is defined)\n",
    "eval_loop(model_saved_weights, test_dataloader, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Guardar el modelo completo\n",
    "\n",
    "Después de 2018, a medida que las arquitecturas de modelos se han vuelto más complejas, también se ha adoptado la práctica de guardar tanto la estructura del modelo como sus pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_112013/3185686172.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_saved = torch.load('model_trained.pth')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5459668265935331, 0.8036)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model, 'model_trained.pth')\n",
    "\n",
    "# Load the entire model\n",
    "model_saved = torch.load('model_trained.pth')\n",
    "model_saved.to(device)  # Move the loaded model to the correct device.\n",
    "model_saved.eval() #  Set the loaded model to evaluation mode\n",
    "\n",
    "# Check performance\n",
    "eval_loop(model_saved, test_dataloader, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método de guardar el modelo completo es conveniente, pero si la definición de la clase del modelo cambia, pueden surgir problemas de compatibilidad. En particular, en entornos de producción, la arquitectura del modelo no suele cambiar con frecuencia, por lo que guardar solo los pesos puede ser más estable. Además, el método de guardar el modelo completo utiliza el módulo `pickle` de Python, y `pickle` tiene una vulnerabilidad que permite ejecutar código arbitrario, lo cual puede ser un riesgo de seguridad.\n",
    "\n",
    "##### Safetensors: Una alternativa más segura\n",
    "\n",
    "Recientemente, se han desarrollado nuevos formatos de almacenamiento como `safetensors`, que mejoran la seguridad y la velocidad de carga en comparación con `pickle`. `safetensors` es un formato diseñado para almacenar datos de tensores de manera segura y eficiente.\n",
    "\n",
    "*   **Seguridad:** `safetensors` no permite ejecutar código arbitrario, por lo que es mucho más seguro que `pickle`.\n",
    "*   **Zero-copy:** los datos se mapean directamente en memoria sin necesidad de copiarlos, lo que hace que la carga sea rápida.\n",
    "*   **Carga perezosa:** solo se cargan las partes necesarias, lo que reduce el uso de memoria.\n",
    "*  **Soporte para múltiples frameworks**: PyTorch, TensorFlow, JAX, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5459668265935331, 0.8036)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install safetensors: pip install safetensors\n",
    "\n",
    "from safetensors.torch import save_file, load_file\n",
    "\n",
    "# Save using safetensors\n",
    "state_dict = model.state_dict()\n",
    "save_file(state_dict, \"model_weights.safetensors\")\n",
    "\n",
    "# Load using safetensors\n",
    "loaded_state_dict = load_file(\"model_weights.safetensors\", device=device) # Load directly to the device.\n",
    "model_new = SimpleNetwork().to(device) # Create an instance of your model class\n",
    "model_new.load_state_dict(loaded_state_dict)\n",
    "model_new.eval()\n",
    "\n",
    "# Check performance\n",
    "eval_loop(model_new, test_dataloader, loss_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 TensorBoard \n",
    "\n",
    "TensorBoard es una herramienta que registra, rastrea y visualiza de manera eficiente los diversos registros generados durante el entrenamiento de aprendizaje profundo. Es un tipo de herramienta de registro y visualización de datos de registro comúnmente conocida como tablero de instrumentos. Aunque se desarrolló originalmente para TensorFlow, ahora está integrado con PyTorch. Existen otras herramientas de visualización en formato de panel similar a TensorBoard, como las siguientes:\n",
    "\n",
    "- Weights & Biases (WandB): una plataforma integral de MLOps basada en la nube que ofrece un amplio rango de funciones, incluyendo seguimiento de experimentos, gestión de versiones de conjuntos de datos y administración de modelos. Se destaca por su funcionalidad de colaboración en equipo y es ampliamente utilizada en entornos empresariales.\n",
    "- Vertex AI: una herramienta de ML completamente administrada de Google Cloud que proporciona integración nativa con BigQuery, Dataproc y Spark. Permite construir, implementar y escalar modelos rápidamente, lo que la hace adecuada para flujos de trabajo de ML a gran escala.\n",
    "- MLflow: una herramienta de código abierto que ofrece seguimiento de experimentos, empaquetado de modelos y un registro centralizado. Simplifica el seguimiento e implementación de modelos de ML y es ampliamente utilizada en los campos de ciencia de datos y aprendizaje automático.\n",
    "\n",
    "Además de estas tres herramientas, existen muchas otras. En este contexto, nos enfocaremos principalmente en TensorBoard.\n",
    "\n",
    "### 3.2.1 Uso básico de TensorBoard\n",
    "\n",
    "TensorBoard apareció junto con TensorFlow en 2015. En ese momento, la complejidad de los modelos de aprendizaje profundo aumentó significativamente, lo que hizo evidente la necesidad de monitorear eficazmente el proceso de entrenamiento.\n",
    "\n",
    "Las funciones principales de TensorBoard son las siguientes:\n",
    "1. Rastreo de métricas escalares: registro de valores como la pérdida y la precisión.\n",
    "2. Visualización de estructuras de modelo: representación gráfica del grafo de cálculo.\n",
    "3. Rastreo de distribuciones: observación de cambios en las distribuciones de pesos y gradientes.\n",
    "4. Proyección de incrustaciones: visualización 2D/3D de vectores de alta dimensión.\n",
    "5. Optimización de hiperparámetros: comparación de resultados experimentales con diferentes configuraciones.\n",
    "\n",
    "TensorBoard es una poderosa herramienta para visualizar y analizar el proceso de entrenamiento de aprendizaje profundo. El uso básico de TensorBoard consta principalmente de tres etapas: instalación, configuración del directorio de logs y configuración de callbacks.\n",
    "\n",
    "##### Métodos de instalación\n",
    "\n",
    "TensorBoard se puede instalar mediante pip o conda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!pip install tensorboard\n",
    "# 또는\n",
    "!conda install -c conda-forge tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Configuración del directorio de registro\n",
    "\n",
    "TensorBoard lee los archivos de eventos almacenados en el directorio de registro para visualizarlos. En Jupyter Notebook o Colab, se configura de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# 로그 디렉토리 설정\n",
    "log_dir = 'logs/experiment_1'\n",
    "writer = SummaryWriter(log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ejecución de TensorBoard\n",
    "\n",
    "TensorBoard se puede ejecutar de las siguientes dos maneras.\n",
    "\n",
    "1. Desde la línea de comandos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "tensorboard --logdir=logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ejecutar en Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecución posterior, puede acceder al panel de TensorBoard en su navegador web ingresando http://localhost:6006.\n",
    "\n",
    "##### Ejecución en un servidor remoto\n",
    "\n",
    "Cuando se ejecuta TensorBoard en un servidor remoto, use el túnel SSH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "ssh -L 6006:127.0.0.1:6006 username@server_ip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parámetros principales (SummaryWriter)**\n",
    "\n",
    "`SummaryWriter` es la clase principal que genera datos para registrar en TensorBoard. Los parámetros principales son los siguientes:\n",
    "\n",
    "*   `log_dir`: ruta del directorio donde se guardarán los archivos de registro.\n",
    "*   `comment`: cadena a agregar al final de `log_dir`.\n",
    "*   `flush_secs`: frecuencia con la que se escriben los registros en el disco (en segundos).\n",
    "*   `max_queue`: número de eventos/pasos pendientes que se pueden almacenar.\n",
    "\n",
    "**Métodos principales (SummaryWriter)**\n",
    "\n",
    "*   `add_scalar(tag, scalar_value, global_step=None)`: registra un valor escalar (por ejemplo, pérdida, precisión).\n",
    "*   `add_histogram(tag, values, global_step=None, bins='tensorflow')`: registra un histograma (distribución de valores).\n",
    "*   `add_image(tag, img_tensor, global_step=None, dataformats='CHW')`: registra una imagen.\n",
    "*   `add_figure(tag, figure, global_step=None, close=True)`: registra una figura de Matplotlib.\n",
    "*   `add_video(tag, vid_tensor, global_step=None, fps=4, dataformats='NCHW')`: registra un video.\n",
    "*   `add_audio(tag, snd_tensor, global_step=None, sample_rate=44100)`: registra audio.\n",
    "*   `add_text(tag, text_string, global_step=None)`: registra texto.\n",
    "*   `add_graph(model, input_to_model=None, verbose=False)`: registra un gráfico de modelo.\n",
    "*   `add_embedding(mat, metadata=None, label_img=None, global_step=None, tag='default', metadata_header=None)`: registra un proyector de incrustaciones (embeddings).\n",
    "*   `add_hparams(hparam_dict, metric_dict, hparam_domain_discrete=None, run_name=None)`: registra hiperparámetros y sus métricas correspondientes.\n",
    "*   `flush()`: registra todos los eventos pendientes en el disco.\n",
    "*   `close()`: finaliza la grabación de registros y libera recursos.\n",
    "\n",
    "**Parámetros principales del callback (TensorFlow/Keras)**\n",
    "\n",
    "Cuando se usa TensorBoard con TensorFlow/Keras, se utiliza el callback `tf.keras.callbacks.TensorBoard`. Los parámetros principales son los siguientes:\n",
    "\n",
    "*   `log_dir`: ubicación donde se guardan los registros.\n",
    "*   `histogram_freq`: frecuencia de cálculo del histograma (0 significa que no se calculará). Se usa para visualizar la distribución de pesos, sesgos y valores de activación.\n",
    "*   `write_graph`: indica si se debe visualizar el gráfico del modelo.\n",
    "*   `write_images`: indica si se deben visualizar los pesos del modelo como imágenes.\n",
    "*   `update_freq`: frecuencia con la que se registran las pérdidas y métricas ('batch', 'epoch' o un número entero).\n",
    "*   `profile_batch`: rango de lotes a perfilar (por ejemplo, `profile_batch='5, 8'`). El perfilado es útil para identificar cuellos de botella en el rendimiento.\n",
    "*   `embeddings_freq`: frecuencia con la que se visualizan las capas de incrustaciones.\n",
    "*   `embeddings_metadata`: ruta del archivo de metadatos de incrustaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Funciones de visualización principales de TensorBoard\n",
    "\n",
    "TensorBoard puede visualizar diversas métricas que surgen durante el proceso de entrenamiento del modelo. Los paneles de visualización principales incluyen escalares, histogramas, distribuciones, gráficos y embeddings.\n",
    "\n",
    "##### Visualización de métricas escalares\n",
    "El panel de escalares visualiza cambios en métricas numéricas como valores de pérdida y precisión. Se pueden seguir diversas estadísticas del proceso de entrenamiento del modelo, como la tasa de aprendizaje, la norma del gradiente, el promedio/varianza de los pesos por capa. También se puede monitorear simultáneamente métricas de evaluación de calidad importantes en modelos generativos recientes, como la puntuación FID (Fréchet Inception Distance) o QICE (Quantile Interval Coverage Error). A través de estas métricas, se puede monitorear en tiempo real el progreso del entrenamiento del modelo y detectar problemas como el sobreajuste o la inestabilidad del entrenamiento en una etapa temprana. Se pueden registrar valores escalares de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_scalar('Loss/train', train_loss, step)\n",
    "writer.add_scalar('Accuracy/train', train_acc, step)\n",
    "writer.add_scalar('Learning/learning_rate', current_lr, step)\n",
    "writer.add_scalar('Gradients/norm', grad_norm, step)\n",
    "writer.add_scalar('Quality/fid_score', fid_score, step)\n",
    "writer.add_scalar('Metrics/qice', qice_value, step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Histogramas y visualización de distribuciones\n",
    "Puedes observar los cambios en la distribución de pesos y sesgos. Los histogramas muestran visualmente las distribuciones de pesos, sesgos, gradientes y valores de activación de cada capa, lo que ayuda a comprender el estado interno del modelo. En particular, pueden ayudarte a detectar temprano si los pesos se saturan en ciertos valores o si los gradientes desaparecen/explotan durante el proceso de aprendizaje, lo cual es muy útil para la depuración del modelo. Puedes registrar histogramas de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    writer.add_histogram(f'Parameters/{name}', param.data, global_step)\n",
    "    if param.grad is not None:\n",
    "        writer.add_histogram(f'Gradients/{name}', param.grad, global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualización de la estructura del modelo\n",
    "Puede visualizar la estructura del modelo. En particular, puede comprender intuitivamente la estructura de capas y las conexiones de redes neuronales complejas. TensorBoard representa el flujo de datos, la forma de entrada y salida de cada capa, y el orden de operaciones en forma de gráfico, y permite examinar información detallada expandiendo cada nodo. Recientemente, ha sido especialmente útil para visualizar mecanismos de atención complejos como los de los modelos Transformer o Diffusion, capas de atención cruzada, estructuras de ramificación condicional, etc. Esto es muy útil para depurar y optimizar el modelo, y particularmente ayuda a comprender arquitecturas complejas con conexiones residuales o estructuras paralelas. Puede registrar el gráfico del modelo de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(model, input_to_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualización de incrustaciones\n",
    "El Projector de TensorBoard permite proyectar incrustaciones de alta dimensión en espacios 2D o 3D para su visualización. Esto es útil para analizar las relaciones entre incrustaciones de palabras o vectores de características de imágenes. Se utiliza técnicas de reducción de dimensionalidad, como PCA o UMAP, para visualizar datos de alta dimensión complejos mientras se preservan la estructura de clústeres y las distancias relativas. En particular, UMAP permite una visualización rápida que conserva bien tanto la estructura local como la global. A través de esto, se puede verificar cómo los puntos de datos con características similares se agrupan, si se realiza una buena separación entre clases, y cómo cambia el espacio de características durante el proceso de aprendizaje. Se pueden registrar las incrustaciones de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_embedding(\n",
    "    features,\n",
    "    metadata=labels,\n",
    "    label_img=images,\n",
    "    global_step=step\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualización de hiperparámetros\n",
    "Puede visualizar los resultados del ajuste de hiperparámetros. Además de la tasa de aprendizaje, el tamaño del lote y la tasa de dropout, también puede analizar el impacto de parámetros estructurales como el número de cabezas de atención en modelos Transformer, la longitud del prompt y la dimensión de los embeddings de tokens. Es posible visualizar junto con esto los parámetros de inferencia importantes en LLM modernos o modelos de difusión, como las programaciones de ruido, el número de pasos de muestreo y los pesos CFG (Classifier-Free Guidance). Se pueden representar el rendimiento del modelo según diferentes combinaciones de hiperparámetros mediante gráficos de coordenadas paralelas o diagramas de dispersión para ayudar a encontrar la configuración óptima. En particular, facilita comparar varios resultados experimentales a simple vista y analizar cómo las interacciones entre los hiperparámetros afectan el rendimiento del modelo. Puede registrar hiperparámetros y métricas relacionadas de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_hparams(\n",
    "    {\n",
    "        'lr': learning_rate, \n",
    "        'batch_size': batch_size, \n",
    "        'num_heads': n_heads,\n",
    "        'cfg_scale': guidance_scale,\n",
    "        'sampling_steps': num_steps,\n",
    "        'prompt_length': max_length\n",
    "    },\n",
    "    {\n",
    "        'accuracy': accuracy, \n",
    "        'loss': final_loss,\n",
    "        'fid_score': fid_score\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualización de imágenes\n",
    "Se pueden visualizar las imágenes generadas durante el proceso de aprendizaje o los mapas de características intermedios. Al visualizar los filtros y mapas de activación de las capas convolucionales, se puede comprender intuitivamente qué características está aprendiendo el modelo y en qué partes de la imagen de entrada está prestando atención en cada capa. En particular, es muy útil para rastrear visualmente los cambios en la calidad de las imágenes generadas por modelos generativos modernos como Stable Diffusion o DALL-E. Con el surgimiento de modelos híbridos, se ha vuelto posible generar imágenes más sofisticadas y realistas. Se pueden registrar las imágenes de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 이미지나 생성된 이미지 시각화\n",
    "writer.add_images('Images/generated', generated_images, global_step)\n",
    "\n",
    "# 디퓨전 모델의 중간 생성 과정 시각화\n",
    "writer.add_images('Diffusion/steps', diffusion_steps, global_step)\n",
    "\n",
    "# 어텐션 맵 시각화\n",
    "writer.add_image('Attention/maps', attention_visualization, global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A través de las funciones de visualización de TensorBoard, se puede comprender intuitivamente el proceso de aprendizaje del modelo y detectar rápidamente los problemas. En particular, al poder monitorear en tiempo real el progreso del aprendizaje, es útil para la detención temprana del proceso de aprendizaje o para ajustar los hiperparámetros. La visualización de incrustaciones es especialmente útil para comprender las relaciones de datos de alta dimensión y ayuda a analizar la estructura del espacio de características aprendido por el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Ejemplo de TensorBoard\n",
    "\n",
    "En esta sección, examinaremos un ejemplo concreto de cómo aplicar las diversas funcionalidades de TensorBoard en el entrenamiento de un modelo de aprendizaje profundo real. Utilizaremos el conjunto de datos MNIST de dígitos manuscritos para entrenar un modelo CNN (Convolutional Neural Network) simple y explicaremos paso a paso cómo visualizar los indicadores y datos clave generados durante el proceso de entrenamiento mediante TensorBoard.\n",
    "\n",
    "**Elementos de visualización clave:**\n",
    "\n",
    "| Tipo de visualización | Contenido de la visualización                                                                                           | Pestaña de TensorBoard |\n",
    "| :------------------- | :--------------------------------------------------------------------------------------------------- | :---------- |\n",
    "| **Indicadores escalares**     | Pérdida de entrenamiento/prueba, precisión de entrenamiento/prueba, tasa de aprendizaje, norma del gradiente | SCALARS     |\n",
    "| **Histogramas/distribuciones**   | Distribución de pesos en todas las capas, distribución de gradientes en todas las capas                          | DISTRIBUTIONS, HISTOGRAMS |\n",
    "| **Estructura del modelo**       | Grafo computacional del modelo CNN MNIST                                                       | GRAPHS      |\n",
    "| **Mapas de características**         | Mapas de características de la capa Conv1, mapas de características de la capa Conv2, cuadrícula de imágenes de entrada, visualización de filtros de Conv1                        | IMAGES      |\n",
    "| **Embeddings**          | Vectores de características de 32 dimensiones de la capa FC1, visualización en 2D utilizando t-SNE, etiquetas de imágenes MNIST                            | PROJECTOR   |\n",
    "| **Hiperparámetros**   | Tamaño del lote, tasa de aprendizaje, ratio de dropout, tipo de optimizador, Weight decay, Momentum, pasos/gamma del programador       | HPARAMS     |\n",
    "\n",
    "**Frecuencia de visualización:**\n",
    "\n",
    "*   Escalares/histogramas: cada 50 lotes(batch)\n",
    "*   Mapas de características/imágenes: cada 50 lotes\n",
    "*   Embeddings: al final de cada época(epoch)\n",
    "*   Hiperparámetros: al inicio y final del entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo de código**\n",
    "\n",
    "En este ejemplo se utiliza el paquete `dld`. Se importan los módulos necesarios y se inicia el entrenamiento. La función `train()` entrena un modelo CNN en el conjunto de datos MNIST utilizando hiperparámetros predeterminados, y registra el proceso de entrenamiento en TensorBoard. Para experimentar con diferentes hiperparámetros, puede pasar el argumento `hparams_dict` a la función `train()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a notebook cell:\n",
    "from dldna.chapter_03.train import train\n",
    "\n",
    "# Run with default hyperparameters\n",
    "train()\n",
    "\n",
    "# Run with custom hyperparameters\n",
    "my_hparams = {\n",
    "    'batch_size': 128,\n",
    "    'learning_rate': 0.01,\n",
    "    'epochs': 8,\n",
    "}\n",
    "train(hparams_dict=my_hparams, log_dir='runs/my_custom_run')\n",
    "\n",
    "# Start TensorBoard (in a separate cell, or from the command line)\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejecución de TensorBoard:**\n",
    "\n",
    "Una vez que el entrenamiento esté completo, use el siguiente comando en la shell para ejecutar TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede ver el panel de TensorBoard conectándose a `http://localhost:6006` en su navegador web. \n",
    "\n",
    "Podrá confirmar que se han creado varias tarjetas para cada elemento.\n",
    "![TensorBoard](../../../assets/images/03_01.png)\n",
    "\n",
    "En cada elemento, puede verificar los cambios individuales de valores e imágenes.\n",
    "![TensorBoard](../../../assets/images/03_02.png)\n",
    "\n",
    "\n",
    "**Uso del panel de TensorBoard**\n",
    "\n",
    "*   **Pestaña SCALARS:** rastrea los cambios en el tiempo de la pérdida de entrenamiento/prueba, precisión, tasa de aprendizaje, etc. Esto le permite determinar si el modelo está aprendiendo bien y si se produce un ajuste excesivo (overfitting).\n",
    "*   **Pestaña GRAPHS:** visualiza el grafo de cálculo del modelo para mostrar la flujo de datos y los procesos de cálculo a simple vista. Ayuda a comprender la estructura de modelos complejos.\n",
    "*   **Pestañas DISTRIBUTIONS/HISTOGRAMS:** visualiza la distribución de pesos y gradientes. Esto le permite diagnosticar si la inicialización de los pesos es adecuada y si se producen problemas de desvanecimiento o explosión de gradientes (vanishing or exploding gradients).\n",
    "*   **Pestaña IMAGES:** visualiza las imágenes de entrada, mapas de características y filtros en formato de imagen. Esto le permite verificar de manera intuitiva qué partes de la imagen está observando el modelo y si la extracción de características es efectiva.\n",
    "*   **Pestaña PROJECTOR:** proyecta incrustaciones de alta dimensión a 2D/3D para su visualización. Ayuda a identificar agrupamientos de datos y valores atípicos (outliers).\n",
    "*   **Pestaña HPARAMS:** compara los resultados de experimentos realizados con diferentes combinaciones de hiperparámetros, ayudándole a encontrar la configuración óptima.\n",
    "\n",
    "En este ejemplo, hemos explorado cómo usar TensorBoard para visualizar el proceso de entrenamiento de un modelo de deep learning. TensorBoard es más que una simple herramienta de visualización; es esencial para comprender el funcionamiento del modelo, diagnosticar problemas y mejorar su rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Hugging Face Transformers\n",
    "\n",
    "Hugging Face comenzó en 2016 como una aplicación de chatbot para adolescentes fundada por empresarios franceses. Inicialmente, su objetivo era proporcionar un amigo AI que ofreciera apoyo emocional y entretenimiento, pero experimentó un gran punto de inflexión al hacer público el modelo NLP de su chatbot de código abierto. Esto coincidió con un período en el que modelos de lenguaje de alto rendimiento como BERT y GPT estaban emergiendo, aunque era difícil utilizarlos en la práctica, lo que generó una gran resonancia. El lanzamiento de la biblioteca Transformers en 2019 revolucionó el campo del procesamiento de lenguaje natural. Si PyTorch proporciona las operaciones básicas y el marco de aprendizaje profundo, Hugging Face se centra en la implementación y uso práctico de los modelos de lenguaje. En particular, facilitaron la compartición y reutilización de modelos preentrenados, lo que permitió a cualquiera utilizar modelos de lenguaje a gran escala, que hasta entonces eran el dominio exclusivo de un puñado de grandes empresas.\n",
    "\n",
    "Hugging Face ha construido un ecosistema abierto digno del título \"GitHub del AI\". Actualmente se comparten más de un millón de modelos y cientos de miles de conjuntos de datos, convirtiéndose en una plataforma que va más allá de un simple repositorio de código para fomentar el desarrollo ético y responsable de la IA. Especialmente, han implementado un sistema de tarjetas de modelo que detalla las limitaciones y sesgos de cada modelo, y un sistema de retroalimentación basado en la comunidad para verificar continuamente la calidad y la ética del modelo. Estos esfuerzos no solo han democratizado el desarrollo de IA, sino que también han establecido un nuevo paradigma de desarrollo tecnológico responsable. El enfoque de Hugging Face equilibra la innovación técnica con consideraciones éticas, convirtiéndose en un ejemplo a seguir en el desarrollo de AI moderno.\n",
    "\n",
    "### 3.3.1 Introducción a la biblioteca Transformers\n",
    "\n",
    "Transformers proporciona una interfaz integrada para descargar y usar modelos preentrenados fácilmente. Funciona sobre marcos como PyTorch o TensorFlow, lo que garantiza su compatibilidad con los ecosistemas de aprendizaje profundo existentes. En particular, también admite nuevos marcos como JAX, ampliando las opciones disponibles para los investigadores. Los componentes principales de Transformers son dos.\n",
    "\n",
    "##### Modelo Hub y Pipelines\n",
    "\n",
    "El Modelo Hub actúa como un repositorio central para modelos preentrenados. Se publican modelos especializados en diversas tareas de procesamiento de lenguaje natural, como generación de texto, clasificación, traducción, resumen y respuestas a preguntas. Cada modelo se proporciona con detallada metadatos, incluyendo métricas de rendimiento, información de licencia, origen de los datos de entrenamiento, etc. En particular, el sistema de tarjetas de modelo (Model Card) también especifica las limitaciones y sesgos del modelo para fomentar el desarrollo responsable de IA.\n",
    "\n",
    "Las pipelines abstraen procesos complejos de preprocesamiento y postprocesamiento, proporcionándolos a través de una interfaz simple. Esto es especialmente útil en entornos de producción, reduciendo significativamente los costos de integración del modelo. Internamente, las pipelines configuran automáticamente el tokenizador y el modelo, y también realizan optimizaciones como procesamiento por lotes o aceleración GPU de manera automática."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6703892f09b4ade869f16b776740536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5210ba6dfe24216ab409ef41d197c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc25443102364b8e96035a7c0218e23b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e19048c8971437b82f666267ec92f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "result = classifier(\"I love this book!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenizador y clases de modelos\n",
    "\n",
    "El tokenizador convierte el texto de entrada en una secuencia numérica que el modelo puede procesar. Cada modelo tiene un tokenizador dedicado, lo cual refleja las características de los datos de entrenamiento. El tokenizador no solo se limita a la división de palabras, sino que también maneja consistentemente preprocesamientos complejos como la tokenización subpalabra, la adición de tokens especiales, el relleno y la truncatura. En particular, integra varios algoritmos de tokenización, como WordPiece, BPE, SentencePiece, lo que permite seleccionar la mejor forma de tokenización adaptada a las características de cada idioma y dominio.\n",
    "\n",
    "Las clases de modelos implementan las redes neuronales que realizan los cálculos reales. Se admite una variedad de arquitecturas como BERT, GPT, T5, y se puede seleccionar automáticamente la arquitectura del modelo a través de las clases de la serie AutoModel. Cada modelo viene con pesos pre-entrenados y puede ser ajustado para tareas específicas según sea necesario. Además, técnicas de optimización como la paralelización de modelos, cuantización y poda también pueden aplicarse inmediatamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Casos de uso principales\n",
    "\n",
    "La biblioteca Transformers se utiliza en una variedad de tareas de procesamiento de lenguaje natural. Desde el desarrollo de modelos de la serie GPT a partir de 2020, las capacidades de generación de texto han mejorado enormemente, y para 2024, con la aparición de modelos de código abierto de alto rendimiento como Llama 3, el alcance de uso se ha ampliado aún más. En particular, el modelo de 405B parámetros de Llama 3 muestra un rendimiento comparable al de GPT-4 y ha logrado avances significativos en el procesamiento multilingüe, codificación e inferencia. Este progreso ha permitido diversas aplicaciones en entornos empresariales reales, incluyendo soporte al cliente, generación de contenido, análisis de datos y procesamiento automatizado de tareas. En particular, la mejora significativa en la generación y depuración de código también ha contribuido a aumentar la productividad de los desarrolladores.\n",
    "\n",
    "**Uso del Hugging Face Hub:**\n",
    "\n",
    "El Hugging Face Hub ([https://huggingface.co/models](https://huggingface.co/models)) es una plataforma para buscar, filtrar y descargar numerosos modelos y conjuntos de datos.\n",
    "\n",
    "*   **Búsqueda de modelos:**  Puede buscar por nombre de modelo (por ejemplo, \"bert\", \"gpt2\", \"t5\") o tarea (por ejemplo, \"text-classification\", \"question-answering\") en la barra de búsqueda de la esquina superior izquierda.\n",
    "*   **Filtrado:**  Puede filtrar por Tarea, Biblioteca, Idioma, Conjunto de datos y otros criterios en el panel lateral izquierdo.\n",
    "*   **Páginas de modelos:**  Cada página de modelo proporciona información útil como una descripción del modelo, ejemplos de uso, métricas de rendimiento y tarjetas de modelo.\n",
    "\n",
    "**Generación y clasificación de texto**\n",
    "\n",
    "La generación de texto es la tarea de crear texto natural basado en un prompt dado. Los modelos más recientes ofrecen las siguientes funciones avanzadas:\n",
    "- Generación multimodal: creación de contenido que combina texto e imágenes\n",
    "- Generación automática de código: escritura de código optimizado para diferentes lenguajes de programación\n",
    "- Agentes conversacionales: implementación de chatbots inteligentes que comprenden el contexto\n",
    "- Texto especializado: generación de documentos en dominios especializados como la medicina y el derecho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Design a webpage that is compatible with your browser with our FREE SEO Service.\n",
      "\n",
      "You read that right. By utilizing a web browser's default settings, your webpage should be free from advertisements and other types of spam. The best way to avoid this\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Text generation pipeline (using gpt2 model)\n",
    "generator = pipeline('text-generation', model='gpt2')  # Smaller model\n",
    "result = generator(\"Design a webpage that\", max_length=50, num_return_sequences=1)\n",
    "print(result[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La clasificación de texto se habrá sofisticado aún más para 2025, ofreciendo las siguientes funciones:\n",
    "\n",
    "- Aprendizaje por cero/uno: a través de la biblioteca Transformers de Hugging Face es posible una adaptación inmediata a nuevas categorías. En particular, los modelos de aprendizaje previo basados en inferencia de lenguaje natural pueden lograr una precisión superior al 90% con menos de 8 ejemplos y son aplicables a diversos dominios.\n",
    "- Clasificación multilingüe: los modelos multilingües más recientes, como ModernBERT de Hugging Face, admiten más de 16 idiomas principales. Específicamente, el modelo base de 150M de parámetros logra una puntuación F1 superior al 80% y muestra un rendimiento excelente incluso en idiomas con recursos limitados.\n",
    "- Clasificación jerárquica: el marco HiGen de Hugging Face proporciona funciones especializadas para la clasificación de etiquetas jerárquicas. A través de una función de pérdida basada en niveles, captura eficazmente las relaciones semánticas entre texto y etiquetas, mostrando un alto rendimiento incluso en clases con datos limitados.\n",
    "- Clasificación en tiempo real: a través de las pipelines de Hugging Face es posible el procesamiento en tiempo real de datos de transmisión. Con tecnologías de optimización como Flash Attention integradas por defecto, se pueden manejar secuencias largas de manera eficiente y se ofrece un alto rendimiento en aplicaciones en tiempo real.\n",
    "\n",
    "##### Ajuste fino y compartición de modelos\n",
    "\n",
    "Hugging Face proporciona la última tecnología de ajuste fino para apoyar el aprendizaje eficiente de grandes modelos de lenguaje. Estas tecnologías permiten reducir significativamente los costos y tiempos de aprendizaje mientras mantienen el rendimiento del modelo.\n",
    "\n",
    "- QLoRA (Quantized Low-Rank Adaptation): proporcionado a través de la biblioteca PEFT de Hugging Face, combina cuantización de 4 bits con adaptación de bajo rango para reducir el uso de memoria en más del 90%. En particular, es posible ajustar modelos de 65B parámetros en una GPU de 48GB.\n",
    "- Spectrum: técnica de optimización selectiva por capa integrada con la biblioteca TRL de Hugging Face. Analiza la relación señal-ruido de cada capa y selecciona para el aprendizaje solo las capas más importantes, mejorando así la eficiencia computacional.\n",
    "- Flash Attention: compatible por defecto desde la versión 2.2 de Transformers de Hugging Face y se puede activar fácilmente con el parámetro attn_implementation=\"flash_attention_2\". En particular, mejora significativamente la eficiencia de memoria en el procesamiento de secuencias largas.\n",
    "- DeepSpeed: totalmente integrado a través de la biblioteca Accelerate de Hugging Face y apoya eficientemente el aprendizaje distribuido a gran escala mediante el optimizador ZeRO. También es utilizable durante la inferencia, permitiendo cargar modelos grandes en múltiples GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad7aa580feaf4d5fa3abcd96b1bc43e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24731acb95cb4dbea5d194f768b17df3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee9456452ccb4910849e2973a1765462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "688ecbdc102a4cc6b562c911f79851c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62d43521fee04e07a6ce10a5488d2b38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2522a9d78974c45beeb8575e3c29e85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sean/anaconda3/envs/DL/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.667500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Load a pre-trained model and tokenizer ---\n",
    "model_name = \"distilbert-base-uncased\"  # Use a small, fast model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)  # Binary classification\n",
    "\n",
    "# --- 2. Create a simple dataset (for demonstration) ---\n",
    "raw_data = {\n",
    "    \"text\": [\n",
    "        \"This is a positive example!\",\n",
    "        \"This is a negative example.\",\n",
    "        \"Another positive one.\",\n",
    "        \"And a negative one.\"\n",
    "    ],\n",
    "    \"label\": [1, 0, 1, 0],  # 1 for positive, 0 for negative\n",
    "}\n",
    "dataset = Dataset.from_dict(raw_data)\n",
    "\n",
    "# --- 3. Tokenize the dataset ---\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True) #padding is handled by data collator\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset = tokenized_dataset.remove_columns([\"text\"]) # remove text, keep label\n",
    "\n",
    "# --- 4. Data Collator (for dynamic padding) ---\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# --- 5. Training Arguments ---\n",
    "fp16_enabled = False\n",
    "if torch.cuda.is_available():\n",
    "    try:\n",
    "        if torch.cuda.get_device_capability()[0] >= 7:\n",
    "            fp16_enabled = True\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=1,          # Keep it short\n",
    "    per_device_train_batch_size=2,  # Small batch size\n",
    "    logging_steps=1,           # Log every step\n",
    "    save_strategy=\"no\",         # No saving\n",
    "    report_to=\"none\",          # No reporting\n",
    "    fp16=fp16_enabled,  # Use fp16 if avail.\n",
    "    # --- Optimization techniques (demonstration) ---\n",
    "    # gradient_checkpointing=True,  # Enable gradient checkpointing (if needed for large models)\n",
    "    # gradient_accumulation_steps=2, # Increase effective batch size\n",
    ")\n",
    "\n",
    "\n",
    "# --- 6. Trainer ---\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    # eval_dataset=...,  # Add an eval dataset if you have one\n",
    "    data_collator=data_collator,  # Use the data collator\n",
    "    # optimizers=(optimizer, scheduler) # you could also customize optimizer\n",
    ")\n",
    "\n",
    "# --- 7. Train ---\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "print(\"Training finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El ecosistema de compartir modelos actualmente admite las siguientes características más recientes para 2025.\n",
    "- Generación automática de tarjetas de modelo: el sistema automatizado de tarjetas de modelo de Hugging Face analiza y documenta automáticamente los indicadores de rendimiento y sesgo. En particular, se puede describir claramente las características y limitaciones del modelo en un formato estandarizado a través de la Herramienta de Tarjeta de Modelo.\n",
    "- Control de versiones: el sistema de control de versiones basado en Git de Hugging Face Hub permite rastrear el historial de cambios y las variaciones de rendimiento del modelo. Se pueden registrar y comparar automáticamente los métricas de rendimiento y los cambios de parámetros para cada versión.\n",
    "- Herramientas colaborativas: proporciona un entorno colaborativo integrado con Hugging Face Spaces. Los miembros del equipo pueden compartir en tiempo real el proceso de desarrollo, prueba y despliegue de modelos, intercambiar comentarios y también se admite la integración con pipelines CI/CD.\n",
    "- IA ética: a través del marco de IA ética de Hugging Face, se puede verificar y evaluar automáticamente el sesgo del modelo. En particular, se pueden analizar las diferencias en rendimiento entre diversos grupos demográficos y se pueden identificar riesgos potenciales con anticipación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios de práctica\n",
    "\n",
    "**1. Problemas básicos**\n",
    "\n",
    "  * Explique las diferencias entre los tensores de PyTorch y los arrays de NumPy, y cómo convertir entre ellos.\n",
    "  * Describa el papel de la capa `torch.nn.Linear` y cómo inicializar sus pesos.\n",
    "  * Explique cómo funciona la diferenciación automática (automatic differentiation) en PyTorch y el rol de la propiedad `requires_grad`.\n",
    "\n",
    "**2. Problemas aplicados**\n",
    "\n",
    "  * Escriba un código para dividir un conjunto de datos dado en conjuntos de entrenamiento, validación y prueba utilizando `torch.utils.data.Dataset` y `torch.utils.data.DataLoader`, y cargue los datos por lotes.\n",
    "  * Implemente un modelo de CNN simple (por ejemplo, LeNet-5) heredando de `nn.Module` y use `torchsummary` para verificar la estructura del modelo y el número de parámetros.\n",
    "  * Entrene un modelo usando el conjunto de datos MNIST o Fashion-MNIST y visualice el proceso de entrenamiento (pérdida, precisión, etc.) utilizando TensorBoard.\n",
    "\n",
    "**3. Problemas avanzados**\n",
    "\n",
    "  * Implemente multiplicación de matrices, transposición, multiplicación de matrices por lotes, transformaciones bilineales, etc., usando `torch.einsum`. (Proporcione la notación de Einstein para cada operación y implemente el código en PyTorch.)\n",
    "  * Escriba un código para crear un conjunto de datos personalizado y aplicar aumentación de datos (data augmentation) utilizando `torchvision.transforms` (por ejemplo, rotación de imágenes, recorte, transformaciones de color).\n",
    "  * Explique cómo calcular derivadas de orden superior usando `torch.autograd.grad` y escriba un ejemplo de código simple. (Por ejemplo, el cálculo de la matriz Hessiana)\n",
    "  * Explique por qué se puede llamar a un objeto de modelo como una función sin necesidad de invocar directamente el método `forward()` de `torch.nn.Module`. (Pista: considere la relación con el método `__call__` y el sistema de diferenciación automática)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-note collapse=\"true\" title=\"Haga clic para ver el contenido (solución)\"}\n",
    "## Soluciones a los Ejercicios de Práctica\n",
    "\n",
    "### 1. Soluciones a los Problemas Básicos\n",
    "\n",
    "1.  **Tensor vs. Array NumPy:**\n",
    "    *   **Diferencias:** El tensor admite aceleración GPU y diferenciación automática. NumPy es una operación de matriz genérica basada en CPU.\n",
    "    *   **Conversión:** `torch.from_numpy()`, `.numpy()` (sin embargo, para tensores GPU se requiere `.cpu()` primero).\n",
    "\n",
    "    ```python\n",
    "    # Ejemplo\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    numpy_array = np.array([1, 2, 3])\n",
    "    torch_tensor = torch.from_numpy(numpy_array)  # o torch.tensor()\n",
    "    numpy_back = torch_tensor.cpu().numpy()\n",
    "    ```\n",
    "2.  **`nn.Linear`:**\n",
    "    *   **Función:** `y = xW^T + b` (transformación lineal). Multiplica la entrada `x` por el peso `W` y suma el sesgo `b`.\n",
    "    *   **Inicialización:** Por defecto, inicialización Kaiming He (distribución uniforme). Se puede cambiar usando el módulo `torch.nn.init`.\n",
    "\n",
    "    ```python\n",
    "    # Ejemplo\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.init as init\n",
    "    linear_layer = nn.Linear(in_features=10, out_features=5)\n",
    "    init.xavier_uniform_(linear_layer.weight) # Inicialización Xavier\n",
    "    ```\n",
    "\n",
    "3.  **Diferenciación Automática (Autograd):**\n",
    "    *   **Funcionamiento:** Cuando se realizan operaciones con tensores `requires_grad=True`, se crea un grafo de cálculo, y al llamar a `.backward()`, se calcula el gradiente mediante la regla de la cadena.\n",
    "    *   **`requires_grad`:** Establece si se debe calcular y rastrear el gradiente.\n",
    "\n",
    "    ```python\n",
    "    # Ejemplo\n",
    "    import torch\n",
    "    x = torch.tensor([2.0], requires_grad=True)\n",
    "    y = x**2 + 3*x + 1\n",
    "    y.backward()\n",
    "    print(x.grad)  # Salida: tensor([7.])\n",
    "    ```\n",
    "\n",
    "### 2. Soluciones a los Problemas de Aplicación\n",
    "\n",
    "4.  **`Dataset`, `DataLoader`:**\n",
    "\n",
    "    ```python\n",
    "    from torch.utils.data import Dataset, DataLoader, random_split\n",
    "    import torchvision.transforms as transforms\n",
    "    from torchvision import datasets\n",
    "\n",
    "    # Conjunto de Datos Personalizado (Ejemplo)\n",
    "    class CustomDataset(Dataset):\n",
    "        def __init__(self, data, targets, transform=None):\n",
    "            self.data = data\n",
    "            self.targets = targets\n",
    "            self.transform = transform\n",
    "        def __len__(self):\n",
    "            return len(self.data)\n",
    "        def __getitem__(self, idx):\n",
    "            sample, label = self.data[idx], self.targets[idx]\n",
    "            if self.transform:\n",
    "                sample = self.transform(sample)\n",
    "            return sample, label\n",
    "    ```\n",
    "# MNIST DataLoader ejemplo (utilizando torchvision)\n",
    "transform = transforms.ToTensor() # datos de imagen a tensor\n",
    "mnist_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_size = int(0.8 * len(mnist_dataset))\n",
    "val_size = len(mnist_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(mnist_dataset, [train_size, val_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "```\n",
    "\n",
    "5.  **LeNet-5, `torchsummary`, tensorboard:** (código completo ver respuesta anterior, aquí solo la parte clave)\n",
    "\n",
    "```python\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Modelo LeNet-5\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2)\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = LeNet5()\n",
    "summary(model, input_size=(1, 28, 28)) # resumen de la estructura del modelo\n",
    "\n",
    "# ... (código de entrenamiento, ver respuesta anterior) ...\n",
    "\n",
    "writer = SummaryWriter() # tensorboard\n",
    "# ... (durante el entrenamiento usar writer.add_scalar() para registrar) ...\n",
    "writer.close()\n",
    "```\n",
    "\n",
    "### 3. Solución a problemas avanzados\n",
    "\n",
    "6.  **`torch.einsum`:**\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "```\n",
    "A = torch.randn(3, 4)\n",
    "B = torch.randn(4, 5)\n",
    "C = torch.einsum(\"ij,jk->ik\", A, B)   # multiplicación de matrices\n",
    "D = torch.einsum(\"ij->ji\", A)        # transposición\n",
    "E = torch.einsum(\"bi,bj,ijk->bk\", A, B, torch.randn(2,3,4))  # transformación bilineal\n",
    "```\n",
    "\n",
    "7.  **Conjunto de datos personalizado, aumento de datos:**\n",
    "\n",
    "```python\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class CustomImageDataset(Dataset): # herencia de Dataset\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        # ... (implementación del constructor) ...\n",
    "        pass\n",
    "    def __len__(self):\n",
    "        # ... (devolver el número de datos) ...\n",
    "        pass\n",
    "    def __getitem__(self, idx):\n",
    "        # ... (devolver la muestra correspondiente a idx) ...\n",
    "        pass\n",
    "\n",
    "# aumento de datos\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),  # recorte aleatorio con tamaño y relación de aspecto\n",
    "    transforms.RandomHorizontalFlip(),     # volteo horizontal aleatorio\n",
    "    transforms.ToTensor(),              # conversión a tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # normalización\n",
    "])\n",
    "\n",
    "# dataset = CustomImageDataset(root_dir='path/to/images', transform=transform)\n",
    "```\n",
    "\n",
    "8.  **Funciones de orden superior:**\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = x**3\n",
    "\n",
    "# derivada primera\n",
    "first_derivative = torch.autograd.grad(y, x, create_graph=True)[0]  # create_graph=True\n",
    "print(first_derivative)\n",
    "\n",
    "# derivada segunda (hessiano)\n",
    "second_derivative = torch.autograd.grad(first_derivative, x)[0]\n",
    "print(second_derivative)\n",
    "```\n",
    "\n",
    "9. **Método `__call__`:**\n",
    "\n",
    "El método `__call__` de `nn.Module` realiza tareas adicionales (como registrar hooks, configuraciones relacionadas con la diferenciación automática) *antes y después* de llamar a `forward()`. Si se llama directamente a `forward()`, estas funcionalidades pueden ser omitidas, lo que podría resultar en cálculos incorrectos de gradientes o en mal funcionamiento de otras características del modelo (por ejemplo, la configuración de la propiedad `training` de `nn.Module`). Por lo tanto, *siempre* debe llamarse al objeto de modelo como si fuera una función (`model(input)`).\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Referencias**\n",
    "\n",
    "1.  **Tutorial oficial de PyTorch:** [https://pytorch.org/tutorials/](https://www.google.com/url?sa=E&source=gmail&q=https://pytorch.org/tutorials/)\n",
    "2.  **Deep Learning with PyTorch (Stevens, Antiga, Viehmann, 2020):** [https://pytorch.org/deep-learning-with-pytorch](https://www.google.com/search?q=https://pytorch.org/deep-learning-with-pytorch)\n",
    "3.  **Programming PyTorch for Deep Learning (Delugach, 2023):** [https://www.oreilly.com/library/view/programming-pytorch-for/9781098142481/](https://www.google.com/search?q=https://www.oreilly.com/library/view/programming-pytorch-for/9781098142481/)\n",
    "4.  **PyTorch Recipes (Kalyan, 2019):** [https://pytorch.org/tutorials/recipes/recipes\\_index.html](https://www.google.com/url?sa=E&source=gmail&q=https://pytorch.org/tutorials/recipes/recipes_index.html)\n",
    "5.  **Understanding the difficulty of training deep feedforward neural networks (Glorot & Bengio, 2010):** [http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf)\n",
    "6.  **Biblioteca Fastai:** [https://docs.fast.ai/](https://www.google.com/url?sa=E&source=gmail&q=https://docs.fast.ai/)\n",
    "7.  **PyTorch Lightning:** [https://www.pytorchlightning.ai/](https://www.google.com/url?sa=E&source=gmail&q=https://www.pytorchlightning.ai/)\n",
    "8.  **Documentación de Hugging Face Transformers:** [https://huggingface.co/docs/transformers/index](https://www.google.com/url?sa=E&source=gmail&q=https://huggingface.co/docs/transformers/index)\n",
    "9.  **Documentación de TensorBoard:** [https://www.tensorflow.org/tensorboard](https://www.google.com/url?sa=E&source=gmail&q=https://www.tensorflow.org/tensorboard)\n",
    "10. **Documentación de Weights & Biases:** [https://docs.wandb.ai/](https://www.google.com/url?sa=E&source=gmail&q=https://docs.wandb.ai/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
