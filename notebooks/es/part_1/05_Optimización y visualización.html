<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>optimización-y-visualización – Deep Learning DNA: Surviving Architectures and Essential Principles</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-f507c7d0488cb7630e20aad62ad8c2aa.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>
<script>window.MathJax = {loader: {load: ['[tex]/boldsymbol']},tex: {packages: {'[+]': ['boldsymbol']}}};</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../notebooks/es/part_1/01_El inicio del aprendizaje profundo.html">part_1</a></li><li class="breadcrumb-item"><a href="../../../notebooks/es/part_1/05_Optimización y visualización.html">5. Optimización y visualización</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../../">Español</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Language</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index_de.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Deutsch</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index_en.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">English</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index_es.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Español</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">한국어</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index_zh.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">中文</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/00_Introducción.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introducción</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">part_1</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/01_El inicio del aprendizaje profundo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1. El inicio del aprendizaje profundo</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/02_Matemáticas de deep learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2. Matemáticas de deep learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/03_marco de aprendizaje profundo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3. marco de aprendizaje profundo</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/04_función de activación.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4. función de activación</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/05_Optimización y visualización.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">5. Optimización y visualización</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/06_Sobreajuste y desarrollo de técnicas de solución.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">6. Sobreajuste y desarrollo de técnicas de solución</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/07_Evolución de las redes neuronales convolucionales.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">7. Evolución de las redes neuronales convolucionales</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/08_El nacimiento del transformer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8. El nacimiento del transformer</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/09_La evolución del transformer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">9. La evolución del transformer</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/10_Multimodal deep learning: el inicio de la fusión multisensorial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">10. Multimodal deep learning: el inicio de la fusión multisensorial</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/11_Multimodal deep learning: inteligencia más allá de los límites.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">11. Multimodal deep learning: inteligencia más allá de los límites</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">la vanguardia del deep learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/la vanguardia del deep learning/01_SLM: pequeño pero poderoso modelo de lenguaje.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1. SLM: pequeño pero poderoso modelo de lenguaje</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/la vanguardia del deep learning/02_conducción autónoma.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2. conducción autónoma</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#optimización-y-visualización" id="toc-optimización-y-visualización" class="nav-link active" data-scroll-target="#optimización-y-visualización">5. Optimización y visualización</a>
  <ul class="collapse">
  <li><a href="#evolución-y-enfoque-moderno-en-la-inicialización-de-parámetros" id="toc-evolución-y-enfoque-moderno-en-la-inicialización-de-parámetros" class="nav-link" data-scroll-target="#evolución-y-enfoque-moderno-en-la-inicialización-de-parámetros">5.1 Evolución y enfoque moderno en la inicialización de parámetros</a>
  <ul class="collapse">
  <li><a href="#principios-matemáticos-de-los-métodos-de-inicialización" id="toc-principios-matemáticos-de-los-métodos-de-inicialización" class="nav-link" data-scroll-target="#principios-matemáticos-de-los-métodos-de-inicialización">5.1.1 Principios matemáticos de los métodos de inicialización</a></li>
  <li><a href="#métodos-de-inicialización-análisis-comparativo-práctico" id="toc-métodos-de-inicialización-análisis-comparativo-práctico" class="nav-link" data-scroll-target="#métodos-de-inicialización-análisis-comparativo-práctico">5.1.2 Métodos de inicialización: análisis comparativo práctico</a></li>
  <li><a href="#recomendaciones-prácticas-y-consideraciones-adicionales" id="toc-recomendaciones-prácticas-y-consideraciones-adicionales" class="nav-link" data-scroll-target="#recomendaciones-prácticas-y-consideraciones-adicionales">5.1.3 Recomendaciones prácticas y consideraciones adicionales</a></li>
  </ul></li>
  <li><a href="#algoritmos-de-optimización-el-motor-central-del-aprendizaje-profundo" id="toc-algoritmos-de-optimización-el-motor-central-del-aprendizaje-profundo" class="nav-link" data-scroll-target="#algoritmos-de-optimización-el-motor-central-del-aprendizaje-profundo">5.2 Algoritmos de optimización: el motor central del aprendizaje profundo</a>
  <ul class="collapse">
  <li><a href="#evolución-e-implementación-de-algoritmos-de-optimización---una-evolución-continua" id="toc-evolución-e-implementación-de-algoritmos-de-optimización---una-evolución-continua" class="nav-link" data-scroll-target="#evolución-e-implementación-de-algoritmos-de-optimización---una-evolución-continua">5.2.1 Evolución e implementación de algoritmos de optimización - una evolución continua</a></li>
  <li><a href="#comparación-de-entrenamiento-de-optimización" id="toc-comparación-de-entrenamiento-de-optimización" class="nav-link" data-scroll-target="#comparación-de-entrenamiento-de-optimización">5.2.2 Comparación de entrenamiento de optimización</a></li>
  </ul></li>
  <li><a href="#visualización-y-análisis-del-proceso-de-optimización-mirando-dentro-de-la-caja-negra-del-aprendizaje-profundo" id="toc-visualización-y-análisis-del-proceso-de-optimización-mirando-dentro-de-la-caja-negra-del-aprendizaje-profundo" class="nav-link" data-scroll-target="#visualización-y-análisis-del-proceso-de-optimización-mirando-dentro-de-la-caja-negra-del-aprendizaje-profundo">5.3 Visualización y análisis del proceso de optimización: Mirando dentro de la caja negra del aprendizaje profundo</a>
  <ul class="collapse">
  <li><a href="#comprensión-de-la-superficie-de-pérdida-loss-landscape-el-mapa-topográfico-del-modelo-de-aprendizaje-profundo" id="toc-comprensión-de-la-superficie-de-pérdida-loss-landscape-el-mapa-topográfico-del-modelo-de-aprendizaje-profundo" class="nav-link" data-scroll-target="#comprensión-de-la-superficie-de-pérdida-loss-landscape-el-mapa-topográfico-del-modelo-de-aprendizaje-profundo">5.3.1 Comprensión de la Superficie de Pérdida (Loss Landscape): El mapa topográfico del modelo de aprendizaje profundo</a></li>
  <li><a href="#técnicas-avanzadas-de-análisis-de-la-superficie-de-pérdida" id="toc-técnicas-avanzadas-de-análisis-de-la-superficie-de-pérdida" class="nav-link" data-scroll-target="#técnicas-avanzadas-de-análisis-de-la-superficie-de-pérdida">5.3.2 Técnicas avanzadas de análisis de la superficie de pérdida</a></li>
  </ul></li>
  <li><a href="#visualización-del-proceso-de-optimización-explorando-los-secretos-del-aprendizaje-profundo-con-la-función-gaussiana" id="toc-visualización-del-proceso-de-optimización-explorando-los-secretos-del-aprendizaje-profundo-con-la-función-gaussiana" class="nav-link" data-scroll-target="#visualización-del-proceso-de-optimización-explorando-los-secretos-del-aprendizaje-profundo-con-la-función-gaussiana">5.4 Visualización del proceso de optimización: explorando los secretos del aprendizaje profundo con la función gaussiana</a>
  <ul class="collapse">
  <li><a href="#análisis-aproximado-mediante-funciones-gaussianas-insights-ocultos-en-la-simplicidad" id="toc-análisis-aproximado-mediante-funciones-gaussianas-insights-ocultos-en-la-simplicidad" class="nav-link" data-scroll-target="#análisis-aproximado-mediante-funciones-gaussianas-insights-ocultos-en-la-simplicidad">5.4.1 Análisis aproximado mediante funciones gaussianas: insights ocultos en la simplicidad</a></li>
  <li><a href="#visualización-de-trayectorias" id="toc-visualización-de-trayectorias" class="nav-link" data-scroll-target="#visualización-de-trayectorias">5.4.2 Visualización de trayectorias</a></li>
  </ul></li>
  <li><a href="#análisis-dinámico-del-proceso-de-optimización-exploración-de-la-trayectoria-de-aprendizaje" id="toc-análisis-dinámico-del-proceso-de-optimización-exploración-de-la-trayectoria-de-aprendizaje" class="nav-link" data-scroll-target="#análisis-dinámico-del-proceso-de-optimización-exploración-de-la-trayectoria-de-aprendizaje">5.5 Análisis dinámico del proceso de optimización: exploración de la trayectoria de aprendizaje</a>
  <ul class="collapse">
  <li><a href="#características-del-proceso-de-entrenamiento" id="toc-características-del-proceso-de-entrenamiento" class="nav-link" data-scroll-target="#características-del-proceso-de-entrenamiento">5.5.1 Características del proceso de entrenamiento</a></li>
  <li><a href="#análisis-y-control-de-estabilidad-del-aprendizaje" id="toc-análisis-y-control-de-estabilidad-del-aprendizaje" class="nav-link" data-scroll-target="#análisis-y-control-de-estabilidad-del-aprendizaje">5.5.2 Análisis y control de estabilidad del aprendizaje</a></li>
  <li><a href="#conclusión" id="toc-conclusión" class="nav-link" data-scroll-target="#conclusión">Conclusión</a></li>
  <li><a href="#ejercicios-de-práctica" id="toc-ejercicios-de-práctica" class="nav-link" data-scroll-target="#ejercicios-de-práctica">Ejercicios de práctica</a></li>
  <li><a href="#referencia" id="toc-referencia" class="nav-link" data-scroll-target="#referencia">Referencia</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../notebooks/es/part_1/01_El inicio del aprendizaje profundo.html">part_1</a></li><li class="breadcrumb-item"><a href="../../../notebooks/es/part_1/05_Optimización y visualización.html">5. Optimización y visualización</a></li></ol></nav></header>




<p><a href="https://colab.research.google.com/github/Quantum-Intelligence-Frontier/dldna/blob/main/notebooks/es/part_1/05_optimización_y_visualización.ipynb" target="_parent"> <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Abrir en Colab"> </a></p>
<section id="optimización-y-visualización" class="level1">
<h1>5. Optimización y visualización</h1>
<blockquote class="blockquote">
<p>“Entre la teoría y la práctica, hay una diferencia más grande que la diferencia entre la teoría y la práctica.” - Yann LeCun, ganador del Premio Turing en 2018</p>
</blockquote>
<p>El éxito de los modelos de deep learning depende en gran medida de algoritmos de optimización eficaces y estrategias adecuadas de inicialización de pesos. En este capítulo, exploramos a fondo los métodos de optimización e inicialización que son elementos clave en el aprendizaje de modelos de deep learning, y presentamos formas de entender intuitivamente estos procesos a través de la visualización. Primero, examinamos el desarrollo y los principios matemáticos de diversos métodos de inicialización de pesos, que son fundamentales para el aprendizaje de redes neuronales. Luego, analizamos y comparamos las características y rendimiento de algoritmos de optimización modernos, comenzando con el descenso del gradiente (Gradient Descent), y pasando por Adam, Lion, Sophia, AdaFactor, entre otros. En particular, no solo exploramos los fundamentos teóricos, sino también cómo cada algoritmo funciona en la práctica durante el proceso de aprendizaje de modelos de deep learning a través de experimentación. Finalmente, presentamos diversas técnicas para visualizar y analizar espacios de funciones de pérdida (loss landscape) de alta dimensión, proporcionando una comprensión profunda de las dinámicas de aprendizaje de los modelos de deep learning.</p>
<section id="evolución-y-enfoque-moderno-en-la-inicialización-de-parámetros" class="level2">
<h2 class="anchored" data-anchor-id="evolución-y-enfoque-moderno-en-la-inicialización-de-parámetros">5.1 Evolución y enfoque moderno en la inicialización de parámetros</h2>
<p>La inicialización de parámetros en redes neuronales es un elemento clave que determina la convergencia, la eficiencia del aprendizaje y el rendimiento final del modelo. Una inicialización incorrecta puede ser una causa principal de fallos en el aprendizaje. PyTorch proporciona diversos métodos de inicialización a través del módulo torch.nn.init, y se pueden encontrar detalles adicionales en la <a href="https://pytorch.org/docs/stable/nn.init.html">documentación oficial</a>. La evolución de los métodos de inicialización refleja el esfuerzo de los investigadores de deep learning para superar las dificultades del aprendizaje en redes neuronales. En particular, una inicialización inadecuada puede causar problemas como la desaparición (vanishing gradient) o explosión (exploding gradient) del gradiente, que son obstáculos principales para el aprendizaje en redes neuronales profundas. Con la aparición de modelos de lenguaje a gran escala (Large Language Models, LLMs) como GPT-3 y LaMDA, la importancia de la inicialización se ha destacado aún más. A medida que aumenta el tamaño del modelo, la distribución de los parámetros iniciales tiene un impacto cada vez mayor en las primeras etapas del aprendizaje. Por lo tanto, seleccionar una estrategia de inicialización adecuada según las características y el tamaño del modelo se ha convertido en una etapa esencial en el desarrollo de modelos de deep learning.</p>
<section id="principios-matemáticos-de-los-métodos-de-inicialización" class="level3">
<h3 class="anchored" data-anchor-id="principios-matemáticos-de-los-métodos-de-inicialización">5.1.1 Principios matemáticos de los métodos de inicialización</h3>
<p>El desarrollo de los métodos de inicialización de redes neuronales es resultado de un profundo trabajo teórico y numerosas validaciones experimentales. Cada método de inicialización ha sido diseñado para abordar situaciones específicas (por ejemplo, el uso de funciones de activación particulares, la profundidad de la red, el tipo de modelo) o para mejorar las dinámicas de aprendizaje, evolucionando con el tiempo para enfrentar nuevos desafíos.</p>
<p>A continuación se presentan los métodos de inicialización que serán analizados y comparados en detalle en este libro. (El código completo de implementación está incluido en el archivo chapter_04/initialization/base.py.)</p>
<div id="cell-2" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install dldna[colab] <span class="co"># in Colab</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip install dldna[all] # in your local</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>load_ext autoreload</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>autoreload <span class="dv">2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="cell-3" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Set seed</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">7</span>)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">7</span>)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_05.initialization.base <span class="im">import</span> init_methods, init_weights_lecun, init_weights_scaled_orthogonal, init_weights_lmomentum <span class="co"># init_weights_emergence, init_weights_dynamic 삭제</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>init_methods <span class="op">=</span> {</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Historical/Educational Significance</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">'lecun'</span>: init_weights_lecun,        <span class="co"># The first systematic initialization proposed in 1998</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">'xavier_normal'</span>: nn.init.xavier_normal_, <span class="co"># Key to the revival of deep learning in 2010</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">'kaiming_normal'</span>: nn.init.kaiming_normal_, <span class="co"># Standard for the ReLU era, 2015</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Modern Standard</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    <span class="st">'orthogonal'</span>: nn.init.orthogonal_,  <span class="co"># Important in RNN/LSTM</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    <span class="st">'scaled_orthogonal'</span>: init_weights_scaled_orthogonal, <span class="co"># Optimization of deep neural networks</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2024 Latest Research</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>    <span class="st">'l-momentum'</span>: init_weights_lmomentum <span class="co"># L-Momentum Initialization</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<section id="inicialización-tradicional" class="level5">
<h5 class="anchored" data-anchor-id="inicialización-tradicional">Inicialización Tradicional</h5>
<ul>
<li><p><strong>Inicialización de LeCun (1998):</strong> <span class="math inline">\(std = \sqrt{\frac{1}{n_{in}}}\)</span></p>
<ul>
<li>Método propuesto por Yann LeCun en 1998, que determina la desviación estándar de los pesos considerando solo la dimensión de entrada (<span class="math inline">\(n_{in}\)</span>). Se diseñó para evitar que las salidas de cada neurona varíen significativamente con el número de entradas. Sin embargo, en redes profundas, tendía a reducir la varianza de los valores de activación a medida que se profundizaba en las capas. <em>Este problema era particularmente notable cuando se utilizaban funciones de activación sigmoidales como tanh.</em></li>
</ul></li>
</ul>
</section>
<section id="inicialización-moderna" class="level5">
<h5 class="anchored" data-anchor-id="inicialización-moderna">Inicialización Moderna</h5>
<ul>
<li><p><strong>Inicialización Xavier (Glorot, 2010):</strong> <span class="math inline">\(std = \sqrt{\frac{2}{n_{in} + n_{out}}}\)</span></p>
<ul>
<li>Método propuesto por Xavier Glorot y Yoshua Bengio que considera tanto la dimensión de entrada (<span class="math inline">\(n_{in}\)</span>) como la de salida (<span class="math inline">\(n_{out}\)</span>) para mitigar el problema del desvanecimiento/explotación de gradientes. El objetivo es mantener adecuadamente la varianza de los valores de activación y los gradientes en cada capa. <em>Es particularmente efectivo cuando se utiliza con funciones de activación saturadas como sigmoid, tanh.</em></li>
</ul></li>
<li><p><strong>Inicialización Kaiming (He, 2015):</strong> <span class="math inline">\(std = \sqrt{\frac{2}{n_{in}}}\)</span></p>
<ul>
<li>Método propuesto por Kaiming He y otros que considera las características de la función de activación ReLU (que convierte los valores negativos en cero). Dado que ReLU tiende a reducir la varianza de los valores de activación a la mitad, se utiliza una varianza mayor (<span class="math inline">\(\sqrt{2}\)</span> veces) que la inicialización Xavier para compensar esto. <em>Esto reduce el problema de “neuronas muertas” y permite un aprendizaje estable en redes profundas, convirtiéndose en un estándar de facto cuando se utilizan funciones de activación tipo ReLU.</em></li>
</ul></li>
</ul>
</section>
<section id="últimas-inicializaciones-después-de-2023" class="level5">
<h5 class="anchored" data-anchor-id="últimas-inicializaciones-después-de-2023">Últimas Inicializaciones (después de 2023)</h5>
<ul>
<li><strong>Inicialización L-Momentum (Zhuang, 2024)</strong>
<ul>
<li><p>La inicialización L-Momentum es un método propuesto en 2024 que controla el L-momentum de las matrices de pesos iniciales, inspirado en los algoritmos de optimización basados en momentum.</p></li>
<li><p><strong>Fórmula:</strong></p>
<p><span class="math inline">\(W \sim U(-\sqrt{\frac{6}{n_{in}}}, \sqrt{\frac{6}{n_{in}}})\)</span> <span class="math inline">\(W = W \cdot \sqrt{\frac{\alpha}{Var(W)}}\)</span></p>
<p>Donde <span class="math inline">\(U\)</span> es una distribución uniforme, y <span class="math inline">\(\alpha\)</span> es un valor que representa el L-momentum, utilizando el cuadrado del momentum del optimizador.</p></li>
<li><p>El objetivo es reducir la variabilidad de los gradientes en las etapas iniciales para proporcionar una ruta de aprendizaje más estable.</p></li>
<li><p>Es aplicable a diversos optimizadores y funciones de activación, y ha demostrado contribuir a tasas de aprendizaje más altas, convergencia rápida y mejor desempeño general.</p></li>
</ul></li>
</ul>
</section>
<section id="principios-matemáticos" class="level5">
<h5 class="anchored">Principios Matemáticos</h5>
<p>La mayoría de los métodos de inicialización moderna siguen (explícita o implícitamente) los siguientes tres principios fundamentales.</p>
<ol type="1">
<li><p><strong>Preservación de Varianza (Variance Preservation):</strong> La varianza de los valores de activación durante la propagación hacia adelante y la varianza de los gradientes durante la propagación hacia atrás deben mantenerse constantes en cada capa.</p>
<p><span class="math inline">\(Var(y) \approx Var(x)\)</span></p>
<p>Esto ayuda a evitar que las señales se vuelvan demasiado grandes o pequeñas, facilitando un aprendizaje más estable.</p></li>
<li><p><strong>Control Espectral (Spectral Control):</strong> Se debe controlar la distribución de los valores singulares de la matriz de pesos para garantizar la estabilidad numérica durante el proceso de aprendizaje.</p>
<p><span class="math inline">\(\sigma_{max}(W) / \sigma_{min}(W) \leq C\)</span></p>
<p>Esto es particularmente importante en estructuras como las redes neuronales recurrentes (RNN), donde la matriz de pesos se multiplica repetidamente.</p></li>
<li><p><strong>Optimización de la expresividad (Expressivity Optimization):</strong> se debe maximizar el rango efectivo de las matrices de pesos para que la red tenga una suficiente capacidad de expresión.</p>
<p><span class="math inline">\(rank_{eff}(W) = \frac{\sum_i \sigma_i}{\max_i \sigma_i}\)</span> <em>Las investigaciones recientes han estado esforzándose por satisfacer explícitamente estos principios.</em></p></li>
</ol>
<p>En conclusión, el método de inicialización debe seleccionarse cuidadosamente teniendo en cuenta la interacción con el tamaño del modelo, su estructura, las funciones de activación y los algoritmos de optimización. Esto se debe a que tiene un gran impacto en la velocidad de aprendizaje, la estabilidad y el rendimiento final del modelo.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Haga clic para ver el contenido (deep dive: principios matemáticos y técnicas avanzadas de la inicialización de redes neuronales profundas)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Haga clic para ver el contenido (deep dive: principios matemáticos y técnicas avanzadas de la inicialización de redes neuronales profundas)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<section id="principios-matemáticos-y-técnicas-avanzadas-de-inicialización-de-redes-neuronales-profundas" class="level3">
<h3 class="anchored" data-anchor-id="principios-matemáticos-y-técnicas-avanzadas-de-inicialización-de-redes-neuronales-profundas">Principios matemáticos y técnicas avanzadas de inicialización de redes neuronales profundas</h3>
<section id="principio-de-preservación-de-la-varianza-variance-preservation-principle" class="level4">
<h4 class="anchored" data-anchor-id="principio-de-preservación-de-la-varianza-variance-preservation-principle">1. Principio de preservación de la varianza (Variance Preservation Principle)</h4>
<section id="fundamento-teórico" class="level5">
<h5 class="anchored" data-anchor-id="fundamento-teórico">1.1 Fundamento teórico</h5>
<p>A medida que aumenta la profundidad de la red neuronal, es muy importante preservar las características estadísticas del señal (especialmente la varianza) durante el proceso de propagación hacia adelante (forward propagation) y el proceso de retropropagación (backpropagation). Esto evita que la señal se desvanezca (vanishing) o explote (exploding), lo cual permite un aprendizaje estable.</p>
<p>Denotemos los valores de activación del <span class="math inline">\(l\)</span>-ésimo nivel como <span class="math inline">\(h_l\)</span>, la matriz de pesos como <span class="math inline">\(W_l\)</span>, el sesgo como <span class="math inline">\(b_l\)</span>, y la función de activación como <span class="math inline">\(f\)</span>. La propagación hacia adelante se expresa de la siguiente manera:</p>
<p><span class="math inline">\(h_l = f(W_l h_{l-1} + b_l)\)</span></p>
<p>Si asumimos que los elementos del señal de entrada <span class="math inline">\(h_{l-1} \in \mathbb{R}^{n_{in}}\)</span> son variables aleatorias independientes con media 0 y varianza <span class="math inline">\(\sigma^2_{h_{l-1}}\)</span>, y que los elementos de la matriz de pesos <span class="math inline">\(W_l \in \mathbb{R}^{n_{out} \times n_{in}}\)</span> son variables aleatorias independientes con media 0 y varianza <span class="math inline">\(Var(W_l)\)</span>, y el sesgo <span class="math inline">\(b_l = 0\)</span>, entonces, <em>asumiendo que la función de activación es lineal</em>, se tiene:</p>
<p><span class="math inline">\(Var(h_l) = n_{in} Var(W_l) Var(h_{l-1})\)</span> (donde <span class="math inline">\(n_{in}\)</span> es la dimensión de entrada del <span class="math inline">\(l\)</span>-ésimo nivel)</p>
<p>Para preservar la varianza de los valores de activación, debe cumplirse que <span class="math inline">\(Var(h_l) = Var(h_{l-1})\)</span>, por lo tanto, se necesita que <span class="math inline">\(Var(W_l) = 1/n_{in}\)</span>.</p>
<p>Durante la retropropagación, para el error <span class="math inline">\(\delta_l = \frac{\partial L}{\partial h_l}\)</span> (donde <span class="math inline">\(L\)</span> es la función de pérdida), se cumple la siguiente relación:</p>
<p><span class="math inline">\(\delta_{l-1} = W_l^T \delta_l\)</span> (asumiendo que la función de activación es lineal)</p>
<p>Por lo tanto, para preservar la varianza durante la retropropagación, debe cumplirse que <span class="math inline">\(Var(\delta_{l-1}) = n_{out}Var(W_l)Var(\delta_l)\)</span>, por lo tanto, se necesita que <span class="math inline">\(Var(W_l) = 1/n_{out}\)</span> (donde <span class="math inline">\(n_{out}\)</span> es la dimensión de salida del <span class="math inline">\(l\)</span>-ésimo nivel).</p>
</section>
<section id="extensión-a-funciones-de-activación-no-lineales" class="level5">
<h5 class="anchored" data-anchor-id="extensión-a-funciones-de-activación-no-lineales">1.2 Extensión a funciones de activación no lineales</h5>
<p><strong>Función de activación ReLU</strong></p>
<p>La función ReLU (<span class="math inline">\(f(x) = max(0, x)\)</span>) tiende a reducir la varianza de los valores de activación porque anula la mitad de las entradas. Kaiming He propuso corregir esto utilizando la siguiente fórmula de preservación de la varianza:</p>
<p><span class="math inline">\(Var(W_l) = \frac{2}{n_{in}} \quad (\text{especial para ReLU})\)</span></p>
<p>Esta fórmula compensa la reducción de varianza causada por el paso a través de ReLU, aumentándola en un factor de 2.</p>
<p><strong>Función de activación Leaky ReLU</strong></p>
<p>Para la función Leaky ReLU (<span class="math inline">\(f(x) = max(\alpha x, x)\)</span>, donde <span class="math inline">\(\alpha\)</span> es una constante pequeña), la fórmula generalizada es:</p>
<p><span class="math inline">\(Var(W_l) = \frac{2}{(1 + \alpha^2) n_{in}}\)</span></p>
</section>
<section id="enfoque-probabilístico-referencia" class="level5">
<h5 class="anchored" data-anchor-id="enfoque-probabilístico-referencia">1.3 Enfoque probabilístico (referencia)</h5>
<p>También se puede utilizar el inverso de la matriz de información de Fisher (FIM) para inicializar los pesos. La FIM contiene información sobre la curvatura del espacio de parámetros, lo cual permite una inicialización más eficiente. (Para más detalles, ver [4] Martens, 2020).</p>
</section>
</section>
<section id="control-espectral-spectral-control" class="level4">
<h4 class="anchored" data-anchor-id="control-espectral-spectral-control">2. Control espectral (Spectral Control)</h4>
<section id="descomposición-en-valores-singulares-y-dinámica-del-aprendizaje" class="level5">
<h5 class="anchored" data-anchor-id="descomposición-en-valores-singulares-y-dinámica-del-aprendizaje">2.1 Descomposición en valores singulares y dinámica del aprendizaje</h5>
<p>La descomposición en valores singulares (Singular Value Decomposition, SVD) de la matriz de pesos <span class="math inline">\(W \in \mathbb{R}^{m \times n}\)</span> se expresa como <span class="math inline">\(W = U\Sigma V^T\)</span>. Aquí, <span class="math inline">\(\Sigma\)</span> es una matriz diagonal, cuyos elementos diagonales son los valores singulares de <span class="math inline">\(W\)</span> (<span class="math inline">\(\sigma_1 \geq \sigma_2 \geq ... \geq 0\)</span>). Si el valor singular máximo de la matriz de pesos (<span class="math inline">\(\sigma_{max}\)</span>) es demasiado grande, puede causar un gradiente explosivo (exploding gradient), y si el valor singular mínimo (<span class="math inline">\(\sigma_{min}\)</span>) es demasiado pequeño, puede causar un gradiente desvanecido (vanishing gradient).</p>
<p>Por lo tanto, es importante controlar la proporción de los valores singulares (número de condición, condition number) <span class="math inline">\(\kappa = \sigma_{max}/\sigma_{min}\)</span>. Cuanto más cercano a 1 sea <span class="math inline">\(\kappa\)</span>, mayor será la estabilidad del flujo de gradientes.</p>
<p><strong>Teorema 2.1 (Saxe et al., 2014)</strong>: En una red neuronal lineal profunda inicializada ortogonalmente, si cada matriz de pesos <span class="math inline">\(W_l\)</span> es una matriz ortogonal, la norma Frobenius de la matriz jacobiana <span class="math inline">\(J\)</span> del output con respecto a la entrada se mantiene en 1.</p>
<p><span class="math inline">\(||J||_F = 1\)</span></p>
<p>Esto ayuda a mitigar los problemas de gradiente desvanecido o explosivo incluso en redes muy profundas.</p>
</section>
<section id="normalización-espectral-dinámica" class="level5">
<h5 class="anchored" data-anchor-id="normalización-espectral-dinámica">2.2 Normalización espectral dinámica</h5>
<p>Miyato et al.&nbsp;(2018) propusieron la técnica de Normalización Espectral para mejorar la estabilidad del entrenamiento de GANs, limitando la norma espectral (valor singular máximo) de las matrices de pesos.</p>
<p><span class="math inline">\(W_{SN} = \frac{W}{\sigma_{max}(W)}\)</span></p>
<p>Este método ha demostrado ser particularmente efectivo en el entrenamiento de GANs y recientemente se ha aplicado a otros modelos, como Vision Transformers.</p>
</section>
</section>
<section id="optimización-de-la-expresividad" class="level4">
<h4 class="anchored" data-anchor-id="optimización-de-la-expresividad">3. Optimización de la expresividad</h4>
<section id="teoría-del-rango-efectivo" class="level5">
<h5 class="anchored" data-anchor-id="teoría-del-rango-efectivo">3.1 Teoría del rango efectivo</h5>
<p>La capacidad de una matriz de pesos <span class="math inline">\(W\)</span> para representar diversas características (features) puede medirse por la uniformidad de la distribución de los valores singulares. El rango efectivo se define como:</p>
<p><span class="math inline">\(\text{rank}_{eff}(W) = \exp\left( -\sum_{i=1}^r p_i \ln p_i \right) \quad \text{donde } p_i = \frac{\sigma_i}{\sum_j \sigma_j}\)</span></p>
<p>Aquí, <span class="math inline">\(r\)</span> es el rango de <span class="math inline">\(W\)</span>, <span class="math inline">\(\sigma_i\)</span> es el <span class="math inline">\(i\)</span>-ésimo valor singular y <span class="math inline">\(p_i\)</span> es el valor singular normalizado. El rango efectivo es una métrica que indica la distribución de los valores singulares; cuanto mayor sea su valor, más uniformemente distribuidos estarán los valores singulares, lo cual implica una mayor expresividad.</p>
</section>
<section id="tabla-de-comparación-de-estrategias-de-inicialización" class="level5">
<h5 class="anchored" data-anchor-id="tabla-de-comparación-de-estrategias-de-inicialización">3.2 Tabla de comparación de estrategias de inicialización</h5>
<table class="caption-top table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>Estrategia</th>
<th>Descripción</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Inicialización aleatoria</td>
<td>Los pesos se inicializan con valores aleatorios.</td>
</tr>
<tr class="even">
<td>Inicialización Xavier/Glorot</td>
<td>Los pesos se inicializan con una distribución normal o uniforme, ajustando la varianza para mantener el flujo de gradientes estable.</td>
</tr>
<tr class="odd">
<td>Inicialización He</td>
<td>Similar a Xavier, pero optimizada para funciones de activación ReLU.</td>
</tr>
<tr class="even">
<td>Inicialización ortogonal</td>
<td>Los pesos se inicializan como matrices ortogonales para mantener la norma Frobenius del Jacobiano en 1.</td>
</tr>
<tr class="odd">
<td>Método de inicialización</td>
<td>Distribución de valores singulares</td>
</tr>
<tr class="even">
<td>————————</td>
<td>————————————————————————————————–</td>
</tr>
<tr class="odd">
<td>Xavier</td>
<td>Disminuye relativamente rápidamente</td>
</tr>
<tr class="even">
<td>Kaiming</td>
<td>Ajustado para la función de activación ReLU (disminuye menos)</td>
</tr>
<tr class="odd">
<td>Ortogonal</td>
<td>Todos los valores singulares son 1</td>
</tr>
<tr class="even">
<td>Promoviendo Emergencia</td>
<td>Se ajusta según el tamaño de la red, disminuye relativamente lentamente (cercano a una distribución heavy-tailed)</td>
</tr>
</tbody>
</table>
</section>
<section id="inicialización-promoviendo-emergencia" class="level5">
<h5 class="anchored" data-anchor-id="inicialización-promoviendo-emergencia">3.3 Inicialización Promoviendo Emergencia</h5>
<p>La inicialización Promoviendo Emergencia es una técnica reciente propuesta para fomentar habilidades emergentes en modelos de lenguaje a gran escala (LLM). Este método ajusta la varianza de los pesos iniciales según el tamaño de la red (específicamente, la profundidad de las capas), lo que tiene el efecto de aumentar el rango efectivo.</p>
<p>Chen et al.&nbsp;(2023) propusieron un factor de escala <span class="math inline">\(\nu_l\)</span> en modelos Transformer como sigue:</p>
<p><span class="math inline">\(\nu_l = \frac{1}{\sqrt{d_{in}}} \left( 1 + \frac{\ln l}{\ln d} \right)\)</span></p>
<p>Donde <span class="math inline">\(d_{in}\)</span> es la dimensión de entrada, <span class="math inline">\(l\)</span> es el índice de la capa, y <span class="math inline">\(d\)</span> es la profundidad del modelo. Este factor de escala se multiplica por la desviación estándar de las matrices de pesos para la inicialización. Es decir, se muestrean desde una distribución normal con <span class="math inline">\(\nu_l \sqrt{2/n_{in}}\)</span> como desviación estándar.</p>
</section>
</section>
<section id="interacción-entre-inicialización-y-optimización" class="level4">
<h4 class="anchored" data-anchor-id="interacción-entre-inicialización-y-optimización">4. Interacción entre inicialización y optimización</h4>
<section id="extensión-de-la-teoría-ntk" class="level5">
<h5 class="anchored" data-anchor-id="extensión-de-la-teoría-ntk">4.1 Extensión de la teoría NTK</h5>
<p>La teoría del Kernel Tangente Neuronal (NTK) de Jacot et al.&nbsp;(2018) es una herramienta útil para analizar la dinámica de aprendizaje en redes neuronales “muy anchas” (infinitely wide). Según la teoría NTK, se espera que la matriz hessiana de una red muy ancha sea proporcional a la identidad en el punto de inicialización. Es decir,</p>
<p><span class="math inline">\(\lim_{n_{in} \to \infty} \mathbb{E}[\nabla^2 \mathcal{L}] \propto I\)</span> (en el punto de inicialización)</p>
<p>Esto sugiere que la inicialización Xavier proporciona una inicialización cercana a lo óptimo en redes muy anchas.</p>
</section>
<section id="estrategias-de-inicialización-meta" class="level5">
<h5 class="anchored" data-anchor-id="estrategias-de-inicialización-meta">4.2 Estrategias de inicialización meta</h5>
<p>Investigaciones recientes, como MetaInit (2023), proponen métodos para aprender la distribución de inicialización óptima para una arquitectura y conjunto de datos dados a través del aprendizaje meta.</p>
<p><span class="math inline">\(\theta_{init} = \arg\min_\theta \mathbb{E}_{\mathcal{T}}[\mathcal{L}(\phi_{fine-tune}(\theta, \mathcal{T}))]\)</span></p>
<p>Donde <span class="math inline">\(\theta\)</span> son los parámetros de inicialización, <span class="math inline">\(\mathcal{T}\)</span> es la tarea de entrenamiento, y <span class="math inline">\(\phi\)</span> representa el proceso de fine-tuning de un modelo inicializado con <span class="math inline">\(\theta\)</span>.</p>
</section>
</section>
<section id="referencia-técnicas-de-inicialización-basadas-en-física" class="level4">
<h4 class="anchored" data-anchor-id="referencia-técnicas-de-inicialización-basadas-en-física">5. (Referencia) Técnicas de inicialización basadas en física</h4>
<p>Recientemente, también se están investigando métodos de inicialización inspirados en los principios de la física. Por ejemplo, se han propuesto métodos que imitan la ecuación de Schrödinger de la mecánica cuántica o las ecuaciones de Navier-Stokes de la dinámica de fluidos para optimizar el flujo de información entre capas. Sin embargo, estos métodos aún están en una etapa inicial de investigación y su utilidad práctica no ha sido verificada.</p>
</section>
<section id="recomendaciones-prácticas" class="level4">
<h4 class="anchored" data-anchor-id="recomendaciones-prácticas">6. Recomendaciones Prácticas</h4>
<ol type="1">
<li><strong>Arquitectura CNN:</strong> Generalmente es recomendable usar la inicialización Kaiming (He initialization) junto con la normalización por lotes (Batch Normalization).</li>
<li><strong>Transformadores:</strong> Se utilizan ampliamente la Inicialización Ortogonal Escalada (ajuste de valores singulares) o la inicialización Xavier.</li>
<li><strong>Modelos de Lenguaje Grandes (LLM):</strong> Deben considerarse métodos de inicialización especializados para modelos grandes, como la inicialización que promueve el surgimiento (Emergence-Promoting Initialization).</li>
<li><strong>Neural ODE:</strong> Se utilizan los métodos habituales a menos que haya una situación especial.</li>
</ol>
<hr>
</section>
</section>
<section id="referencias" class="level3">
<h3 class="anchored" data-anchor-id="referencias">Referencias</h3>
<ol type="1">
<li>He et al.&nbsp;“Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification”, ICCV 2015</li>
<li>Saxe et al.&nbsp;“Exact solutions to the nonlinear dynamics of learning in deep linear neural networks”, ICLR 2014</li>
<li>Jacot et al.&nbsp;“Neural Tangent Kernel: Convergence and Generalization in Neural Networks”, NeurIPS 2018</li>
<li>Martens, J. “New insights and perspectives on the natural gradient method.” The Journal of Machine Learning Research, 2020.</li>
<li>Chen et al.&nbsp;“Towards Understanding Large Language Models: A Transformative Reading List”, arXiv preprint arXiv:2307.12980, 2023. (Relacionado con la inicialización que promueve el surgimiento)</li>
<li>Miyato et al., “Spectral Normalization for Generative Adversarial Networks”, ICLR 2018</li>
</ol>
</section>
</div>
</div>
</div>
</section>
</section>
<section id="métodos-de-inicialización-análisis-comparativo-práctico" class="level3">
<h3 class="anchored" data-anchor-id="métodos-de-inicialización-análisis-comparativo-práctico">5.1.2 Métodos de inicialización: análisis comparativo práctico</h3>
<p>Para comprender cómo los diferentes métodos de inicialización vistos anteriormente afectan realmente el aprendizaje del modelo, realizaremos experimentos de comparación utilizando un modelo simple. Entrenaremos modelos con cada método de inicialización bajo las mismas condiciones y analizaremos los resultados. Los criterios de evaluación son los siguientes.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 18%">
<col style="width: 42%">
<col style="width: 38%">
</colgroup>
<thead>
<tr class="header">
<th>Criterio de Evaluación</th>
<th>Significado</th>
<th>Características Deseables</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Tasa de Error (%)</td>
<td>Rendimiento predictivo del modelo final (mejor si es bajo)</td>
<td>Mejor si es bajo</td>
</tr>
<tr class="even">
<td>Velocidad de Convergencia</td>
<td>Pendiente de la curva de aprendizaje (indicador de estabilidad de aprendizaje)</td>
<td>Baja (más empinada) converge más rápido</td>
</tr>
<tr class="odd">
<td>Número de Condición Promedio</td>
<td>Estabilidad numérica de las matrices de pesos</td>
<td>Mejor si es bajo (cercano a 1)</td>
</tr>
<tr class="even">
<td>Norma Espectral</td>
<td>Tamaño de la matriz de pesos (mayor valor singular)</td>
<td>Se necesita un valor adecuado, no demasiado grande ni pequeño</td>
</tr>
<tr class="odd">
<td>Razón de Rango Efectivo</td>
<td>Expresividad de la matriz de pesos (uniformidad en la distribución de valores singulares)</td>
<td>Mejor si es alta</td>
</tr>
<tr class="even">
<td>Tiempo de Ejecución(s)</td>
<td>Tiempo de aprendizaje</td>
<td>Mejor si es bajo</td>
</tr>
</tbody>
</table>
<div id="cell-7" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_04.models.base <span class="im">import</span> SimpleNetwork</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_04.utils.data <span class="im">import</span> get_data_loaders, get_device</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_05.initialization.base <span class="im">import</span> init_methods</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_05.initialization.analysis <span class="im">import</span> analyze_initialization, create_detailed_analysis_table</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> get_device()</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize data loaders</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>train_dataloader, test_dataloader <span class="op">=</span> get_data_loaders()</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Detailed analysis of initialization methods</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> analyze_initialization(</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    model_class<span class="op">=</span><span class="kw">lambda</span>: SimpleNetwork(act_func<span class="op">=</span>nn.PReLU()),</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    init_methods<span class="op">=</span>init_methods,</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    train_loader<span class="op">=</span>train_dataloader,</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    test_loader<span class="op">=</span>test_dataloader,</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    device<span class="op">=</span>device</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Print detailed analysis results table</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>create_detailed_analysis_table(results)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Initialization method: lecun</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f7415089fb524e58a3bc0648f03072a2","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/sean/Developments/expert_ai/books/dld/dld/chapter_04/experiments/model_training.py:320: UserWarning: std(): degrees of freedom is &lt;= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1823.)
  'std': param.data.std().item(),</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Initialization method: xavier_normal</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"29ce93b749b746c7a45214d8a3d878f9","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Initialization method: kaiming_normal</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"fd9357f07d154648991dcd18979512aa","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Initialization method: orthogonal</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"bdc4bd358cf64c8ea5002b02fad46550","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Initialization method: scaled_orthogonal</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e80c4b3368c249dd8edd6b4f4d125d62","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Initialization method: l-momentum</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"622b899e8de849aba61c8cec8bd7e078","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Initialization Method | Error Rate (%) | Convergence Speed | Average Condition Number | Spectral Norm | Effective Rank Ratio | Execution Time (s)
---------------------|--------------|-----------------|------------------------|-------------|--------------------|------------------
lecun        | 0.48 | 0.33 | 5.86 | 1.42 | 0.89 | 30.5
xavier_normal | 0.49 | 0.33 | 5.53 | 1.62 | 0.89 | 30.2
kaiming_normal | 0.45 | 0.33 | 5.85 | 1.96 | 0.89 | 30.1
orthogonal   | 0.49 | 0.33 | 1.00 | 0.88 | 0.95 | 30.0
scaled_orthogonal | 2.30 | 1.00 | 1.00 | 0.13 | 0.95 | 30.0
l-momentum   | nan | 0.00 | 5.48 | 19.02 | 0.89 | 30.1</code></pre>
</div>
</div>
<p>Los resultados del experimento se resumen en la siguiente tabla.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 16%">
<col style="width: 11%">
<col style="width: 13%">
<col style="width: 18%">
<col style="width: 10%">
<col style="width: 15%">
<col style="width: 14%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Método de Inicialización</th>
<th style="text-align: center;">Tasa de Error (%)</th>
<th style="text-align: center;">Velocidad de Convergencia</th>
<th style="text-align: center;">Número de Condición Promedio</th>
<th style="text-align: center;">Norma Espectral</th>
<th style="text-align: center;">Proporción de Rango Efectivo</th>
<th style="text-align: center;">Tiempo de Ejecución (s)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">lecun</td>
<td style="text-align: center;">0.48</td>
<td style="text-align: center;">0.33</td>
<td style="text-align: center;">5.66</td>
<td style="text-align: center;">1.39</td>
<td style="text-align: center;">0.89</td>
<td style="text-align: center;">23.3</td>
</tr>
<tr class="even">
<td style="text-align: left;">xavier_normal</td>
<td style="text-align: center;">0.48</td>
<td style="text-align: center;">0.33</td>
<td style="text-align: center;">5.60</td>
<td style="text-align: center;">1.64</td>
<td style="text-align: center;">0.89</td>
<td style="text-align: center;">23.2</td>
</tr>
<tr class="odd">
<td style="text-align: left;">kaiming_normal</td>
<td style="text-align: center;">0.45</td>
<td style="text-align: center;">0.33</td>
<td style="text-align: center;">5.52</td>
<td style="text-align: center;">1.98</td>
<td style="text-align: center;">0.89</td>
<td style="text-align: center;">23.2</td>
</tr>
<tr class="even">
<td style="text-align: left;">orthogonal</td>
<td style="text-align: center;">0.49</td>
<td style="text-align: center;">0.33</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.88</td>
<td style="text-align: center;">0.95</td>
<td style="text-align: center;">23.3</td>
</tr>
<tr class="odd">
<td style="text-align: left;">scaled_orthogonal</td>
<td style="text-align: center;">2.30</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.13</td>
<td style="text-align: center;">0.95</td>
<td style="text-align: center;">23.3</td>
</tr>
<tr class="even">
<td style="text-align: left;">l-momentum</td>
<td style="text-align: center;">nan</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">5.78</td>
<td style="text-align: center;">20.30</td>
<td style="text-align: center;">0.89</td>
<td style="text-align: center;">23.2</td>
</tr>
</tbody>
</table>
<p>Los puntos destacados de los resultados del experimento son los siguientes.</p>
<ol type="1">
<li><p><strong>Excelente rendimiento de la inicialización Kaiming:</strong> La inicialización Kaiming mostró la tasa de error más baja, con un 0.45%. Este resultado demuestra una combinación óptima con las funciones de activación ReLU, lo que confirma nuevamente la eficacia de la inicialización Kaiming cuando se usa con funciones del tipo ReLU.</p></li>
<li><p><strong>Estabilidad de los métodos ortogonales:</strong> La inicialización ortogonal mostró el número de condición más bajo (1.00), lo que indica una excelente estabilidad numérica. Esto significa que durante el proceso de aprendizaje, los gradientes no se distorsionan y se propagan correctamente, lo cual es particularmente importante en modelos como las redes neuronales recurrentes (RNN), donde las matrices de pesos se multiplican repetidamente. <em>Sin embargo, en este experimento la tasa de error fue relativamente alta, lo que podría deberse a las características del modelo utilizado (una MLP simple).</em></p></li>
<li><p><strong>Problemas con la inicialización ortogonal escalada:</strong> La inicialización ortogonal escalada mostró una tasa de error muy alta, del 2.30%. Esto sugiere que este método de inicialización no es adecuado para el modelo y conjunto de datos utilizados, o que se requieren ajustes adicionales de hiperparámetros. <em>Es posible que el factor de escala (scaling factor) sea demasiado pequeño, lo que impide un aprendizaje adecuado.</em></p></li>
<li><p><strong>Inestabilidad de la inicialización de L-Momentum</strong>: L-Momentum tiene una tasa de error y velocidad de convergencia de nan y 0.00, lo que indica que no se realizó ningún aprendizaje. El espectro norma de 20.30 es muy alto, lo que sugiere que los valores iniciales de los pesos podrían ser demasiado grandes, causando divergencia.</p></li>
</ol>
</section>
<section id="recomendaciones-prácticas-y-consideraciones-adicionales" class="level3">
<h3 class="anchored" data-anchor-id="recomendaciones-prácticas-y-consideraciones-adicionales">5.1.3 Recomendaciones prácticas y consideraciones adicionales</h3>
<p>La inicialización de modelos de deep learning es un <em>hiperparámetro</em> que debe seleccionarse cuidadosamente teniendo en cuenta la arquitectura del modelo, las funciones de activación, los algoritmos de optimización y las características del conjunto de datos. A continuación se presentan aspectos a considerar al elegir métodos de inicialización en la práctica.</p>
<section id="principios-básicos" class="level5">
<h5 class="anchored" data-anchor-id="principios-básicos">Principios básicos</h5>
<ul>
<li><strong>Funciones de activación ReLU:</strong>
<ul>
<li><strong>Inicialización Kaiming (He initialization):</strong> Este es el método de inicialización más utilizado actualmente con ReLU y sus variantes (Leaky ReLU, ELU, SELU, etc.). Está bien respaldado tanto por resultados experimentales como por fundamentos teóricos (preservación de la varianza).</li>
<li><strong>L-Momentum Initialization</strong>: Si se utilizan optimizadores basados en Momentum, como Adam o AdamW, esto puede ser una opción a considerar.</li>
</ul></li>
<li><strong>Funciones de activación Sigmoid, Tanh:</strong>
<ul>
<li><strong>Inicialización Xavier (Glorot initialization):</strong> Estas funciones de activación pueden sufrir el problema del desvanecimiento del gradiente (vanishing gradient problem) si los valores de entrada son muy grandes o muy pequeños. Por lo tanto, la inicialización Xavier sigue siendo una opción válida.</li>
</ul></li>
<li><strong>Redes neuronales recurrentes (RNN, LSTM, GRU):</strong>
<ul>
<li><strong>Inicialización Ortogonal:</strong> En modelos RNN con conexiones recurrentes, es importante mantener los valores singulares de las matrices de pesos cerca de 1. La inicialización ortogonal asegura esto y ayuda a mitigar problemas de explosión/degeneración del gradiente y facilita el aprendizaje de dependencias a largo plazo (long-range dependency).</li>
<li><em>Nota: La inicialización ortogonal se aplica típicamente a la matriz de pesos hidden-to-hidden en RNN, mientras que para la matriz de pesos input-to-hidden se suele usar otro método de inicialización (por ejemplo, Kaiming).</em></li>
</ul></li>
</ul>
</section>
<section id="escala-y-características-del-modelo" class="level5">
<h5 class="anchored" data-anchor-id="escala-y-características-del-modelo">Escala y características del modelo</h5>
<ul>
<li><strong>Redes neuronales profundas generales (menos de 50 capas):</strong>
<ul>
<li>En muchos casos, la inicialización Kaiming (para funciones ReLU) o Xavier (para Sigmoid/Tanh) es suficiente.</li>
</ul></li>
<li><strong>Redes neuronales muy profundas (más de 50 capas):</strong>
<ul>
<li><strong>Conexiones residuales (ResNet):</strong> Si el modelo tiene conexiones residuales, la inicialización Kaiming funciona bien.</li>
<li><strong>Sin conexiones residuales (ResNet):</strong> Se debe ser más cauteloso con la inicialización. Considerar métodos como Scaled Orthogonal o Fixup Initialization.</li>
</ul></li>
<li><strong>Modelos de gran escala (1B+ parámetros):</strong>
<ul>
<li><strong>L-Momentum Initialization</strong></li>
<li><strong>Inicialización a cero (en partes específicas):</strong> Inicializar a 0 ciertas partes del modelo, como la proyección de salida de capas de atención en modelos Transformer, puede ser efectivo. (Referencia: Megatron-LM)</li>
<li><em>Nota: Los modelos de gran escala tienden a ser inestables durante el entrenamiento, por lo que además de la inicialización, es importante combinar cuidadosamente otras técnicas como programación del tasa de aprendizaje, recorte de gradiente y métodos de regularización.</em></li>
</ul></li>
</ul>
</section>
<section id="consideraciones-adicionales" class="level5">
<h5 class="anchored" data-anchor-id="consideraciones-adicionales">Consideraciones adicionales</h5>
<ul>
<li><strong>Normalización por lotes (Batch Normalization) / Normalización de capa (Layer Normalization):</strong> las técnicas de normalización reducen <em>algo</em> la importancia de la inicialización, pero no la reemplazan completamente. Aún es recomendable elegir una inicialización adecuada.</li>
<li><strong>Aprendizaje por transferencia (Transfer Learning):</strong> cuando se utilizan modelos preentrenados, es común mantener los pesos preentrenados o aplicar la inicialización de Kaiming/Xavier con tasas de aprendizaje pequeñas solo a las capas que se afinarán.</li>
<li><strong>Algoritmos de optimización:</strong> dependiendo del optimizador utilizado, puede haber una inicialización más adecuada. Por ejemplo, si se utiliza el optimizador Adam, se puede aplicar la inicialización L-Momentum.</li>
<li><strong>Experimentación y validación:</strong> el mejor método de inicialización puede variar según el problema y los datos. Es importante probar varios métodos de inicialización y seleccionar el que ofrece el mejor rendimiento en el conjunto de validación.</li>
</ul>
<p>La inicialización es como el “héroe oculto” del aprendizaje profundo. Una inicialización adecuada puede determinar el éxito o fracaso del entrenamiento del modelo, maximizando su rendimiento y reduciendo significativamente el tiempo de entrenamiento. Basándose en las pautas presentadas en esta sección y las tendencias actuales de la investigación, esperamos que puedan encontrar la estrategia de inicialización más adecuada para sus modelos de aprendizaje profundo.</p>
</section>
</section>
</section>
<section id="algoritmos-de-optimización-el-motor-central-del-aprendizaje-profundo" class="level2">
<h2 class="anchored" data-anchor-id="algoritmos-de-optimización-el-motor-central-del-aprendizaje-profundo">5.2 Algoritmos de optimización: el motor central del aprendizaje profundo</h2>
<blockquote class="blockquote">
<p><strong>Desafío:</strong> ¿Cómo se pueden resolver los problemas de caer en mínimos locales (local minima) o que la velocidad de aprendizaje sea demasiado lenta con el descenso del gradiente (Gradient Descent)?</p>
<p><strong>Lamentación del investigador:</strong> Reducir simplemente la tasa de aprendizaje no fue suficiente. En algunos casos, el aprendizaje se volvió demasiado lento y tomaba mucho tiempo, mientras que en otros casos divergía y fallaba. Al igual que tanteando un camino montañoso envuelto en niebla, encontrar el óptimo ha sido una tarea ardua. Aparecieron diversos algoritmos de optimización como momentum, RMSProp y Adam, pero aún no existe una solución universal perfecta para todos los problemas.</p>
</blockquote>
<p>El impresionante desarrollo del aprendizaje profundo no solo se debe a la innovación en la estructura del modelo, sino también al <em>avance de los algoritmos de optimización eficientes</em>. Los algoritmos de optimización son como el motor central que automatiza y acelera el proceso de encontrar el mínimo de la función de pérdida. <em>La eficiencia y estabilidad de este motor determinan la velocidad de aprendizaje y el rendimiento final del modelo de aprendizaje profundo</em>.</p>
<section id="evolución-e-implementación-de-algoritmos-de-optimización---una-evolución-continua" class="level3">
<h3 class="anchored" data-anchor-id="evolución-e-implementación-de-algoritmos-de-optimización---una-evolución-continua">5.2.1 Evolución e implementación de algoritmos de optimización - una evolución continua</h3>
<p>Los algoritmos de optimización han evolucionado durante las últimas décadas, <em>al igual que los seres vivos</em>, resolviendo tres tareas centrales.</p>
<ol type="1">
<li><strong>Eficiencia computacional (Computational Efficiency):</strong> Se debe completar el aprendizaje lo más rápido posible con recursos de cómputo limitados.</li>
<li><strong>Rendimiento de generalización (Generalization Performance):</strong> Debe ofrecer un buen rendimiento no solo en los datos de entrenamiento, sino también en nuevos datos.</li>
<li><strong>Escala (Scalability):</strong> Debe funcionar de manera estable incluso cuando el tamaño del modelo y los datos aumenta.</li>
</ol>
<p>Cada desafío ha dado lugar a la creación de nuevos algoritmos, y la competencia por encontrar mejores algoritmos continúa hasta hoy.</p>
<section id="historia-de-los-algoritmos-de-optimización" class="level5">
<h5 class="anchored" data-anchor-id="historia-de-los-algoritmos-de-optimización">Historia de los algoritmos de optimización</h5>
<ul>
<li><strong>1847, Cauchy:</strong> Propuso el descenso del gradiente (Gradient Descent). Esta idea simple pero poderosa de ajustar ligeramente los parámetros siguiendo la pendiente (gradient) de la función de pérdida se convirtió en la base del aprendizaje profundo moderno.</li>
<li><strong>1951, Robbins y Monro:</strong> Establecieron las bases matemáticas del descenso del gradiente estocástico (Stochastic Gradient Descent, SGD). El SGD mejoró significativamente la eficiencia computacional al usar mini-lotes (mini-batch) en lugar de todo el conjunto de datos.</li>
<li><strong>1986, Rumelhart:</strong> Propuso el método de momentum junto con el algoritmo de retropropagación (Backpropagation). El momentum introduce inercia al proceso de optimización, lo que reduce las oscilaciones del SGD y mejora la velocidad de convergencia.</li>
<li><strong>2011, Duchi:</strong> Presentó el algoritmo AdaGrad. AdaGrad fue pionero en el ajuste adaptativo de la tasa de aprendizaje para cada parámetro.</li>
<li><strong>2012, Hinton:</strong> Propuso RMSProp. (Introducido en notas de clase, no publicado en un paper) RMSProp mejoró el problema de disminución de la tasa de aprendizaje en AdaGrad, permitiendo un aprendizaje más estable.</li>
<li><strong>2014, Kingma y Ba:</strong> Presentaron Adam (Adaptive Moment Estimation). Adam combina las ventajas del momentum y RMSProp, convirtiéndose en uno de los algoritmos de optimización más ampliamente utilizados actualmente.</li>
</ul>
<p>Los algoritmos de optimización recientes están evolucionando en tres direcciones principales. 1. <strong>Eficiencia de memoria:</strong> Lion, AdaFactor, entre otros, se centran en reducir el uso de memoria necesario para entrenar modelos a gran escala (especialmente basados en Transformer). 2. <strong>Optimización del aprendizaje distribuido:</strong> LAMB, LARS, entre otros, mejoran la eficiencia al entrenar modelos a gran escala en paralelo utilizando múltiples GPU/TPU. 3. <strong>Optimización especializada por dominio/tarea:</strong> Sophia, AdaBelief, entre otros, proporcionan un rendimiento optimizado para áreas de problema específicas (por ejemplo, procesamiento de lenguaje natural, visión por computadora) o estructuras de modelo específicas.</p>
<p><em>Especialmente con el surgimiento de modelos de lenguaje a gran escala (LLM) y modelos multimodales, se ha vuelto más importante optimizar eficientemente cientos de millones, incluso billones de parámetros, entrenar en entornos de memoria limitada y converger de manera estable en entornos distribuidos. Estos desafíos han llevado al surgimiento de nuevas técnicas como la optimización de 8 bits, ZeRO optimization, gradient checkpointing, entre otras.</em></p>
</section>
<section id="algoritmos-de-optimización-básicos" class="level5">
<h5 class="anchored" data-anchor-id="algoritmos-de-optimización-básicos">Algoritmos de optimización básicos</h5>
<p>En el aprendizaje profundo, los algoritmos de optimización desempeñan un papel crucial al buscar el mínimo del función de pérdida, es decir, encontrar los parámetros óptimos del modelo. Cada algoritmo tiene características y ventajas únicas, y es importante seleccionar el algoritmo adecuado según las características del problema y la estructura del modelo.</p>
<p><strong>SGD y momentum</strong></p>
<p>El descenso de gradiente estocástico (Stochastic Gradient Descent, SGD) es un algoritmo de optimización básico y ampliamente utilizado. En cada paso, utiliza datos de mini-lote (mini-batch) para calcular el gradiente de la función de pérdida y actualiza los parámetros en la dirección opuesta.</p>
<ul>
<li><p><strong>Fórmula de actualización de parámetros:</strong></p>
<p><span class="math display">\[w^{(t)} = w^{(t-1)} - \eta \cdot g^{(t)}\]</span></p>
<ul>
<li><span class="math inline">\(w^{(t)}\)</span>: parámetro (peso) en el paso <span class="math inline">\(t\)</span></li>
<li><span class="math inline">\(\eta\)</span>: tasa de aprendizaje (learning rate)</li>
<li><span class="math inline">\(g^{(t)}\)</span>: gradiente calculado en el paso <span class="math inline">\(t\)</span></li>
</ul></li>
</ul>
<p>El momentum introduce el concepto de inercia del movimiento físico para mejorar SGD. Utiliza la media móvil exponencial (exponential moving average) de los gradientes pasados para otorgar inercia a la trayectoria de optimización, mitigando así el problema de oscilación en SGD y aumentando la velocidad de convergencia.</p>
<ul>
<li><p><strong>Fórmula de actualización con momentum:</strong></p>
<p><span class="math display">\[v^{(t)} = \mu \cdot v^{(t-1)} + g^{(t)}\]</span></p>
<p><span class="math display">\[w^{(t)} = w^{(t-1)} - \eta \cdot v^{(t)}\]</span></p>
<ul>
<li><span class="math inline">\(\mu\)</span>: coeficiente de momentum (generalmente 0.9 o 0.99)</li>
<li><span class="math inline">\(v^{(t)}\)</span>: velocidad en el paso <span class="math inline">\(t\)</span></li>
</ul></li>
</ul>
<p><em>El código de implementación de los principales algoritmos de optimización utilizados en el aprendizaje se incluye en el directorio <code>chapter_05/optimizer/</code>.</em> A continuación, se muestra un ejemplo de implementación para el algoritmo SGD (incluyendo momentum) utilizado en el aprendizaje. Todas las clases de algoritmos de optimización heredan de la clase <code>BaseOptimizer</code> y se implementan de manera simple con fines de aprendizaje. (En bibliotecas reales como PyTorch, estas implementaciones son más complejas para mayor eficiencia y generalización.)</p>
<div id="cell-11" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> Iterable, List, Optional</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_05.optimizers.basic <span class="im">import</span> BaseOptimizer</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SGD(BaseOptimizer):</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Implements SGD with momentum."""</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, params: Iterable[nn.Parameter], lr: <span class="bu">float</span>, </span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>                 maximize: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span>, momentum: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.0</span>):</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(params, lr)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.maximize <span class="op">=</span> maximize</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.momentum <span class="op">=</span> momentum</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.momentum_buffer_list: List[Optional[torch.Tensor]] <span class="op">=</span> [<span class="va">None</span>] <span class="op">*</span> <span class="bu">len</span>(<span class="va">self</span>.params)</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">@torch.no_grad</span>()</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> step(<span class="va">self</span>) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i, p <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="va">self</span>.params):</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>            grad <span class="op">=</span> p.grad <span class="cf">if</span> <span class="kw">not</span> <span class="va">self</span>.maximize <span class="cf">else</span> <span class="op">-</span>p.grad</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="va">self</span>.momentum <span class="op">!=</span> <span class="fl">0.0</span>:</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>                buf <span class="op">=</span> <span class="va">self</span>.momentum_buffer_list[i]</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> buf <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>                    buf <span class="op">=</span> torch.clone(grad).detach()</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>                    buf.mul_(<span class="va">self</span>.momentum).add_(grad, alpha<span class="op">=</span><span class="dv">1</span><span class="op">-</span><span class="va">self</span>.momentum)</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>                grad <span class="op">=</span> buf</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.momentum_buffer_list[i] <span class="op">=</span> buf</span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>            p.add_(grad, alpha<span class="op">=-</span><span class="va">self</span>.lr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><strong>Algoritmos de tasa de aprendizaje adaptativa (Adaptive Learning Rate Algorithms)</strong></p>
<p><em>Los parámetros del modelo de aprendizaje profundo se actualizan con frecuencias e importancias diferentes. Los algoritmos de tasa de aprendizaje adaptativa ajustan la tasa de aprendizaje individualmente para cada parámetro, teniendo en cuenta sus características específicas.</em></p>
<ul>
<li><p><strong>AdaGrad (Adaptive Gradient, 2011):</strong></p>
<ul>
<li><p><strong>Idea principal:</strong> Aplica una tasa de aprendizaje pequeña a los parámetros que se actualizan con frecuencia y una tasa de aprendizaje grande a los parámetros que se actualizan raramente.</p></li>
<li><p><strong>Fórmula:</strong></p>
<p><span class="math inline">\(w^{(t)} = w^{(t-1)} - \frac{\eta}{\sqrt{G^{(t)} + \epsilon}} \cdot g^{(t)}\)</span></p>
<ul>
<li><span class="math inline">\(G^{(t)}\)</span>: suma acumulativa de los cuadrados de los gradientes pasados</li>
<li><span class="math inline">\(\epsilon\)</span>: pequeña constante para evitar la división por cero (por ejemplo: <span class="math inline">\(10^{-8}\)</span>)</li>
</ul></li>
<li><p><strong>Ventajas:</strong> Es efectivo al tratar con datos dispersos (sparse data).</p></li>
<li><p><strong>Desventajas:</strong> La tasa de aprendizaje disminuye monótonamente a medida que avanza el entrenamiento, lo que puede hacer que el aprendizaje se detenga prematuramente.</p></li>
</ul></li>
<li><p><strong>RMSProp (Root Mean Square Propagation, 2012):</strong></p>
<ul>
<li><p><strong>Idea principal:</strong> Para resolver el problema de la disminución de la tasa de aprendizaje en AdaGrad, utiliza una media móvil exponencial (exponential moving average) de los cuadrados de los gradientes pasados en lugar de su suma.</p></li>
<li><p><strong>Fórmula:</strong></p>
<p><span class="math inline">\(v^{(t)} = \beta \cdot v^{(t-1)} + (1-\beta) \cdot (g^{(t)})^2\)</span></p>
<p><span class="math inline">\(w^{(t)} = w^{(t-1)} - \frac{\eta}{\sqrt{v^{(t)} + \epsilon}} \cdot g^{(t)}\)</span></p>
<ul>
<li><span class="math inline">\(\beta\)</span>: tasa de decaimiento (decay rate) que ajusta la influencia de los cuadrados de los gradientes pasados (generalmente 0.9)</li>
</ul></li>
<li><p><strong>Ventajas:</strong> El problema de disminución de la tasa de aprendizaje es menos pronunciado en comparación con AdaGrad, permitiendo un entrenamiento efectivo por un período más largo.</p></li>
</ul></li>
</ul>
<p><strong>Adam (Adaptive Moment Estimation, 2014):</strong></p>
<p><em>Adam es uno de los algoritmos de optimización más utilizados actualmente, que combina las ideas de momentum y RMSProp.</em></p>
<ul>
<li><p><strong>Idea principal:</strong></p>
<ul>
<li>Momentum: utiliza una media móvil exponencial del gradiente pasado (primer momento) para introducir un efecto de inercia.</li>
<li>RMSProp: utiliza una media móvil exponencial de los cuadrados de los gradientes pasados (segundo momento) para ajustar la tasa de aprendizaje por parámetro.</li>
<li>Corrección de sesgo (Bias Correction): corrige el sesgo de los primeros y segundos momentos hacia cero en las etapas iniciales.</li>
</ul></li>
<li><p><strong>Fórmula:</strong></p>
<p><span class="math inline">\(m^{(t)} = \beta\_1 \cdot m^{(t-1)} + (1-\beta\_1) \cdot g^{(t)}\)</span></p>
<p><span class="math inline">\(v^{(t)} = \beta\_2 \cdot v^{(t-1)} + (1-\beta\_2) \cdot (g^{(t)})^2\)</span></p>
<p><span class="math inline">\(\hat{m}^{(t)} = \frac{m^{(t)}}{1-\beta\_1^t}\)</span></p>
<p><span class="math inline">\(\hat{v}^{(t)} = \frac{v^{(t)}}{1-\beta\_2^t}\)</span></p>
<p><span class="math inline">\(w^{(t)} = w^{(t-1)} - \eta \cdot \frac{\hat{m}^{(t)}}{\sqrt{\hat{v}^{(t)}} + \epsilon}\)</span></p>
<ul>
<li><span class="math inline">\(\beta_1\)</span>: tasa de decaimiento del primer momento (momentum) (generalmente 0.9)</li>
<li><span class="math inline">\(\beta_2\)</span>: tasa de decaimiento del segundo momento (RMSProp) (generalmente 0.999) Los algoritmos de optimización mencionados anteriormente tienen cada uno sus propias ventajas y desventajas, y es necesario elegir el algoritmo adecuado según las características del problema, la estructura del modelo, los datos, etc. Adam muestra un buen rendimiento en muchos casos, pero a veces la combinación de SGD + Momentum puede ofrecer un mejor rendimiento de generalización, o en problemas específicos, otros algoritmos de tasa de aprendizaje adaptativa (por ejemplo: RMSProp) pueden ser más efectivos. Por lo tanto, es importante encontrar el algoritmo óptimo a través de experimentos.</li>
</ul></li>
</ul>
</section>
<section id="algoritmos-de-optimización-modernos-más-rápidos-más-eficientes-y-para-modelos-más-grandes" class="level5">
<h5 class="anchored">Algoritmos de optimización modernos: más rápidos, más eficientes y para modelos más grandes</h5>
<p>Con el aumento explosivo del tamaño de los modelos de aprendizaje profundo y los conjuntos de datos, se ha incrementado la demanda de nuevos algoritmos de optimización que soporten <em>eficiencia en memoria, velocidad de convergencia rápida y aprendizaje distribuido a gran escala</em>. A continuación, se presentan los algoritmos más recientes que han surgido para responder a estas necesidades.</p>
<ul>
<li><p><strong>Lion (Evolved Sign Momentum, 2023):</strong></p>
<ul>
<li><strong>Idea central:</strong> Un algoritmo descubierto por Google Research a través de la búsqueda de programas (program search), similar a Adam en el uso del momentum, pero que realiza actualizaciones utilizando solo el signo (sign) de los gradientes. Es decir, ignora la magnitud del gradiente y considera solo su dirección.</li>
<li><strong>Ventajas:</strong>
<ul>
<li>Utiliza menos memoria que Adam (no requiere almacenar el segundo momento).</li>
<li>Realiza actualizaciones del mismo tamaño para todos los parámetros, lo que lo hace efectivo en problemas con gradientes dispersos (por ejemplo, procesamiento de lenguaje natural).</li>
<li>Permite utilizar tasas de aprendizaje más altas que Adam.</li>
<li>Empíricamente, muestra un mejor rendimiento que AdamW en muchos casos.</li>
</ul></li>
<li><strong>Desventajas:</strong>
<ul>
<li>Ignorar la información de magnitud del gradiente puede resultar en una convergencia más lenta o un rendimiento inferior a Adam en ciertos problemas.</li>
<li>Puede ser más sensible al ajuste de la tasa de aprendizaje.</li>
</ul></li>
<li>Para obtener más detalles, consulte el análisis detallado.</li>
</ul></li>
<li><p><strong>Sophia (Second-order Clipped Stochastic Optimization, 2023):</strong></p>
<ul>
<li><strong>Idea central:</strong> Utiliza información de segundo orden (matriz hessian), pero para reducir los costos computacionales, estima y utiliza solo los componentes diagonales del hessiano y aplica clipping a las actualizaciones para aumentar la estabilidad.</li>
<li><strong>Ventajas:</strong> Convergencia más rápida y aprendizaje más estable que Adam.</li>
<li><strong>Desventajas:</strong> Requiere ajustar más hiperparámetros que Adam (por ejemplo, frecuencia de estimación del hessiano, umbral de clipping).</li>
<li>Para obtener más detalles, consulte el análisis detallado.</li>
</ul></li>
<li><p><strong>AdaFactor (2018):</strong></p>
<ul>
<li><strong>Idea central:</strong> Algoritmo propuesto para reducir el uso de memoria en modelos a gran escala (especialmente Transformers), que aproxima la matriz del segundo momento en Adam mediante el producto de matrices de baja dimensión.</li>
<li><strong>Ventajas:</strong> Utiliza significativamente menos memoria que Adam.</li>
<li><strong>Desventajas:</strong> Debido a la aproximación del segundo momento, puede mostrar un rendimiento inferior a Adam en ciertos problemas.</li>
<li>Para obtener más detalles, consulte el análisis detallado.</li>
</ul></li>
</ul>
<p>Investigaciones recientes sugieren que los algoritmos mencionados (Lion, Sophia, AdaFactor) pueden superar el rendimiento de Adam/AdamW existente bajo condiciones específicas.</p>
<ul>
<li><strong>Lion:</strong> En el aprendizaje con tamaños de lote grandes (large batch size), Lion es más rápido que AdamW, utiliza menos memoria y tiende a mostrar un mejor rendimiento de generalización.</li>
<li><strong>Sophia:</strong> Durante la etapa de pre-entrenamiento (especialmente para modelos de lenguaje a gran escala), Sophia converge más rápidamente que Adam y puede alcanzar una menor perplejidad (o mayor precisión).</li>
<li><strong>AdaFactor:</strong> En entornos con limitaciones de memoria, AdaFactor puede ser una buena alternativa a Adam para entrenar modelos Transformer a gran escala. Sin embargo, no existe un algoritmo de optimización “todo en uno” que garantice siempre el mejor rendimiento para todos los problemas. Por lo tanto, al aplicarlos a problemas reales, es necesario considerar integralmente el tamaño del modelo, las características de los datos de entrenamiento, los recursos disponibles (memoria, potencia de cómputo), si se realizará aprendizaje distribuido, etc., para seleccionar un algoritmo adecuado y <em>necesariamente encontrar los hiperparámetros óptimos a través de experimentos y validación.</em></li>
</ul>
<p>Ahora vamos a realizar una prueba de 1 época para ver cómo funciona.</p>
<div id="cell-14" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_04.models.base <span class="im">import</span> SimpleNetwork</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_04.utils.data <span class="im">import</span> get_data_loaders, get_device</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_05.optimizers.basic <span class="im">import</span> Adam, SGD</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_05.optimizers.advanced <span class="im">import</span> Lion, Sophia</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_04.experiments.model_training <span class="im">import</span> train_model  <span class="co"># Corrected import</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> get_device()</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SimpleNetwork(act_func<span class="op">=</span>nn.ReLU(), hidden_shape<span class="op">=</span>[<span class="dv">512</span>, <span class="dv">64</span>]).to(device)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize SGD optimizer</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> SGD(params<span class="op">=</span>model.parameters(), lr<span class="op">=</span><span class="fl">1e-3</span>, momentum<span class="op">=</span><span class="fl">0.9</span>)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a><span class="co"># # Initialize Adam optimizer</span></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a><span class="co"># optimizer = Adam(params=model.parameters(), lr=1e-3, beta1=0.9, beta2=0.999, eps=1e-8)</span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a><span class="co"># # Initialize AdaGrad optimizer</span></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a><span class="co"># optimizer = AdaGrad(params=model.parameters(), lr=1e-2, eps=1e-10)</span></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a><span class="co"># # Initialize Lion optimizer</span></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a><span class="co"># optimizer = Lion(params=model.parameters(), lr=1e-4,  betas=(0.9, 0.99), weight_decay=0.0)</span></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize Sophia optimizer</span></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a><span class="co"># optimizer = Sophia(params=model.parameters(), lr=1e-3, betas=(0.965, 0.99), rho=0.04, weight_decay=0.0, k=10)</span></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>train_dataloader, test_dataloader <span class="op">=</span> get_data_loaders()</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>train_model(model, train_dataloader, test_dataloader, device, optimizer<span class="op">=</span>optimizer, epochs<span class="op">=</span><span class="dv">1</span>, batch_size<span class="op">=</span><span class="dv">256</span>, save_dir<span class="op">=</span><span class="st">"./tmp/opts/ReLU"</span>, retrain<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Starting training for SimpleNetwork-ReLU.</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c406d6c56f5d409e87cd8759b19fd284","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Execution completed for SimpleNetwork-ReLU, Execution time = 7.4 secs</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>{'epochs': [1],
 'train_losses': [2.2232478597005207],
 'train_accuracies': [0.20635],
 'test_losses': [2.128580910873413],
 'test_accuracies': [0.3466]}</code></pre>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Haga clic para ver el contenido (deep dive: análisis profundo de los algoritmos de optimización modernos)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Haga clic para ver el contenido (deep dive: análisis profundo de los algoritmos de optimización modernos)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<section id="análisis-profundo-de-los-algoritmos-de-optimización-modernos" class="level3 callout-body-container callout-body">
<h3 class="anchored" data-anchor-id="análisis-profundo-de-los-algoritmos-de-optimización-modernos">Análisis profundo de los algoritmos de optimización modernos</h3>
<section id="lion-evolved-sign-momentum" class="level4">
<h4 class="anchored" data-anchor-id="lion-evolved-sign-momentum">Lion (EvoLved Sign Momentum)</h4>
<p>Lion es un algoritmo de optimización descubierto por Google Research mediante técnicas de AutoML. Aunque similar a Adam en el uso del momentum, su característica principal es que utiliza solo el signo de los gradientes y no su magnitud.</p>
<p><strong>Idea clave:</strong></p>
<ul>
<li><strong>Descenso por Signo:</strong> Decide la dirección de actualización utilizando solo el signo de los gradientes. Esto fuerza una actualización de tamaño uniforme para todos los parámetros, lo que resulta efectivo en problemas con gradientes dispersos (por ejemplo, procesamiento de lenguaje natural).</li>
<li><strong>Momentum:</strong> Considera la dirección de las actualizaciones anteriores para mejorar la estabilidad y velocidad del aprendizaje.</li>
</ul>
<p><strong>Principios matemáticos:</strong></p>
<ol type="1">
<li><p><strong>Cálculo de actualización:</strong></p>
<p><span class="math inline">\(c\_t = \beta\_1 m\_{t-1} + (1 - \beta\_1) g\_t\)</span></p>
<ul>
<li><span class="math inline">\(c\_t\)</span>: Vector de actualización para el paso actual. Es una media ponderada del momentum (<span class="math inline">\(m\_{t-1}\)</span>) y el gradiente actual (<span class="math inline">\(g\_t\)</span>).</li>
<li><span class="math inline">\(\beta\_1\)</span>: Tasa de decay exponencial del momentum (generalmente 0.9 o 0.99).</li>
</ul></li>
<li><p><strong>Actualización de pesos:</strong></p>
<p><span class="math inline">\(w\_{t+1} = w\_t - \eta \cdot \text{sign}(c\_t)\)</span></p>
<ul>
<li><span class="math inline">\(\eta\)</span>: Tasa de aprendizaje</li>
<li><span class="math inline">\(\text{sign}(c\_t)\)</span>: El signo (+1 o -1) de cada elemento de <span class="math inline">\(c\_t\)</span>. Si es 0, se mantiene como 0.</li>
</ul></li>
<li><p><strong>Actualización del momentum:</strong></p>
<p><span class="math inline">\(m\_t = c\_t\)</span></p>
<ul>
<li>Se utiliza el valor calculado en la actualización para el siguiente paso del momentum.</li>
</ul></li>
</ol>
<p><strong>Ventajas:</strong></p>
<ul>
<li><strong>Eficiencia de memoria:</strong> A diferencia de Adam, no necesita almacenar el segundo momento (varianza), lo que reduce el uso de memoria.</li>
<li><strong>Eficiencia computacional:</strong> La operación de signo es menos costosa en términos de cálculo que la multiplicación.</li>
<li><strong>Robustez a la dispersidad:</strong> Al actualizar todos los parámetros con un tamaño uniforme, resulta efectivo en problemas con gradientes dispersos.</li>
</ul>
<p><strong>Desventajas:</strong></p>
<ul>
<li>Ignora la información de magnitud del gradiente, lo que puede resultar en una convergencia más lenta o un rendimiento inferior a Adam en ciertos problemas.</li>
<li>Puede ser más sensible al ajuste de la tasa de aprendizaje.</li>
</ul>
<p><strong>Referencias:</strong></p>
<ul>
<li>Se ha analizado que Lion tiene efectos similares a la regularización L1. (Se requiere investigación adicional para detalles)</li>
<li>El artículo <a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://arxiv.org/abs/2302.06675">Chen et al., 2023</a> informa que, durante el entrenamiento del modelo BERT, Lion mostró una mejora en la tasa de aprendizaje y la estabilidad. Sin embargo, estos resultados son específicos del experimento y no pueden generalizarse a todos los casos.</li>
</ul>
</section>
<section id="sophia-optimización-estocástica-de-segundo-orden-recortada" class="level4">
<h4 class="anchored" data-anchor-id="sophia-optimización-estocástica-de-segundo-orden-recortada">Sophia (Optimización Estocástica de Segundo Orden Recortada)</h4>
<p>Sophia es un algoritmo de optimización que utiliza información de segundo orden (la matriz Hessiana) para mejorar la velocidad y estabilidad del aprendizaje. Sin embargo, el cálculo directo de la matriz Hessiana es muy costoso, por lo que Sophia estima solo los componentes diagonales de la Hessiana mediante una versión mejorada del método de Hutchinson.</p>
<p><strong>Idea clave:</strong></p>
<ul>
<li><strong>Estimación ligera de la Hessiana:</strong> Mejora el método de Hutchinson para estimar eficientemente los componentes diagonales de la matriz Hessiana.
<ul>
<li>El método de Hutchinson original utiliza <span class="math inline">\(h\_t = \mathbb{E}[z\_t z\_t^T H\_t] = diag(H\_t)\)</span>, donde ( z ) es un vector aleatorio.</li>
<li>Mejora: Utiliza covarianza para reducir la varianza.</li>
</ul></li>
<li><strong>Recorte (Clipping):</strong> Limita el tamaño de la actualización antes de aplicar los gradientes para mejorar la estabilidad del aprendizaje.</li>
</ul>
<p><strong>Principios matemáticos:</strong> 1. <strong>Estimación de la Diagonal de Hessian:</strong></p>
<pre><code>  * En cada paso, se muestrea un vector aleatorio $z\_t$ (cada elemento de $z\_t$ se selecciona uniformemente de {-1, +1}).

  * Se calcula la estimación de la diagonal de Hessian $h\_t$ de la siguiente manera.

    $h\_t = \beta\_2 h\_{t-1} + (1 - \beta\_2) \text{diag}(H\_t z\_t) z\_t^T$

    (donde $H\_t$ es el Hessian en el paso t)

  * Sophia utiliza una media móvil exponencial (EMA) que aprovecha estimaciones pasadas ($h\_{t-1}$) para reducir la varianza del estimador de Hutchinson.</code></pre>
<ol start="2" type="1">
<li><p><strong>Cálculo de la Actualización:</strong></p>
<ul>
<li><span class="math inline">\(m\_t = \beta\_1 m\_{t-1} + (1 - \beta\_1) g\_t\)</span> (momentum)</li>
<li><span class="math inline">\(u\_t = \text{clip}(m\_t / (h\_t + \epsilon), \rho)\)</span>
<ul>
<li><span class="math inline">\(u\_t\)</span>: actualización recortada después de dividir por el Hessian.</li>
<li><span class="math inline">\(\text{clip}(x, \rho) = \text{sign}(x) \cdot \min(|x|, \rho)\)</span>.</li>
<li><span class="math inline">\(\rho\)</span>: valor umbral de recorte (hiperparámetro)</li>
<li><span class="math inline">\(h\_t + \epsilon\)</span> es una operación que suma <span class="math inline">\(\epsilon\)</span> a cada elemento de <span class="math inline">\(h\_t\)</span></li>
</ul></li>
</ul></li>
<li><p><strong>Actualización de Pesos:</strong></p>
<p><span class="math inline">\(w\_{t+1} = w\_t - \eta \cdot u\_t\)</span></p>
<ul>
<li><span class="math inline">\(\eta\)</span>: tasa de aprendizaje</li>
</ul></li>
</ol>
<p><strong>Ventajas:</strong></p>
<ul>
<li><strong>Convergencia rápida:</strong> Utiliza información de segundo orden para converger más rápido que Adam.</li>
<li><strong>Estabilidad:</strong> Mejora la estabilidad del aprendizaje mediante el recorte.</li>
</ul>
<p><strong>Desventajas:</strong></p>
<ul>
<li>Requiere ajustar más hiperparámetros (<span class="math inline">\(\beta\_1\)</span>, <span class="math inline">\(\beta\_2\)</span>, <span class="math inline">\(\rho\)</span>) en comparación con Adam.</li>
<li>El rendimiento puede variar según la precisión de la estimación del Hessian.</li>
</ul>
<p><strong>Referencia:</strong></p>
<ul>
<li><a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://arxiv.org/abs/2305.14342">Li et al., 2023</a> informa que Sophia logró una pérdida (loss) más baja en menos pasos de Adam durante el pre-entrenamiento de modelos de lenguaje. (usando métricas como precisión/perplexity)</li>
</ul>
</section>
<section id="adafactor" class="level4">
<h4 class="anchored" data-anchor-id="adafactor">AdaFactor</h4>
<p>AdaFactor es un algoritmo de optimización eficiente en términos de memoria, diseñado para el entrenamiento de modelos a gran escala, especialmente los modelos Transformer. Aunque similar a Adam en su uso de tasas de aprendizaje adaptativas, mejora la forma de almacenar el segundo momento (varianza), reduciendo significativamente el consumo de memoria.</p>
<p><strong>Idea clave:</strong></p>
<ul>
<li><strong>Factorización matricial (Matrix Factorization):</strong> Aproxima la matriz del segundo momento como el producto de dos matrices de baja dimensión para reducir el uso de memoria.</li>
</ul>
<p><strong>Principio matemático:</strong></p>
<p>En Adam, la matriz del segundo momento <span class="math inline">\(v\_t\)</span> para una matriz de pesos de tamaño <span class="math inline">\(n \times m\)</span> requiere <span class="math inline">\(O(nm)\)</span> de memoria. AdaFactor aproxima esta matriz de la siguiente manera.</p>
<ol type="1">
<li><strong>Estimación del Segundo Momento:</strong></li>
</ol>
<ul>
<li>En lugar de <span class="math inline">\(v\_t\)</span>, mantenemos dos vectores <span class="math inline">\(R\_t\)</span> (<span class="math inline">\(n \times 1\)</span>) y <span class="math inline">\(C\_t\)</span> (<span class="math inline">\(m \times 1\)</span>) que representan la suma de cada fila y columna de <span class="math inline">\(v\_t\)</span>.
<ul>
<li><span class="math inline">\(R\_t = \beta\_{2t} R\_{t-1} + (1 - \beta\_{2t}) (\text{row\_sum}(g\_t^2)/m)\)</span></li>
<li><span class="math inline">\(C\_t = \beta\_{2t} C\_{t-1} + (1 - \beta\_{2t}) (\text{col\_sum}(g\_t^2)/n)\)</span></li>
</ul></li>
<li><span class="math inline">\(R\_t\)</span> y <span class="math inline">\(C\_t\)</span> son valores de media móvil exponencial (exponential moving average) de la suma de las filas y columnas de <span class="math inline">\(g\_t^2\)</span>, respectivamente. (<span class="math inline">\(\beta\_{2t}\)</span> es el horizonte de planificación)</li>
<li>Aproximamos <span class="math inline">\(\hat{v\_t} = R\_t C\_t^T / (\text{sum}(R\_t) \cdot \text{sum}(C\_t))\)</span></li>
</ul>
<ol start="2" type="1">
<li><p><strong>Cálculo de la actualización:</strong></p>
<p><span class="math inline">\(u\_t =  g\_t / \sqrt{\hat{v\_t}}\)</span></p></li>
<li><p><strong>Actualización de los pesos</strong> <span class="math inline">\(w\_{t+1} = w\_t - \eta \cdot u\_t\)</span></p></li>
</ol>
<p><strong>Ventajas:</strong></p>
<ul>
<li><strong>Eficiencia de memoria:</strong> En lugar de almacenar una matriz de segundo momento de tamaño <span class="math inline">\(O(nm)\)</span>, solo almacenamos vectores de tamaño <span class="math inline">\(O(n+m)\)</span>, lo que reduce significativamente el uso de memoria.</li>
<li><strong>Aprendizaje de modelos grandes:</strong> Debido a la eficiencia en el uso de memoria, es adecuado para el aprendizaje de modelos de gran escala.</li>
</ul>
<p><strong>Desventajas:</strong></p>
<ul>
<li>Dado que se aproxima la información del segundo momento, en ciertos problemas puede tener un rendimiento inferior al de Adam.</li>
<li>Puede incurrir en costos computacionales adicionales debido a la descomposición matricial.</li>
</ul>
<p><strong>Referencia:</strong></p>
<ul>
<li><a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://arxiv.org/abs/1804.04235">Shazeer &amp; Stern, 2018</a> informan que AdaFactor logra un rendimiento similar al de Adam mientras reduce el uso de memoria en el aprendizaje de modelos de transformers.</li>
</ul>
</section>
<section id="otros-algoritmos-de-optimización-relevantes-y-recientes" class="level4">
<h4 class="anchored" data-anchor-id="otros-algoritmos-de-optimización-relevantes-y-recientes">Otros algoritmos de optimización relevantes y recientes</h4>
<ul>
<li><strong>LAMB (Layer-wise Adaptive Moments optimizer for Batch training):</strong> Un algoritmo especializado para el aprendizaje con lotes grandes. Ajusta la tasa de aprendizaje por capa, permitiendo un aprendizaje estable incluso con lotes de gran tamaño. (Referencia: <a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://arxiv.org/abs/1904.00962">You et al., 2019</a>)</li>
<li><strong>LARS (Layer-wise Adaptive Rate Scaling):</strong> Similar a LAMB, utiliza ajustes de tasa de aprendizaje por capa y es efectivo para el aprendizaje con lotes grandes. Se usa principalmente en modelos de clasificación de imágenes como ResNet. (Referencia: <a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://arxiv.org/abs/1708.03888">You et al., 2017</a>)</li>
</ul>
</section>
</section>
</div>
</div>
</section>
</section>
<section id="comparación-de-entrenamiento-de-optimización" class="level3">
<h3 class="anchored" data-anchor-id="comparación-de-entrenamiento-de-optimización">5.2.2 Comparación de entrenamiento de optimización</h3>
<p>El rendimiento del algoritmo de optimización puede variar significativamente según la tarea y la estructura del modelo. Analizaremos estas características a través de experimentos.</p>
<section id="análisis-de-tareas-básicas" class="level5">
<h5 class="anchored" data-anchor-id="análisis-de-tareas-básicas">Análisis de tareas básicas</h5>
<p>Comparamos el rendimiento básico utilizando el conjunto de datos FashionMNIST. Este conjunto de datos simplifica el problema de clasificación de imágenes de ropa reales, lo que lo hace adecuado para analizar las características básicas de los algoritmos de deep learning.</p>
<div id="cell-17" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_05.experiments.basic <span class="im">import</span> run_basic_experiment</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_05.visualization.optimization <span class="im">import</span> plot_training_results</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_04.utils.data <span class="im">import</span> get_data_loaders</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_05.optimizers.basic <span class="im">import</span> SGD, Adam</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_05.optimizers.advanced <span class="im">import</span> Lion</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Device configuration</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda:0"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Data loaders</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>train_loader, test_loader <span class="op">=</span> get_data_loaders()</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Optimizer dictionary</span></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>optimizers <span class="op">=</span> {</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">'SGD'</span>: SGD,</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Adam'</span>: Adam,</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Lion'</span>: Lion</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Optimizer configurations</span></span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>optimizer_configs <span class="op">=</span> {</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>    <span class="st">'SGD'</span>: {<span class="st">'lr'</span>: <span class="fl">0.01</span>, <span class="st">'momentum'</span>: <span class="fl">0.9</span>},</span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Adam'</span>: {<span class="st">'lr'</span>: <span class="fl">0.001</span>},</span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Lion'</span>: {<span class="st">'lr'</span>: <span class="fl">1e-4</span>}</span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Run experiments</span></span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> {}</span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, config <span class="kw">in</span> optimizer_configs.items():</span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Starting experiment with </span><span class="sc">{</span>name<span class="sc">}</span><span class="ss"> optimizer..."</span>)</span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a>    results[name] <span class="op">=</span> run_basic_experiment(</span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a>        optimizer_class<span class="op">=</span>optimizers[name],</span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a>        train_loader<span class="op">=</span>train_loader,</span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a>        test_loader<span class="op">=</span>test_loader,</span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a>        config<span class="op">=</span>config,</span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a>        device<span class="op">=</span>device,</span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a>        epochs<span class="op">=</span><span class="dv">20</span></span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize training curves</span></span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a>plot_training_results(</span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a>    results,</span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a>    metrics<span class="op">=</span>[<span class="st">'loss'</span>, <span class="st">'accuracy'</span>, <span class="st">'gradient_norm'</span>, <span class="st">'memory'</span>],</span>
<span id="cb18-46"><a href="#cb18-46" aria-hidden="true" tabindex="-1"></a>    mode<span class="op">=</span><span class="st">"train"</span>,  <span class="co"># Changed mode to "train"</span></span>
<span id="cb18-47"><a href="#cb18-47" aria-hidden="true" tabindex="-1"></a>    title<span class="op">=</span><span class="st">'Optimizer Comparison on FashionMNIST'</span></span>
<span id="cb18-48"><a href="#cb18-48" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Starting experiment with SGD optimizer...

==================================================
Optimizer: SGD
Initial CUDA Memory Status (GPU 0):
Allocated: 23.0MB
Reserved: 48.0MB
Model Size: 283.9K parameters
==================================================
</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ada5e53909f54c17bd9780217a7549fc","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
==================================================
Final CUDA Memory Status (GPU 0):
Peak Allocated: 27.2MB
Peak Reserved: 48.0MB
Current Allocated: 25.2MB
Current Reserved: 48.0MB
==================================================


Starting experiment with Adam optimizer...

==================================================
Optimizer: Adam
Initial CUDA Memory Status (GPU 0):
Allocated: 25.2MB
Reserved: 48.0MB
Model Size: 283.9K parameters
==================================================
</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"672f6e9f6a2c4916aa04a216cf6fa722","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
==================================================
Final CUDA Memory Status (GPU 0):
Peak Allocated: 28.9MB
Peak Reserved: 50.0MB
Current Allocated: 26.3MB
Current Reserved: 50.0MB
==================================================


Starting experiment with Lion optimizer...

==================================================
Optimizer: Lion
Initial CUDA Memory Status (GPU 0):
Allocated: 24.1MB
Reserved: 50.0MB
Model Size: 283.9K parameters
==================================================
</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"df577f7a7c8042899f6580786f12b819","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
==================================================
Final CUDA Memory Status (GPU 0):
Peak Allocated: 27.2MB
Peak Reserved: 50.0MB
Current Allocated: 25.2MB
Current Reserved: 50.0MB
==================================================
</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="05_Optimización y visualización_files/figure-html/cell-7-output-8.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Los resultados del experimento muestran las características de cada algoritmo. En el experimento realizado con el conjunto de datos FashionMNIST y el modelo MLP, los principales hallazgos son los siguientes:</p>
<ol type="1">
<li><strong>Velocidad de convergencia:</strong>
<ul>
<li>Adam y Lion convergen muy rápidamente en las primeras etapas del aprendizaje. (disminución rápida de la pérdida y aumento rápido de la precisión en los primeros pocos episodios)</li>
<li>SGD muestra un patrón de convergencia más lento y constante.</li>
</ul></li>
<li><strong>Estabilidad de la curva de aprendizaje:</strong>
<ul>
<li>Adam presenta una curva de aprendizaje muy suave y estable.</li>
<li>Lion es similar a Adam en estabilidad, pero presenta algunas fluctuaciones en la curva de precisión.</li>
<li>SGD muestra grandes fluctuaciones tanto en las curvas de pérdida como de precisión.</li>
</ul></li>
<li><strong>Uso de memoria:</strong>
<ul>
<li>Lion utiliza ligeramente menos memoria que Adam, aunque no hay una gran diferencia (Adam: aproximadamente 26.2MB, Lion: aproximadamente 25.2MB).</li>
<li>SGD es el que consume la menor cantidad de memoria entre los tres.</li>
</ul></li>
<li><strong>Norma del gradiente:</strong>
<ul>
<li>Lion: La norma del gradiente inicial es muy alta (aproximadamente 4.0) y disminuye rápidamente, estabilizándose en un valor bajo (aproximadamente 1.5). (exploración de grandes pasos iniciales, movimiento rápido hacia el óptimo)</li>
<li>Adam: La norma del gradiente inicial es menor que la de Lion (aproximadamente 2.0), disminuye rápidamente y se estabiliza en un valor aún más bajo (aproximadamente 1.0). (ajuste adaptativo de la tasa de aprendizaje)</li>
<li>SGD: La norma del gradiente inicial es la menor (aproximadamente 0.3), presenta grandes fluctuaciones y oscila a valores más altos (aproximadamente 2.0-2.5) en comparación con los otros algoritmos. (exploración de un amplio área, posibilidad de mínimos planos)</li>
</ul></li>
</ol>
<p>En el experimento básico, Adam y Lion mostraron una rápida velocidad de convergencia inicial, Adam presentó el aprendizaje más estable, Lion utilizó ligeramente menos memoria, y SGD tendía a explorar un rango más amplio.</p>
</section>
<section id="evaluación-de-tareas-avanzadas" class="level5">
<h5 class="anchored" data-anchor-id="evaluación-de-tareas-avanzadas">Evaluación de tareas avanzadas</h5>
<p>Con CIFAR-100 y modelos CNN/transformer, las diferencias entre los algoritmos de optimización se vuelven aún más evidentes.</p>
<div id="cell-19" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_05.experiments.advanced <span class="im">import</span> run_advanced_experiment</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_05.visualization.optimization <span class="im">import</span> plot_training_results</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_04.utils.data <span class="im">import</span> get_data_loaders</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_05.optimizers.basic <span class="im">import</span> SGD, Adam</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_05.optimizers.advanced <span class="im">import</span> Lion</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Device configuration</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda:0"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Data loaders</span></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>train_loader, test_loader <span class="op">=</span> get_data_loaders(dataset<span class="op">=</span><span class="st">"CIFAR100"</span>)</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Optimizer dictionary</span></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>optimizers <span class="op">=</span> {</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">'SGD'</span>: SGD,</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Adam'</span>: Adam,</span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Lion'</span>: Lion</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Optimizer configurations</span></span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a>optimizer_configs <span class="op">=</span> {</span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a>    <span class="st">'SGD'</span>: {<span class="st">'lr'</span>: <span class="fl">0.01</span>, <span class="st">'momentum'</span>: <span class="fl">0.9</span>},</span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Adam'</span>: {<span class="st">'lr'</span>: <span class="fl">0.001</span>},</span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Lion'</span>: {<span class="st">'lr'</span>: <span class="fl">1e-4</span>}</span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Run experiments</span></span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> {}</span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, config <span class="kw">in</span> optimizer_configs.items():</span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Starting experiment with </span><span class="sc">{</span>name<span class="sc">}</span><span class="ss"> optimizer..."</span>)</span>
<span id="cb23-32"><a href="#cb23-32" aria-hidden="true" tabindex="-1"></a>    results[name] <span class="op">=</span> run_advanced_experiment(</span>
<span id="cb23-33"><a href="#cb23-33" aria-hidden="true" tabindex="-1"></a>        optimizer_class<span class="op">=</span>optimizers[name],</span>
<span id="cb23-34"><a href="#cb23-34" aria-hidden="true" tabindex="-1"></a>        model_type<span class="op">=</span><span class="st">'cnn'</span>,</span>
<span id="cb23-35"><a href="#cb23-35" aria-hidden="true" tabindex="-1"></a>        train_loader<span class="op">=</span>train_loader,</span>
<span id="cb23-36"><a href="#cb23-36" aria-hidden="true" tabindex="-1"></a>        test_loader<span class="op">=</span>test_loader,</span>
<span id="cb23-37"><a href="#cb23-37" aria-hidden="true" tabindex="-1"></a>        config<span class="op">=</span>config,</span>
<span id="cb23-38"><a href="#cb23-38" aria-hidden="true" tabindex="-1"></a>        device<span class="op">=</span>device,</span>
<span id="cb23-39"><a href="#cb23-39" aria-hidden="true" tabindex="-1"></a>        epochs<span class="op">=</span><span class="dv">40</span></span>
<span id="cb23-40"><a href="#cb23-40" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb23-41"><a href="#cb23-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-42"><a href="#cb23-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize training curves</span></span>
<span id="cb23-43"><a href="#cb23-43" aria-hidden="true" tabindex="-1"></a>plot_training_results(</span>
<span id="cb23-44"><a href="#cb23-44" aria-hidden="true" tabindex="-1"></a>    results,</span>
<span id="cb23-45"><a href="#cb23-45" aria-hidden="true" tabindex="-1"></a>    metrics<span class="op">=</span>[<span class="st">'loss'</span>, <span class="st">'accuracy'</span>, <span class="st">'gradient_norm'</span>, <span class="st">'memory'</span>],</span>
<span id="cb23-46"><a href="#cb23-46" aria-hidden="true" tabindex="-1"></a>    mode<span class="op">=</span><span class="st">"train"</span>,</span>
<span id="cb23-47"><a href="#cb23-47" aria-hidden="true" tabindex="-1"></a>    title<span class="op">=</span><span class="st">'Optimizer Comparison on CIFAR100'</span></span>
<span id="cb23-48"><a href="#cb23-48" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Files already downloaded and verified
Files already downloaded and verified

Starting experiment with SGD optimizer...

==================================================
Optimizer: SGD
Initial CUDA Memory Status (GPU 0):
Allocated: 26.5MB
Reserved: 50.0MB
Model Size: 1194.1K parameters
==================================================
</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f9006d867491454a9db530180a287b44","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
==================================================
Final CUDA Memory Status (GPU 0):
Peak Allocated: 120.4MB
Peak Reserved: 138.0MB
Current Allocated: 35.6MB
Current Reserved: 138.0MB
==================================================

Results saved to: SGD_cnn_20250225_161620.csv

Starting experiment with Adam optimizer...

==================================================
Optimizer: Adam
Initial CUDA Memory Status (GPU 0):
Allocated: 35.6MB
Reserved: 138.0MB
Model Size: 1194.1K parameters
==================================================
</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"dcd60bbfe3b64789828b28ff1a1c305e","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
==================================================
Final CUDA Memory Status (GPU 0):
Peak Allocated: 124.9MB
Peak Reserved: 158.0MB
Current Allocated: 40.2MB
Current Reserved: 158.0MB
==================================================

Results saved to: Adam_cnn_20250225_162443.csv

Starting experiment with Lion optimizer...

==================================================
Optimizer: Lion
Initial CUDA Memory Status (GPU 0):
Allocated: 31.0MB
Reserved: 158.0MB
Model Size: 1194.1K parameters
==================================================
</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"31f67588627840bd8e354958b5028454","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
==================================================
Final CUDA Memory Status (GPU 0):
Peak Allocated: 120.4MB
Peak Reserved: 158.0MB
Current Allocated: 35.6MB
Current Reserved: 158.0MB
==================================================

Results saved to: Lion_cnn_20250225_163259.csv</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="05_Optimización y visualización_files/figure-html/cell-8-output-8.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Los resultados del experimento comparan los algoritmos de optimización SGD, Adam y Lion utilizando el conjunto de datos CIFAR-100 y un modelo CNN, mostrando las características de cada algoritmo.</p>
<ol type="1">
<li><p><strong>Velocidad de convergencia y precisión:</strong></p>
<ul>
<li>SGD muestra una baja precisión (inferior a aproximadamente 50%) incluso después de 40 épocas, convergiendo lentamente.</li>
<li>Adam alcanza una precisión de aproximadamente 50% alrededor de las 20 épocas, convergiendo relativamente rápido.</li>
<li>Lion converge más rápidamente que Adam y logra la mayor precisión de aproximadamente 55% en 40 épocas.</li>
</ul></li>
<li><p><strong>Estabilidad de la curva de aprendizaje:</strong></p>
<ul>
<li>Adam es estable tanto en las curvas de Loss como de Accuracy.</li>
<li>Lion es similarmente estable a Adam, aunque presenta alguna variación en la curva de Accuracy.</li>
<li>SGD muestra alta variabilidad tanto en las curvas de Loss como de Accuracy.</li>
</ul></li>
<li><p><strong>Uso de memoria:</strong></p>
<ul>
<li>Lion (aproximadamente 31MB) y SGD (aproximadamente 31MB) utilizan menos memoria que Adam (aproximadamente 34MB).</li>
</ul></li>
<li><p><strong>Norma del gradiente:</strong></p>
<ul>
<li>Lion: La norma del gradiente inicial es alta (aproximadamente 3.56), aumenta rápidamente y luego disminuye, estabilizándose alrededor de 10. (exploración con grandes pasos iniciales)</li>
<li>Adam: La norma del gradiente inicial es menor que la de Lion (aproximadamente 3.26), aumenta gradualmente y se estabiliza. (exploración estable)</li>
<li>SGD: La norma del gradiente inicial es la más baja (aproximadamente 3.13), muestra alta variabilidad y se mantiene en valores altos en comparación con los otros algoritmos.</li>
</ul></li>
</ol>
<p>Dadas las condiciones experimentales, <strong>Lion</strong> mostró la velocidad de convergencia más rápida y la mayor precisión. <strong>Adam</strong> presentó curvas de aprendizaje estables, mientras que <strong>SGD</strong> fue lento y variable. En términos de uso de memoria, Lion y SGD utilizaron menos memoria que Adam.</p>
<div id="cell-21" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_05.experiments.advanced <span class="im">import</span> run_advanced_experiment</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_05.visualization.optimization <span class="im">import</span> plot_training_results</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_04.utils.data <span class="im">import</span> get_data_loaders</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_05.optimizers.basic <span class="im">import</span> SGD, Adam</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_05.optimizers.advanced <span class="im">import</span> Lion</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Device configuration</span></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda:0"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Data loaders</span></span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>train_loader, test_loader <span class="op">=</span> get_data_loaders(dataset<span class="op">=</span><span class="st">"CIFAR100"</span>)</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Optimizer dictionary</span></span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>optimizers <span class="op">=</span> {</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">'SGD'</span>: SGD,</span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Adam'</span>: Adam,</span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Lion'</span>: Lion</span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Optimizer configurations</span></span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a>optimizer_configs <span class="op">=</span> {</span>
<span id="cb28-23"><a href="#cb28-23" aria-hidden="true" tabindex="-1"></a>    <span class="st">'SGD'</span>: {<span class="st">'lr'</span>: <span class="fl">0.01</span>, <span class="st">'momentum'</span>: <span class="fl">0.9</span>},</span>
<span id="cb28-24"><a href="#cb28-24" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Adam'</span>: {<span class="st">'lr'</span>: <span class="fl">0.001</span>},</span>
<span id="cb28-25"><a href="#cb28-25" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Lion'</span>: {<span class="st">'lr'</span>: <span class="fl">1e-4</span>}</span>
<span id="cb28-26"><a href="#cb28-26" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb28-27"><a href="#cb28-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-28"><a href="#cb28-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Run experiments</span></span>
<span id="cb28-29"><a href="#cb28-29" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> {}</span>
<span id="cb28-30"><a href="#cb28-30" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, config <span class="kw">in</span> optimizer_configs.items():</span>
<span id="cb28-31"><a href="#cb28-31" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Starting experiment with </span><span class="sc">{</span>name<span class="sc">}</span><span class="ss"> optimizer..."</span>)</span>
<span id="cb28-32"><a href="#cb28-32" aria-hidden="true" tabindex="-1"></a>    results[name] <span class="op">=</span> run_advanced_experiment(</span>
<span id="cb28-33"><a href="#cb28-33" aria-hidden="true" tabindex="-1"></a>        optimizer_class<span class="op">=</span>optimizers[name],</span>
<span id="cb28-34"><a href="#cb28-34" aria-hidden="true" tabindex="-1"></a>        model_type<span class="op">=</span><span class="st">'transformer'</span>,</span>
<span id="cb28-35"><a href="#cb28-35" aria-hidden="true" tabindex="-1"></a>        train_loader<span class="op">=</span>train_loader,</span>
<span id="cb28-36"><a href="#cb28-36" aria-hidden="true" tabindex="-1"></a>        test_loader<span class="op">=</span>test_loader,</span>
<span id="cb28-37"><a href="#cb28-37" aria-hidden="true" tabindex="-1"></a>        config<span class="op">=</span>config,</span>
<span id="cb28-38"><a href="#cb28-38" aria-hidden="true" tabindex="-1"></a>        device<span class="op">=</span>device,</span>
<span id="cb28-39"><a href="#cb28-39" aria-hidden="true" tabindex="-1"></a>        epochs<span class="op">=</span><span class="dv">40</span></span>
<span id="cb28-40"><a href="#cb28-40" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb28-41"><a href="#cb28-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-42"><a href="#cb28-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize training curves</span></span>
<span id="cb28-43"><a href="#cb28-43" aria-hidden="true" tabindex="-1"></a>plot_training_results(</span>
<span id="cb28-44"><a href="#cb28-44" aria-hidden="true" tabindex="-1"></a>    results,</span>
<span id="cb28-45"><a href="#cb28-45" aria-hidden="true" tabindex="-1"></a>    metrics<span class="op">=</span>[<span class="st">'loss'</span>, <span class="st">'accuracy'</span>, <span class="st">'gradient_norm'</span>, <span class="st">'memory'</span>],</span>
<span id="cb28-46"><a href="#cb28-46" aria-hidden="true" tabindex="-1"></a>    mode<span class="op">=</span><span class="st">"train"</span>,</span>
<span id="cb28-47"><a href="#cb28-47" aria-hidden="true" tabindex="-1"></a>    title<span class="op">=</span><span class="st">'Optimizer Comparison on CIFAR100'</span></span>
<span id="cb28-48"><a href="#cb28-48" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Files already downloaded and verified
Files already downloaded and verified

Starting experiment with SGD optimizer...</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/sean/anaconda3/envs/DL/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
==================================================
Optimizer: SGD
Initial CUDA Memory Status (GPU 0):
Allocated: 274.5MB
Reserved: 318.0MB
Model Size: 62099.8K parameters
==================================================
</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"0194a84568dd47cc87bcbd8b8efcf1c7","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
==================================================
Final CUDA Memory Status (GPU 0):
Peak Allocated: 836.8MB
Peak Reserved: 906.0MB
Current Allocated: 749.5MB
Current Reserved: 906.0MB
==================================================

Results saved to: SGD_transformer_20250225_164652.csv

Starting experiment with Adam optimizer...

==================================================
Optimizer: Adam
Initial CUDA Memory Status (GPU 0):
Allocated: 748.2MB
Reserved: 906.0MB
Model Size: 62099.8K parameters
==================================================
</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a67a0697ce6e40169da7fa60aa2dd45f","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
==================================================
Final CUDA Memory Status (GPU 0):
Peak Allocated: 1073.0MB
Peak Reserved: 1160.0MB
Current Allocated: 985.1MB
Current Reserved: 1160.0MB
==================================================

Results saved to: Adam_transformer_20250225_170159.csv

Starting experiment with Lion optimizer...

==================================================
Optimizer: Lion
Initial CUDA Memory Status (GPU 0):
Allocated: 511.4MB
Reserved: 1160.0MB
Model Size: 62099.8K parameters
==================================================
</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"7cdfacd5f0ef4c57b845cc96581dcd2e","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
==================================================
Final CUDA Memory Status (GPU 0):
Peak Allocated: 985.1MB
Peak Reserved: 1160.0MB
Current Allocated: 748.2MB
Current Reserved: 1160.0MB
==================================================

Results saved to: Lion_transformer_20250225_171625.csv</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="05_Optimización y visualización_files/figure-html/cell-9-output-10.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Generalmente, los transformadores se utilizan más en forma de estructuras adaptadas a las características de las imágenes, como el ViT (Vision Transformer), en lugar de aplicarse directamente a tareas de clasificación de imágenes. Este experimento se lleva a cabo como un ejemplo para comparar algoritmos de optimización. Los resultados del experimento del modelo de transformador son los siguientes.</p>
<ol type="1">
<li>Rendimiento de convergencia: Adam muestra la convergencia inicial más rápida, seguido por Lion y SGD.</li>
<li>Estabilidad y generalización: Adam alcanza el 30.5% y muestra el rendimiento más estable. Lion alcanza una precisión de prueba del 28.88%, con una ligera disminución en el rendimiento en la etapa final del entrenamiento. SGD logra un 31.1% de precisión, mostrando el mejor rendimiento de generalización.</li>
<li>Uso de memoria: Lion y SGD usan cantidades similares de memoria, mientras que Adam usa relativamente más memoria.</li>
<li>Dinámica del gradiente: La norma del gradiente de Adam disminuye gradualmente de 1.98 a 0.92. Lion comienza en 2.81 y disminuye hasta 1.21, mientras que SGD comienza en 8.41 y disminuye hasta 5.92, mostrando el cambio más significativo.</li>
</ol>
<p><strong>Conclusión</strong> Los resultados del experimento con el conjunto de datos CIFAR-100 muestran que SGD presenta el mejor rendimiento de generalización, aunque es el más lento en términos de velocidad de aprendizaje. Adam muestra la convergencia más rápida y un aprendizaje estable, pero consume mucha memoria, mientras que Lion demuestra un rendimiento equilibrado en términos de eficiencia de memoria y velocidad de convergencia.</p>
</section>
</section>
</section>
<section id="visualización-y-análisis-del-proceso-de-optimización-mirando-dentro-de-la-caja-negra-del-aprendizaje-profundo" class="level2">
<h2 class="anchored" data-anchor-id="visualización-y-análisis-del-proceso-de-optimización-mirando-dentro-de-la-caja-negra-del-aprendizaje-profundo">5.3 Visualización y análisis del proceso de optimización: Mirando dentro de la caja negra del aprendizaje profundo</h2>
<blockquote class="blockquote">
<p><strong>Desafío:</strong> ¿Cómo podemos visualizar y comprender eficazmente el proceso de optimización de redes neuronales en espacios de alta dimensión, con millones o incluso decenas de millones de dimensiones?</p>
<p><strong>Lamentaciones del investigador:</strong> El espacio de parámetros de los modelos de aprendizaje profundo es un espacio de ultra-alta dimensión que resulta difícil de imaginar intuitivamente para los humanos. A pesar de los esfuerzos de los investigadores por desarrollar diversas técnicas de reducción de dimensionalidad y herramientas de visualización para abrir esta “caja negra”, aún hay muchas áreas que permanecen veladas.</p>
</blockquote>
<p>Entender el proceso de aprendizaje de las redes neuronales es fundamental para diseñar modelos eficaces, seleccionar algoritmos de optimización y ajustar hiperparámetros. En particular, visualizar y analizar la geometría de la función de pérdida (loss function) y la trayectoria de optimización proporciona importantes insights sobre la dinámica del proceso de aprendizaje y su estabilidad. <em>En los últimos años, la investigación en la visualización de superficies de pérdida ha brindado pistas clave a los investigadores de aprendizaje profundo para desentrañar los misterios del aprendizaje de redes neuronales, contribuyendo al desarrollo de algoritmos y arquitecturas de modelos más eficientes y estables.</em></p>
<p>En esta sección, examinaremos los conceptos básicos y las técnicas más recientes en la visualización de superficies de pérdida, y cómo estas pueden ayudarnos a analizar diversos fenómenos que ocurren durante el proceso de aprendizaje en redes neuronales (por ejemplo: mínimos locales, puntos de silla, características de la trayectoria de optimización). En particular, nos centraremos en cómo la estructura del modelo (por ejemplo, conexiones residuales) afecta a la superficie de pérdida y las diferencias en la trayectoria de optimización según el algoritmo de optimización utilizado.</p>
<section id="comprensión-de-la-superficie-de-pérdida-loss-landscape-el-mapa-topográfico-del-modelo-de-aprendizaje-profundo" class="level3">
<h3 class="anchored" data-anchor-id="comprensión-de-la-superficie-de-pérdida-loss-landscape-el-mapa-topográfico-del-modelo-de-aprendizaje-profundo">5.3.1 Comprensión de la Superficie de Pérdida (Loss Landscape): El mapa topográfico del modelo de aprendizaje profundo</h3>
<p>La visualización de la superficie de pérdida es una herramienta clave para comprender el proceso de aprendizaje en modelos de aprendizaje profundo. <em>Al igual que un mapa topográfico nos permite entender las altitudes y depresiones de un paisaje, la visualización de la superficie de pérdida nos permite visualizar los cambios de la función de pérdida en el espacio de parámetros.</em></p>
<p>En 2017, Goodfellow et al.&nbsp;demostraron que la planitud (flatness) de la superficie de pérdida está estrechamente relacionada con el rendimiento de generalización del modelo (la tendencia es que los mínimos anchos y planos tienen un mejor rendimiento de generalización que los mínimos estrechos y afilados). En 2018, Li et al.&nbsp;mostraron mediante visualizaciones tridimensionales que las conexiones residuales (residual connections) aplanan la superficie de pérdida, facilitando el aprendizaje. Estos descubrimientos han sido fundamentales en el diseño de arquitecturas modernas de redes neuronales como ResNet.</p>
<section id="técnicas-básicas-de-visualización" class="level5">
<h5 class="anchored" data-anchor-id="técnicas-básicas-de-visualización">Técnicas básicas de visualización</h5>
<ol type="1">
<li><p><strong>Interpolación Lineal (Linear Interpolation):</strong></p>
<ul>
<li><p><em>Concepto:</em> Se combinan linealmente los pesos de dos modelos diferentes (por ejemplo, un modelo antes y después del aprendizaje, o modelos que convergen a diferentes mínimos locales) para calcular el valor de la función de pérdida entre ellos.</p></li>
<li><p><em>Fórmula:</em></p>
<p><span class="math inline">\(w(\alpha) = (1-\alpha)w_1 + \alpha w_2\)</span></p>
<ul>
<li><span class="math inline">\(w_1\)</span>, <span class="math inline">\(w_2\)</span>: pesos de los dos modelos</li>
<li><span class="math inline">\(\alpha \in [0,1]\)</span>: coeficiente de interpolación (0 para <span class="math inline">\(w_1\)</span>, 1 para <span class="math inline">\(w_2\)</span>, y valores intermedios para combinaciones lineales de los pesos)</li>
<li><span class="math inline">\(L(w(\alpha))\)</span>: valor de pérdida en el peso interpolado <span class="math inline">\(w(\alpha)\)</span></li>
</ul></li>
</ul></li>
</ol>
<div id="cell-24" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader, Subset</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_05.visualization.loss_surface <span class="im">import</span> linear_interpolation, visualize_linear_interpolation</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_04.utils.data <span class="im">import</span> get_dataset</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_04.utils.metrics <span class="im">import</span> load_model</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Linear Interpolation</span></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Device configuration</span></span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the dataset</span></span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>_, test_dataset <span class="op">=</span> get_dataset(dataset<span class="op">=</span><span class="st">"FashionMNIST"</span>)</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a small dataset</span></span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a>small_dataset <span class="op">=</span> Subset(test_dataset, torch.arange(<span class="dv">0</span>, <span class="dv">256</span>))</span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>data_loader <span class="op">=</span> DataLoader(small_dataset, batch_size<span class="op">=</span><span class="dv">256</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>loss_func <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a><span class="co"># model1, _ = load_model(model_file="SimpleNetwork-ReLU.pth", path="tmp/models/")</span></span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a><span class="co"># model2, _ = load_model(model_file="SimpleNetwork-Tanh.pth", path="tmp/models/")</span></span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>model1, _ <span class="op">=</span> load_model(model_file<span class="op">=</span><span class="st">"SimpleNetwork-ReLU-epoch1.pth"</span>, path<span class="op">=</span><span class="st">"tmp/models/"</span>)</span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a>model2, _ <span class="op">=</span> load_model(model_file<span class="op">=</span><span class="st">"SimpleNetwork-ReLU-epoch15.pth"</span>, path<span class="op">=</span><span class="st">"tmp/models/"</span>)</span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a>model1 <span class="op">=</span> model1.to(device)</span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a>model2 <span class="op">=</span> model2.to(device)</span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Linear interpolation</span></span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-30"><a href="#cb35-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Test with a small dataset</span></span>
<span id="cb35-31"><a href="#cb35-31" aria-hidden="true" tabindex="-1"></a>_, test_dataset <span class="op">=</span> get_dataset(dataset<span class="op">=</span><span class="st">"FashionMNIST"</span>)</span>
<span id="cb35-32"><a href="#cb35-32" aria-hidden="true" tabindex="-1"></a>small_dataset <span class="op">=</span> Subset(test_dataset, torch.arange(<span class="dv">0</span>, <span class="dv">256</span>))</span>
<span id="cb35-33"><a href="#cb35-33" aria-hidden="true" tabindex="-1"></a>data_loader <span class="op">=</span> DataLoader(small_dataset, batch_size<span class="op">=</span><span class="dv">256</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb35-34"><a href="#cb35-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-35"><a href="#cb35-35" aria-hidden="true" tabindex="-1"></a>alphas, losses,  accuracies <span class="op">=</span> linear_interpolation(model1, model2, data_loader, loss_func, device)</span>
<span id="cb35-36"><a href="#cb35-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-37"><a href="#cb35-37" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> visualize_linear_interpolation(alphas, losses, accuracies,  <span class="st">"ReLU(1)-ReLU(15)"</span>,  size<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">4</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="05_Optimización y visualización_files/figure-html/cell-10-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>En la interpolación lineal, α=0 representa el primer modelo (1 época de entrenamiento), y α=1 representa el segundo modelo (15 épocas de entrenamiento), mientras que los valores intermedios indican combinaciones lineales de los pesos de ambos modelos. En el gráfico, se observa una tendencia a la disminución de los valores de la función de pérdida a medida que α aumenta, lo cual indica que el modelo se desplaza hacia un mejor óptimo a medida que avanza el entrenamiento. Sin embargo, la interpolación lineal tiene la limitación de mostrar solo una faceta muy restringida del espacio de pesos de alta dimensión. La ruta óptima real entre los dos modelos es probablemente no lineal, y extender el rango de α más allá de [0,1] dificulta su interpretación.</p>
<p>La exploración de rutas no lineales utilizando curvas de Bézier o splines, y la visualización de estructuras de alta dimensión mediante PCA o t-SNE, pueden proporcionar información más completa. En la práctica, se recomienda utilizar la interpolación lineal como herramienta de análisis inicial, y limitar α al rango [0,1] o con una pequeña extrapolación. Es importante analizar de manera integral junto con otras técnicas de visualización, especialmente cuando las diferencias en el rendimiento del modelo son significativas.</p>
<p>A continuación se presentan los análisis de PCA y t-SNE.</p>
<div id="cell-26" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_05.visualization.loss_surface <span class="im">import</span> analyze_weight_space, visualize_weight_space</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_04.utils.metrics <span class="im">import</span> load_model, load_models_by_pattern</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>models, labels <span class="op">=</span> load_models_by_pattern(</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>    activation_types<span class="op">=</span>[<span class="st">'ReLU'</span>],</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># activation_types=['Tanh'],</span></span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># activation_types=['GELU'],</span></span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span>[<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">7</span>,<span class="dv">8</span>,<span class="dv">9</span>,<span class="dv">10</span>,<span class="dv">11</span>,<span class="dv">12</span>,<span class="dv">13</span>,<span class="dv">14</span>,<span class="dv">15</span>]</span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a><span class="co"># PCA analysis</span></span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a>embedded_pca <span class="op">=</span> analyze_weight_space(models, labels, method<span class="op">=</span><span class="st">'pca'</span>)</span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a>visualize_weight_space(embedded_pca, labels, method<span class="op">=</span><span class="st">'PCA'</span>)</span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"embedded_pca = </span><span class="sc">{</span>embedded_pca<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-18"><a href="#cb36-18" aria-hidden="true" tabindex="-1"></a><span class="co"># t-SNE analysis</span></span>
<span id="cb36-19"><a href="#cb36-19" aria-hidden="true" tabindex="-1"></a>embedded_tsne <span class="op">=</span> analyze_weight_space(models, labels, method<span class="op">=</span><span class="st">'tsne'</span>, perplexity<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb36-20"><a href="#cb36-20" aria-hidden="true" tabindex="-1"></a>visualize_weight_space(embedded_tsne, labels, method<span class="op">=</span><span class="st">'t-SNE'</span>)</span>
<span id="cb36-21"><a href="#cb36-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"embedded_tsne = </span><span class="sc">{</span>embedded_tsne<span class="sc">}</span><span class="ss">"</span>) <span class="co"># Corrected: Print embedded_tsne, not embedded_pca</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="05_Optimización y visualización_files/figure-html/cell-11-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>embedded_pca = [[ 9.8299894e+00  2.1538167e+00]
 [-1.1609798e+01 -9.0169059e-03]
 [-1.1640446e+01 -1.2218434e-02]
 [-1.1667191e+01 -1.3469303e-02]
 [-1.1691980e+01 -1.5136327e-02]
 [-1.1714937e+01 -1.6765745e-02]
 [-1.1735878e+01 -1.8110925e-02]
 [ 9.9324265e+00  1.5862983e+00]
 [ 1.0126298e+01  4.7935897e-01]
 [ 1.0256655e+01 -2.8844318e-01]
 [ 1.0319887e+01 -6.6510278e-01]
 [ 1.0359785e+01 -8.9812231e-01]
 [ 1.0392080e+01 -1.0731999e+00]
 [ 1.0418671e+01 -1.2047548e+00]
 [-1.1575559e+01 -5.1336871e-03]]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="05_Optimización y visualización_files/figure-html/cell-11-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>embedded_tsne = [[ 119.4719    -99.78837 ]
 [ 100.26558    66.285835]
 [  94.79294    62.795162]
 [  89.221085   59.253677]
 [  83.667984   55.70297 ]
 [  77.897224   52.022995]
 [  74.5897     49.913578]
 [ 123.20351  -100.34615 ]
 [ -70.45423   -65.66194 ]
 [ -65.55417   -68.90429 ]
 [ -60.166885  -72.466805]
 [ -54.70004   -76.077   ]
 [ -49.00131   -79.833694]
 [ -45.727974  -81.99213 ]
 [ 105.22419    69.45333 ]]</code></pre>
</div>
</div>
<p>La visualización de PCA y t-SNE proyecta los cambios en el espacio de pesos del modelo durante el proceso de aprendizaje a una dimensión más baja (2D).</p>
<ul>
<li><strong>Visualización de PCA:</strong>
<ul>
<li>Los puntos representan los pesos del modelo para cada época (epoch). (Morado (época 1) -&gt; Rojo (época 9) -&gt; Verde (después de la época 10))</li>
<li>Los pesos que se dispersaban ampliamente al principio se agrupan en una región específica a medida que avanza el aprendizaje.</li>
<li>En particular, se observa un cambio significativo cuando se pasa de la época 9 a la época 10.</li>
<li>PCA muestra las direcciones (componentes principales) donde ocurren los mayores cambios en el espacio de pesos.</li>
</ul></li>
<li><strong>Visualización de t-SNE:</strong>
<ul>
<li>Similar a PCA, los colores de los puntos cambian según la época y muestran cómo evoluciona la distribución de los pesos durante las etapas tempranas, medias y tardías del aprendizaje.</li>
<li>t-SNE es una técnica de reducción de dimensiones <em>no lineal</em> que se centra en preservar las <em>relaciones de vecindad local</em> en el espacio de alta dimensión.</li>
<li>El grupo de épocas 1-9 y el grupo de épocas 10-15 están relativamente bien separados, lo cual respalda los resultados de PCA.</li>
</ul></li>
</ul>
<p>A través de estas visualizaciones, se puede obtener una comprensión intuitiva de cómo cambian los pesos del modelo durante el proceso de aprendizaje y cómo el algoritmo de optimización explora el espacio de pesos. <em>Particularmente, usar PCA y t-SNE juntos permite apreciar tanto los cambios globales (PCA) como las estructuras locales (t-SNE) simultáneamente.</em></p>
<ol start="2" type="1">
<li><strong>Mapa de contorno (Contour Plot)</strong></li>
</ol>
<p>El mapa de contorno es un método que traza líneas (contornos) que conectan puntos donde el valor de la función de pérdida es constante en un plano bidimensional, para visualizar la forma de la superficie de pérdida. <em>Al igual que las líneas de contorno en un mapa topográfico, muestra las “elevaciones” de la función de pérdida.</em></p>
<p><em>El procedimiento general es el siguiente:</em></p>
<ol type="1">
<li><p><strong>Establecimiento del punto de referencia:</strong> Se selecciona un conjunto de parámetros del modelo (<span class="math inline">\(w_0\)</span>) como punto de referencia. (ejemplo: los parámetros de un modelo ya entrenado)</p></li>
<li><p><strong>Selección de vectores de dirección:</strong> Se eligen dos vectores de dirección (<span class="math inline">\(d_1\)</span>, <span class="math inline">\(d_2\)</span>). <em>Estos vectores forman una base para el plano bidimensional.</em></p>
<ul>
<li><em>Elecciones comunes:</em> direcciones aleatorias, direcciones de los componentes principales obtenidas a través de PCA (Análisis de Componentes Principales), o los dos primeros autovectores del tensor Hessiano obtenidos usando bibliotecas como PyHessian. <em>En el último caso, representan las direcciones en las que la función de pérdida cambia más drásticamente.</em></li>
</ul></li>
<li><p><strong>Perturbación de parámetros:</strong> Se perturban (varían) los parámetros a lo largo de los dos vectores de dirección seleccionados <span class="math inline">\(d_1\)</span>, <span class="math inline">\(d_2\)</span> con el punto de referencia <span class="math inline">\(w_0\)</span> como centro.</p>
<pre><code>$w(\lambda_1, \lambda_2) = w_0 + \lambda_1 d_1 + \lambda_2 d_2$

*   $\lambda_1$, $\lambda_2$: coeficientes escalares para cada vector de dirección (ejemplo: valores seleccionados a intervalos constantes en el rango -0.2 ~ 0.2)</code></pre></li>
<li><p><strong>Cálculo del valor de pérdida:</strong> Para cada combinación <span class="math inline">\((\lambda_1, \lambda_2)\)</span>, se aplican los parámetros perturbados <span class="math inline">\(w(\lambda_1, \lambda_2)\)</span> al modelo y se calcula el valor de la función de pérdida.</p></li>
<li><p><strong>Gráfico de contorno:</strong> Se traza un gráfico de contorno bidimensional utilizando los datos <span class="math inline">\((\lambda_1, \lambda_2, L(w(\lambda_1, \lambda_2)))\)</span>. (se pueden usar funciones como <code>contour</code> o <code>tricontourf</code> de matplotlib)</p></li>
</ol>
<p><em>El mapa de contorno muestra visualmente la geometría local de la superficie de pérdida y puede utilizarse para analizar el comportamiento de los algoritmos de optimización al mostrar sus trayectorias junto con las líneas de contorno.</em></p>
<div id="cell-29" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader, Subset</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_05.visualization.loss_surface <span class="im">import</span> hessian_eigenvectors, xy_perturb_loss, visualize_loss_surface, linear_interpolation</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_04.utils.data <span class="im">import</span> get_dataset</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_04.utils.metrics <span class="im">import</span> load_model</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_05.optimizers.basic <span class="im">import</span> SGD, Adam</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Device configuration</span></span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the dataset</span></span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a>_, test_dataset <span class="op">=</span> get_dataset(dataset<span class="op">=</span><span class="st">"FashionMNIST"</span>)</span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a small dataset</span></span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a>small_dataset <span class="op">=</span> Subset(test_dataset, torch.arange(<span class="dv">0</span>, <span class="dv">256</span>))</span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a>data_loader <span class="op">=</span> DataLoader(small_dataset, batch_size<span class="op">=</span><span class="dv">256</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a>loss_func <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a>trained_model, _ <span class="op">=</span> load_model(model_file<span class="op">=</span><span class="st">"SimpleNetwork-ReLU.pth"</span>, path<span class="op">=</span><span class="st">"tmp/models/"</span>)</span>
<span id="cb40-21"><a href="#cb40-21" aria-hidden="true" tabindex="-1"></a><span class="co"># trained_model, _ = load_model(model_file="SimpleNetwork-Tanh.pth", path="tmp/models/")</span></span>
<span id="cb40-22"><a href="#cb40-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-23"><a href="#cb40-23" aria-hidden="true" tabindex="-1"></a>trained_model <span class="op">=</span> trained_model.to(device)</span>
<span id="cb40-24"><a href="#cb40-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-25"><a href="#cb40-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-26"><a href="#cb40-26" aria-hidden="true" tabindex="-1"></a><span class="co"># pyhessian</span></span>
<span id="cb40-27"><a href="#cb40-27" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> []  <span class="co"># List to store the calculated result sets</span></span>
<span id="cb40-28"><a href="#cb40-28" aria-hidden="true" tabindex="-1"></a>top_n <span class="op">=</span> <span class="dv">4</span>  <span class="co"># Must be an even number.  Each pair of eigenvectors is used.  2 is the minimum.  10 means 5 graphs.</span></span>
<span id="cb40-29"><a href="#cb40-29" aria-hidden="true" tabindex="-1"></a>top_eigenvalues, top_eignevectors <span class="op">=</span> hessian_eigenvectors(model<span class="op">=</span>trained_model, loss_func<span class="op">=</span>loss_func, data_loader<span class="op">=</span>data_loader, top_n<span class="op">=</span>top_n, is_cuda<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb40-30"><a href="#cb40-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-31"><a href="#cb40-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the scale with lambda.</span></span>
<span id="cb40-32"><a href="#cb40-32" aria-hidden="true" tabindex="-1"></a>lambda1, lambda2 <span class="op">=</span> np.linspace(<span class="op">-</span><span class="fl">0.2</span>, <span class="fl">0.2</span>, <span class="dv">40</span>).astype(np.float32), np.linspace(<span class="op">-</span><span class="fl">0.2</span>, <span class="fl">0.2</span>, <span class="dv">40</span>).astype(np.float32)</span>
<span id="cb40-33"><a href="#cb40-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-34"><a href="#cb40-34" aria-hidden="true" tabindex="-1"></a><span class="co"># If top_n=10, a total of 5 pairs of graphs can be drawn.</span></span>
<span id="cb40-35"><a href="#cb40-35" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(top_n <span class="op">//</span> <span class="dv">2</span>):</span>
<span id="cb40-36"><a href="#cb40-36" aria-hidden="true" tabindex="-1"></a>    x, y, z <span class="op">=</span> xy_perturb_loss(model<span class="op">=</span>trained_model, top_eigenvectors<span class="op">=</span>top_eignevectors[i<span class="op">*</span><span class="dv">2</span>:(i<span class="op">+</span><span class="dv">1</span>)<span class="op">*</span><span class="dv">2</span>], data_loader<span class="op">=</span>data_loader, loss_func<span class="op">=</span>loss_func, lambda1<span class="op">=</span>lambda1, lambda2<span class="op">=</span>lambda2, device<span class="op">=</span>device)</span>
<span id="cb40-37"><a href="#cb40-37" aria-hidden="true" tabindex="-1"></a>    data.append((x, y, z))</span>
<span id="cb40-38"><a href="#cb40-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-39"><a href="#cb40-39" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> visualize_loss_surface(data, <span class="st">"ReLU"</span>, color<span class="op">=</span><span class="st">"C0"</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, plot_3d<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb40-40"><a href="#cb40-40" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> visualize_loss_surface(data, <span class="st">"ReLU"</span>, color<span class="op">=</span><span class="st">"C0"</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, plot_3d<span class="op">=</span><span class="va">False</span>) <span class="co"># Changed "ReLu" to "ReLU" for consistency</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>/home/sean/anaconda3/envs/DL/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at ../torch/csrc/autograd/engine.cpp:1201.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="05_Optimización y visualización_files/figure-html/cell-12-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="05_Optimización y visualización_files/figure-html/cell-12-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>El mapa de contornos proporciona información más rica <em>sobre el área local</em> en comparación con la interpolación lineal simple. Mientras que la interpolación lineal muestra los cambios en los valores de la función de pérdida a lo largo de una <em>ruta unidimensional</em> entre dos modelos, el mapa de contornos visualiza los cambios en la función de pérdida en un <em>plano bidimensional</em> con ejes definidos por las dos direcciones seleccionadas (<span class="math inline">\(\lambda_1\)</span>, <span class="math inline">\(\lambda_2\)</span>). De esta manera, se pueden identificar sutiles cambios a lo largo del camino de optimización, <em>mínimos locales y puntos de silla en el área circundante que no se pueden detectar con interpolación lineal</em>, así como las barreras entre ellos.</p>
</section>
</section>
<section id="técnicas-avanzadas-de-análisis-de-la-superficie-de-pérdida" class="level3">
<h3 class="anchored" data-anchor-id="técnicas-avanzadas-de-análisis-de-la-superficie-de-pérdida">5.3.2 Técnicas avanzadas de análisis de la superficie de pérdida</h3>
<p>Más allá de visualizaciones simples (interpolación lineal, mapas de contorno), se están investigando técnicas de análisis avanzado para comprender más profundamente la superficie de pérdida de los modelos de deep learning.</p>
<ol type="1">
<li><p><strong>Análisis topológico (Topological Data Analysis, TDA):</strong></p>
<ul>
<li><em>Idea clave:</em> Utiliza herramientas de topología para analizar la “forma” de la superficie de pérdida, como su conectividad.</li>
<li><em>Técnicas principales:</em> Homología persistente, algoritmo Mapper, etc.</li>
<li><em>Aplicación:</em> Permite comprender la complejidad de la superficie de pérdida, la estructura de conexión de los mínimos locales, las características de los puntos de silla, y obtener insights sobre la dinámica del aprendizaje y el rendimiento de la generalización. <em>(Para más detalles, ver “Profundizando: Análisis topológico de la superficie de pérdida”)</em></li>
</ul></li>
<li><p><strong>Análisis multi-escala (Multi-scale Analysis):</strong></p>
<ul>
<li><em>Idea clave:</em> Analiza la superficie de pérdida a diferentes escalas para comprender tanto las estructuras macroscópicas como microscópicas.</li>
<li><em>Técnicas principales:</em> Transformada wavelet, teoría del espacio de escala, etc.</li>
<li><em>Aplicación:</em> Permite analizar la rugosidad de la superficie de pérdida y la distribución de características a diferentes escalas, lo que ayuda a entender el funcionamiento de los algoritmos de optimización y las dificultades del aprendizaje. <em>(Para más detalles, ver “Profundizando: Análisis multi-escala de la superficie de pérdida”)</em></li>
</ul></li>
</ol>
<p><em>Estas técnicas avanzadas de análisis proporcionan información más abstracta y cuantitativa sobre la superficie de pérdida, lo que contribuye a una comprensión más profunda del proceso de aprendizaje de los modelos de deep learning y al diseño de mejores estrategias de modelado y optimización.</em></p>
<div id="cell-32" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn  <span class="co"># Import the nn module</span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader, Subset  <span class="co"># Import DataLoader and Subset</span></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_05.visualization.loss_surface <span class="im">import</span>  analyze_loss_surface_multiscale</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_04.utils.data <span class="im">import</span> get_dataset  <span class="co"># Import get_dataset</span></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_04.utils.metrics <span class="im">import</span> load_model  <span class="co"># Import load_model</span></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Device configuration</span></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Load dataset and create a small subset</span></span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>_, test_dataset <span class="op">=</span> get_dataset(dataset<span class="op">=</span><span class="st">"FashionMNIST"</span>)</span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>small_dataset <span class="op">=</span> Subset(test_dataset, torch.arange(<span class="dv">0</span>, <span class="dv">256</span>))</span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a>data_loader <span class="op">=</span> DataLoader(small_dataset, batch_size<span class="op">=</span><span class="dv">256</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a>loss_func <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Load model (example: SimpleNetwork-ReLU)</span></span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a>model, _ <span class="op">=</span> load_model(model_file<span class="op">=</span><span class="st">"SimpleNetwork-ReLU.pth"</span>, path<span class="op">=</span><span class="st">"tmp/models/"</span>)</span>
<span id="cb42-19"><a href="#cb42-19" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> model.to(device)</span>
<span id="cb42-20"><a href="#cb42-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-21"><a href="#cb42-21" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> analyze_loss_surface_multiscale(model, data_loader, loss_func, device)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="05_Optimización y visualización_files/figure-html/cell-13-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Se utilizó la función <code>analyze_loss_surface_multiscale</code> para analizar y visualizar la superficie de pérdida del modelo <code>SimpleNetwork-ReLU</code> entrenado en el conjunto de datos FashionMNIST desde una perspectiva multiscale.</p>
<p><strong>Interpretación del gráfico (basada en transformada wavelet):</strong></p>
<ul>
<li><p><strong>Coeficientes Aproximados (coeficientes aproximados):</strong> Representan la forma general de la superficie de pérdida (estructura global). Es probable que haya un mínimo en el centro (valores de baja pérdida).</p></li>
<li><p><strong>Coef. Detalle Nivel 1/2 (coeficientes detallados):</strong> Representan cambios a una escala más pequeña. “Nivel 1” muestra la escala intermedia, mientras que “Nivel 2” muestra las irregularidades a la escala más fina (mínimos locales, puntos de silla, ruido, etc.).</p></li>
<li><p><strong>Color:</strong> Color oscuro (baja pérdida), color claro (alta pérdida)</p></li>
<li><p>Los resultados pueden variar según la implementación de la función <code>analyze_loss_surface_multiscale</code> (función wavelet, niveles de descomposición, etc.).</p></li>
<li><p>Esta visualización muestra solo <em>parte</em> de la superficie de pérdida; es difícil capturar completamente la complejidad del espacio de alta dimensión.</p></li>
</ul>
<p>El análisis multiscale descompone la superficie de pérdida en múltiples escalas para mostrar estructuras multifacéticas que son difíciles de apreciar con una simple visualización. A gran escala, permite comprender las tendencias generales; a pequeña escala, permite observar los cambios locales, lo que ayuda a entender el comportamiento de los algoritmos de optimización, la dificultad del aprendizaje y el rendimiento de generalización.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Haga clic para ver el contenido (análisis de la superficie de pérdida basado en topología)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Haga clic para ver el contenido (análisis de la superficie de pérdida basado en topología)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<section id="análisis-de-superficies-de-pérdida-basado-en-topología" class="level3 callout-body-container callout-body">
<h3 class="anchored" data-anchor-id="análisis-de-superficies-de-pérdida-basado-en-topología">Análisis de superficies de pérdida basado en topología</h3>
<p>La topología es el estudio de las propiedades geométricas que no cambian bajo transformaciones continuas. En el aprendizaje profundo, el análisis basado en topología se utiliza para examinar características topológicas como la conectividad, los agujeros y los vacíos de las superficies de pérdida, lo que proporciona insights sobre la dinámica del aprendizaje y el rendimiento de generalización.</p>
<p><strong>Conceptos clave:</strong></p>
<ul>
<li><p><strong>Conjunto de nivel inferior (Sublevel Set):</strong> Dada una función <span class="math inline">\(f: \mathbb{R}^n \rightarrow \mathbb{R}\)</span> y un valor crítico <span class="math inline">\(c\)</span>, se define como <span class="math inline">\(f^{-1}((-\infty, c]) = {x \in \mathbb{R}^n | f(x) \leq c}\)</span>. En el contexto de una función de pérdida, representa las regiones del espacio de parámetros donde la pérdida es menor o igual a un cierto valor.</p></li>
<li><p><strong>Homología persistente (Persistent Homology):</strong> Rastrea los cambios en los conjuntos de nivel inferior y registra la creación y anulación de características topológicas (componentes conectados, lazos, vacíos, …).</p>
<ul>
<li><strong>Características de orden 0 (Componentes Conectados):</strong> Número de regiones que están interconectadas. En las superficies de pérdida, está relacionado con el número de mínimos locales.</li>
<li><strong>Características de orden 1 (Lazos):</strong> Número de lazos cerrados. En las superficies de pérdida, se asocia con la existencia de caminos que rodean los puntos de silla.</li>
</ul></li>
<li><p><strong>Diagrama de persistencia (Persistence Diagram):</strong> Muestra los valores de pérdida en los momentos de creación y anulación de cada característica topológica en un plano de coordenadas. La coordenada <span class="math inline">\(y\)</span> (<span class="math inline">\(\text{death} - \text{birth}\)</span>) representa la “vida” o “persistencia” de una característica, y cuanto mayor sea el valor, más estable se considera la característica.</p></li>
<li><p><strong>Distancia embotellamiento (Bottleneck Distance):</strong> Es uno de los métodos para medir la distancia entre dos diagramas de persistencia. Encuentra el mejor emparejamiento de puntos entre los dos diagramas y calcula el valor máximo de las distancias entre los puntos emparejados.</p></li>
</ul>
<p><strong>Antecedentes matemáticos (resumidos):</strong></p>
<ul>
<li><strong>Complejo simplicial (Simplicial Complex):</strong> Concepto que generaliza puntos, líneas, triángulos, tetraedros, etc., y se utiliza para aproximar espacios topológicos.</li>
<li><strong>Operador de borde (Boundary Operator):</strong> Operador que calcula el borde de un complejo simplicial.</li>
<li><strong>Grupo de homología (Homology Group):</strong> Grupo definido usando el operador de borde, que representa los “agujeros” en un espacio topológico.</li>
<li><strong>Algoritmo de homología persistente (Persistent Homology Algorithm):</strong> Construye un complejo simplicial a través de la filtración de conjuntos de nivel inferior y rastrea los cambios en el grupo de homología para calcular el diagrama de persistencia. (Para más detalles, ver referencia [1])</li>
</ul>
<p><strong>Aplicación en investigación de aprendizaje profundo:</strong> * <strong>Análisis de la estructura de la superficie de pérdida:</strong> A través del diagrama de persistencia, se puede determinar la complejidad de la superficie de pérdida, el número de mínimos locales y su estabilidad, así como la existencia de puntos de silla. * Ejemplo: <a href="https://www.google.com/search?q=https://www.google.com/search%3Fq%3Dhttps://arxiv.org/abs/1803.06934">Gur-Ari et al., 2018</a> calcularon el diagrama de persistencia de la superficie de pérdida de redes neuronales y demostraron que las redes anchas (wide) tienen una estructura topológica más simple en comparación con las redes estrechas (narrow). * <strong>Predicción del rendimiento de generalización:</strong> Las características del diagrama de persistencia (por ejemplo, la duración de la característica 0 de mayor vida) pueden estar correlacionadas con el rendimiento de generalización del modelo. * Ejemplo: <a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://proceedings.mlr.press/v162/perez22a.html">Perez et al., 2022</a> propusieron un método para predecir el rendimiento de generalización del modelo utilizando características del diagrama de persistencia. * <strong>Conectividad modal</strong>: Se buscan caminos que conecten diferentes mínimos locales y se analizan las barreras de energía a lo largo de esos caminos. * Ejemplo: <a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://arxiv.org/abs/1802.10026">Garipov et al., 2018</a></p>
<p><strong>Referencias:</strong></p>
<ol type="1">
<li>Edelsbrunner, H., &amp; Harer, J. (2010). <em>Computational Topology: An Introduction</em>. American Mathematical Society.</li>
<li>Gur-Ari, G., Roberts, D. A., &amp; Dyer, E. (2018). <em>Gradient descent happens in a tiny subspace</em>. arXiv preprint arXiv:1812.04754.</li>
<li>Perez, D., Masoomi, A., DiCecco, J., &amp; Chwialkowski, K. (2022). <em>Relating loss landscape topology to generalization with persistent homology</em>. In International Conference on Machine Learning (pp.&nbsp;17953-17977). PMLR.</li>
<li>Garipov, T., Izmailov, P., Podoprikhin, D., Vetrov, D. P., &amp; Wilson, A. G. (2018). <em>Loss surfaces, mode connectivity, and fast ensembling of dnns.</em> Advances in neural information processing systems, 31.</li>
</ol>
</section>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Haga clic para ver el contenido (análisis profundo: análisis de superficie de pérdida multiscale)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Haga clic para ver el contenido (análisis profundo: análisis de superficie de pérdida multiscale)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<section id="análisis-de-superficie-de-pérdida-a-múltiples-escalas" class="level3 callout-body-container callout-body">
<h3 class="anchored" data-anchor-id="análisis-de-superficie-de-pérdida-a-múltiples-escalas">Análisis de superficie de pérdida a múltiples escalas</h3>
<p>La superficie de pérdida de los modelos de deep learning presenta características en diversas escalas. Desde valles y crestas grandes hasta baches y hoyos pequeños, las estructuras geométricas de diferentes tamaños influyen en el proceso de aprendizaje. El análisis a múltiples escalas es un método que separa y analiza estas características de diferentes escalas.</p>
<p><strong>Idea principal:</strong></p>
<ul>
<li><p><strong>Transformada de ondaletas (Wavelet Transform):</strong> La transformada de ondaletas es una herramienta matemática que descompone una señal en componentes de frecuencia. Al aplicarla a la función de pérdida, se pueden separar características a diferentes escalas.</p>
<ul>
<li><p><strong>Transformada continua de ondaletas (Continuous Wavelet Transform, CWT):</strong></p>
<p><span class="math inline">\(W(a, b) = \int\_{-\infty}^{\infty} f(x) \psi\_{a,b}(x) dx\)</span></p>
<ul>
<li><span class="math inline">\(f(x)\)</span>: función a analizar (función de pérdida)</li>
<li><span class="math inline">\(\psi\_{a,b}(x) = \frac{1}{\sqrt{a}}\psi(\frac{x-b}{a})\)</span>: función de ondaleta (función madre de ondaleta <span class="math inline">\(\psi\)</span> escalada (<span class="math inline">\(a\)</span>) y trasladada (<span class="math inline">\(b\)</span>))</li>
<li><span class="math inline">\(W(a, b)\)</span>: coeficiente de ondaleta en la escala <span class="math inline">\(a\)</span>, posición <span class="math inline">\(b\)</span></li>
</ul></li>
<li><p><strong>Función madre de ondaleta:</strong> función que cumple ciertas condiciones (por ejemplo, Mexican hat wavelet, Morlet wavelet) (ver referencia [2] para más detalles)</p></li>
</ul></li>
<li><p><strong>Análisis multiresolución (Multi-resolution Analysis, MRA):</strong> Método que descompone una señal en diferentes niveles de resolución al discretizar la CWT.</p></li>
</ul>
<p><strong>Fondo matemático (resumido):</strong></p>
<ul>
<li><strong>Función de escalamiento:</strong> función que representa los componentes de baja frecuencia.</li>
<li><strong>Función de ondaleta:</strong> función que representa los componentes de alta frecuencia.</li>
<li><strong>Descomposición:</strong> descomponer la señal en una combinación de funciones de escalamiento y ondaletas.</li>
<li><strong>Reconstrucción:</strong> reconstruir la señal original a partir de las señales descompuestas. <em>(ver referencia [1] para más detalles)</em></li>
</ul>
<p><strong>Aplicaciones en investigación de deep learning:</strong></p>
<ul>
<li><p><strong>Análisis de rugosidad de la superficie de pérdida:</strong> A través de la transformada de ondaletas, se puede cuantificar la rugosidad de la superficie de pérdida y analizar su impacto en la velocidad de aprendizaje y el rendimiento de generalización.</p>
<ul>
<li>Ejemplo: <a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=%5Bhttps://www.google.com/search?q=https://arxiv.org/abs/1910.00779">Li et al., 2019</a> usaron un análisis multiresolución basado en ondaletas para analizar el impacto de la rugosidad de la superficie de pérdida en la dinámica del aprendizaje.</li>
</ul></li>
<li><p><strong>Análisis de algoritmos de optimización:</strong> Analizar cómo los algoritmos de optimización se mueven a lo largo de las características en cada escala para comprender mejor su funcionamiento.</p></li>
</ul>
<p><strong>Referencias:</strong> 1. Mallat, S. (2008). <em>Un recorrido por las ondículas en el procesamiento de señales: el camino escaso</em>. Academic press. 2. Daubechies, I. (1992). <em>Diez lecciones sobre ondículas</em>. Society for industrial and applied mathematics. 3. Li, Y., Hu, W., Zhang, Y., &amp; Gu, Q. (2019). <em>Análisis multirresolución del paisaje de pérdida de redes profundas</em>. arXiv preprint arXiv:1910.00779.</p>
</section>
</div>
</div>
</section>
</section>
<section id="visualización-del-proceso-de-optimización-explorando-los-secretos-del-aprendizaje-profundo-con-la-función-gaussiana" class="level2">
<h2 class="anchored" data-anchor-id="visualización-del-proceso-de-optimización-explorando-los-secretos-del-aprendizaje-profundo-con-la-función-gaussiana">5.4 Visualización del proceso de optimización: explorando los secretos del aprendizaje profundo con la función gaussiana</h2>
<p>La superficie de pérdida real de un modelo de aprendizaje profundo existe en un <em>espacio de ultra alta dimensión</em> que puede tener millones o incluso billones de dimensiones, y presenta una estructura geométrica muy compleja. Por lo tanto, visualizar y analizar directamente esta superficie es <em>prácticamente imposible</em>. Además, la superficie de pérdida real presenta diversos problemas como puntos no diferenciables, discontinuidades e inestabilidades numéricas, lo que dificulta su análisis teórico.</p>
<section id="análisis-aproximado-mediante-funciones-gaussianas-insights-ocultos-en-la-simplicidad" class="level3">
<h3 class="anchored" data-anchor-id="análisis-aproximado-mediante-funciones-gaussianas-insights-ocultos-en-la-simplicidad">5.4.1 Análisis aproximado mediante funciones gaussianas: insights ocultos en la simplicidad</h3>
<p>Para superar estas limitaciones y entender <em>conceptualmente</em> el proceso de optimización, utilizamos la función gaussiana (Gaussian function), que es suave (smooth), continua (continuous) y <em>convexa</em>, para aproximar (approximate) la superficie de pérdida.</p>
<p><strong>Razones para usar funciones gaussianas (ventajas de la aproximación de la superficie de pérdida):</strong></p>
<ol type="1">
<li><strong>Diferenciabilidad:</strong> La función gaussiana es infinitamente diferenciable en todos los puntos, lo cual es una condición esencial para aplicar y analizar algoritmos de optimización basados en el descenso del gradiente (gradient descent).</li>
<li><strong>Convexidad:</strong> Una sola función gaussiana es convexa. Las funciones convexas tienen un único mínimo global, lo que facilita el análisis de la convergencia de los algoritmos de optimización.</li>
<li><strong>Simetría:</strong> La función gaussiana tiene una forma simétrica respecto a su punto central, lo que significa que no hay sesgo en direcciones específicas de la superficie de pérdida, simplificando las suposiciones para el análisis del comportamiento del algoritmo de optimización.</li>
<li><strong>Simplicidad matemática:</strong> La función gaussiana se puede expresar con una fórmula relativamente simple, lo que facilita su análisis matemático y permite entender teóricamente el funcionamiento de los algoritmos de optimización y derivar resultados predecibles.</li>
<li><strong>Complejidad ajustable:</strong> Se puede ajustar la complejidad utilizando modelos mixtos gaussianos (Gaussian Mixture Models, GMM).</li>
</ol>
<p><strong>Fórmula de la función gaussiana:</strong></p>
<p><span class="math inline">\(z = A \exp\left(-\left(\frac{(x-x_0)^2}{2\sigma_1^2} + \frac{(y-y_0)^2}{2\sigma_2^2}\right)\right)\)</span></p>
<ul>
<li><span class="math inline">\(A\)</span>: amplitud - altura máxima de la función de pérdida</li>
<li><span class="math inline">\(x_0\)</span>, <span class="math inline">\(y_0\)</span>: centro - posición del mínimo de la función de pérdida</li>
<li><span class="math inline">\(\sigma_1\)</span>, <span class="math inline">\(\sigma_2\)</span>: desviaciones estándar en las direcciones x e y - ancho de la superficie de pérdida (ancho o estrecho)</li>
</ul>
<p>Por supuesto, la superficie de pérdida real puede ser mucho más compleja que una función gaussiana (con múltiples mínimos locales, puntos de silla, mesetas, etc.). Sin embargo, <em>la aproximación mediante una sola función gaussiana proporciona un punto de partida útil para comprender las características básicas del comportamiento del algoritmo de optimización (por ejemplo, velocidad de convergencia, patrones de oscilación) y comparar diferentes algoritmos</em>. Para simular superficies de pérdida más complejas, se pueden usar modelos mixtos gaussianos que combinan múltiples funciones gaussianas.</p>
<p><em>En esta sección, utilizaremos una sola función gaussiana para aproximar la superficie de pérdida y aplicaremos diversos algoritmos de optimización (SGD, Adam, etc.) para visualizar las trayectorias de aprendizaje, permitiéndonos comprender intuitivamente las características dinámicas y los puntos fuertes y débiles de cada algoritmo.</em></p>
<div id="cell-37" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader, Subset</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_05.visualization.loss_surface <span class="im">import</span> hessian_eigenvectors, xy_perturb_loss, visualize_loss_surface, linear_interpolation</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_04.utils.data <span class="im">import</span> get_dataset  </span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_04.utils.metrics <span class="im">import</span> load_model  </span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_05.optimizers.basic <span class="im">import</span> SGD, Adam</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_05.visualization.gaussian_loss_surface <span class="im">import</span> (</span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>    get_opt_params,  visualize_gaussian_fit, train_loss_surface, visualize_optimization_path</span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Device configuration</span></span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the dataset</span></span>
<span id="cb43-18"><a href="#cb43-18" aria-hidden="true" tabindex="-1"></a>_, test_dataset <span class="op">=</span> get_dataset(dataset<span class="op">=</span><span class="st">"FashionMNIST"</span>)</span>
<span id="cb43-19"><a href="#cb43-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a small dataset</span></span>
<span id="cb43-20"><a href="#cb43-20" aria-hidden="true" tabindex="-1"></a>small_dataset <span class="op">=</span> Subset(test_dataset, torch.arange(<span class="dv">0</span>, <span class="dv">256</span>))</span>
<span id="cb43-21"><a href="#cb43-21" aria-hidden="true" tabindex="-1"></a>data_loader <span class="op">=</span> DataLoader(small_dataset, batch_size<span class="op">=</span><span class="dv">256</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb43-22"><a href="#cb43-22" aria-hidden="true" tabindex="-1"></a>loss_func <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb43-23"><a href="#cb43-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-24"><a href="#cb43-24" aria-hidden="true" tabindex="-1"></a>trained_model, _ <span class="op">=</span> load_model(model_file<span class="op">=</span><span class="st">"SimpleNetwork-ReLU.pth"</span>, path<span class="op">=</span><span class="st">"tmp/models/"</span>)</span>
<span id="cb43-25"><a href="#cb43-25" aria-hidden="true" tabindex="-1"></a><span class="co"># trained_model, _ = load_model(model_file="SimpleNetwork-Tanh.pth", path="tmp/models/")</span></span>
<span id="cb43-26"><a href="#cb43-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-27"><a href="#cb43-27" aria-hidden="true" tabindex="-1"></a>trained_model <span class="op">=</span> trained_model.to(device)</span>
<span id="cb43-28"><a href="#cb43-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-29"><a href="#cb43-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Loss surface data generation</span></span>
<span id="cb43-30"><a href="#cb43-30" aria-hidden="true" tabindex="-1"></a>top_n <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb43-31"><a href="#cb43-31" aria-hidden="true" tabindex="-1"></a>top_eigenvalues, top_eignevectors <span class="op">=</span> hessian_eigenvectors(</span>
<span id="cb43-32"><a href="#cb43-32" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>trained_model,</span>
<span id="cb43-33"><a href="#cb43-33" aria-hidden="true" tabindex="-1"></a>    loss_func<span class="op">=</span>loss_func,</span>
<span id="cb43-34"><a href="#cb43-34" aria-hidden="true" tabindex="-1"></a>    data_loader<span class="op">=</span>data_loader,</span>
<span id="cb43-35"><a href="#cb43-35" aria-hidden="true" tabindex="-1"></a>    top_n<span class="op">=</span>top_n,</span>
<span id="cb43-36"><a href="#cb43-36" aria-hidden="true" tabindex="-1"></a>    is_cuda<span class="op">=</span><span class="va">True</span></span>
<span id="cb43-37"><a href="#cb43-37" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb43-38"><a href="#cb43-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-39"><a href="#cb43-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Define lambda range</span></span>
<span id="cb43-40"><a href="#cb43-40" aria-hidden="true" tabindex="-1"></a>d_min, d_max, d_num <span class="op">=</span> <span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">30</span></span>
<span id="cb43-41"><a href="#cb43-41" aria-hidden="true" tabindex="-1"></a>lambda1 <span class="op">=</span> np.linspace(d_min, d_max, d_num).astype(np.float32)</span>
<span id="cb43-42"><a href="#cb43-42" aria-hidden="true" tabindex="-1"></a>lambda2 <span class="op">=</span> np.linspace(d_min, d_max, d_num).astype(np.float32)</span>
<span id="cb43-43"><a href="#cb43-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-44"><a href="#cb43-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate loss surface</span></span>
<span id="cb43-45"><a href="#cb43-45" aria-hidden="true" tabindex="-1"></a>x, y, z <span class="op">=</span> xy_perturb_loss(</span>
<span id="cb43-46"><a href="#cb43-46" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>trained_model,</span>
<span id="cb43-47"><a href="#cb43-47" aria-hidden="true" tabindex="-1"></a>    top_eigenvectors<span class="op">=</span>top_eignevectors,</span>
<span id="cb43-48"><a href="#cb43-48" aria-hidden="true" tabindex="-1"></a>    data_loader<span class="op">=</span>data_loader,</span>
<span id="cb43-49"><a href="#cb43-49" aria-hidden="true" tabindex="-1"></a>    loss_func<span class="op">=</span>loss_func,</span>
<span id="cb43-50"><a href="#cb43-50" aria-hidden="true" tabindex="-1"></a>    lambda1<span class="op">=</span>lambda1,</span>
<span id="cb43-51"><a href="#cb43-51" aria-hidden="true" tabindex="-1"></a>    lambda2<span class="op">=</span>lambda2,</span>
<span id="cb43-52"><a href="#cb43-52" aria-hidden="true" tabindex="-1"></a>    device<span class="op">=</span>device</span>
<span id="cb43-53"><a href="#cb43-53" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb43-54"><a href="#cb43-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-55"><a href="#cb43-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-56"><a href="#cb43-56" aria-hidden="true" tabindex="-1"></a><span class="co"># After generating loss surface data</span></span>
<span id="cb43-57"><a href="#cb43-57" aria-hidden="true" tabindex="-1"></a>popt, _, offset <span class="op">=</span> get_opt_params(x, y, z)</span>
<span id="cb43-58"><a href="#cb43-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-59"><a href="#cb43-59" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize Gaussian fitting</span></span>
<span id="cb43-60"><a href="#cb43-60" aria-hidden="true" tabindex="-1"></a>visualize_gaussian_fit(x, y, z, popt, offset, d_min, d_max, d_num)</span>
<span id="cb43-61"><a href="#cb43-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-62"><a href="#cb43-62" aria-hidden="true" tabindex="-1"></a><span class="co"># View from a different angle</span></span>
<span id="cb43-63"><a href="#cb43-63" aria-hidden="true" tabindex="-1"></a>visualize_gaussian_fit(x, y, z, popt, offset, d_min, d_max, d_num,</span>
<span id="cb43-64"><a href="#cb43-64" aria-hidden="true" tabindex="-1"></a>                      elev<span class="op">=</span><span class="dv">30</span>, azim<span class="op">=</span><span class="dv">45</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Function parameters = [29.27164346 -0.0488573  -0.06687705  0.7469189   0.94904458]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="05_Optimización y visualización_files/figure-html/cell-14-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="05_Optimización y visualización_files/figure-html/cell-14-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Se ha visualizado el plano de datos de pérdida real (puntos azules) superpuesto con el plano aproximado mediante una función gaussiana (rojo). Como se puede ver en el gráfico, la función gaussiana generada captura bastante bien <em>la tendencia general de los datos de la superficie de pérdida original</em> (especialmente, la forma cóncava del centro), generando una superficie similar. Ahora utilizaremos esta función de plano de pérdida aproximado para analizar y visualizar cómo diferentes algoritmos de optimización (optimizers) encuentran el mínimo.</p>
</section>
<section id="visualización-de-trayectorias" class="level3">
<h3 class="anchored" data-anchor-id="visualización-de-trayectorias">5.4.2 Visualización de trayectorias</h3>
<p>Utilizando una superficie de pérdida aproximada con una función gaussiana, visualizaremos cómo funciona el optimizador en un plano 2D.</p>
<p>Original text:</p>
<p>Traducción:</p>
<div id="cell-41" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Gaussian fitting</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>popt, _, offset <span class="op">=</span> get_opt_params(x, y, z)</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>gaussian_params <span class="op">=</span> (<span class="op">*</span>popt, offset)</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate optimization paths</span></span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>points_sgd <span class="op">=</span> train_loss_surface(</span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">lambda</span> params: SGD(params, lr<span class="op">=</span><span class="fl">0.1</span>),</span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>    [d_min, d_max], <span class="dv">100</span>, gaussian_params</span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a>points_sgd_m <span class="op">=</span> train_loss_surface(</span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">lambda</span> params: SGD(params, lr<span class="op">=</span><span class="fl">0.05</span>, momentum<span class="op">=</span><span class="fl">0.8</span>),</span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a>    [d_min, d_max], <span class="dv">100</span>, gaussian_params</span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a>points_adam <span class="op">=</span> train_loss_surface(</span>
<span id="cb45-15"><a href="#cb45-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">lambda</span> params: Adam(params, lr<span class="op">=</span><span class="fl">0.1</span>),</span>
<span id="cb45-16"><a href="#cb45-16" aria-hidden="true" tabindex="-1"></a>    [d_min, d_max], <span class="dv">100</span>, gaussian_params</span>
<span id="cb45-17"><a href="#cb45-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb45-18"><a href="#cb45-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-19"><a href="#cb45-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualization</span></span>
<span id="cb45-20"><a href="#cb45-20" aria-hidden="true" tabindex="-1"></a>visualize_optimization_path(</span>
<span id="cb45-21"><a href="#cb45-21" aria-hidden="true" tabindex="-1"></a>    x, y, z, popt, offset,</span>
<span id="cb45-22"><a href="#cb45-22" aria-hidden="true" tabindex="-1"></a>    [points_sgd, points_sgd_m, points_adam],</span>
<span id="cb45-23"><a href="#cb45-23" aria-hidden="true" tabindex="-1"></a>    act_name<span class="op">=</span><span class="st">"ReLU"</span></span>
<span id="cb45-24"><a href="#cb45-24" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>El gráfico muestra las trayectorias de aprendizaje de tres algoritmos de optimización: SGD, Momentum SGD y Adam, en una superficie de pérdida aproximada por una función gaussiana. En áreas tanto suaves como abruptas, los tres algoritmos muestran <strong>características distintas</strong>.</p>
<ul>
<li><strong>SGD (naranja):</strong> En las áreas donde la pendiente es suave, avanza hacia el mínimo con un <em>movimiento oscilatorio relativamente amplio</em>, pero en las áreas de pendientes pronunciadas, muestra una <em>oscilación aún mayor,</em> y cerca del mínimo presenta una <em>tendencia a converger más lentamente</em>.</li>
<li><strong>Momentum SGD (verde):</strong> Se acerca al mínimo con un <em>menor movimiento oscilatorio y una curva más suave</em> en comparación con el SGD. Gracias al efecto de inercia, puede encontrar el mínimo de manera <em>más estable incluso en áreas de pendientes pronunciadas</em>.</li>
<li><strong>Adam (rojo):</strong> Avanza hacia el mínimo con <em>las menores oscilaciones,</em> reaccionando <em>sensiblemente a los cambios de pendiente</em> y siguiendo un camino eficiente. <em>En particular, muestra una convergencia más rápida incluso en áreas de pendientes pronunciadas.</em> Esto se debe al mecanismo de ajuste de la tasa de aprendizaje adaptativa (adaptive learning rate) de Adam.</li>
</ul>
<p>En la práctica, el SGD con momentum es mucho más preferido que el SGD simple, y los algoritmos de optimización adaptativos como Adam o AdamW también son ampliamente utilizados. En general, la superficie de pérdida tiende a ser plana en la mayoría de las áreas, pero cerca del mínimo presenta una forma de valle estrecho y profundo. Esto hace que una tasa de aprendizaje alta corra el riesgo de pasar por alto o diverger del mínimo, por lo que es común usar un programador de tasas de aprendizaje (learning rate scheduler) para reducir gradualmente la tasa de aprendizaje. Además, es importante considerar no solo la elección del algoritmo de optimización, sino también una tasa de aprendizaje adecuada, el tamaño del lote, las técnicas de regularización, entre otros.</p>
<p><img src="../../../assets/images/04_loss_resnet_ft_imagenet_2.png" class="img-fluid"></p>
<p><img src="../../../assets/images/04_loss_resnet_ft_imagenet_1.png" class="img-fluid"></p>
<p>Las imágenes anteriores de la superficie de pérdida muestran una visualización tridimensional de la superficie de pérdida del modelo ResNet-50 entrenado con el conjunto de datos ImageNet. (Se usaron los dos primeros autovectores del gradiente hessiano calculado con PyHessian como ejes). A diferencia de la aproximación por función gaussiana, se puede ver que la superficie de pérdida de un modelo de aprendizaje profundo real es mucho más compleja y irregular. Sin embargo, se observa que la tendencia general de tener el mínimo en el centro (área azul) se mantiene. Estas visualizaciones ayudan a entender intuitivamente cuán complicada es la topografía de la superficie de pérdida de un modelo de aprendizaje profundo y por qué la optimización es un problema difícil.</p>
</section>
</section>
<section id="análisis-dinámico-del-proceso-de-optimización-exploración-de-la-trayectoria-de-aprendizaje" class="level2">
<h2 class="anchored" data-anchor-id="análisis-dinámico-del-proceso-de-optimización-exploración-de-la-trayectoria-de-aprendizaje">5.5 Análisis dinámico del proceso de optimización: exploración de la trayectoria de aprendizaje</h2>
<p>Entender las características dinámicas (dynamics) de cómo los algoritmos de optimización encuentran el mínimo de la función de pérdida en el aprendizaje de modelos de deep learning es importante. <em>Especialmente con la aparición de modelos de lenguaje a gran escala (LLM), el análisis y control de las dinámicas de aprendizaje de modelos con miles de millones de parámetros se ha vuelto aún más crítico.</em></p>
<section id="características-del-proceso-de-entrenamiento" class="level3">
<h3 class="anchored" data-anchor-id="características-del-proceso-de-entrenamiento">5.5.1 Características del proceso de entrenamiento</h3>
<p>El proceso de aprendizaje de un modelo de deep learning puede dividirse en etapas inicial, media y final, cada una con sus propias características.</p>
<ol type="1">
<li><p><strong>Características por etapa de aprendizaje:</strong></p>
<ul>
<li><strong>Inicial:</strong> La norma del gradiente (gradient norm) es alta y fluctúa mucho, mientras que el valor de la función de pérdida disminuye rápidamente.</li>
<li><strong>Media:</strong> El gradiente se estabiliza y los parámetros exploran la región óptima (optimal region).</li>
<li><strong>Final:</strong> Los parámetros realizan ajustes finos (fine-tuning) alrededor del óptimo local (local optimum). (Es importante el early stopping)</li>
</ul></li>
<li><p><strong>Características de gradiente por capa:</strong></p>
<ul>
<li>En redes neuronales profundas, los gradientes tienden a ser más grandes cerca de la capa de entrada y más pequeños cerca de la capa de salida. (vanishing gradient problem)</li>
<li>Esto se debe al regreso hacia atrás (backpropagation) y a la aplicación de la regla de la cadena (chain rule).</li>
<li>Las conexiones residuales (residual connections) ayudan a mitigar este desequilibrio, permitiendo un aprendizaje más estable en capas profundas.</li>
</ul></li>
<li><p><strong>Dependencia entre parámetros:</strong></p>
<ul>
<li>Los parámetros de la red neuronal son interdependientes, lo que hace que el proceso de optimización sea no lineal (nonlinear).</li>
<li>Algunos parámetros pueden tener un mayor impacto en el aprendizaje, por lo que es importante mantener un equilibrio (balance) entre los parámetros.</li>
</ul></li>
<li><p><strong>Análisis del camino de optimización:</strong></p>
<ul>
<li>El camino que siguen los parámetros sobre la superficie de pérdida durante el proceso de optimización se denomina camino de optimización (optimization path).</li>
<li>Las regiones con mínimos locales en forma de valles anchos y suaves tienden a tener un mejor rendimiento de generalización (generalization performance) que los valles estrechos y puntiagudos.</li>
<li>En espacios de alta dimensión, los puntos de silla (saddle points) son muy comunes. (algoritmos como momentum y Adam están diseñados para evitarlos)</li>
<li>En áreas planas (flat) de la superficie de pérdida, los gradientes pueden ser pequeños, lo que puede hacer que el aprendizaje sea más lento. (algoritmos de tasa de aprendizaje adaptativa pueden ayudar)</li>
</ul></li>
</ol>
</section>
<section id="análisis-y-control-de-estabilidad-del-aprendizaje" class="level3">
<h3 class="anchored" data-anchor-id="análisis-y-control-de-estabilidad-del-aprendizaje">5.5.2 Análisis y control de estabilidad del aprendizaje</h3>
<section id="metodologías-de-análisis-de-estabilidad" class="level4">
<h4 class="anchored" data-anchor-id="metodologías-de-análisis-de-estabilidad">Metodologías de análisis de estabilidad</h4>
<p>Para analizar la estabilidad (stability) del proceso de optimización, se consideran los siguientes aspectos:</p>
<ol type="1">
<li><p><strong>Detección de gradientes:</strong></p>
<ul>
<li>Identificación de fenómenos de gradiente que explotan (exploding gradient) o desaparecen (vanishing gradient).</li>
<li>Observación periódica de la norma del gradiente durante el entrenamiento.</li>
</ul></li>
<li><p><strong>Análisis basado en la Hessiana:</strong></p>
<ul>
<li>La distribución de los valores propios (eigenvalue) y el número de condición (condition number) de la matriz Hessiana indican la estabilidad del camino de optimización.</li>
<li>(Ver visualizaciones basadas en la Hessiana en la Sección 5.3)</li>
</ul></li>
<li><p><strong>Monitoreo en tiempo real:</strong></p>
<ul>
<li>Monitoreo en tiempo real de la norma del gradiente, el tamaño de las actualizaciones de parámetros, los valores de la función de pérdida y las métricas de rendimiento durante el aprendizaje.</li>
</ul></li>
</ol>
<section id="técnicas-de-estabilización-stabilization-techniques" class="level5">
<h5 class="anchored" data-anchor-id="técnicas-de-estabilización-stabilization-techniques">Técnicas de estabilización (Stabilization Techniques)</h5>
<ul>
<li><p><strong>Recorte de gradientes (Gradient Clipping):</strong> Limitar el tamaño del gradiente para que no supere un umbral (threshold).</p>
<p><span class="math inline">\(g \leftarrow \text{clip}(g) = \min(\max(g, -c), c)\)</span></p></li>
<li><p><span class="math inline">\(g\)</span>: gradiente, <span class="math inline">\(c\)</span>: valor umbral</p></li>
<li><p><strong>Tasa de aprendizaje adaptativa (Adaptive Learning Rate):</strong> Adam, RMSProp, Lion, Sophia ajustan automáticamente la tasa de aprendizaje según las estadísticas del gradiente.</p></li>
<li><p><strong>Programador de tasa de aprendizaje (Learning Rate Scheduler):</strong> disminución gradual de la tasa de aprendizaje basada en el número de épocas o la pérdida de validación.</p></li>
<li><p><strong>Optimización de hiperparámetros (Hyperparameter Optimization):</strong> búsqueda y ajuste automático de los hiperparámetros relacionados con la optimización.</p></li>
</ul>
</section>
<section id="tendencias-de-investigación-recientes" class="level5">
<h5 class="anchored" data-anchor-id="tendencias-de-investigación-recientes">Tendencias de investigación recientes</h5>
<p>La investigación sobre dinámica de aprendizaje en la actualidad (2024) se está desarrollando en las siguientes direcciones:</p>
<ul>
<li><strong>Estabilización predictiva (Predictive Stabilization):</strong> eliminación o mitigación anticipada de factores de inestabilidad mediante el análisis de la estructura del modelo, la inicialización y las características del conjunto de datos <em>antes</em> del aprendizaje.</li>
<li><strong>Análisis integrado (Unified Analysis):</strong> profundización en la comprensión de los algoritmos de optimización a través del análisis conjunto de información de curvatura (hessiana) y estadísticas de gradiente.</li>
<li><strong>Control automatizado (Automated Control):</strong> ajuste automático de hiperparámetros de algoritmos de optimización utilizando técnicas como el aprendizaje por refuerzo.</li>
</ul>
<p>Estas investigaciones están contribuyendo a hacer que el aprendizaje de modelos de deep learning sea más estable y eficiente, y a mejorar la comprensión del “caja negra”.</p>
<p>Ahora exploremos un ejemplo sencillo para analizar dinámicamente el proceso de optimización.</p>
<div id="cell-44" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader, Subset  <span class="co"># Import Subset</span></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_05.visualization.train_dynamics <span class="im">import</span> visualize_training_dynamics</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_04.utils.data <span class="im">import</span> get_dataset  </span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_04.utils.metrics <span class="im">import</span> load_model  </span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Device configuration</span></span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the FashionMNIST dataset (both training and testing)</span></span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a>train_dataset, test_dataset <span class="op">=</span> get_dataset(dataset<span class="op">=</span><span class="st">"FashionMNIST"</span>)</span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> DataLoader(train_dataset, batch_size<span class="op">=</span><span class="dv">256</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a>loss_func <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb46-16"><a href="#cb46-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-17"><a href="#cb46-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Load a pre-trained model (e.g., ReLU-based network)</span></span>
<span id="cb46-18"><a href="#cb46-18" aria-hidden="true" tabindex="-1"></a>trained_model, _ <span class="op">=</span> load_model(model_file<span class="op">=</span><span class="st">"SimpleNetwork-ReLU.pth"</span>, path<span class="op">=</span><span class="st">"tmp/models/"</span>)</span>
<span id="cb46-19"><a href="#cb46-19" aria-hidden="true" tabindex="-1"></a>trained_model <span class="op">=</span> trained_model.to(device)</span>
<span id="cb46-20"><a href="#cb46-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-21"><a href="#cb46-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Choose an optimizer (e.g., Adam)</span></span>
<span id="cb46-22"><a href="#cb46-22" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.Adam(trained_model.parameters(), lr<span class="op">=</span><span class="fl">0.001</span>)</span>
<span id="cb46-23"><a href="#cb46-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-24"><a href="#cb46-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Call the training dynamics visualization function (e.g., train for 10 epochs with the entire training dataset)</span></span>
<span id="cb46-25"><a href="#cb46-25" aria-hidden="true" tabindex="-1"></a>metrics <span class="op">=</span> visualize_training_dynamics(</span>
<span id="cb46-26"><a href="#cb46-26" aria-hidden="true" tabindex="-1"></a>    trained_model, optimizer, train_loader, loss_func, num_epochs<span class="op">=</span><span class="dv">20</span>, device<span class="op">=</span>device</span>
<span id="cb46-27"><a href="#cb46-27" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb46-28"><a href="#cb46-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-29"><a href="#cb46-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the final results for each metric</span></span>
<span id="cb46-30"><a href="#cb46-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Final Loss:"</span>, metrics[<span class="st">"loss"</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb46-31"><a href="#cb46-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Final Grad Norm:"</span>, metrics[<span class="st">"grad_norm"</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb46-32"><a href="#cb46-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Final Param Change:"</span>, metrics[<span class="st">"param_change"</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb46-33"><a href="#cb46-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Final Weight Norm:"</span>, metrics[<span class="st">"weight_norm"</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb46-34"><a href="#cb46-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Final Loss Improvement:"</span>, metrics[<span class="st">"loss_improvement"</span>][<span class="op">-</span><span class="dv">1</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>El ejemplo anterior muestra varios aspectos de la dinámica del aprendizaje (learning dynamics) en la práctica. Utilizando un modelo SimpleNetwork-ReLU preentrenado en el conjunto de datos FashionMNIST, se realizó un entrenamiento adicional utilizando el algoritmo de optimización Adam y se visualizaron los siguientes cinco indicadores clave (metric) por época:</p>
<ul>
<li><strong>Loss (pérdida):</strong> muestra cómo disminuye el valor de la función de pérdida durante el proceso de aprendizaje. (línea azul)</li>
<li><strong>Grad Norm (norma del gradiente):</strong> indica el tamaño del gradiente (L2 norm). (línea roja)</li>
<li><strong>Param Change (cambio de parámetros):</strong> representa el cambio en los parámetros (pesos) con respecto a la época anterior.</li>
<li><strong>Weight Norm (norma del peso):</strong> indica el tamaño de todos los parámetros del modelo (pesos). (línea morada)</li>
<li><strong>Loss Improvement (mejora de pérdida):</strong> muestra cuánto ha disminuido el valor de la función de pérdida en comparación con la época anterior. (línea amarilla)</li>
</ul>
<p>Los gráficos muestran lo siguiente:</p>
<ul>
<li><strong>Loss:</strong> el valor de pérdida, que era aproximadamente 0.51 al inicio de la primera época (época 1), disminuye constantemente a medida que avanza el entrenamiento y llega a aproximadamente 0.16 en la última época (época 20).</li>
<li><strong>Grad Norm:</strong> la norma del gradiente, que era relativamente alta al inicio de la primera época (aproximadamente 4.5), disminuye gradualmente a medida que avanza el entrenamiento y llega a alrededor de 2.0 en la última época.</li>
<li><strong>Param Change:</strong> el cambio en los parámetros es grande al inicio del entrenamiento, pero tiende a disminuir a medida que el entrenamiento progresa. Esto indica que el modelo se acerca gradualmente al punto óptimo y el cambio en los parámetros se vuelve más pequeño.</li>
<li><strong>Weight Norm:</strong> la norma del peso aumenta constantemente durante todo el proceso de aprendizaje. Esto significa que los parámetros del modelo se vuelven “más grandes” a medida que avanza el entrenamiento. (Sin embargo, esto no necesariamente implica sobreajuste (overfitting).)</li>
<li><strong>Loss Improvement:</strong> la mejora en la pérdida es grande al inicio del entrenamiento y tiende a disminuir a medida que el entrenamiento progresa.</li>
</ul>
<p><em>A través de este ejemplo, podemos visualizar y comprender intuitivamente cómo el algoritmo de optimización minimiza la función de pérdida, cómo cambia el gradiente y los parámetros, entre otros aspectos de la dinámica del aprendizaje.</em></p>
</section>
</section>
</section>
<section id="conclusión" class="level3">
<h3 class="anchored" data-anchor-id="conclusión">Conclusión</h3>
<p>En este capítulo 5, hemos examinado a profundidad varios temas relacionados con la optimización, que son elementos clave en el proceso de aprendizaje de modelos de deep learning. Hemos explorado la importancia de los métodos de inicialización de pesos, los principios y características de diversos algoritmos de optimización (SGD, Momentum, Adam, Lion, Sophia, AdaFactor), así como la visualización de superficies de pérdida y el análisis de dinámica del aprendizaje para comprender mejor el proceso de aprendizaje de modelos de deep learning.</p>
<p><em>En el capítulo 6, profundizaremos en las técnicas clave para mejorar el rendimiento de generalización de los modelos de deep learning, como la regularización (regularization). Estudiaremos los principios y efectos de diversas técnicas de regularización, incluyendo L1/L2 regularization, dropout, batch normalization, data augmentation, y aprenderemos métodos prácticos para su aplicación a través de ejemplos.</em></p>
</section>
<section id="ejercicios-de-práctica" class="level3">
<h3 class="anchored" data-anchor-id="ejercicios-de-práctica">Ejercicios de práctica</h3>
<section id="problemas-básicos" class="level4">
<h4 class="anchored" data-anchor-id="problemas-básicos">Problemas básicos</h4>
<ol type="1">
<li><strong>Cálculo manual de SGD:</strong> Calcule manualmente la regla de actualización de SGD para la función de pérdida <span class="math inline">\(L(w) = w^2\)</span> en al menos 3 pasos, con una tasa de aprendizaje de 0.1 y un momento de 0.9. Establezca el peso inicial como <span class="math inline">\(w_0 = 2\)</span>.</li>
<li><strong>Comparación de la velocidad de convergencia del descenso de gradiente:</strong> Aplique el descenso de gradiente a una función cuadrática simple <span class="math inline">\(f(x, y) = x^2 + 2y^2\)</span> y compare la velocidad de convergencia cambiando la tasa de aprendizaje a 0.1, 0.01, 0.001.</li>
<li><strong>Comparación de métodos de inicialización:</strong> Compare la inicialización Kaiming con la inicialización Xavier y explique por qué la inicialización Kaiming es más adecuada cuando se usa con la función de activación ReLU.</li>
</ol>
</section>
<section id="problemas-aplicados" class="level4">
<h4 class="anchored" data-anchor-id="problemas-aplicados">Problemas aplicados</h4>
<ol type="1">
<li><strong>Optimizador Adam:</strong> Explique el principio de funcionamiento del optimizador Adam (incluyendo las fórmulas) y describa los roles de los parámetros <span class="math inline">\(\beta_1\)</span> y <span class="math inline">\(\beta_2\)</span>.</li>
<li><strong>Normalización por lotes y inicialización:</strong> Explique cómo la normalización por lotes (Batch Normalization) reduce la importancia del método de inicialización y proporcione razones para ello.</li>
<li><strong>Plano de pérdida gaussiano:</strong> En el ejemplo de aproximación del plano de pérdida usando una función gaussiana (sección 5.5.1), explique cómo los parámetros de la función gaussiana (amplitud, punto central, varianza) afectan el proceso de optimización. (Observe cómo cambia la trayectoria de optimización al modificar cada parámetro).</li>
</ol>
</section>
<section id="problemas-avanzados" class="level4">
<h4 class="anchored">Problemas avanzados</h4>
<ol type="1">
<li><strong>Análisis del optimizador Lion:</strong> Explique la idea principal del optimizador Lion (incluyendo las fórmulas) y analice sus ventajas y desventajas en comparación con Adam.</li>
<li><strong>Experimento de métodos de inicialización:</strong> Aplique diferentes métodos de inicialización (LeCun, Xavier, Kaiming, Ortogonal) a un conjunto de datos dado (por ejemplo, FashionMNIST) y un modelo (SimpleNetwork del capítulo 5.1), y compare los resultados (tasas de error, velocidad de convergencia, número condicionado promedio, norma espectral, relación de rango efectivo).</li>
<li><strong>Visualización de trayectorias de optimización:</strong> Utilizando el código de visualización de trayectorias de optimización del capítulo 5.5, defina su propia función de pérdida (por ejemplo, una función multimodal o no convexa) y visualice y compare las trayectorias de optimización de varios optimizadores (SGD, Momentum, Adam, Lion, etc.). (Compare al menos 3 optimizadores diferentes).</li>
</ol>
<div class="callout callout-style-default callout-note callout-titled" title="Haga clic para ver el contenido (análisis de la superficie de pérdida basado en topología)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Haga clic para ver el contenido (análisis de la superficie de pérdida basado en topología)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<section id="soluciones-de-ejercicios" class="level3 callout-body-container callout-body">
<h3 class="anchored" data-anchor-id="soluciones-de-ejercicios">Soluciones de ejercicios</h3>
<section id="problemas-básicos-1" class="level4">
<h4 class="anchored" data-anchor-id="problemas-básicos-1">Problemas básicos</h4>
<ol type="1">
<li><p><strong>Cálculo manual de SGD:</strong></p>
<ul>
<li><strong>Paso 1:</strong>
<ul>
<li><span class="math inline">\(g_0 = \frac{dL}{dw}(w_0) = 2w_0 = 4\)</span></li>
<li><span class="math inline">\(v_0 = 0\)</span> (valor inicial del momento)</li>
<li><span class="math inline">\(w_1 = w_0 - \eta v_1 = 2 - 0.1 \cdot (0.9 \cdot 0 + 4) = 1.6\)</span></li>
</ul></li>
<li><strong>Paso 2:</strong>
<ul>
<li><span class="math inline">\(g_1 = 2w_1 = 3.2\)</span></li>
<li><span class="math inline">\(v_1 = 0.9 \cdot v_0 + g_0= 0.9 \cdot 0 + 4 = 4\)</span></li>
<li><span class="math inline">\(w_2 = w_1 - \eta \cdot (0.9 \cdot v_1 + g_1) = 1.6 - 0.1 \cdot (0.9 \cdot 4+ 3.2) = 0.92\)</span></li>
</ul></li>
<li><strong>Paso 3:</strong>
<ul>
<li><span class="math inline">\(g_2 = 2w_2 = 1.84\)</span></li>
<li><span class="math inline">\(v_2 = 0.9 \cdot 4 + 3.2 = 6.8\)</span></li>
<li><span class="math inline">\(w_3 = w_2 - \eta \cdot (0.9 * v_2 + g_2) = 0.92 - 0.1 \cdot (0.9 \cdot 6.8 + 1.84) = 0.124\)</span></li>
</ul></li>
</ul></li>
<li><p><strong>Comparación de la velocidad de convergencia del descenso por gradiente:</strong></p>
<ul>
<li>Cuanto mayor es la tasa de aprendizaje (0.1), más rápida es la convergencia inicial, pero puede producirse vibración cerca del punto óptimo.</li>
<li>Cuanto menor es la tasa de aprendizaje (0.001), más lenta es la velocidad de convergencia, pero se acerca al punto óptimo de manera más estable.</li>
<li>Una tasa de aprendizaje adecuada (0.01) muestra una velocidad de convergencia y estabilidad moderadas.</li>
</ul></li>
<li><p><strong>Comparación de métodos de inicialización:</strong></p>
<ul>
<li><strong>Inicialización Kaiming:</strong> Considera la característica de la función de activación ReLU (convierte entradas negativas en 0), y inicializa los pesos con una distribución que tiene una desviación estándar de <span class="math inline">\(\sqrt{2/n_{in}}\)</span>.</li>
<li><strong>Inicialización Xavier:</strong> Independientemente del tipo de función de activación, utiliza una desviación estándar de <span class="math inline">\(\sqrt{2/(n_{in} + n_{out})}\)</span> para mantener la varianza de las entradas y salidas.</li>
<li><strong>ReLU + Kaiming:</strong> Utiliza una distribución con una desviación estándar de <span class="math inline">\(\sqrt{2/n_{in}}\)</span> para proporcionar una inicialización adecuada que funcione bien con ReLU, evitando el problema de los gradientes que se apagan.</li>
</ul></li>
</ol>
</section>
<section id="problemas-avanzados-1" class="level4">
<h4 class="anchored" data-anchor-id="problemas-avanzados-1">Problemas avanzados</h4>
<ol type="1">
<li><p><strong>Normalización por lotes y métodos de inicialización:</strong></p>
<ul>
<li>La normalización por lotes ayuda a estabilizar el entrenamiento al reducir la covarianza cambiante interna.</li>
<li>Se puede combinar con métodos de inicialización como Kaiming o Xavier para mejorar aún más el rendimiento del modelo.</li>
</ul></li>
<li><p><strong>Normalización por lotes y aprendizaje:</strong></p>
<ul>
<li>La normalización por lotes puede acelerar la convergencia del entrenamiento y permitir una tasa de aprendizaje más alta.</li>
<li>También ayuda a reducir la dependencia entre las capas, lo que facilita el entrenamiento de redes más profundas.</li>
</ul></li>
</ol>
<ul>
<li><strong>Normalización por lotes:</strong> normaliza las entradas de cada mini-lote a una media de 0 y una varianza de 1.
<ul>
<li><strong>Reducción de la importancia de la inicialización:</strong> la normalización por lotes reduce el cambio de covarianza interna (internal covariate shift) en la red, disminuyendo así la dependencia de la distribución de los pesos iniciales.</li>
<li><strong>Razón:</strong> las entradas normalizadas sitúan las funciones de activación dentro de un rango adecuado (por ejemplo, el rango positivo de ReLU), lo que alivia los problemas de desvanecimiento y explosión del gradiente y estabiliza el aprendizaje.</li>
</ul></li>
</ul>
<ol start="3" type="1">
<li><strong>Plano de pérdida gaussiano:</strong>
<ul>
<li><strong>Amplitud (A):</strong> ajusta la magnitud general de la función de pérdida. Si la amplitud es grande, el rango de cambio de los valores de pérdida puede ser mayor, lo que podría hacer que el aprendizaje sea inestable.</li>
<li><strong>Punto central (<span class="math inline">\(x_0\)</span>, <span class="math inline">\(y_0\)</span>):</strong> determina la ubicación del mínimo de la función de pérdida. El algoritmo de optimización se moverá hacia este punto central.</li>
<li><strong>Varianza (<span class="math inline">\(\sigma_1\)</span>, <span class="math inline">\(\sigma_2\)</span>):</strong> indica el grado de cambio de la función de pérdida en cada dirección del eje. Una varianza pequeña resulta en una forma estrecha y afilada, mientras que una grande produce una forma ancha y suave. Si las varianzas son diferentes, se deben ajustar los tasas de aprendizaje en cada dirección de manera diferente.</li>
</ul></li>
</ol>
</section>
<section id="problemas-avanzados-2" class="level4">
<h4 class="anchored" data-anchor-id="problemas-avanzados-2">Problemas avanzados</h4>
<ol type="1">
<li><p><strong>Análisis del optimizador Lion:</strong></p>
<ul>
<li><strong>Idea clave:</strong> realiza actualizaciones utilizando solo el signo (sign) del gradiente.</li>
<li><strong>Fórmula:</strong> <code>c_t = β_1 * m_{t-1} + (1 - β_1) * g_t     w_{t+1} = w_t - η * sign(c_t)     m_t = c_t</code>
<ul>
<li>solo se utiliza el signo de la actualización, por lo que no es necesario calcular ni almacenar el segundo momento como en Adam.</li>
</ul></li>
<li><strong>Ventajas:</strong>
<ul>
<li>consume menos memoria que Adam (no almacena el segundo momento).</li>
<li>el tamaño de las actualizaciones es uniforme para todos los parámetros, lo que lo hace robusto a gradientes escasos.</li>
</ul></li>
<li><strong>Desventajas:</strong>
<ul>
<li>ignora la magnitud del gradiente, lo que puede resultar en una convergencia más lenta que Adam en ciertas situaciones.</li>
<li>el ajuste de la tasa de aprendizaje puede ser más sensible que en Adam.</li>
</ul></li>
</ul></li>
<li><p><strong>Experimentación con métodos de inicialización:</strong></p>
<ul>
<li><strong>Diseño del experimento:</strong>
<ul>
<li>se utiliza el mismo modelo (SimpleNetwork) y conjunto de datos (FashionMNIST).</li>
<li>se aplican los métodos de inicialización LeCun, Xavier, Kaiming y Ortogonal.</li>
<li>se usa el mismo algoritmo de optimización (por ejemplo, Adam) y tasa de aprendizaje.</li>
<li>se entrena durante un número suficiente de épocas (por ejemplo, 20), registrando las métricas de evaluación (tasa de error, velocidad de convergencia, condición media, norma espectral, relación de rango efectivo) en cada época.</li>
</ul></li>
<li><strong>Análisis de resultados:</strong>
<ul>
<li>si se usa la función de activación ReLU, Kaiming inicialización probablemente tenga el mejor rendimiento.</li>
<li>la inicialización Ortogonal puede dar buenos resultados en RNN/LSTM.</li>
<li>Xavier inicialización puede ser buena para funciones de activación tanh y sigmoid.</li>
<li>LeCun inicialización puede tener un rendimiento inferior en redes modernas.</li>
</ul></li>
</ul></li>
<li><p><strong>Visualización del camino de optimización:</strong></p></li>
</ol>
<ul>
<li><strong>Definir su propia función de pérdida:</strong></li>
<li>Ejemplo: <span class="math inline">\(f(x, y) = (x^2 + y - 11)^2 + (x + y^2 - 7)^2\)</span> (Función de Himmelblau, función multimodal)</li>
<li>Ejemplo: <span class="math inline">\(f(x, y) = 0.5x^2 - 0.25y^2 + 3\)</span> (Función no convexa con puntos de silla)</li>
<li><strong>Seleccionar algoritmo de optimización:</strong> SGD, Momentum(SGD with momentum), Adam, Lion</li>
<li><strong>Visualización:</strong> Consulte el código del Capítulo 5.5 para visualizar la trayectoria de optimización de cada optimizador en un plano bidimensional.</li>
<li><strong>Análisis de resultados:</strong>
<ul>
<li>SGD tiene una alta probabilidad de quedar atrapado en mínimos locales/puntos de silla.</li>
<li>Momentum puede escapar de mínimos locales gracias a su inercia, pero puede oscilar.</li>
<li>Adam puede alcanzar el óptimo más eficientemente gracias a su tasa de aprendizaje adaptativa.</li>
<li>Lion puede mostrar un comportamiento similar o incluso una convergencia más rápida que Adam, pero puede ser sensible al ajuste de la tasa de aprendizaje.</li>
<li>Analice y compare los resultados de optimización según la forma de la función de pérdida, como múltiples picos y puntos de silla.</li>
</ul></li>
</ul>
</section>
</section>
</div>
</div>
</section>
</section>
<section id="referencia" class="level3">
<h3 class="anchored" data-anchor-id="referencia">Referencia</h3>
<ol type="1">
<li><strong><a href="https://arxiv.org/abs/1609.04747">An overview of gradient descent optimization algorithms</a></strong> (Sebastian Ruder, 2016) - Un excelente resumen de los algoritmos de optimización en el aprendizaje profundo. Compara y analiza varios algoritmos como SGD, Momentum, AdaGrad, RMSProp, Adam, entre otros.</li>
<li><strong><a href="https://arxiv.org/abs/1712.09913">Visualizing the Loss Landscape of Neural Nets</a></strong> (Li et al., 2018) - Un artículo pionero sobre la visualización de las superficies de pérdida. Muestra cómo las conexiones residuales (residual connections) aplanan la superficie de pérdida.</li>
<li><strong><a href="https://www.google.com/search?q=https://ruder.io/deep-learning-optimization-2023/">Optimization for Deep Learning Highlights in 2023</a></strong> (Sebastian Ruder, 2023) - Un artículo de blog que resume los puntos clave de la optimización en el aprendizaje profundo para 2023. Es útil para estar al tanto de las últimas tendencias en investigación.</li>
<li><strong><a href="https://arxiv.org/abs/2110.08536">Improving Deep Learning with Better Initialization</a></strong> (Mishkin &amp; Matas, 2021) - Un artículo que presenta la última investigación sobre métodos de inicialización modernos. Compara diferentes técnicas de inicialización y proporciona directrices prácticas.</li>
<li><strong><a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://arxiv.org/abs/2302.06675">Symbolic Discovery of Optimization Algorithms</a></strong> (Chen et al., 2023) - Un artículo sobre el algoritmo Lion descubierto por Google Brain.</li>
<li><strong><a href="https://arxiv.org/abs/1912.07145">PyHessian: Neural Networks Through the Lens of the Hessian</a></strong> (Yao et al., 2020) - Un artículo sobre la herramienta PyHessian, que utiliza la matriz Hessiana para analizar las superficies de pérdida.</li>
<li><strong><a href="https://arxiv.org/abs/1705.08292">The Marginal Value of Adaptive Gradient Methods in Machine Learning</a></strong> (Wilson et al., 2017) - Un artículo que cuestiona el valor marginal de los métodos de gradiente adaptativo en el aprendizaje automático.</li>
<li><strong><a href="https://arxiv.org/abs/2411.01593">A Closer Look at Smoothness in Deep Learning: A Tensor Decomposition Approach</a></strong> (Li et al., 2024) - Un artículo que utiliza la descomposición de tensores para analizar la suavidad en los modelos de aprendizaje profundo.</li>
<li><strong><a href="https://arxiv.org/abs/2502.00894">Understanding Measures of Efficiency for Stochastic Optimization</a></strong> (Defazio &amp; Bottou, 2025) - Un artículo que propone métodos para medir la eficiencia de los algoritmos de optimización estocástica.</li>
<li><strong><a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://www.deeplearningbook.org/">Deep Learning</a></strong> (Goodfellow, Bengio, Courville, 2016) - Un libro de texto sobre aprendizaje profundo. Los capítulos 6 (Redes Neuronales Feedforward Profundas) y 8 (Optimización para el Entrenamiento de Modelos Profundos) tratan temas relacionados con la inicialización y la optimización.</li>
<li><strong><a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://cs231n.github.io/optimization-1/">Stanford CS231n: Convolutional Neural Networks for Visual Recognition</a></strong> - Un curso de Stanford sobre redes neuronales convolucionales. La sección de optimización cubre temas relacionados con la optimización.</li>
<li><strong><a href="https://www.google.com/search?q=https://paperswithcode.com/methods/category/optimization-methods">Papers with Code - Optimization Methods</a></strong> - Un sitio web que recopila los últimos artículos sobre métodos de optimización.</li>
<li><strong><a href="https://arxiv.org/abs/1609.04747">An overview of gradient descent optimization algorithms</a></strong> (Sebastian Ruder, 2016) - Un excelente resumen de los algoritmos de optimización de descenso de gradiente en aprendizaje profundo. Compara y analiza diversos algoritmos como SGD, Momentum, AdaGrad, RMSProp, Adam, entre otros.</li>
<li><strong><a href="https://arxiv.org/abs/1712.09913">Visualizing the Loss Landscape of Neural Nets</a></strong> (Li et al., 2018) - Un trabajo pionero en la visualización del paisaje de pérdida de redes neuronales. Muestra cómo las conexiones residuales (residual connection) aplanan el paisaje de pérdida.</li>
<li><strong><a href="https://www.google.com/search?q=https://ruder.io/deep-learning-optimization-2023/">Optimization for Deep Learning Highlights in 2023</a></strong> (Sebastian Ruder, 2023) - Un blog que resume los puntos clave de la optimización en aprendizaje profundo para 2023. Es útil para estar al día con las tendencias de investigación más recientes.</li>
<li><strong><a href="https://arxiv.org/abs/2110.08536">Improving Deep Learning with Better Initialization</a></strong> (Mishkin &amp; Matas, 2021) - Un estudio que aborda las tendencias modernas en la inicialización de redes neuronales. Compara varios métodos de inicialización y proporciona directrices prácticas.</li>
<li><strong><a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://arxiv.org/abs/2302.06675">Symbolic Discovery of Optimization Algorithms</a></strong> (Chen et al.&nbsp;2023) - Un artículo sobre el descubrimiento del algoritmo Lion por parte de Google Brain.</li>
<li><strong><a href="https://arxiv.org/abs/1912.07145">PyHessian: Neural Networks Through the Lens of the Hessian</a></strong> (Yao et al., 2020) - Un artículo sobre PyHessian, una herramienta para analizar el paisaje de pérdida utilizando la matriz Hessiana.</li>
<li><strong><a href="https://arxiv.org/abs/1705.08292">The Marginal Value of Adaptive Gradient Methods in Machine Learning</a></strong> (Wilson et al., 2017) - Un estudio que demuestra que los métodos de gradiente adaptativo (como Adam) no siempre son mejores que SGD.</li>
<li><strong><a href="https://www.offconvex.org/2016/03/22/saddlepoints/">How to escape saddle points efficiently</a></strong> (Ge et al., 2015) - Un artículo de blog que explica cómo usar el descenso de gradiente perturbado (perturbed gradient descent) para escapar eficientemente de los puntos de silla.</li>
<li><strong><a href="https://www.google.com/search?q=https://openreview.net/forum%3Fid%3DFpgg9h-xO_a">Deep Understanding of Modern Initialization Methods with Block Diagonal Matrices</a></strong> (Huang et al., 2021) - Un artículo que analiza los métodos de inicialización utilizando matrices diagonales por bloques. <strong><a href="https://www.google.com/search?q=https://proceedings.neurips.cc/paper/2020/hash/9c838d2e45b2ad1094d42f4ef36764f6-Abstract.html">AdaHessian: An Adaptive Second Order Optimizer for Machine Learning</a></strong> (Yao et al., 2020) - Artículo sobre el optimizador AdaHessian que utiliza los componentes diagonales de la matriz hessiana para aprovechar información de segundo orden. 11. <strong><a href="https://arxiv.org/abs/2411.01593">A Closer Look at Smoothness in Deep Learning: A Tensor Decomposition Approach</a></strong> (Li et al., 2024) - Artículo que analiza la suavidad (smoothness) de los modelos de aprendizaje profundo utilizando descomposición de tensores. 12. <strong><a href="https://arxiv.org/abs/2502.00894">Understanding Measures of Efficiency for Stochastic Optimization</a></strong> (Defazio &amp; Bottou, 2025) - Artículo que propone métodos para medir la eficiencia de los algoritmos de optimización estocástica. 13. <strong><a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://www.deeplearningbook.org/">Deep Learning</a></strong> (Goodfellow, Bengio, Courville, 2016) - Libro de texto sobre aprendizaje profundo. Los capítulos 6 (Redes Neuronales Feedforward Profundas) y 8 (Optimización para el Entrenamiento de Modelos Profundos) tratan temas relacionados con la inicialización y la optimización. 14. <strong><a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://cs231n.github.io/optimization-1/">Stanford CS231n: Convolutional Neural Networks for Visual Recognition</a></strong> - Curso de aprendizaje profundo de la Universidad de Stanford. La parte de optimización cubre contenido relacionado con la optimización. 15. <strong><a href="https://www.google.com/search?q=https://paperswithcode.com/methods/category/optimization-methods">Papers with Code - Optimization Methods</a></strong> - Sitio web que recopila los últimos artículos relacionados con la optimización.</li>
</ol>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>