<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>marco-de-aprendizaje-profundo – Deep Learning DNA: Surviving Architectures and Essential Principles</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-f507c7d0488cb7630e20aad62ad8c2aa.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>
<script>window.MathJax = {loader: {load: ['[tex]/boldsymbol']},tex: {packages: {'[+]': ['boldsymbol']}}};</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../notebooks/es/part_1/01_El inicio del aprendizaje profundo.html">part_1</a></li><li class="breadcrumb-item"><a href="../../../notebooks/es/part_1/03_marco de aprendizaje profundo.html">3. marco de aprendizaje profundo</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../../">Español</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Language</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index_de.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Deutsch</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index_en.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">English</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index_es.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Español</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">한국어</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index_zh.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">中文</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/00_Introducción.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introducción</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">part_1</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/01_El inicio del aprendizaje profundo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1. El inicio del aprendizaje profundo</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/02_Matemáticas de deep learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2. Matemáticas de deep learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/03_marco de aprendizaje profundo.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">3. marco de aprendizaje profundo</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/04_función de activación.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4. función de activación</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/05_Optimización y visualización.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5. Optimización y visualización</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/06_Sobreajuste y desarrollo de técnicas de solución.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">6. Sobreajuste y desarrollo de técnicas de solución</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/07_Evolución de las redes neuronales convolucionales.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">7. Evolución de las redes neuronales convolucionales</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/08_El nacimiento del transformer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8. El nacimiento del transformer</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/09_La evolución del transformer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">9. La evolución del transformer</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/10_Multimodal deep learning: el inicio de la fusión multisensorial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">10. Multimodal deep learning: el inicio de la fusión multisensorial</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/part_1/11_Multimodal deep learning: inteligencia más allá de los límites.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">11. Multimodal deep learning: inteligencia más allá de los límites</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">la vanguardia del deep learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/la vanguardia del deep learning/01_SLM: pequeño pero poderoso modelo de lenguaje.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1. SLM: pequeño pero poderoso modelo de lenguaje</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notebooks/es/la vanguardia del deep learning/02_conducción autónoma.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2. conducción autónoma</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#marco-de-aprendizaje-profundo" id="toc-marco-de-aprendizaje-profundo" class="nav-link active" data-scroll-target="#marco-de-aprendizaje-profundo">3. Marco de aprendizaje profundo</a>
  <ul class="collapse">
  <li><a href="#pytorch" id="toc-pytorch" class="nav-link" data-scroll-target="#pytorch">3.1 PyTorch</a>
  <ul class="collapse">
  <li><a href="#objeto-tensor" id="toc-objeto-tensor" class="nav-link" data-scroll-target="#objeto-tensor">3.1.1 Objeto Tensor</a></li>
  <li><a href="#operaciones" id="toc-operaciones" class="nav-link" data-scroll-target="#operaciones">3.1.2 Operaciones</a></li>
  <li><a href="#grafo-de-cálculo-para-operaciones-de-gradiente" id="toc-grafo-de-cálculo-para-operaciones-de-gradiente" class="nav-link" data-scroll-target="#grafo-de-cálculo-para-operaciones-de-gradiente">3.1.3 Grafo de cálculo para operaciones de gradiente</a></li>
  <li><a href="#carga-de-datos" id="toc-carga-de-datos" class="nav-link" data-scroll-target="#carga-de-datos">3.1.4 Carga de datos</a></li>
  <li><a href="#transformación-de-datos-transform" id="toc-transformación-de-datos-transform" class="nav-link" data-scroll-target="#transformación-de-datos-transform">3.1.5 Transformación de datos (Transform)</a></li>
  <li><a href="#modelo" id="toc-modelo" class="nav-link" data-scroll-target="#modelo">3.1.6 Modelo</a></li>
  <li><a href="#entrenamiento" id="toc-entrenamiento" class="nav-link" data-scroll-target="#entrenamiento">3.1.7 Entrenamiento</a></li>
  <li><a href="#guardado-y-lectura-de-modelos" id="toc-guardado-y-lectura-de-modelos" class="nav-link" data-scroll-target="#guardado-y-lectura-de-modelos">3.1.8 Guardado y lectura de modelos</a></li>
  </ul></li>
  <li><a href="#tensorboard" id="toc-tensorboard" class="nav-link" data-scroll-target="#tensorboard">3.2 TensorBoard</a>
  <ul class="collapse">
  <li><a href="#uso-básico-de-tensorboard" id="toc-uso-básico-de-tensorboard" class="nav-link" data-scroll-target="#uso-básico-de-tensorboard">3.2.1 Uso básico de TensorBoard</a></li>
  <li><a href="#funciones-de-visualización-principales-de-tensorboard" id="toc-funciones-de-visualización-principales-de-tensorboard" class="nav-link" data-scroll-target="#funciones-de-visualización-principales-de-tensorboard">3.2.2 Funciones de visualización principales de TensorBoard</a></li>
  <li><a href="#ejemplo-de-tensorboard" id="toc-ejemplo-de-tensorboard" class="nav-link" data-scroll-target="#ejemplo-de-tensorboard">3.2.3 Ejemplo de TensorBoard</a></li>
  </ul></li>
  <li><a href="#hugging-face-transformers" id="toc-hugging-face-transformers" class="nav-link" data-scroll-target="#hugging-face-transformers">3.3 Hugging Face Transformers</a>
  <ul class="collapse">
  <li><a href="#introducción-a-la-biblioteca-transformers" id="toc-introducción-a-la-biblioteca-transformers" class="nav-link" data-scroll-target="#introducción-a-la-biblioteca-transformers">3.3.1 Introducción a la biblioteca Transformers</a></li>
  <li><a href="#casos-de-uso-principales" id="toc-casos-de-uso-principales" class="nav-link" data-scroll-target="#casos-de-uso-principales">3.3.2 Casos de uso principales</a></li>
  </ul></li>
  <li><a href="#ejercicios-de-práctica" id="toc-ejercicios-de-práctica" class="nav-link" data-scroll-target="#ejercicios-de-práctica">Ejercicios de práctica</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../notebooks/es/part_1/01_El inicio del aprendizaje profundo.html">part_1</a></li><li class="breadcrumb-item"><a href="../../../notebooks/es/part_1/03_marco de aprendizaje profundo.html">3. marco de aprendizaje profundo</a></li></ol></nav></header>




<p><a href="https://colab.research.google.com/github/Quantum-Intelligence-Frontier/dldna/blob/main/notebooks/es/part_1/03_marco_de_aprendizaje_profundo.ipynb" target="_parent"> <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Abrir en Colab"> </a></p>
<section id="marco-de-aprendizaje-profundo" class="level1">
<h1>3. Marco de aprendizaje profundo</h1>
<blockquote class="blockquote">
<p>“La herramienta es tan buena como el que la hace.” - <em>Anónimo, pero a menudo citado por von Neumann</em></p>
</blockquote>
<p>El desarrollo de los marcos en la historia del aprendizaje profundo ha sido muy importante. Después del éxito de AlexNet en 2012, han surgido varios marcos. A través de Caffe, Theano, Torch7 y otros, actualmente PyTorch y TensorFlow son los más utilizados.</p>
<p>A principios de la década de 2010, el aprendizaje profundo comenzó a mostrar resultados sorprendentes en varios campos, como el reconocimiento de imágenes y el reconocimiento de voz, superando las tecnologías existentes. Sin embargo, entrenar y desplegar modelos de aprendizaje profundo todavía era una tarea difícil. Esto se debía a que había que implementar directamente la configuración de redes neuronales, el cálculo de gradientes, la aceleración GPU y otros aspectos. Esta complejidad elevaba las barreras de entrada para la investigación en aprendizaje profundo y ralentizaba el ritmo de la investigación. Para abordar estos problemas, surgieron los marcos de aprendizaje profundo. Estos marcos proporcionan API de alto nivel y herramientas para construir, entrenar y desplegar modelos de redes neuronales, simplificando y acelerando el proceso de desarrollo. En sus primeras etapas, frameworks como Theano, Caffe y Torch se popularizaron y fueron ampliamente utilizados en la academia y la industria.</p>
<p>En 2015, Google lanzó TensorFlow como software de código abierto, lo que trajo grandes cambios al ecosistema de marcos de aprendizaje profundo. TensorFlow ganó rápidamente popularidad gracias a su arquitectura flexible, potentes herramientas de visualización y soporte para el entrenamiento distribuido a gran escala. En 2017, Facebook presentó PyTorch, estableciendo otro hito importante. PyTorch ofrecía un grafo de cálculo dinámico, una interfaz intuitiva y excelentes capacidades de depuración, lo que llevó a su rápida difusión entre los investigadores.</p>
<p>Actualmente, los marcos de aprendizaje profundo han trascendido el papel de simples herramientas para convertirse en infraestructura esencial para la investigación y desarrollo de aprendizaje profundo. Proporcionan funciones clave como diferenciación automática, aceleración GPU, paralelización de modelos y entrenamiento distribuido, acelerando así el desarrollo de nuevos modelos y algoritmos. Además, la competencia y colaboración entre los marcos están impulsando aún más el avance del ecosistema de aprendizaje profundo.</p>
<section id="pytorch" class="level2">
<h2 class="anchored" data-anchor-id="pytorch">3.1 PyTorch</h2>
<p>PyTorch es un marco de aprendizaje automático de código abierto basado en la biblioteca Torch, utilizado para aplicaciones como visión por computadora y procesamiento de lenguaje natural. Fue desarrollado como el marco principal por el laboratorio de investigación de IA de Facebook (FAIR) en 2016, reimplemementando Torch7 en Python. Debido a su grafo de cálculo dinámico y capacidades intuitivas de depuración, ganó rápidamente popularidad entre los investigadores. Aunque hay otros marcos como TensorFlow, JAX y Caffe, PyTorch se ha convertido en el estándar de facto en la investigación. Muchos nuevos modelos a menudo se lanzan con implementaciones de PyTorch.</p>
<p>Una vez que se es competente en un marco, también puede ser una buena estrategia aprovechar las ventajas de otros marcos. Por ejemplo, se pueden utilizar las pipelines de preprocesamiento de datos de TensorFlow o las transformaciones funcionales de JAX junto con PyTorch.</p>
<div id="cell-2" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install dldna[colab] <span class="co"># in Colab</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip install dldna[all] # in your local</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="cell-3" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Print PyTorch version</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"PyTorch version: </span><span class="sc">{</span>torch<span class="sc">.</span>__version__<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the random seed for reproducibility</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">7</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>PyTorch version: 2.6.0+cu124</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="1">
<pre><code>&lt;torch._C.Generator at 0x7352f02b33f0&gt;</code></pre>
</div>
</div>
<p>Cuando se genera un número aleatorio, al configurar el valor inicial de la semilla se pueden obtener los mismos números aleatorios cada vez. Esto es comúnmente utilizado en la investigación para garantizar resultados consistentes en entrenamientos repetitivos.</p>
<section id="objeto-tensor" class="level3">
<h3 class="anchored" data-anchor-id="objeto-tensor">3.1.1 Objeto Tensor</h3>
<blockquote class="blockquote">
<p><strong>Desafío</strong>: ¿Cómo se pueden realizar eficientemente operaciones de matrices a gran escala utilizando GPU?</p>
<p><strong>Dilema del investigador</strong>: A medida que el tamaño de los modelos de aprendizaje profundo aumentaba, aprender y hacer inferencia con solo CPU llevaba demasiado tiempo. Las GPU estaban especializadas en cálculos paralelos y eran adecuadas para el aprendizaje profundo, pero la programación de GPU era compleja y difícil. Se necesitaba una herramienta que abstrajera y automatizara las operaciones de GPU para que los investigadores de aprendizaje profundo pudieran utilizarlas fácilmente.</p>
</blockquote>
<p>El tensor es la estructura de datos básica en PyTorch. Desde la aparición de CUDA en 2006, las operaciones de GPU se han convertido en el núcleo del aprendizaje profundo, y los tensores están diseñados para realizar estas operaciones de manera eficiente. Un tensor es un arreglo multidimensional que generaliza escalares, vectores y matrices. En el aprendizaje profundo, las dimensiones de los datos (rango del tensor) son muy variadas. Por ejemplo, una imagen se representa como un tensor de 4 dimensiones (lote, canal, altura, anchura), y el lenguaje natural se representa como un tensor de 3 dimensiones (lote, longitud de secuencia, dimensión de incrustación). Como se vio en el Capítulo 2, es importante poder transformar y procesar estas dimensiones con flexibilidad.</p>
<p>Puedes declarar un tensor de la siguiente manera.</p>
<div id="cell-6" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a 3x2x4 tensor with random values</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.Tensor(<span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">4</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[[ 1.1210e-44,  0.0000e+00,  0.0000e+00,  4.1369e-41],
         [ 1.8796e-17,  0.0000e+00,  2.8026e-45,  0.0000e+00]],

        [[ 0.0000e+00,  0.0000e+00,         nan,         nan],
         [ 6.3058e-44,  4.7424e+30,  1.4013e-45,  1.3563e-19]],

        [[ 1.0089e-43,  0.0000e+00,  1.1210e-44,  0.0000e+00],
         [-8.8105e+09,  4.1369e-41,  1.8796e-17,  0.0000e+00]]])</code></pre>
</div>
</div>
<p>También se pueden inicializar tensores a partir de datos existentes.</p>
<div id="cell-8" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># From a Python list</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> [[<span class="dv">1</span>, <span class="dv">2</span>], [<span class="dv">3</span>, <span class="dv">4</span>]]</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Type of d: </span><span class="sc">{</span><span class="bu">type</span>(d)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.Tensor(d)  <span class="co"># Creates a *copy*</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Tensor a:</span><span class="ch">\n</span><span class="sc">{</span>a<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Type of a: </span><span class="sc">{</span><span class="bu">type</span>(a)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="co"># From a NumPy array</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>d_np <span class="op">=</span> np.array(d)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Type of d_np: </span><span class="sc">{</span><span class="bu">type</span>(d_np)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.from_numpy(d_np) <span class="co"># Shares memory with d_np (zero-copy)</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Tensor b (from_numpy):</span><span class="ch">\n</span><span class="sc">{</span>b<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> torch.Tensor(d_np)  <span class="co"># Creates a *copy*</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Tensor c (from np array using torch.Tensor):</span><span class="ch">\n</span><span class="sc">{</span>c<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Example of memory sharing with torch.from_numpy</span></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>d_np[<span class="dv">0</span>, <span class="dv">0</span>] <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Modified d_np:</span><span class="ch">\n</span><span class="sc">{</span>d_np<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Tensor b (from_numpy) after modifying d_np:</span><span class="ch">\n</span><span class="sc">{</span>b<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Tensor c (copy) after modifying d_np:</span><span class="ch">\n</span><span class="sc">{</span>c<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Type of d: &lt;class 'list'&gt;
Tensor a:
tensor([[1., 2.],
        [3., 4.]])
Type of a: &lt;class 'torch.Tensor'&gt;
Type of d_np: &lt;class 'numpy.ndarray'&gt;
Tensor b (from_numpy):
tensor([[1, 2],
        [3, 4]])
Tensor c (from np array using torch.Tensor):
tensor([[1., 2.],
        [3., 4.]])
Modified d_np:
[[100   2]
 [  3   4]]
Tensor b (from_numpy) after modifying d_np:
tensor([[100,   2],
        [  3,   4]])
Tensor c (copy) after modifying d_np:
tensor([[1., 2.],
        [3., 4.]])</code></pre>
</div>
</div>
<p>No es lo mismo que se vean iguales cuando se imprimen. <code>d</code> es un objeto de lista de Python y los tensores pueden ser creados a partir de diversas estructuras de datos. La interacción con matrices NumPy es particularmente eficiente. Sin embargo, dado que los objetos de lista y las matrices NumPy no admiten GPU, la conversión a tensores es esencial para operaciones de gran escala. <em>Un punto importante</em> es entender la diferencia entre <code>torch.Tensor(data)</code> y <code>torch.from_numpy(data)</code>. El primero <em>siempre</em> crea una copia, mientras que el segundo crea una <em>vista</em> que comparte memoria con la matriz NumPy original (copia cero cuando sea posible). Si se modifica la matriz NumPy, también cambia el tensor creado por <code>from_numpy</code> y viceversa.</p>
<p>Hay muchas maneras de inicializar tensores. La importancia de los métodos de inicialización ha sido destacada desde el artículo de Hinton en 2006 y se han desarrollado diversas estrategias de inicialización. Las funciones básicas de inicialización son las siguientes:</p>
<ul>
<li><code>torch.zeros</code>: inicializa con ceros.</li>
<li><code>torch.ones</code>: inicializa con unos.</li>
<li><code>torch.rand</code>: inicializa con números aleatorios de una distribución uniforme entre 0 y 1.</li>
<li><code>torch.randn</code>: inicializa con números aleatorios de una distribución normal estándar (media 0, varianza 1).</li>
<li><code>torch.arange</code>: inicializa secuencialmente como n, n+1, n+2, …</li>
</ul>
<div id="cell-10" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>shape <span class="op">=</span> (<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>rand_t <span class="op">=</span> torch.rand(shape)     <span class="co"># Uniform distribution [0, 1)</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>randn_t <span class="op">=</span> torch.randn(shape)   <span class="co"># Standard normal distribution</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>ones_t <span class="op">=</span> torch.ones(shape)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>zeros_t <span class="op">=</span> torch.zeros(shape)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Random tensor (uniform):</span><span class="ch">\n</span><span class="sc">{</span>rand_t<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Random tensor (normal):</span><span class="ch">\n</span><span class="sc">{</span>randn_t<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Ones tensor:</span><span class="ch">\n</span><span class="sc">{</span>ones_t<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Zeros tensor:</span><span class="ch">\n</span><span class="sc">{</span>zeros_t<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Random tensor (uniform):
tensor([[0.5349, 0.1988, 0.6592],
        [0.6569, 0.2328, 0.4251]])
Random tensor (normal):
tensor([[-1.2514, -1.8841,  0.4457],
        [-0.7068, -1.5750, -0.6318]])
Ones tensor:
tensor([[1., 1., 1.],
        [1., 1., 1.]])
Zeros tensor:
tensor([[0., 0., 0.],
        [0., 0., 0.]])</code></pre>
</div>
</div>
<p>PyTorch admite más de 100 operaciones de tensor, y todas ellas pueden ejecutarse en GPU. Los tensores se crean básicamente en la memoria de CPU, por lo que para usar GPU, es necesario moverlos explícitamente usando la función <code>to()</code>. Mover tensores grandes entre CPU y GPU tiene un costo considerable, por lo que una gestión cuidadosa de la memoria es esencial. En el entrenamiento de deep learning práctico, el ancho de banda de memoria de la GPU tiene un impacto decisivo en el rendimiento. Por ejemplo, al entrenar modelos de transformador, cuanto mayor sea la memoria de GPU, más grande será el tamaño del lote que se puede usar, lo que mejora la eficiencia del entrenamiento. Sin embargo, la memoria de alta banda es muy costosa de producir y constituye una parte significativa del precio de la GPU. La diferencia en rendimiento entre las operaciones de tensor de CPU y GPU es particularmente notable en operaciones que se pueden paralelizar, como la multiplicación de matrices. Por esta razón, en el deep learning moderno son esenciales los aceleradores dedicados como GPU, TPU, NPU.</p>
<div id="cell-12" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Device setting</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> torch.cuda.is_available():</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    tensor <span class="op">=</span> zeros_t.to(<span class="st">"cuda"</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> <span class="st">"cuda:0"</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> <span class="st">"cpu"</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'GPU not available'</span>)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="co"># CPU/GPU performance comparison</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a><span class="co"># CPU operation</span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.rand(<span class="dv">10000</span>, <span class="dv">10000</span>)</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time.time()</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>torch.matmul(x, x)</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>cpu_time <span class="op">=</span> time.time() <span class="op">-</span> start</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"CPU computation time = </span><span class="sc">{</span>cpu_time<span class="sc">:3.2f}</span><span class="ss"> seconds"</span>)</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a><span class="co"># GPU operation</span></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> device <span class="op">!=</span> <span class="st">"cpu"</span>:</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> x.to(device)</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>    start <span class="op">=</span> torch.cuda.Event(enable_timing<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>    end <span class="op">=</span> torch.cuda.Event(enable_timing<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>    start.record()</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>    torch.matmul(x, x)</span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>    end.record()</span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>    torch.cuda.synchronize()  <span class="co"># Wait for all operations to complete</span></span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>    gpu_time <span class="op">=</span> start.elapsed_time(end) <span class="op">/</span> <span class="dv">1000</span>  <span class="co"># Convert milliseconds to seconds</span></span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"GPU computation time = </span><span class="sc">{</span>gpu_time<span class="sc">:3.2f}</span><span class="ss"> seconds"</span>)</span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"GPU is </span><span class="sc">{</span>cpu_time <span class="op">/</span> gpu_time<span class="sc">:3.1f}</span><span class="ss"> times faster."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>CPU computation time = 2.34 seconds
GPU computation time = 0.14 seconds
GPU is 16.2 times faster.</code></pre>
</div>
</div>
<p>La conversión entre NumPy y tensores se implementa de manera muy eficiente. En particular, como vimos anteriormente, al usar <code>torch.from_numpy()</code>, la memoria se comparte sin necesidad de copiarla.</p>
<div id="cell-14" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>np_a <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">1</span>], [<span class="dv">2</span>, <span class="dv">3</span>]])</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>tensor_a <span class="op">=</span> torch.from_numpy(np_a)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>np_b <span class="op">=</span> tensor_a.numpy() <span class="co"># Shares memory.  If tensor_a is on CPU.</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"NumPy array: </span><span class="sc">{</span>np_a<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Tensor: </span><span class="sc">{</span>tensor_a<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"NumPy array from Tensor: </span><span class="sc">{</span>np_b<span class="sc">}</span><span class="ss">"</span>) <span class="co">#if tensor_a is on CPU.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>NumPy array: [[1 1]
 [2 3]]
Tensor: tensor([[1, 1],
        [2, 3]])
NumPy array from Tensor: [[1 1]
 [2 3]]</code></pre>
</div>
</div>
<p>Cuando se convierte un tensor a NumPy, el tensor debe estar en la CPU. Si el tensor está en la GPU, primero debe moverse a la CPU usando <code>.cpu()</code>. Las propiedades básicas de un tensor son <code>shape</code>, <code>dtype</code>, <code>device</code>, y a través de estas se puede verificar la forma del tensor y su ubicación de almacenamiento.</p>
<div id="cell-16" class="cell" data-execution_count="18">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.rand(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Shape = </span><span class="sc">{</span>a<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Data type = </span><span class="sc">{</span>a<span class="sc">.</span>dtype<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Device = </span><span class="sc">{</span>a<span class="sc">.</span>device<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Shape = torch.Size([2, 3])
Data type = torch.float32
Device = cpu</code></pre>
</div>
</div>
<p>El indexado y el slicing utilizan la misma sintaxis que NumPy.</p>
<div id="cell-18" class="cell" data-execution_count="19">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.rand(<span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Tensor a:</span><span class="ch">\n</span><span class="sc">{</span>a<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"First row: </span><span class="sc">{</span>a[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"First column: </span><span class="sc">{</span>a[:, <span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Last column: </span><span class="sc">{</span>a[..., <span class="op">-</span><span class="dv">1</span>]<span class="sc">}</span><span class="ss">"</span>)  <span class="co"># Equivalent to a[:, -1]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Tensor a:
tensor([[0.2069, 0.8296, 0.4973],
        [0.9265, 0.8386, 0.6611],
        [0.5329, 0.7822, 0.0975]])
First row: tensor([0.2069, 0.8296, 0.4973])
First column: tensor([0.2069, 0.9265, 0.5329])
Last column: tensor([0.4973, 0.6611, 0.0975])</code></pre>
</div>
</div>
</section>
<section id="operaciones" class="level3">
<h3 class="anchored">3.1.2 Operaciones</h3>
<p>PyTorch admite casi todas las operaciones de NumPy. La tradición de operaciones en matrices multidimensionales, que comenzó con el lenguaje APL en 1964, se ha transmitido a través de NumPy hasta PyTorch. Puede consultar la lista completa de operaciones soportadas en la documentación oficial de PyTorch (<a href="[https://pytorch.org/docs/stable/tensors.html">documentación de PyTorch</a>).</p>
<p>El cambio de forma de tensores es una de las operaciones más frecuentemente utilizadas en redes neuronales. Se puede cambiar la dimensión de un tensor mediante la función <code>view()</code>, manteniendo el número total de elementos. La función <code>permute()</code> reordena las dimensiones.</p>
<div id="cell-20" class="cell" data-execution_count="20">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.arange(<span class="dv">12</span>)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"a: </span><span class="sc">{</span>a<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> a.view(<span class="dv">3</span>, <span class="dv">4</span>)  <span class="co"># Reshape to 3x4</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"x: </span><span class="sc">{</span>x<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> x.permute(<span class="dv">1</span>, <span class="dv">0</span>)  <span class="co"># Swap dimensions 0 and 1</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"y: </span><span class="sc">{</span>y<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.randn(<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">5</span>)</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"b shape: </span><span class="sc">{</span>b<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> b.permute(<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>)  <span class="co"># Change dimension order to (2, 0, 1)</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"z shape: </span><span class="sc">{</span>z<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>a: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])
x: tensor([[ 0,  1,  2,  3],
        [ 4,  5,  6,  7],
        [ 8,  9, 10, 11]])
y: tensor([[ 0,  4,  8],
        [ 1,  5,  9],
        [ 2,  6, 10],
        [ 3,  7, 11]])
b shape: torch.Size([2, 3, 5])
z shape: torch.Size([5, 2, 3])</code></pre>
</div>
</div>
<p>Las operaciones de matriz son fundamentales en el aprendizaje profundo, y PyTorch proporciona varias funciones para operaciones con matrices.</p>
<ol type="1">
<li><code>torch.matmul</code>: realiza operaciones de matriz generales. Dependiendo de las dimensiones, funciona de la siguiente manera.
<ul>
<li>1D × 1D: producto escalar (dot product)</li>
<li>2D × 2D: multiplicación de matrices</li>
<li>1D × 2D: agrega una dimensión a la primera matriz y luego realiza la multiplicación de matrices</li>
<li>N-D × M-D: realiza broadcasting y luego la multiplicación de matrices</li>
</ul></li>
<li><code>torch.mm</code>: operación de multiplicación de matrices pura (sin soporte para broadcasting)</li>
<li><code>torch.bmm</code>: multiplicación de matrices con dimensión de lote ((b, i, k) × (b, k, j) → (b, i, j))</li>
<li><code>torch.einsum</code>: operaciones de tensores usando la notación de suma de Einstein. Permite expresar operaciones de tensores complejas de manera concisa. (Consulte “Teoría Profunda” para más detalles)
<ul>
<li><code>torch.einsum('ij,jk-&gt;ik', a, b)</code>: producto de las matrices a y b</li>
</ul></li>
</ol>
<div id="cell-22" class="cell" data-execution_count="21">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.arange(<span class="dv">6</span>)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.arange(<span class="dv">12</span>)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> a.view(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> b.view(<span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"X: </span><span class="sc">{</span>X<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Y: </span><span class="sc">{</span>Y<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="co"># matmul (2,3) X (3,4) -&gt; (2, 4)</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"X @ Y = </span><span class="sc">{</span>torch<span class="sc">.</span>matmul(X, Y)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Using torch.einsum for matrix multiplication</span></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>einsum_result <span class="op">=</span> torch.einsum(<span class="st">'ij,jk-&gt;ik'</span>, X, Y)</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"X @ Y (using einsum) = </span><span class="sc">{</span>einsum_result<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.arange(<span class="dv">2</span>)</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.arange(<span class="dv">2</span>)</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"a: </span><span class="sc">{</span>a<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"b: </span><span class="sc">{</span>b<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Vector x Vector operation</span></span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"a @ b = </span><span class="sc">{</span>torch<span class="sc">.</span>matmul(a, b)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a><span class="co"># 1D tensor (vector), 2D tensor (matrix) operation</span></span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a><span class="co"># (2) x (2,2) is treated as (1,2) x (2,2) for matrix multiplication.</span></span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Result: (1,2) x (2,2) -&gt; (1,2)</span></span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.arange(<span class="dv">4</span>)</span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a>B <span class="op">=</span> b.view(<span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"a: </span><span class="sc">{</span>a<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"B: </span><span class="sc">{</span>B<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"a @ B = </span><span class="sc">{</span>torch<span class="sc">.</span>matmul(a, B)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Matrix x Vector operation</span></span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.randn(<span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb21-36"><a href="#cb21-36" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.randn(<span class="dv">4</span>)</span>
<span id="cb21-37"><a href="#cb21-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"X @ b shape = </span><span class="sc">{</span>torch<span class="sc">.</span>matmul(X, b)<span class="sc">.</span>size()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-38"><a href="#cb21-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-39"><a href="#cb21-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Batched matrix x Batched matrix</span></span>
<span id="cb21-40"><a href="#cb21-40" aria-hidden="true" tabindex="-1"></a><span class="co"># The leading batch dimension is maintained.</span></span>
<span id="cb21-41"><a href="#cb21-41" aria-hidden="true" tabindex="-1"></a><span class="co"># The 2nd and 3rd dimensions are treated as matrices for multiplication.</span></span>
<span id="cb21-42"><a href="#cb21-42" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.arange(<span class="dv">18</span>).view(<span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb21-43"><a href="#cb21-43" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> torch.arange(<span class="dv">18</span>).view(<span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">2</span>)</span>
<span id="cb21-44"><a href="#cb21-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"X: </span><span class="sc">{</span>X<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-45"><a href="#cb21-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Y: </span><span class="sc">{</span>Y<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-46"><a href="#cb21-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Batch dimension remains the same, and (2,3)x(3,2) -&gt; (2,2)</span></span>
<span id="cb21-47"><a href="#cb21-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"X @ Y shape: </span><span class="sc">{</span>torch<span class="sc">.</span>matmul(X, Y)<span class="sc">.</span>size()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-48"><a href="#cb21-48" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"X @ Y: </span><span class="sc">{</span>torch<span class="sc">.</span>matmul(X, Y)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-49"><a href="#cb21-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-50"><a href="#cb21-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Batched matrix x Broadcasted matrix</span></span>
<span id="cb21-51"><a href="#cb21-51" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.arange(<span class="dv">18</span>).view(<span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb21-52"><a href="#cb21-52" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> torch.arange(<span class="dv">6</span>).view(<span class="dv">3</span>, <span class="dv">2</span>)</span>
<span id="cb21-53"><a href="#cb21-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"X: </span><span class="sc">{</span>X<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-54"><a href="#cb21-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Y: </span><span class="sc">{</span>Y<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-55"><a href="#cb21-55" aria-hidden="true" tabindex="-1"></a><span class="co"># The second matrix lacks a batch dimension.</span></span>
<span id="cb21-56"><a href="#cb21-56" aria-hidden="true" tabindex="-1"></a><span class="co"># It's broadcasted to match the batch dimension of the first matrix (repeated 3 times).</span></span>
<span id="cb21-57"><a href="#cb21-57" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"X @ Y shape: </span><span class="sc">{</span>torch<span class="sc">.</span>matmul(X, Y)<span class="sc">.</span>size()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-58"><a href="#cb21-58" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"X @ Y: </span><span class="sc">{</span>torch<span class="sc">.</span>matmul(X, Y)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-59"><a href="#cb21-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-60"><a href="#cb21-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-61"><a href="#cb21-61" aria-hidden="true" tabindex="-1"></a><span class="co"># Using torch.einsum for matrix multiplication</span></span>
<span id="cb21-62"><a href="#cb21-62" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.arange(<span class="dv">6</span>).view(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb21-63"><a href="#cb21-63" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> torch.arange(<span class="dv">12</span>).view(<span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb21-64"><a href="#cb21-64" aria-hidden="true" tabindex="-1"></a>einsum_result <span class="op">=</span> torch.einsum(<span class="st">'ij,jk-&gt;ik'</span>, X, Y)  <span class="co"># Equivalent to torch.matmul(X, Y)</span></span>
<span id="cb21-65"><a href="#cb21-65" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"X @ Y (using einsum) = </span><span class="sc">{</span>einsum_result<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>X: tensor([[0, 1, 2],
        [3, 4, 5]])
Y: tensor([[ 0,  1,  2,  3],
        [ 4,  5,  6,  7],
        [ 8,  9, 10, 11]])
X @ Y = tensor([[20, 23, 26, 29],
        [56, 68, 80, 92]])
X @ Y (using einsum) = tensor([[20, 23, 26, 29],
        [56, 68, 80, 92]])
a: tensor([0, 1])
b: tensor([0, 1])
a @ b = 1
a: tensor([0, 1])
B: tensor([[0, 1],
        [2, 3]])
a @ B = tensor([2, 3])
X @ b shape = torch.Size([3])
X: tensor([[[ 0,  1,  2],
         [ 3,  4,  5]],

        [[ 6,  7,  8],
         [ 9, 10, 11]],

        [[12, 13, 14],
         [15, 16, 17]]])
Y: tensor([[[ 0,  1],
         [ 2,  3],
         [ 4,  5]],

        [[ 6,  7],
         [ 8,  9],
         [10, 11]],

        [[12, 13],
         [14, 15],
         [16, 17]]])
X @ Y shape: torch.Size([3, 2, 2])
X @ Y: tensor([[[ 10,  13],
         [ 28,  40]],

        [[172, 193],
         [244, 274]],

        [[550, 589],
         [676, 724]]])
X: tensor([[[ 0,  1,  2],
         [ 3,  4,  5]],

        [[ 6,  7,  8],
         [ 9, 10, 11]],

        [[12, 13, 14],
         [15, 16, 17]]])
Y: tensor([[0, 1],
        [2, 3],
        [4, 5]])
X @ Y shape: torch.Size([3, 2, 2])
X @ Y: tensor([[[ 10,  13],
         [ 28,  40]],

        [[ 46,  67],
         [ 64,  94]],

        [[ 82, 121],
         [100, 148]]])
X @ Y (using einsum) = tensor([[20, 23, 26, 29],
        [56, 68, 80, 92]])</code></pre>
</div>
</div>
<p><code>torch.einsum</code> utiliza la notación de Einstein para expresar operaciones de tensores. <code>'ij,jk-&gt;ik'</code> significa que se deben multiplicar las dimensiones <code>(i, j)</code> del tensor <code>X</code> con las dimensiones <code>(j, k)</code> del tensor <code>Y</code> para generar un resultado de dimensión <code>(i, k)</code>. Esto produce el mismo resultado que la multiplicación de matrices <code>torch.matmul(X, Y)</code>. <code>einsum</code> también admite varias otras operaciones, incluyendo transposición, suma, producto interno, producto externo y multiplicación de matrices por lotes. Para más detalles, consulte la documentación de PyTorch.</p>
<div id="cell-24" class="cell" data-execution_count="22">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Other einsum examples</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Transpose</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.randn(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.einsum(<span class="st">'ij-&gt;ji'</span>, a)  <span class="co"># Swap dimensions</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Sum of all elements</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.randn(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.einsum(<span class="st">'ij-&gt;'</span>, a)  <span class="co"># Sum all elements</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Batch matrix multiplication</span></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.randn(<span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">5</span>)</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.randn(<span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">3</span>)</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> torch.einsum(<span class="st">'bij,bjk-&gt;bik'</span>, a, b) <span class="co"># Batch matrix multiplication</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Haga clic para ver el contenido (análisis detallado: notación de Einstein y torch.einsum)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Haga clic para ver el contenido (análisis detallado: notación de Einstein y torch.einsum)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<section id="notación-de-einstein-y-torch.einsum" class="level2">
<h2 class="anchored" data-anchor-id="notación-de-einstein-y-torch.einsum">Notación de Einstein y torch.einsum</h2>
<section id="notación-de-einstein-einstein-notation" class="level3">
<h3 class="anchored" data-anchor-id="notación-de-einstein-einstein-notation">Notación de Einstein (Einstein Notation)</h3>
<p>La notación de Einstein (o Convención de Suma de Einstein) es un método de notación introducido por Albert Einstein en 1916 para describir la teoría general de la relatividad. Originalmente se diseñó para simplificar las expresiones matemáticas en física, especialmente en la teoría de la relatividad, pero gracias a su comodidad y expresividad, es ampliamente utilizada en diversos campos que manejan operaciones con tensores.</p>
<p><strong>Idea central:</strong></p>
<ul>
<li><strong>Los índices repetidos implican suma:</strong> cuando un índice aparece dos veces en un término, se implica que se suman todos los valores posibles de ese índice. Se omite el símbolo de suma explícito (<span class="math inline">\(\sum\)</span>) para simplificar la notación.</li>
<li><strong>Índices libres y ficticios:</strong>
<ul>
<li><strong>Índice libre (free index):</strong> índice que aparece en el tensor resultante. Aparece una vez por término.</li>
<li><strong>Índice ficticio (dummy index):</strong> índice sobre el cual se realiza la suma. Aparece dos veces en un término. (índice de suma, índice ligado)</li>
</ul></li>
</ul>
<p><strong>Reglas básicas</strong></p>
<ol type="1">
<li><strong>Si un mismo índice aparece dos veces en un término, se suman los valores correspondientes a ese índice.</strong></li>
<li><strong>Los índices libres determinan las dimensiones del tensor resultante.</strong></li>
<li><strong>Los índices ficticios solo se utilizan para cálculos internos y no aparecen en el resultado.</strong></li>
<li><strong>Las letras de los índices pueden elegirse arbitrariamente, pero es recomendable mantener la consistencia para evitar confusiones.</strong> (por convención se usan <span class="math inline">\(i, j, k, l, m, n\)</span>)</li>
<li><strong>La flecha (<span class="math inline">\(\rightarrow\)</span>) a la izquierda</strong> representa los tensores de entrada, y <strong>a la derecha</strong> el tensor de salida.</li>
</ol>
<p><strong>Ejemplos</strong></p>
<ul>
<li><strong>Producto escalar (dot product):</strong> <span class="math inline">\(a_i b_i\)</span> (equivalente a <span class="math inline">\(\sum_i a_i b_i\)</span>)</li>
<li><strong>Multiplicación de matrices (matrix multiplication):</strong> <span class="math inline">\(A_{ij} B_{jk} = C_{ik}\)</span> (equivalente a <span class="math inline">\(\sum_j A_{ij}B_{jk}\)</span>)</li>
<li><strong>Transposición (transpose):</strong> <span class="math inline">\(A_{ij} = B_{ji}\)</span> (B es la transpuesta de A)</li>
<li><strong>Traza (trace):</strong> <span class="math inline">\(A_{ii}\)</span> (equivalente a <span class="math inline">\(\sum_i A_{ii}\)</span>)</li>
<li><strong>Producto exterior (outer product):</strong> <span class="math inline">\(a_i b_j = C_{ij}\)</span></li>
<li><strong>Multiplicación elemento por elemento (element-wise multiplication):</strong> <span class="math inline">\(A_{ij}B_{ij} = C_{ij}\)</span> (producto de Hadamard)</li>
</ul>
<p><strong>Ejemplos de uso en deep learning</strong> * <strong>Multiplicación de matrices por lotes (batched matrix multiplication):</strong> <span class="math inline">\(A\_{bij} B\_{bjk} = C\_{bik}\)</span> (<span class="math inline">\(b\)</span>: dimensión del lote) * <strong>Mecanismo de atención (attention mechanism):</strong> <span class="math inline">\(e\_{ij} = Q\_{ik} K\_{jk}\)</span>, <span class="math inline">\(a\_{ij} = \text{softmax}(e\_{ij})\)</span>, <span class="math inline">\(v\_{i} = a\_{ij} V\_{j}\)</span> (<span class="math inline">\(Q\)</span>: consulta, <span class="math inline">\(K\)</span>: clave, <span class="math inline">\(V\)</span>: valor) * <strong>Transformación bilineal (bilinear transformation):</strong> <span class="math inline">\(x\_i W\_{ijk} y\_j = z\_k\)</span> * <strong>Convolución multidimensional (convolution):</strong> <span class="math inline">\(I\_{b,c,i,j} \* F\_{o,c,k,l} = O\_{b,o,i',j'}\)</span> (<span class="math inline">\(b\)</span>: lote, <span class="math inline">\(c\)</span>: canales de entrada, <span class="math inline">\(o\)</span>: canales de salida, <span class="math inline">\(i, j\)</span>: dimensiones espaciales de entrada, <span class="math inline">\(k, l\)</span>: dimensiones espaciales del filtro) * <strong>Normalización por lotes (Batch Normalization):</strong> <span class="math inline">\(\gamma\_c \* \frac{x\_{b,c,h,w} - \mu\_c}{\sigma\_c} + \beta\_c\)</span> (<span class="math inline">\(c\)</span>: dimensión de canal, <span class="math inline">\(b\)</span>: lote, <span class="math inline">\(h\)</span>: altura, <span class="math inline">\(w\)</span>: anchura) * <strong>Actualización del estado oculto de RNN</strong>: <span class="math inline">\(h\_t = \tanh(W\_{ih}x\_t + b\_{ih} + W\_{hh}h\_{t-1} + b\_{hh})\)</span> (<span class="math inline">\(h\)</span>: oculto, <span class="math inline">\(x\)</span>: entrada, <span class="math inline">\(W\)</span>: peso, <span class="math inline">\(b\)</span>: sesgo) * <strong>Actualización del estado de celda de LSTM</strong>: <span class="math inline">\(c\_t = f\_t \* c\_{t-1} + i\_t \* \tilde{c}\_t\)</span> (<span class="math inline">\(c\)</span>: estado de celda, <span class="math inline">\(f\)</span>: puerta de olvido, <span class="math inline">\(i\)</span>: puerta de entrada, <span class="math inline">\(\tilde{c}\_t\)</span>: estado de celda candidato)</p>
</section>
<section id="torch.einsum" class="level3">
<h3 class="anchored" data-anchor-id="torch.einsum">torch.einsum</h3>
<p><code>torch.einsum</code> es una función en PyTorch que realiza operaciones de tensores utilizando la notación de Einstein. <code>einsum</code> es el acrónimo de “Einstein summation”.</p>
<p><strong>Uso:</strong></p>
<div class="sourceCode" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>torch.einsum(equation, <span class="op">*</span>operands)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li><code>equation</code>: cadena de caracteres en notación de Einstein. Tiene forma <code>'ij,jk-&gt;ik'</code>.</li>
<li><code>*operands</code>: tensores que participan en la operación (argumentos variables).</li>
</ul>
<p><strong>Ventajas</strong></p>
<ul>
<li><strong>Concisión:</strong> permite expresar operaciones complejas de tensores en una sola línea de código.</li>
<li><strong>Legibilidad:</strong> la notación de Einstein clarifica el significado de las operaciones de tensores.</li>
<li><strong>Flexibilidad:</strong> facilita combinar diversas operaciones de tensores para definir nuevas operaciones.</li>
<li><strong>Optimización:</strong> PyTorch optimiza automáticamente las operaciones <code>einsum</code> para realizar cálculos eficientes. Puede ser más rápido que operaciones implementadas manualmente, utilizando rutinas optimizadas de bibliotecas como BLAS, cuBLAS y ajustando el orden de las operaciones.</li>
<li><strong>Compatibilidad con diferenciación automática</strong>: las operaciones definidas con <code>einsum</code> son completamente compatibles con el sistema de diferenciación automática de PyTorch.</li>
</ul>
<p><strong>Ejemplos de torch.einsum:</strong></p>
<div class="sourceCode" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Multiplicación de matrices</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> torch.randn(<span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>B <span class="op">=</span> torch.randn(<span class="dv">4</span>, <span class="dv">5</span>)</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>C <span class="op">=</span> torch.einsum(<span class="st">'ij,jk-&gt;ik'</span>, A, B)  <span class="co"># C = A @ B</span></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Transposición</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> torch.randn(<span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>B <span class="op">=</span> torch.einsum(<span class="st">'ij-&gt;ji'</span>, A)  <span class="co"># B = A.T</span></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Suma de la diagonal</span></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> torch.randn(<span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>trace <span class="op">=</span> torch.einsum(<span class="st">'ii-&gt;'</span>, A)  <span class="co"># trace = torch.trace(A)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="multiplicación-de-matrices-por-lotes" class="level1">
<h1>multiplicación de matrices por lotes</h1>
<p>A = torch.randn(2, 3, 4) B = torch.randn(2, 4, 5) C = torch.einsum(‘bij,bjk-&gt;bik’, A, B) # C = torch.bmm(A, B)</p>
</section>
<section id="producto-exterior" class="level1">
<h1>producto exterior</h1>
<p>a = torch.randn(3) b = torch.randn(4) C = torch.einsum(‘i,j-&gt;ij’, a, b) # C = torch.outer(a, b)</p>
</section>
<section id="multiplicación-elemento-por-elemento" class="level1">
<h1>multiplicación elemento por elemento</h1>
<p>A = torch.randn(2,3) B = torch.randn(2,3) C = torch.einsum(‘ij,ij-&gt;ij’, A, B) # C = A * B</p>
</section>
<section id="transformación-bilineal" class="level1">
<h1>transformación bilineal</h1>
<p>x = torch.randn(3) W = torch.randn(5, 3, 4) y = torch.randn(4) z = torch.einsum(‘i,ijk,j-&gt;k’, x, W, y) # z_k = sum_i sum_j x_i * W_{ijk} * y_j</p>
</section>
<section id="reducción-de-tensores-multidimensionales" class="level1">
<h1>reducción de tensores multidimensionales</h1>
<p>tensor = torch.randn(3, 4, 5, 6) result = torch.einsum(‘…ij-&gt;…i’, tensor) # suma sobre las últimas dos dimensiones</p>
<pre><code>
**`torch.einsum` vs. otros operadores:**

| Operación               | `torch.einsum`           | Otros métodos                                   |
| :---------------------- | :----------------------- | :------------------------------------------ |
| multiplicación de matrices | `'ij,jk-&gt;ik'`           | `torch.matmul(A, B)` o `A @ B`          |
| transposición            | `'ij-&gt;ji'`               | `torch.transpose(A, 0, 1)` o `A.T`        |
| traza                    | `'ii-&gt;'`                 | `torch.trace(A)`                            |
| multiplicación de matrices por lotes | `'bij,bjk-&gt;bik'`        | `torch.bmm(A, B)`                           |
| producto interno         | `'i,i-&gt;'`                | `torch.dot(a, b)`                            |
| producto exterior        | `'i,j-&gt;ij'`              | `torch.outer(a, b)`                          |
| multiplicación elemento por elemento | `'ij,ij-&gt;ij'`          | `A * B`                                      |
| reducción de tensores (sum, mean, etc.) | `'ijk-&gt;i'` (ejemplo)      | `torch.sum(A, dim=(1, 2))`                   |

**Limitaciones de `torch.einsum`**

  * **Curva de aprendizaje inicial:** Para usuarios no familiarizados con la notación de Einstein, puede ser un poco difícil al principio.
  * **Legibilidad en operaciones complejas:** En casos muy complejos, la cadena `einsum` puede volverse larga y menos legible. En estos casos, es recomendable dividir la operación en varios pasos o utilizar comentarios.
  * **Imposibilidad de expresar todas las operaciones:** Dado que `einsum` se basa en operaciones de álgebra lineal, no se pueden expresar directamente operaciones no lineales (por ejemplo: `max`, `min`, `sort`) ni operaciones condicionales. En estos casos, es necesario usar otras funciones de PyTorch.

**Optimización de `einsum` (`torch.compile`)**
`torch.compile` (PyTorch 2.0 o superior) puede optimizar aún más las operaciones `einsum`. `compile` realiza diversas optimizaciones a través de la compilación JIT (Just-In-Time), analizando el código, fusionando operaciones de tensores y optimizando patrones de acceso a memoria.

```python
import torch
# Disponible en PyTorch 2.0 o superior

@torch.compile
def my_einsum_function(a, b):
    return torch.einsum('ij,jk-&gt;ik', a, b)

# Se compila al llamar por primera vez, y se ejecuta el código optimizado en llamadas posteriores
result = my_einsum_function(torch.randn(10, 20), torch.randn(20, 30))
</code></pre>
<p><strong>Conclusión:</strong></p>
<p>La notación de Einstein y <code>torch.einsum</code> son herramientas poderosas para expresar y calcular operaciones tensoriales complejas en el aprendizaje profundo de manera concisa y eficiente. Aunque puede parecer extraño al principio, una vez que te familiarices con ellas, puedes mejorar significativamente la legibilidad y eficiencia del código. En particular, cuando se trata de modelos de aprendizaje profundo complejos como los modelos Transformer, donde hay muchas operaciones tensoriales, su valor es evidente. Usarlas junto con <code>torch.compile</code> puede mejorar aún más el rendimiento.</p>
<p><strong>Referencias:</strong></p>
<ol type="1">
<li><strong>Notación de Einstein:</strong> <a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://en.wikipedia.org/wiki/Einstein_notation">https://en.wikipedia.org/wiki/Einstein_notation</a></li>
<li><strong>Documentación de <code>torch.einsum</code>:</strong> <a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://pytorch.org/docs/stable/generated/torch.einsum.html">https://pytorch.org/docs/stable/generated/torch.einsum.html</a></li>
<li><strong>Introducción básica a NumPy’s einsum:</strong> <a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://ajcr.net/Basic-guide-to-einsum/">https://ajcr.net/Basic-guide-to-einsum/</a></li>
<li><strong>Einsum is All You Need - Einstein Summation in Deep Learning:</strong> <a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://rockt.github.io/2018/04/30/einsum">https://rockt.github.io/2018/04/30/einsum</a></li>
</ol>
</section>
</div>
</div>
</div>
</section>
<section id="grafo-de-cálculo-para-operaciones-de-gradiente" class="level3">
<h3 class="anchored" data-anchor-id="grafo-de-cálculo-para-operaciones-de-gradiente">3.1.3 Grafo de cálculo para operaciones de gradiente</h3>
<p>La diferenciación automática (Automatic Differentiation) se ha estado investigando desde la década de 1970, pero ha recibido mucha atención desde el desarrollo del aprendizaje profundo después de 2015. PyTorch implementa la diferenciación automática a través de grafos de cálculo dinámicos (dynamic computation graph), lo cual es una implementación práctica de la regla de la cadena (chain rule) que se examinó en el Capítulo 2.</p>
<p>La diferenciación automática de PyTorch puede rastrear y almacenar los gradientes en cada paso de cálculo. Para esto, es necesario declarar explícitamente el seguimiento de gradientes en los tensores.</p>
<div id="cell-27" class="cell" data-execution_count="23">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.randn((<span class="dv">2</span>,))</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"a.requires_grad (default): </span><span class="sc">{</span>a<span class="sc">.</span>requires_grad<span class="sc">}</span><span class="ss">"</span>)  <span class="co"># False (default)</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>a.requires_grad_(<span class="va">True</span>)  <span class="co"># In-place modification</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"a.requires_grad (after setting to True): </span><span class="sc">{</span>a<span class="sc">.</span>requires_grad<span class="sc">}</span><span class="ss">"</span>)  <span class="co"># True</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Declare during creation</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">2</span>, dtype<span class="op">=</span>torch.float32, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"x.requires_grad (declared at creation): </span><span class="sc">{</span>x<span class="sc">.</span>requires_grad<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>a.requires_grad (default): False
a.requires_grad (after setting to True): True
x.requires_grad (declared at creation): True</code></pre>
</div>
</div>
<p>Por ejemplo, consideremos la siguiente función de pérdida simple. (Figura 3-1, ver versión anterior)</p>
<p><span class="math display">\[y = \frac {1}{N}\displaystyle\sum_{i}^{N} \{(x_i - 1)^2 + 4) \}\]</span></p>
<p>Las operaciones sobre <span class="math inline">\(x_i\)</span> pueden expresarse secuencialmente como <span class="math inline">\(a_i = x_i - 1\)</span>, <span class="math inline">\(b_i = a_i^2\)</span>, <span class="math inline">\(c_i = b_i + 4\)</span>, <span class="math inline">\(y = \frac{1}{N}\sum_{i=1}^{N} c_i\)</span>.</p>
<p>Vamos a realizar las operaciones en la dirección forward y backward para esta ecuación.</p>
<div id="cell-29" class="cell" data-execution_count="24">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> x <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> a<span class="op">**</span><span class="dv">2</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> b <span class="op">+</span> <span class="dv">4</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> c.mean()</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"y = </span><span class="sc">{</span>y<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform backward operation</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>y.backward()</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the gradient of x (x.grad)</span></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"x.grad = </span><span class="sc">{</span>x<span class="sc">.</span>grad<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>y = 4.5
x.grad = tensor([-1.,  0.])</code></pre>
</div>
</div>
<p>La traducción del texto es la siguiente:</p>
<p>Calcular las gradientes de cada paso mediante fórmulas se muestra a continuación.</p>
<p><span class="math inline">\(\frac{\partial a_i}{\partial x_i} = 1, \frac{\partial b_i}{\partial a_i} = 2 \cdot a_i, \frac{\partial c_i}{\partial b_i} = 1,  \frac{\partial y}{\partial c_i} = \frac{1}{N}\)</span></p>
<p>Por lo tanto, por la regla de la cadena:</p>
<p><span class="math inline">\(\frac{\partial y}{\partial x_i} = \frac{\partial y}{\partial  c_i}\frac{\partial c_i}{\partial b_i}\frac{\partial b_i}{\partial a_i}\frac{\partial a_i}{\partial x_i} =  \frac{1}{N} \cdot 1 \cdot 2 \cdot a_i \cdot 1 = \frac{2}{N}a_i = \frac{2}{N}(x_i - 1)\)</span></p>
<p>Dado que <span class="math inline">\(x_i\)</span> está en el intervalo [0, 1] y N=2 (número de elementos de x), <span class="math inline">\(\frac{\partial y}{\partial x_i}  = [-0.5, 0.5]\)</span>. Esto coincide con los resultados de la diferenciación automática de PyTorch.</p>
<p>PyTorch implementa modernamente el concepto de diferenciación automática que ha sido investigado desde la década de 1970. En particular, la creación dinámica de gráficos de cálculo y las funciones de seguimiento de gradientes son muy útiles. Sin embargo, a veces es necesario desactivar estas funciones de diferenciación automática.</p>
<div id="cell-31" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn(<span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> torch.randn(<span class="dv">4</span>, <span class="dv">2</span>)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.randn(<span class="dv">2</span>)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="co"># If gradient tracking is needed</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> torch.matmul(x, w) <span class="op">+</span> b</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>z.requires_grad_(<span class="va">True</span>)  <span class="co"># Can also be set using requires_grad_()</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"z.requires_grad: </span><span class="sc">{</span>z<span class="sc">.</span>requires_grad<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Disable gradient tracking method 1: Using 'with' statement</span></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>    z <span class="op">=</span> torch.matmul(x, w) <span class="op">+</span> b</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"z.requires_grad (inside no_grad): </span><span class="sc">{</span>z<span class="sc">.</span>requires_grad<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Disable gradient tracking method 2: Using detach()</span></span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>z_det <span class="op">=</span> z.detach()</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"z_det.requires_grad: </span><span class="sc">{</span>z_det<span class="sc">.</span>requires_grad<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>z.requires_grad: True
z.requires_grad (inside no_grad): False
z_det.requires_grad: False</code></pre>
</div>
</div>
<p>La desactivación del rastreo de gradientes es particularmente útil en los siguientes casos:</p>
<ol type="1">
<li><strong>Durante la inferencia</strong>: para ahorrar memoria y costos computacionales cuando solo se necesita el paso forward.</li>
<li><strong>Ajuste fino (Fine-tuning)</strong>: cuando se actualizan solo ciertos parámetros y se mantienen fijos los demás.</li>
<li><strong>Optimización del rendimiento</strong>: como el paso backward conlleva costos adicionales de memoria y computación, se desactiva cuando no es necesario.</li>
</ol>
<p>En particular, en el ajuste fino de grandes modelos de lenguaje, es común mantener la mayoría de los parámetros fijos y actualizar solo algunos, por lo que la activación selectiva del rastreo de gradientes es una característica muy importante.</p>
</section>
<section id="carga-de-datos" class="level3">
<h3 class="anchored" data-anchor-id="carga-de-datos">3.1.4 Carga de datos</h3>
<p>La carga de datos es un elemento clave en el aprendizaje profundo. Hasta principios de la década de 2000, cada equipo de investigación utilizaba su propio método de procesamiento de datos, pero con la aparición de conjuntos de datos a gran escala como ImageNet en 2009, surgió la necesidad de un sistema estandarizado para cargar datos.</p>
<p>PyTorch proporciona dos clases clave para separar el procesamiento de datos y la lógica de entrenamiento.</p>
<ol type="1">
<li><code>torch.utils.data.Dataset</code>: Proporciona una interfaz coherente para acceder a los datos y las etiquetas. Debe implementar los métodos <code>__len__</code> y <code>__getitem__</code>.</li>
<li><code>torch.utils.data.DataLoader</code>: Proporciona un mecanismo eficiente de carga de datos en lotes (batch). Envuelve un <code>Dataset</code> para automatizar la generación de mini-lotes, el mezclado, la carga paralela de datos, etc.</li>
</ol>
<p>A continuación se presenta un ejemplo de generación de datos aleatorios utilizando la distribución Dirichlet.</p>
<div id="cell-34" class="cell" data-execution_count="9">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.utils.data <span class="im">as</span> data</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize with Dirichlet distribution</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> np.random.dirichlet(np.ones(<span class="dv">5</span>), size<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> np.zeros_like(a)</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate label values</span></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> (a <span class="op">==</span> a.<span class="bu">max</span>(axis<span class="op">=</span><span class="dv">1</span>)[:, <span class="va">None</span>]).astype(<span class="bu">int</span>)</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Data (a):</span><span class="ch">\n</span><span class="sc">{</span>a<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Labels (b):</span><span class="ch">\n</span><span class="sc">{</span>b<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a custom Dataset class by inheriting from PyTorch's Dataset.</span></span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> RandomData(data.Dataset):</span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, feature, length):</span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.feature <span class="op">=</span> feature</span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.length <span class="op">=</span> length</span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.generate_data()</span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> generate_data(<span class="va">self</span>):</span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> np.random.dirichlet(np.ones(<span class="va">self</span>.feature), size<span class="op">=</span><span class="va">self</span>.length)</span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a>        y <span class="op">=</span> (x <span class="op">==</span> x.<span class="bu">max</span>(axis<span class="op">=</span><span class="dv">1</span>)[:, <span class="va">None</span>]).astype(<span class="bu">int</span>)  <span class="co"># One-hot encoding</span></span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.data <span class="op">=</span> x  <span class="co"># numpy object</span></span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.label <span class="op">=</span> y</span>
<span id="cb33-28"><a href="#cb33-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-29"><a href="#cb33-29" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb33-30"><a href="#cb33-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.length</span>
<span id="cb33-31"><a href="#cb33-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-32"><a href="#cb33-32" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, index):</span>
<span id="cb33-33"><a href="#cb33-33" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Return data and label as torch tensors</span></span>
<span id="cb33-34"><a href="#cb33-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.tensor(<span class="va">self</span>.data[index], dtype<span class="op">=</span>torch.float32), torch.tensor(<span class="va">self</span>.label[index], dtype<span class="op">=</span>torch.int64)</span>
<span id="cb33-35"><a href="#cb33-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-36"><a href="#cb33-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-37"><a href="#cb33-37" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> RandomData(feature<span class="op">=</span><span class="dv">10</span>, length<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb33-38"><a href="#cb33-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of data samples = </span><span class="sc">{</span><span class="bu">len</span>(dataset)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb33-39"><a href="#cb33-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Data at index 0 = </span><span class="sc">{</span>dataset[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb33-40"><a href="#cb33-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Data type = </span><span class="sc">{</span><span class="bu">type</span>(dataset[<span class="dv">0</span>][<span class="dv">0</span>])<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Data (a):
[[0.46073711 0.01119455 0.28991657 0.11259078 0.12556099]
 [0.07331166 0.43554042 0.1243009  0.13339224 0.23345478]]
Labels (b):
[[1 0 0 0 0]
 [0 1 0 0 0]]
Number of data samples = 100
Data at index 0 = (tensor([1.4867e-01, 1.6088e-01, 1.2207e-02, 3.6049e-02, 1.1054e-04, 8.1160e-02,
        2.9811e-02, 1.9398e-01, 4.9448e-02, 2.8769e-01]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1]))
Data type = &lt;class 'torch.Tensor'&gt;</code></pre>
</div>
</div>
<p><code>DataLoader</code> proporciona varias funciones para el procesamiento por lotes. Los parámetros principales son los siguientes.</p>
<ul>
<li><code>batch_size</code>: número de muestras por lote</li>
<li><code>shuffle</code>: aleatorización del orden de los datos (generalmente se establece en <code>True</code> durante el entrenamiento)</li>
<li><code>num_workers</code>: número de procesos para la carga de datos en paralelo</li>
<li><code>drop_last</code>: indicar si se descarta o no el último lote incompleto (se descarta si es <code>True</code>)</li>
</ul>
<p>Se lee los datos del <code>Dataset</code> utilizando <code>__getitem__</code>, y se convierte el resultado en un objeto tensor. En particular, la configuración de <code>num_workers</code> es importante al procesar conjuntos de datos grandes de imágenes o videos. Sin embargo, para conjuntos de datos pequeños, puede ser más eficiente usar un solo proceso. Si se establece un valor demasiado alto para <code>num_workers</code>, puede generar overhead, por lo que es importante encontrar el valor adecuado. (Generalmente se prueban valores como el número de núcleos o el doble del número de núcleos).</p>
<div id="cell-36" class="cell" data-execution_count="10">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>data_loader <span class="op">=</span> data.DataLoader(dataset, batch_size<span class="op">=</span><span class="dv">4</span>, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Read one batch.</span></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>train_x, train_y <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(data_loader))</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"1st batch training data = </span><span class="sc">{</span>train_x<span class="sc">}</span><span class="ss">, </span><span class="ch">\n</span><span class="ss"> Data shape = </span><span class="sc">{</span>train_x<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"1st batch label data = </span><span class="sc">{</span>train_y<span class="sc">}</span><span class="ss">, </span><span class="ch">\n</span><span class="ss"> Data shape = </span><span class="sc">{</span>train_y<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"1st batch label data type = </span><span class="sc">{</span><span class="bu">type</span>(train_y)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>1st batch training data = tensor([[3.3120e-02, 1.4274e-01, 9.7984e-02, 1.9628e-03, 6.8926e-02, 3.4525e-01,
         4.6966e-02, 6.0947e-02, 4.2738e-02, 1.5937e-01],
        [8.0707e-02, 4.9181e-02, 3.1863e-02, 1.4238e-02, 1.6089e-02, 1.7980e-01,
         1.7544e-01, 1.3465e-01, 1.6361e-01, 1.5442e-01],
        [4.2364e-02, 3.3635e-02, 2.0840e-01, 1.6919e-02, 4.5977e-02, 6.5791e-02,
         1.8726e-01, 1.0325e-01, 2.2029e-01, 7.6117e-02],
        [1.4867e-01, 1.6088e-01, 1.2207e-02, 3.6049e-02, 1.1054e-04, 8.1160e-02,
         2.9811e-02, 1.9398e-01, 4.9448e-02, 2.8769e-01]]), 
 Data shape = torch.Size([4, 10])
1st batch label data = tensor([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]), 
 Data shape = torch.Size([4, 10])
1st batch label data type = &lt;class 'torch.Tensor'&gt;</code></pre>
</div>
</div>
<p>PyTorch proporciona paquetes especializados para el procesamiento de datos específicos del dominio. Desde que el aprendizaje profundo se expandió a diversos campos después de 2016, surgió la necesidad de procesamiento de datos especializado en cada dominio.</p>
<ul>
<li><code>torchvision</code>: visión por computadora</li>
<li><code>torchaudio</code>: procesamiento de audio</li>
<li><code>torchtext</code>: procesamiento del lenguaje natural</li>
</ul>
<p>Fashion-MNIST es un conjunto de datos publicado por Zalando Research en 2017, diseñado para reemplazar a MNIST. La composición del conjunto de datos es la siguiente.</p>
<ul>
<li>Datos de entrenamiento: 60,000</li>
<li>Datos de prueba: 10,000</li>
<li>Tamaño de las imágenes: 28x28 en escala de grises</li>
</ul>
<div id="cell-38" class="cell" data-execution_count="11">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset, DataLoader</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.transforms <span class="im">import</span> ToTensor, Normalize, Compose</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn_image <span class="im">as</span> isns</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt <span class="co"># Added for visualization</span></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to calculate mean and std of the dataset</span></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_mean_std(dataset):</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>    dataloader <span class="op">=</span> DataLoader(dataset, batch_size<span class="op">=</span><span class="bu">len</span>(dataset), shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>    data, _ <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(dataloader))</span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>    mean <span class="op">=</span> data.mean(axis<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">3</span>))  <span class="co"># Calculate mean across channel dimension</span></span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>    std <span class="op">=</span> data.std(axis<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">3</span>))    <span class="co"># Calculate std across channel dimension</span></span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> mean, std</span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Datasets.  Note:  We *don't* apply Normalize here yet.</span></span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> datasets.FashionMNIST(</span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a>    root<span class="op">=</span><span class="st">"data"</span>, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>ToTensor()</span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> datasets.FashionMNIST(</span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a>    root<span class="op">=</span><span class="st">"data"</span>, train<span class="op">=</span><span class="va">False</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>ToTensor()</span>
<span id="cb37-24"><a href="#cb37-24" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb37-25"><a href="#cb37-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-26"><a href="#cb37-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate mean and std for normalization</span></span>
<span id="cb37-27"><a href="#cb37-27" aria-hidden="true" tabindex="-1"></a>train_mean, train_std <span class="op">=</span> calculate_mean_std(train_dataset)</span>
<span id="cb37-28"><a href="#cb37-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Train data mean: </span><span class="sc">{</span>train_mean<span class="sc">}</span><span class="ss">, std: </span><span class="sc">{</span>train_std<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb37-29"><a href="#cb37-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-30"><a href="#cb37-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Now define transforms *with* normalization</span></span>
<span id="cb37-31"><a href="#cb37-31" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> Compose([</span>
<span id="cb37-32"><a href="#cb37-32" aria-hidden="true" tabindex="-1"></a>    ToTensor(),</span>
<span id="cb37-33"><a href="#cb37-33" aria-hidden="true" tabindex="-1"></a>    Normalize(train_mean, train_std)  <span class="co"># Use calculated mean and std</span></span>
<span id="cb37-34"><a href="#cb37-34" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb37-35"><a href="#cb37-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-36"><a href="#cb37-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Re-create datasets with the normalization transform</span></span>
<span id="cb37-37"><a href="#cb37-37" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> datasets.FashionMNIST(</span>
<span id="cb37-38"><a href="#cb37-38" aria-hidden="true" tabindex="-1"></a>    root<span class="op">=</span><span class="st">"data"</span>, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform</span>
<span id="cb37-39"><a href="#cb37-39" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb37-40"><a href="#cb37-40" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> datasets.FashionMNIST(</span>
<span id="cb37-41"><a href="#cb37-41" aria-hidden="true" tabindex="-1"></a>    root<span class="op">=</span><span class="st">"data"</span>, train<span class="op">=</span><span class="va">False</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform</span>
<span id="cb37-42"><a href="#cb37-42" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb37-43"><a href="#cb37-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-44"><a href="#cb37-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-45"><a href="#cb37-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Check one training data sample.</span></span>
<span id="cb37-46"><a href="#cb37-46" aria-hidden="true" tabindex="-1"></a>sample_idx <span class="op">=</span> torch.randint(<span class="bu">len</span>(train_dataset), size<span class="op">=</span>(<span class="dv">1</span>,)).item()</span>
<span id="cb37-47"><a href="#cb37-47" aria-hidden="true" tabindex="-1"></a>img, label <span class="op">=</span> train_dataset[sample_idx]  <span class="co"># Use a random index</span></span>
<span id="cb37-48"><a href="#cb37-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-49"><a href="#cb37-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Label: </span><span class="sc">{</span>label<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb37-50"><a href="#cb37-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-51"><a href="#cb37-51" aria-hidden="true" tabindex="-1"></a><span class="co"># Manually create a label map</span></span>
<span id="cb37-52"><a href="#cb37-52" aria-hidden="true" tabindex="-1"></a>labels_map <span class="op">=</span> {</span>
<span id="cb37-53"><a href="#cb37-53" aria-hidden="true" tabindex="-1"></a>    <span class="dv">0</span>: <span class="st">"T-shirt"</span>,</span>
<span id="cb37-54"><a href="#cb37-54" aria-hidden="true" tabindex="-1"></a>    <span class="dv">1</span>: <span class="st">"Trouser"</span>,</span>
<span id="cb37-55"><a href="#cb37-55" aria-hidden="true" tabindex="-1"></a>    <span class="dv">2</span>: <span class="st">"Pullover"</span>,</span>
<span id="cb37-56"><a href="#cb37-56" aria-hidden="true" tabindex="-1"></a>    <span class="dv">3</span>: <span class="st">"Dress"</span>,</span>
<span id="cb37-57"><a href="#cb37-57" aria-hidden="true" tabindex="-1"></a>    <span class="dv">4</span>: <span class="st">"Coat"</span>,</span>
<span id="cb37-58"><a href="#cb37-58" aria-hidden="true" tabindex="-1"></a>    <span class="dv">5</span>: <span class="st">"Sandal"</span>,</span>
<span id="cb37-59"><a href="#cb37-59" aria-hidden="true" tabindex="-1"></a>    <span class="dv">6</span>: <span class="st">"Shirt"</span>,</span>
<span id="cb37-60"><a href="#cb37-60" aria-hidden="true" tabindex="-1"></a>    <span class="dv">7</span>: <span class="st">"Sneaker"</span>,</span>
<span id="cb37-61"><a href="#cb37-61" aria-hidden="true" tabindex="-1"></a>    <span class="dv">8</span>: <span class="st">"Bag"</span>,</span>
<span id="cb37-62"><a href="#cb37-62" aria-hidden="true" tabindex="-1"></a>    <span class="dv">9</span>: <span class="st">"Ankle Boot"</span>,</span>
<span id="cb37-63"><a href="#cb37-63" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb37-64"><a href="#cb37-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-65"><a href="#cb37-65" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Label map: </span><span class="sc">{</span>labels_map[label]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb37-66"><a href="#cb37-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-67"><a href="#cb37-67" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot using seaborn-image.</span></span>
<span id="cb37-68"><a href="#cb37-68" aria-hidden="true" tabindex="-1"></a>isns.imgplot(img.squeeze())  <span class="co"># Squeeze to remove channel dimension for grayscale</span></span>
<span id="cb37-69"><a href="#cb37-69" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f"Label: </span><span class="sc">{</span>labels_map[label]<span class="sc">}</span><span class="ss">"</span>) <span class="co"># Add title to plot</span></span>
<span id="cb37-70"><a href="#cb37-70" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb37-71"><a href="#cb37-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-72"><a href="#cb37-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-73"><a href="#cb37-73" aria-hidden="true" tabindex="-1"></a><span class="co"># Define data loaders</span></span>
<span id="cb37-74"><a href="#cb37-74" aria-hidden="true" tabindex="-1"></a>train_dataloader <span class="op">=</span> DataLoader(train_dataset, batch_size<span class="op">=</span><span class="dv">32</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb37-75"><a href="#cb37-75" aria-hidden="true" tabindex="-1"></a>test_dataloader <span class="op">=</span> DataLoader(test_dataset, batch_size<span class="op">=</span><span class="dv">32</span>, shuffle<span class="op">=</span><span class="va">False</span>) <span class="co"># No need to shuffle test data</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Train data mean: tensor([0.2860]), std: tensor([0.3530])
Label: 5
Label map: Sandal</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="03_marco de aprendizaje profundo_files/figure-html/cell-19-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="transformación-de-datos-transform" class="level3">
<h3 class="anchored" data-anchor-id="transformación-de-datos-transform">3.1.5 Transformación de datos (Transform)</h3>
<p>La transformación de datos es un proceso de preprocesamiento muy importante en el aprendizaje profundo. Desde el éxito de AlexNet en 2012, la ampliación de datos (Data Augmentation) se ha convertido en un factor clave para mejorar el rendimiento del modelo. PyTorch proporciona una variedad de herramientas para estos tipos de transformaciones. <code>transforms.Compose</code> permite aplicar varias transformaciones secuencialmente. Además, con la función <code>Lambda</code>, es fácil implementar transformaciones personalizadas.</p>
<p>La transformación de datos es muy importante para mejorar el rendimiento de generalización del modelo. En particular, en el campo de la visión por computadora, la ampliación de datos a través de diversas transformaciones se ha convertido en una práctica estándar. El caso de la transformación <code>Normalize</code> es un paso esencial para estabilizar el entrenamiento del modelo, ya que estandariza los datos.</p>
<p>Para aplicar la transformación <code>Normalize</code>, es necesario conocer la media (mean) y la desviación estándar (standard deviation) del conjunto de datos. El código para calcular esto es el siguiente.</p>
<div id="cell-40" class="cell" data-execution_count="12">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> transforms</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> PIL</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate mean and std of the dataset</span></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_mean_std(dataset):</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>    dataloader <span class="op">=</span> DataLoader(dataset, batch_size<span class="op">=</span><span class="bu">len</span>(dataset), shuffle<span class="op">=</span><span class="va">False</span>) <span class="co"># Load all data at once</span></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>    data, _ <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(dataloader))</span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># For grayscale images, calculate mean and std over height, width dimensions (0, 2, 3)</span></span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># For RGB images, the calculation would be over (0, 1, 2)</span></span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>    mean <span class="op">=</span> data.mean(dim<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">3</span>))  <span class="co"># Calculate mean across batch and spatial dimensions</span></span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a>    std <span class="op">=</span> data.std(dim<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">3</span>))    <span class="co"># Calculate std across batch and spatial dimensions</span></span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> mean, std</span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Example usage with FashionMNIST ---</span></span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a><span class="co"># 1.  Create dataset *without* normalization first:</span></span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a>train_dataset_for_calc <span class="op">=</span> datasets.FashionMNIST(</span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a>    root<span class="op">=</span><span class="st">"data"</span>, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transforms.ToTensor()  <span class="co"># Only ToTensor</span></span>
<span id="cb39-21"><a href="#cb39-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb39-22"><a href="#cb39-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-23"><a href="#cb39-23" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Calculate mean and std:</span></span>
<span id="cb39-24"><a href="#cb39-24" aria-hidden="true" tabindex="-1"></a>train_mean, train_std <span class="op">=</span> calculate_mean_std(train_dataset_for_calc)</span>
<span id="cb39-25"><a href="#cb39-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Train data mean: </span><span class="sc">{</span>train_mean<span class="sc">}</span><span class="ss">, std: </span><span class="sc">{</span>train_std<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb39-26"><a href="#cb39-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-27"><a href="#cb39-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-28"><a href="#cb39-28" aria-hidden="true" tabindex="-1"></a><span class="co"># 3.  *Now* create the dataset with normalization:</span></span>
<span id="cb39-29"><a href="#cb39-29" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb39-30"><a href="#cb39-30" aria-hidden="true" tabindex="-1"></a>    transforms.ToTensor(),</span>
<span id="cb39-31"><a href="#cb39-31" aria-hidden="true" tabindex="-1"></a>    transforms.Normalize(train_mean, train_std)  <span class="co"># Use calculated mean and std</span></span>
<span id="cb39-32"><a href="#cb39-32" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb39-33"><a href="#cb39-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-34"><a href="#cb39-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Example of defining a custom transform using Lambda</span></span>
<span id="cb39-35"><a href="#cb39-35" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> crop_image(image: PIL.Image.Image) <span class="op">-&gt;</span> PIL.Image.Image:</span>
<span id="cb39-36"><a href="#cb39-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Original image is assumed to be 28x28.</span></span>
<span id="cb39-37"><a href="#cb39-37" aria-hidden="true" tabindex="-1"></a>    left, top, width, height <span class="op">=</span> <span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">18</span>, <span class="dv">18</span> <span class="co"># Example crop parameters</span></span>
<span id="cb39-38"><a href="#cb39-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> transforms.functional.crop(image, top<span class="op">=</span>top, left<span class="op">=</span>left, width<span class="op">=</span>width, height<span class="op">=</span>height)</span>
<span id="cb39-39"><a href="#cb39-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-40"><a href="#cb39-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Compose transforms, including the custom one and normalization.</span></span>
<span id="cb39-41"><a href="#cb39-41" aria-hidden="true" tabindex="-1"></a>transform_with_crop <span class="op">=</span> transforms.Compose([</span>
<span id="cb39-42"><a href="#cb39-42" aria-hidden="true" tabindex="-1"></a>    transforms.Lambda(crop_image), <span class="co"># Custom cropping</span></span>
<span id="cb39-43"><a href="#cb39-43" aria-hidden="true" tabindex="-1"></a>    transforms.ColorJitter(),</span>
<span id="cb39-44"><a href="#cb39-44" aria-hidden="true" tabindex="-1"></a>    transforms.RandomInvert(),</span>
<span id="cb39-45"><a href="#cb39-45" aria-hidden="true" tabindex="-1"></a>    transforms.ToTensor(), <span class="co"># Must be *before* Normalize</span></span>
<span id="cb39-46"><a href="#cb39-46" aria-hidden="true" tabindex="-1"></a>    transforms.Normalize(train_mean, train_std) <span class="co"># Use calculated mean and std</span></span>
<span id="cb39-47"><a href="#cb39-47" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb39-48"><a href="#cb39-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-49"><a href="#cb39-49" aria-hidden="true" tabindex="-1"></a>train_dataset_transformed <span class="op">=</span> datasets.FashionMNIST(root<span class="op">=</span><span class="st">"data"</span>, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform_with_crop)</span>
<span id="cb39-50"><a href="#cb39-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Get one sample to check the transformation.</span></span>
<span id="cb39-51"><a href="#cb39-51" aria-hidden="true" tabindex="-1"></a>sample_img, sample_label <span class="op">=</span> train_dataset_transformed[<span class="dv">0</span>]</span>
<span id="cb39-52"><a href="#cb39-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Transformed image shape: </span><span class="sc">{</span>sample_img<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb39-53"><a href="#cb39-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Transformed image min/max: </span><span class="sc">{</span>sample_img<span class="sc">.</span><span class="bu">min</span>()<span class="sc">}</span><span class="ss">, </span><span class="sc">{</span>sample_img<span class="sc">.</span><span class="bu">max</span>()<span class="sc">}</span><span class="ss">"</span>) <span class="co"># Check normalization</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Train data mean: tensor([0.2860]), std: tensor([0.3530])
Transformed image shape: torch.Size([1, 18, 18])
Transformed image min/max: -0.8102576732635498, 2.022408962249756</code></pre>
</div>
</div>
<p>En el código se genera primero un conjunto de datos al que solo se le aplica la transformación <code>ToTensor()</code> para calcular la media y la desviación estándar. Luego, utilizando los valores calculados, se define la transformación final que incluye la normalización <code>Normalize</code>. También se incluye un ejemplo de cómo añadir una función personalizada <code>crop_image</code> a la cadena de transformaciones usando una función <code>Lambda</code>. <code>ToTensor()</code> debe aplicarse <em>antes</em> de <code>Normalize</code>. <code>ToTensor()</code> convierte imágenes en el rango [0, 255] a tensores en el rango [0, 1], y <code>Normalize</code> normaliza estos datos en el rango [0, 1] para que tengan una media de 0 y una desviación estándar de 1. Es común aplicar el aumento de datos solo a los datos de entrenamiento y no a los datos de validación/prueba.</p>
</section>
<section id="modelo" class="level3">
<h3 class="anchored" data-anchor-id="modelo">3.1.6 Modelo</h3>
<p>La implementación de modelos de redes neuronales ha evolucionado de diversas maneras desde la década de 1980. PyTorch adoptó un enfoque de implementación orientada a objetos desde su lanzamiento en 2016, lo cual se logra a través de <code>nn.Module</code>. Este enfoque mejoró significativamente la reutilización y escalabilidad de los modelos.</p>
<p>Las clases de modelo se implementan heredando de <code>nn.Module</code> y generalmente incluyen los siguientes métodos:</p>
<ul>
<li><code>__init__()</code>: define e inicializa los componentes del red neuronal (capas, funciones de activación, etc.).</li>
<li><code>forward()</code>: recibe datos de entrada, realiza la operación de propagación hacia adelante del modelo y devuelve la salida (logits o predicciones).</li>
<li>(opcional) <code>training_step()</code>, <code>validation_step()</code>, <code>test_step()</code>: cuando se utilizan con bibliotecas como PyTorch Lightning, definen el comportamiento en cada paso de entrenamiento/validación/prueba.</li>
<li>(opcional) otros métodos definidos por el usuario: se pueden agregar métodos adicionales para realizar funciones específicas del modelo.</li>
</ul>
<div id="cell-43" class="cell" data-execution_count="13">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> nn</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SimpleNetwork(nn.Module):</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()  <span class="co"># Or super(SimpleNetwork, self).__init__()</span></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.flatten <span class="op">=</span> nn.Flatten()</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.network_stack <span class="op">=</span> nn.Sequential(</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">28</span> <span class="op">*</span> <span class="dv">28</span>, <span class="dv">512</span>),</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">512</span>, <span class="dv">512</span>),</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">512</span>, <span class="dv">10</span>),</span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.flatten(x)  <span class="co"># Flatten the image data into a 1D array</span></span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> <span class="va">self</span>.network_stack(x)</span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> logits</span>
<span id="cb41-19"><a href="#cb41-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-20"><a href="#cb41-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Move model to the appropriate device (CPU or GPU)</span></span>
<span id="cb41-21"><a href="#cb41-21" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SimpleNetwork().to(device)</span>
<span id="cb41-22"><a href="#cb41-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>SimpleNetwork(
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (network_stack): Sequential(
    (0): Linear(in_features=784, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=10, bias=True)
  )
)</code></pre>
</div>
</div>
<p>La función logit tiene varios significados.</p>
<ul>
<li>Significado matemático: es una función que convierte probabilidades en el rango [0, 1] a números reales en el rango [−∞, ∞].</li>
<li>Significado en aprendizaje profundo: es la salida cruda (sin normalizar) de una red neuronal.</li>
</ul>
<p>En problemas de clasificación multiclase, comúnmente se aplica la función <code>softmax</code> al final para convertir los valores a probabilidades que se puedan comparar con las etiquetas. En este caso, el logit es la entrada de la función <code>softmax</code>.</p>
<p>Se crea un modelo a partir de una clase y se transfiere a un <code>device</code>. Si existe una GPU, el modelo se carga en la memoria de la GPU.</p>
<div id="cell-45" class="cell" data-execution_count="14">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.rand(<span class="dv">1</span>, <span class="dv">28</span>, <span class="dv">28</span>, device<span class="op">=</span>device)</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>logits <span class="op">=</span> model(x)  <span class="co"># Don't call forward() directly!  Call the *model* object.</span></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>prediction <span class="op">=</span> nn.Softmax(dim<span class="op">=</span><span class="dv">1</span>)(logits)  <span class="co"># Convert logits to probabilities</span></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>y_label <span class="op">=</span> prediction.argmax(<span class="dv">1</span>) <span class="co"># Get the predicted class</span></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Logits: </span><span class="sc">{</span>logits<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Prediction probabilities: </span><span class="sc">{</span>prediction<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Predicted class: </span><span class="sc">{</span>y_label<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Logits: tensor([[ 0.0464, -0.0368,  0.0447, -0.0640, -0.0253,  0.0242,  0.0378, -0.1139,
          0.0005,  0.0299]], device='cuda:0', grad_fn=&lt;AddmmBackward0&gt;)
Prediction probabilities: tensor([[0.1052, 0.0968, 0.1050, 0.0942, 0.0979, 0.1029, 0.1043, 0.0896, 0.1005,
         0.1035]], device='cuda:0', grad_fn=&lt;SoftmaxBackward0&gt;)
Predicted class: tensor([0], device='cuda:0')</code></pre>
</div>
</div>
<p>Es importante tener en cuenta que no se debe llamar directamente al método <code>forward()</code> del modelo. En su lugar, cuando se llama al objeto de modelo como una función (<code>model(x)</code>), <code>forward()</code> se ejecuta automáticamente y se integra con el sistema de diferenciación automática de PyTorch. El método <code>__call__</code> del objeto de modelo invoca a <code>forward()</code> y realiza tareas adicionales necesarias (como hooks).</p>
</section>
<section id="entrenamiento" class="level3">
<h3 class="anchored" data-anchor-id="entrenamiento">3.1.7 Entrenamiento</h3>
<blockquote class="blockquote">
<p><strong>Desafío</strong>: ¿Cómo se pueden entrenar eficientemente modelos complejos con conjuntos de datos a gran escala?</p>
<p><strong>Angustia del investigador</strong>: El rendimiento de los modelos de aprendizaje profundo se ve fuertemente influenciado por la cantidad y calidad de los datos, así como por la complejidad del modelo. Sin embargo, entrenar modelos con conjuntos de datos a gran escala requería mucho tiempo y recursos de computación. Estabilizar el proceso de entrenamiento, prevenir el sobreajuste y encontrar los hiperparámetros óptimos eran problemas difíciles. Para abordar estos desafíos, se necesitaban algoritmos de aprendizaje eficientes, técnicas de optimización y bucles de entrenamiento automatizados.</p>
</blockquote>
<p>Una vez que se han preparado los datos y el modelo para el entrenamiento, se realiza el entrenamiento práctico. Para convertir una red neuronal en un buen aproximador (approximator), es necesario actualizar iterativamente sus parámetros. Se define una función de error (loss function) que calcula la diferencia entre las etiquetas y las predicciones, y se selecciona un optimizador para actualizar continuamente los parámetros y reducir el error.</p>
<p>El proceso de entrenamiento sigue estos pasos:</p>
<ol type="1">
<li>Inicialización del conjunto de datos y del cargador de datos (data loader)</li>
<li>Carga de datos por lotes</li>
<li>Cálculo de las predicciones a través de la propagación hacia adelante</li>
<li>Cálculo del error a través de la función de pérdida</li>
<li>Cálculo de los gradientes a través de la retropropagación</li>
<li>Actualización de los parámetros a través del optimizador</li>
</ol>
<p>Se llama época (epoch) a una iteración completa sobre todo el conjunto de datos, y este proceso se repite durante varias épocas en lo que se conoce como bucle de entrenamiento.</p>
<section id="hiperparámetros" class="level5">
<h5 class="anchored" data-anchor-id="hiperparámetros">Hiperparámetros</h5>
<p>El entrenamiento requiere tres hiperparámetros clave:</p>
<ul>
<li>Número de épocas (epoch): Determina cuántas veces se repetirá la época. Generalmente es mejor detenerse justo antes del sobreajuste.</li>
<li>Tamaño del lote: El número de datos de entrenamiento que pasarán a través del modelo en una sola vez. Pasar todo el conjunto de datos puede ser irrealista debido a las limitaciones de memoria de GPU y el aumento exponencial del tiempo de cálculo matricial. Se actualizan gradualmente los parámetros del modelo con subconjuntos de datos para aproximar el valor óptimo. Si el tamaño del lote es demasiado pequeño, las variaciones pueden ser demasiado volátiles y dificultar la aproximación al mínimo.</li>
<li>Tasa de aprendizaje: Ajusta la escala de los valores a actualizar. Puede compararse con el tamaño de paso en un proceso de búsqueda gradual. Generalmente tiene un valor pequeño. En el siguiente capítulo, se explorará la relación entre la tasa de aprendizaje y el optimizador.</li>
</ul>
<div id="cell-48" class="cell" data-execution_count="15">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 3가지 초매개변수</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">32</span></span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">1e-3</span> <span class="co"># 최적화기를 위해 앞서 지정했음.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="bucle-de-entrenamiento" class="level5">
<h5 class="anchored" data-anchor-id="bucle-de-entrenamiento">Bucle de Entrenamiento</h5>
<p>El bucle de entrenamiento se lleva a cabo en dos etapas por cada época. 1. Etapa de entrenamiento: optimización de parámetros 2. Etapa de validación: evaluación del rendimiento</p>
<p>Desde la introducción de la normalización por lotes en 2015, ha sido importante distinguir entre los modos train() y eval(). En el modo eval(), las operaciones de entrenamiento específicas como la normalización por lotes o el dropout se desactivan para mejorar la velocidad de inferencia.</p>
</section>
<section id="función-de-pérdida" class="level5">
<h5 class="anchored" data-anchor-id="función-de-pérdida">Función de Pérdida</h5>
<p>La función de pérdida es un elemento crucial en el aprendizaje de redes neuronales. Desde el modelo de neurona de McCulloch-Pitts en 1943, se han propuesto diversas funciones de pérdida. En particular, la introducción del cross-entropy (entropía cruzada) a partir de la teoría de la información en 1989 marcó un punto de inflexión importante en el desarrollo del aprendizaje profundo.</p>
</section>
<section id="binary-cross-entropy-bce" class="level5">
<h5 class="anchored" data-anchor-id="binary-cross-entropy-bce">Binary Cross-Entropy (BCE)</h5>
<p>El BCE, que se utiliza principalmente en clasificación binaria, está definido como sigue:</p>
<p><span class="math display">\[\mathcal{L} = - \sum_{i} [y_i \log{x_i} + (1-y_i)\log{(1-x_i)}] \]</span></p>
<p>Aquí, <span class="math inline">\(y\)</span> es la etiqueta real y <span class="math inline">\(x\)</span> es el valor predicho por el modelo, ambos con un rango de [0, 1].</p>
<p>PyTorch proporciona varias funciones de pérdida.</p>
<ul>
<li><code>nn.MSELoss</code>: para problemas de regresión (Error Cuadrático Medio)</li>
<li><code>nn.NLLLoss</code>: logaritmo negativo de la verosimilitud</li>
<li><code>nn.CrossEntropyLoss</code>: combinación de <code>LogSoftmax</code> y <code>NLLLoss</code></li>
<li><code>nn.BCEWithLogitsLoss</code>: integración de una capa sigmoide y BCE para mayor estabilidad numérica</li>
</ul>
<p>En particular, <code>nn.BCEWithLogitsLoss</code> es notable por integrar una capa sigmoide y BCE para mayor estabilidad numérica. El uso de la función log tiene las siguientes ventajas (descritas con más detalle en el Capítulo 2):</p>
<ol type="1">
<li>Mitiga cambios bruscos en los valores numéricos</li>
<li>Convierte multiplicaciones en sumas, mejorando la eficiencia computacional</li>
</ol>
<div id="cell-50" class="cell" data-execution_count="16">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the loss function</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> nn.CrossEntropyLoss()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="optimizador" class="level5">
<h5 class="anchored" data-anchor-id="optimizador">Optimizador</h5>
<p>Los algoritmos de optimización comenzaron con el método de descenso del gradiente (Gradient Descent) básico de la década de 1950 y lograron un gran avance con la aparición de Adam en 2014. <code>torch.optim</code> proporciona varios optimizadores, y actualmente Adam y AdamW son los más utilizados.</p>
<div id="cell-52" class="cell" data-execution_count="17">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Declare the optimizer.</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.SGD(model.parameters(), lr<span class="op">=</span>learning_rate)</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Learning rate scheduler (optional, but often beneficial)</span></span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>scheduler <span class="op">=</span> torch.optim.lr_scheduler.StepLR(optimizer, step_size<span class="op">=</span><span class="dv">30</span>, gamma<span class="op">=</span><span class="fl">0.1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>En el código anterior, se agregó un programador de tasa de aprendizaje utilizando <code>torch.optim.lr_scheduler.StepLR</code>. Reduce la tasa de aprendizaje multiplicándola por <code>gamma</code> cada <code>step_size</code> épocas. La programación de la tasa de aprendizaje puede tener un gran impacto en la velocidad y estabilidad del entrenamiento.</p>
</section>
<section id="bucle-de-entrenamiento-training-loop" class="level5">
<h5 class="anchored" data-anchor-id="bucle-de-entrenamiento-training-loop">Bucle de Entrenamiento (Training Loop)</h5>
<p>Vamos a configurar un bucle de entrenamiento que se ejecuta iterativamente sobre el conjunto de datos. Un epoch generalmente consta de dos partes: entrenamiento y validación.</p>
<ol type="1">
<li><strong>Bucle de Entrenamiento</strong>: Optimizamos los parámetros utilizando el conjunto de datos de entrenamiento.</li>
<li><strong>Bucle de Validación</strong>: Verificamos cómo cambia el rendimiento del modelo utilizando el conjunto de datos de prueba (validación).</li>
</ol>
<p>Durante el entrenamiento, se puede configurar el modo del modelo en <code>train</code> y <code>eval</code>. Esto se puede considerar como un tipo de interruptor. La distinción entre los modos <code>train()</code> y <code>eval()</code> se volvió importante con la introducción de la normalización por lotes en 2015. En el modo <code>eval()</code>, se desactivan operaciones de entrenamiento específicas como la normalización por lotes o el dropout para mejorar la velocidad de inferencia.</p>
<div id="cell-55" class="cell" data-execution_count="18">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.tensorboard <span class="im">import</span> SummaryWriter</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a><span class="co"># TensorBoard writer setup</span></span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>writer <span class="op">=</span> SummaryWriter(<span class="st">'runs/fashion_mnist_experiment_1'</span>)</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_loop(model, data_loader, loss_fn, optimizer, epoch):  <span class="co"># Added epoch for logging</span></span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a>    model.train()  <span class="co"># Set the model to training mode</span></span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a>    size <span class="op">=</span> <span class="bu">len</span>(data_loader.dataset)  <span class="co"># Total number of data samples</span></span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a>    num_batches <span class="op">=</span> <span class="bu">len</span>(data_loader)</span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a>    total_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch_count, (input_data, label_data) <span class="kw">in</span> <span class="bu">enumerate</span>(data_loader):</span>
<span id="cb48-16"><a href="#cb48-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Move data to the GPU (if available).</span></span>
<span id="cb48-17"><a href="#cb48-17" aria-hidden="true" tabindex="-1"></a>        input_data <span class="op">=</span> input_data.to(device)</span>
<span id="cb48-18"><a href="#cb48-18" aria-hidden="true" tabindex="-1"></a>        label_data <span class="op">=</span> label_data.to(device)</span>
<span id="cb48-19"><a href="#cb48-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-20"><a href="#cb48-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute predictions</span></span>
<span id="cb48-21"><a href="#cb48-21" aria-hidden="true" tabindex="-1"></a>        preds <span class="op">=</span> model(input_data)</span>
<span id="cb48-22"><a href="#cb48-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-23"><a href="#cb48-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute loss</span></span>
<span id="cb48-24"><a href="#cb48-24" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss_fn(preds, label_data)</span>
<span id="cb48-25"><a href="#cb48-25" aria-hidden="true" tabindex="-1"></a>        total_loss <span class="op">+=</span> loss.item()</span>
<span id="cb48-26"><a href="#cb48-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-27"><a href="#cb48-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Backpropagation</span></span>
<span id="cb48-28"><a href="#cb48-28" aria-hidden="true" tabindex="-1"></a>        loss.backward()  <span class="co"># Perform backpropagation</span></span>
<span id="cb48-29"><a href="#cb48-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-30"><a href="#cb48-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Update parameters</span></span>
<span id="cb48-31"><a href="#cb48-31" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb48-32"><a href="#cb48-32" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()  <span class="co"># Zero the gradients before next iteration</span></span>
<span id="cb48-33"><a href="#cb48-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-34"><a href="#cb48-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> batch_count <span class="op">%</span> <span class="dv">100</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb48-35"><a href="#cb48-35" aria-hidden="true" tabindex="-1"></a>            loss, current <span class="op">=</span> loss.item(), batch_count <span class="op">*</span> batch_size <span class="op">+</span> <span class="bu">len</span>(input_data)</span>
<span id="cb48-36"><a href="#cb48-36" aria-hidden="true" tabindex="-1"></a>            <span class="co"># print(f"loss: {loss:&gt;7f}  [{current:&gt;5d}/{size:&gt;5d}]")</span></span>
<span id="cb48-37"><a href="#cb48-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-38"><a href="#cb48-38" aria-hidden="true" tabindex="-1"></a>    avg_train_loss <span class="op">=</span> total_loss <span class="op">/</span> num_batches</span>
<span id="cb48-39"><a href="#cb48-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> avg_train_loss</span>
<span id="cb48-40"><a href="#cb48-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-41"><a href="#cb48-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-42"><a href="#cb48-42" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> eval_loop(model, data_loader, loss_fn):</span>
<span id="cb48-43"><a href="#cb48-43" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()  <span class="co"># Set the model to evaluation mode</span></span>
<span id="cb48-44"><a href="#cb48-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-45"><a href="#cb48-45" aria-hidden="true" tabindex="-1"></a>    correct, test_loss <span class="op">=</span> <span class="fl">0.0</span>, <span class="fl">0.0</span></span>
<span id="cb48-46"><a href="#cb48-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-47"><a href="#cb48-47" aria-hidden="true" tabindex="-1"></a>    size <span class="op">=</span> <span class="bu">len</span>(data_loader.dataset)  <span class="co"># Total data size</span></span>
<span id="cb48-48"><a href="#cb48-48" aria-hidden="true" tabindex="-1"></a>    num_batches <span class="op">=</span> <span class="bu">len</span>(data_loader)  <span class="co"># Number of batches</span></span>
<span id="cb48-49"><a href="#cb48-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-50"><a href="#cb48-50" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():  <span class="co"># Disable gradient calculation within this block</span></span>
<span id="cb48-51"><a href="#cb48-51" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> input_data, label_data <span class="kw">in</span> data_loader:  <span class="co"># No need for enumerate as count is not used</span></span>
<span id="cb48-52"><a href="#cb48-52" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Move data to GPU (if available).</span></span>
<span id="cb48-53"><a href="#cb48-53" aria-hidden="true" tabindex="-1"></a>            input_data <span class="op">=</span> input_data.to(device)</span>
<span id="cb48-54"><a href="#cb48-54" aria-hidden="true" tabindex="-1"></a>            label_data <span class="op">=</span> label_data.to(device)</span>
<span id="cb48-55"><a href="#cb48-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-56"><a href="#cb48-56" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Compute predictions</span></span>
<span id="cb48-57"><a href="#cb48-57" aria-hidden="true" tabindex="-1"></a>            preds <span class="op">=</span> model(input_data)</span>
<span id="cb48-58"><a href="#cb48-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-59"><a href="#cb48-59" aria-hidden="true" tabindex="-1"></a>            test_loss <span class="op">+=</span> loss_fn(preds, label_data).item()</span>
<span id="cb48-60"><a href="#cb48-60" aria-hidden="true" tabindex="-1"></a>            correct <span class="op">+=</span> (preds.argmax(<span class="dv">1</span>) <span class="op">==</span> label_data).<span class="bu">type</span>(torch.<span class="bu">float</span>).<span class="bu">sum</span>().item()</span>
<span id="cb48-61"><a href="#cb48-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-62"><a href="#cb48-62" aria-hidden="true" tabindex="-1"></a>    test_loss <span class="op">/=</span> num_batches</span>
<span id="cb48-63"><a href="#cb48-63" aria-hidden="true" tabindex="-1"></a>    correct <span class="op">/=</span> size</span>
<span id="cb48-64"><a href="#cb48-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-65"><a href="#cb48-65" aria-hidden="true" tabindex="-1"></a>    <span class="co"># print(f"\n Test Result \n Accuracy: {(100 * correct):&gt;0.1f}%, Average loss: {test_loss:&gt;8f} \n")</span></span>
<span id="cb48-66"><a href="#cb48-66" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> test_loss, correct</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="proceso-de-entrenamiento-completo" class="level5">
<h5 class="anchored" data-anchor-id="proceso-de-entrenamiento-completo">Proceso de entrenamiento completo</h5>
<p>El proceso de entrenamiento completo repite el entrenamiento y la validación en cada época. Se usa <code>tqdm</code> para mostrar visualmente el progreso, y TensorBoard para registrar los cambios en la tasa de aprendizaje.</p>
<div id="cell-57" class="cell" data-execution_count="19">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Progress bar utility</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm.notebook <span class="im">import</span> tqdm</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">5</span>  <span class="co"># Reduced for demonstration</span></span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> tqdm(<span class="bu">range</span>(epochs)):</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ch">\n</span><span class="ss">-------------------------------"</span>)</span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a>    train_loss <span class="op">=</span> train_loop(model, train_dataloader, loss_fn, optimizer, epoch)</span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a>    test_loss, correct <span class="op">=</span> eval_loop(model, test_dataloader, loss_fn)</span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Log training and validation metrics to TensorBoard</span></span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a>    writer.add_scalar(<span class="st">'Loss/train'</span>, train_loss, epoch)</span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a>    writer.add_scalar(<span class="st">'Loss/test'</span>, test_loss, epoch)</span>
<span id="cb49-13"><a href="#cb49-13" aria-hidden="true" tabindex="-1"></a>    writer.add_scalar(<span class="st">'Accuracy/test'</span>, correct, epoch)</span>
<span id="cb49-14"><a href="#cb49-14" aria-hidden="true" tabindex="-1"></a>    writer.add_scalar(<span class="st">'Learning Rate'</span>, optimizer.param_groups[<span class="dv">0</span>][<span class="st">'lr'</span>], epoch) <span class="co"># Log learning rate</span></span>
<span id="cb49-15"><a href="#cb49-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-16"><a href="#cb49-16" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Epoch: </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">, Train Loss: </span><span class="sc">{</span>train_loss<span class="sc">:.4f}</span><span class="ss">, Test Loss: </span><span class="sc">{</span>test_loss<span class="sc">:.4f}</span><span class="ss">, Test Accuracy: </span><span class="sc">{</span>correct<span class="sc">:.2f}</span><span class="ss">%, LR: </span><span class="sc">{</span>optimizer<span class="sc">.</span>param_groups[<span class="dv">0</span>][<span class="st">"lr"</span>]<span class="sc">:.6f}</span><span class="ss">'</span>)</span>
<span id="cb49-17"><a href="#cb49-17" aria-hidden="true" tabindex="-1"></a>    scheduler.step()  <span class="co"># Update learning rate.  Place *after* logging.</span></span>
<span id="cb49-18"><a href="#cb49-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-19"><a href="#cb49-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Done!"</span>)</span>
<span id="cb49-20"><a href="#cb49-20" aria-hidden="true" tabindex="-1"></a>writer.close() <span class="co"># Close TensorBoard Writer</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"84baac2d3bc14a3b960d258d62b7996a","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1
-------------------------------
Epoch: 0, Train Loss: 1.5232, Test Loss: 0.9543, Test Accuracy: 0.71%, LR: 0.001000
Epoch 2
-------------------------------
Epoch: 1, Train Loss: 0.7920, Test Loss: 0.7059, Test Accuracy: 0.76%, LR: 0.001000
Epoch 3
-------------------------------
Epoch: 2, Train Loss: 0.6442, Test Loss: 0.6208, Test Accuracy: 0.78%, LR: 0.001000
Epoch 4
-------------------------------
Epoch: 3, Train Loss: 0.5790, Test Loss: 0.5757, Test Accuracy: 0.79%, LR: 0.001000
Epoch 5
-------------------------------
Epoch: 4, Train Loss: 0.5383, Test Loss: 0.5440, Test Accuracy: 0.80%, LR: 0.001000
Done!</code></pre>
</div>
</div>
<p>Este ciclo de entrenamiento-validación se ha establecido como una práctica estándar en el entrenamiento de deep learning desde la década de 1990. En particular, la etapa de validación desempeña un papel crucial en el monitoreo del sobreajuste y en la determinación del early stopping.</p>
</section>
</section>
<section id="guardado-y-lectura-de-modelos" class="level3">
<h3 class="anchored" data-anchor-id="guardado-y-lectura-de-modelos">3.1.8 Guardado y lectura de modelos</h3>
<p>El guardado de modelos es una parte muy importante en la práctica del aprendizaje profundo. Se pueden guardar los modelos entrenados para cargarlos nuevamente más tarde y reutilizarlos, o para desplegarlos en diferentes entornos (por ejemplo, servidores, dispositivos móviles). PyTorch proporciona dos métodos principales de guardado.</p>
<section id="guardar-solo-pesos" class="level5">
<h5 class="anchored" data-anchor-id="guardar-solo-pesos">Guardar solo pesos</h5>
<p>Los parámetros aprendidos del modelo (pesos y sesgos) se almacenan en un diccionario Python llamado <code>state_dict</code>. El <code>state_dict</code> es una estructura que asigna cada capa (layer) a los tensores de parámetros correspondientes. Este método tiene la ventaja de que permite cargar pesos incluso si la estructura del modelo cambia, por lo que generalmente se recomienda.</p>
<div id="cell-60" class="cell" data-execution_count="37">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Save model weights</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>torch.save(model.state_dict(), <span class="st">'model_weights.pth'</span>)</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load weights</span></span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>model_saved_weights <span class="op">=</span> SimpleNetwork()  <span class="co"># Create an empty model with the same architecture</span></span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>model_saved_weights.load_state_dict(torch.load(<span class="st">'model_weights.pth'</span>))</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a>model_saved_weights.to(device) <span class="co"># Don't forget to move to the correct device!</span></span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>model_saved_weights.<span class="bu">eval</span>() <span class="co"># Set to evaluation mode</span></span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Check performance (assuming eval_loop is defined)</span></span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a>eval_loop(model_saved_weights, test_dataloader, loss_fn)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>/tmp/ipykernel_112013/3522135054.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_saved_weights.load_state_dict(torch.load('model_weights.pth'))</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>(0.5459668265935331, 0.8036)</code></pre>
</div>
</div>
</section>
<section id="guardar-el-modelo-completo" class="level5">
<h5 class="anchored" data-anchor-id="guardar-el-modelo-completo">Guardar el modelo completo</h5>
<p>Después de 2018, a medida que las arquitecturas de modelos se han vuelto más complejas, también se ha adoptado la práctica de guardar tanto la estructura del modelo como sus pesos.</p>
<div id="cell-62" class="cell" data-execution_count="38">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>torch.save(model, <span class="st">'model_trained.pth'</span>)</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the entire model</span></span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>model_saved <span class="op">=</span> torch.load(<span class="st">'model_trained.pth'</span>)</span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>model_saved.to(device)  <span class="co"># Move the loaded model to the correct device.</span></span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a>model_saved.<span class="bu">eval</span>() <span class="co">#  Set the loaded model to evaluation mode</span></span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Check performance</span></span>
<span id="cb54-9"><a href="#cb54-9" aria-hidden="true" tabindex="-1"></a>eval_loop(model_saved, test_dataloader, loss_fn)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>/tmp/ipykernel_112013/3185686172.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_saved = torch.load('model_trained.pth')</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="38">
<pre><code>(0.5459668265935331, 0.8036)</code></pre>
</div>
</div>
<p>El método de guardar el modelo completo es conveniente, pero si la definición de la clase del modelo cambia, pueden surgir problemas de compatibilidad. En particular, en entornos de producción, la arquitectura del modelo no suele cambiar con frecuencia, por lo que guardar solo los pesos puede ser más estable. Además, el método de guardar el modelo completo utiliza el módulo <code>pickle</code> de Python, y <code>pickle</code> tiene una vulnerabilidad que permite ejecutar código arbitrario, lo cual puede ser un riesgo de seguridad.</p>
</section>
<section id="safetensors-una-alternativa-más-segura" class="level5">
<h5 class="anchored" data-anchor-id="safetensors-una-alternativa-más-segura">Safetensors: Una alternativa más segura</h5>
<p>Recientemente, se han desarrollado nuevos formatos de almacenamiento como <code>safetensors</code>, que mejoran la seguridad y la velocidad de carga en comparación con <code>pickle</code>. <code>safetensors</code> es un formato diseñado para almacenar datos de tensores de manera segura y eficiente.</p>
<ul>
<li><strong>Seguridad:</strong> <code>safetensors</code> no permite ejecutar código arbitrario, por lo que es mucho más seguro que <code>pickle</code>.</li>
<li><strong>Zero-copy:</strong> los datos se mapean directamente en memoria sin necesidad de copiarlos, lo que hace que la carga sea rápida.</li>
<li><strong>Carga perezosa:</strong> solo se cargan las partes necesarias, lo que reduce el uso de memoria.</li>
<li><strong>Soporte para múltiples frameworks</strong>: PyTorch, TensorFlow, JAX, etc.</li>
</ul>
<div id="cell-64" class="cell" data-execution_count="39">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Install safetensors: pip install safetensors</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> safetensors.torch <span class="im">import</span> save_file, load_file</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Save using safetensors</span></span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>state_dict <span class="op">=</span> model.state_dict()</span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a>save_file(state_dict, <span class="st">"model_weights.safetensors"</span>)</span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Load using safetensors</span></span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a>loaded_state_dict <span class="op">=</span> load_file(<span class="st">"model_weights.safetensors"</span>, device<span class="op">=</span>device) <span class="co"># Load directly to the device.</span></span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a>model_new <span class="op">=</span> SimpleNetwork().to(device) <span class="co"># Create an instance of your model class</span></span>
<span id="cb57-12"><a href="#cb57-12" aria-hidden="true" tabindex="-1"></a>model_new.load_state_dict(loaded_state_dict)</span>
<span id="cb57-13"><a href="#cb57-13" aria-hidden="true" tabindex="-1"></a>model_new.<span class="bu">eval</span>()</span>
<span id="cb57-14"><a href="#cb57-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-15"><a href="#cb57-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Check performance</span></span>
<span id="cb57-16"><a href="#cb57-16" aria-hidden="true" tabindex="-1"></a>eval_loop(model_new, test_dataloader, loss_fn)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="39">
<pre><code>(0.5459668265935331, 0.8036)</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="tensorboard" class="level2">
<h2 class="anchored" data-anchor-id="tensorboard">3.2 TensorBoard</h2>
<p>TensorBoard es una herramienta que registra, rastrea y visualiza de manera eficiente los diversos registros generados durante el entrenamiento de aprendizaje profundo. Es un tipo de herramienta de registro y visualización de datos de registro comúnmente conocida como tablero de instrumentos. Aunque se desarrolló originalmente para TensorFlow, ahora está integrado con PyTorch. Existen otras herramientas de visualización en formato de panel similar a TensorBoard, como las siguientes:</p>
<ul>
<li>Weights &amp; Biases (WandB): una plataforma integral de MLOps basada en la nube que ofrece un amplio rango de funciones, incluyendo seguimiento de experimentos, gestión de versiones de conjuntos de datos y administración de modelos. Se destaca por su funcionalidad de colaboración en equipo y es ampliamente utilizada en entornos empresariales.</li>
<li>Vertex AI: una herramienta de ML completamente administrada de Google Cloud que proporciona integración nativa con BigQuery, Dataproc y Spark. Permite construir, implementar y escalar modelos rápidamente, lo que la hace adecuada para flujos de trabajo de ML a gran escala.</li>
<li>MLflow: una herramienta de código abierto que ofrece seguimiento de experimentos, empaquetado de modelos y un registro centralizado. Simplifica el seguimiento e implementación de modelos de ML y es ampliamente utilizada en los campos de ciencia de datos y aprendizaje automático.</li>
</ul>
<p>Además de estas tres herramientas, existen muchas otras. En este contexto, nos enfocaremos principalmente en TensorBoard.</p>
<section id="uso-básico-de-tensorboard" class="level3">
<h3 class="anchored" data-anchor-id="uso-básico-de-tensorboard">3.2.1 Uso básico de TensorBoard</h3>
<p>TensorBoard apareció junto con TensorFlow en 2015. En ese momento, la complejidad de los modelos de aprendizaje profundo aumentó significativamente, lo que hizo evidente la necesidad de monitorear eficazmente el proceso de entrenamiento.</p>
<p>Las funciones principales de TensorBoard son las siguientes: 1. Rastreo de métricas escalares: registro de valores como la pérdida y la precisión. 2. Visualización de estructuras de modelo: representación gráfica del grafo de cálculo. 3. Rastreo de distribuciones: observación de cambios en las distribuciones de pesos y gradientes. 4. Proyección de incrustaciones: visualización 2D/3D de vectores de alta dimensión. 5. Optimización de hiperparámetros: comparación de resultados experimentales con diferentes configuraciones.</p>
<p>TensorBoard es una poderosa herramienta para visualizar y analizar el proceso de entrenamiento de aprendizaje profundo. El uso básico de TensorBoard consta principalmente de tres etapas: instalación, configuración del directorio de logs y configuración de callbacks.</p>
<section id="métodos-de-instalación" class="level5">
<h5 class="anchored" data-anchor-id="métodos-de-instalación">Métodos de instalación</h5>
<p>TensorBoard se puede instalar mediante pip o conda.</p>
<div id="cell-66" class="cell" data-vscode="{&quot;languageId&quot;:&quot;shellscript&quot;}">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install tensorboard</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 또는</span></span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>conda install <span class="op">-</span>c conda<span class="op">-</span>forge tensorboard</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="configuración-del-directorio-de-registro" class="level5">
<h5 class="anchored" data-anchor-id="configuración-del-directorio-de-registro">Configuración del directorio de registro</h5>
<p>TensorBoard lee los archivos de eventos almacenados en el directorio de registro para visualizarlos. En Jupyter Notebook o Colab, se configura de la siguiente manera.</p>
<div id="cell-68" class="cell" data-execution_count="41">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.tensorboard <span class="im">import</span> SummaryWriter</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 로그 디렉토리 설정</span></span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>log_dir <span class="op">=</span> <span class="st">'logs/experiment_1'</span></span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a>writer <span class="op">=</span> SummaryWriter(log_dir)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="ejecución-de-tensorboard" class="level5">
<h5 class="anchored" data-anchor-id="ejecución-de-tensorboard">Ejecución de TensorBoard</h5>
<p>TensorBoard se puede ejecutar de las siguientes dos maneras.</p>
<ol type="1">
<li>Desde la línea de comandos</li>
</ol>
<div id="cell-70" class="cell" data-vscode="{&quot;languageId&quot;:&quot;shellscript&quot;}">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>tensorboard <span class="op">--</span>logdir<span class="op">=</span>logs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<ol start="2" type="1">
<li>ejecutar en Jupyter Notebook</li>
</ol>
<div id="cell-72" class="cell" data-vscode="{&quot;languageId&quot;:&quot;shellscript&quot;}">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>load_ext tensorboard</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>tensorboard <span class="op">--</span>logdir<span class="op">=</span>logs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Ejecución posterior, puede acceder al panel de TensorBoard en su navegador web ingresando http://localhost:6006.</p>
</section>
<section id="ejecución-en-un-servidor-remoto" class="level5">
<h5 class="anchored" data-anchor-id="ejecución-en-un-servidor-remoto">Ejecución en un servidor remoto</h5>
<p>Cuando se ejecuta TensorBoard en un servidor remoto, use el túnel SSH.</p>
<div id="cell-74" class="cell" data-vscode="{&quot;languageId&quot;:&quot;shellscript&quot;}">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>ssh <span class="op">-</span>L <span class="dv">6006</span>:<span class="fl">127.0.0.1</span>:<span class="dv">6006</span> username<span class="op">@</span>server_ip</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><strong>Parámetros principales (SummaryWriter)</strong></p>
<p><code>SummaryWriter</code> es la clase principal que genera datos para registrar en TensorBoard. Los parámetros principales son los siguientes:</p>
<ul>
<li><code>log_dir</code>: ruta del directorio donde se guardarán los archivos de registro.</li>
<li><code>comment</code>: cadena a agregar al final de <code>log_dir</code>.</li>
<li><code>flush_secs</code>: frecuencia con la que se escriben los registros en el disco (en segundos).</li>
<li><code>max_queue</code>: número de eventos/pasos pendientes que se pueden almacenar.</li>
</ul>
<p><strong>Métodos principales (SummaryWriter)</strong></p>
<ul>
<li><code>add_scalar(tag, scalar_value, global_step=None)</code>: registra un valor escalar (por ejemplo, pérdida, precisión).</li>
<li><code>add_histogram(tag, values, global_step=None, bins='tensorflow')</code>: registra un histograma (distribución de valores).</li>
<li><code>add_image(tag, img_tensor, global_step=None, dataformats='CHW')</code>: registra una imagen.</li>
<li><code>add_figure(tag, figure, global_step=None, close=True)</code>: registra una figura de Matplotlib.</li>
<li><code>add_video(tag, vid_tensor, global_step=None, fps=4, dataformats='NCHW')</code>: registra un video.</li>
<li><code>add_audio(tag, snd_tensor, global_step=None, sample_rate=44100)</code>: registra audio.</li>
<li><code>add_text(tag, text_string, global_step=None)</code>: registra texto.</li>
<li><code>add_graph(model, input_to_model=None, verbose=False)</code>: registra un gráfico de modelo.</li>
<li><code>add_embedding(mat, metadata=None, label_img=None, global_step=None, tag='default', metadata_header=None)</code>: registra un proyector de incrustaciones (embeddings).</li>
<li><code>add_hparams(hparam_dict, metric_dict, hparam_domain_discrete=None, run_name=None)</code>: registra hiperparámetros y sus métricas correspondientes.</li>
<li><code>flush()</code>: registra todos los eventos pendientes en el disco.</li>
<li><code>close()</code>: finaliza la grabación de registros y libera recursos.</li>
</ul>
<p><strong>Parámetros principales del callback (TensorFlow/Keras)</strong></p>
<p>Cuando se usa TensorBoard con TensorFlow/Keras, se utiliza el callback <code>tf.keras.callbacks.TensorBoard</code>. Los parámetros principales son los siguientes:</p>
<ul>
<li><code>log_dir</code>: ubicación donde se guardan los registros.</li>
<li><code>histogram_freq</code>: frecuencia de cálculo del histograma (0 significa que no se calculará). Se usa para visualizar la distribución de pesos, sesgos y valores de activación.</li>
<li><code>write_graph</code>: indica si se debe visualizar el gráfico del modelo.</li>
<li><code>write_images</code>: indica si se deben visualizar los pesos del modelo como imágenes.</li>
<li><code>update_freq</code>: frecuencia con la que se registran las pérdidas y métricas (‘batch’, ‘epoch’ o un número entero).</li>
<li><code>profile_batch</code>: rango de lotes a perfilar (por ejemplo, <code>profile_batch='5, 8'</code>). El perfilado es útil para identificar cuellos de botella en el rendimiento.</li>
<li><code>embeddings_freq</code>: frecuencia con la que se visualizan las capas de incrustaciones.</li>
<li><code>embeddings_metadata</code>: ruta del archivo de metadatos de incrustaciones.</li>
</ul>
</section>
</section>
<section id="funciones-de-visualización-principales-de-tensorboard" class="level3">
<h3 class="anchored" data-anchor-id="funciones-de-visualización-principales-de-tensorboard">3.2.2 Funciones de visualización principales de TensorBoard</h3>
<p>TensorBoard puede visualizar diversas métricas que surgen durante el proceso de entrenamiento del modelo. Los paneles de visualización principales incluyen escalares, histogramas, distribuciones, gráficos y embeddings.</p>
<section id="visualización-de-métricas-escalares" class="level5">
<h5 class="anchored" data-anchor-id="visualización-de-métricas-escalares">Visualización de métricas escalares</h5>
<p>El panel de escalares visualiza cambios en métricas numéricas como valores de pérdida y precisión. Se pueden seguir diversas estadísticas del proceso de entrenamiento del modelo, como la tasa de aprendizaje, la norma del gradiente, el promedio/varianza de los pesos por capa. También se puede monitorear simultáneamente métricas de evaluación de calidad importantes en modelos generativos recientes, como la puntuación FID (Fréchet Inception Distance) o QICE (Quantile Interval Coverage Error). A través de estas métricas, se puede monitorear en tiempo real el progreso del entrenamiento del modelo y detectar problemas como el sobreajuste o la inestabilidad del entrenamiento en una etapa temprana. Se pueden registrar valores escalares de la siguiente manera.</p>
<div id="cell-77" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>writer.add_scalar(<span class="st">'Loss/train'</span>, train_loss, step)</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>writer.add_scalar(<span class="st">'Accuracy/train'</span>, train_acc, step)</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a>writer.add_scalar(<span class="st">'Learning/learning_rate'</span>, current_lr, step)</span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a>writer.add_scalar(<span class="st">'Gradients/norm'</span>, grad_norm, step)</span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a>writer.add_scalar(<span class="st">'Quality/fid_score'</span>, fid_score, step)</span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a>writer.add_scalar(<span class="st">'Metrics/qice'</span>, qice_value, step)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="histogramas-y-visualización-de-distribuciones" class="level5">
<h5 class="anchored" data-anchor-id="histogramas-y-visualización-de-distribuciones">Histogramas y visualización de distribuciones</h5>
<p>Puedes observar los cambios en la distribución de pesos y sesgos. Los histogramas muestran visualmente las distribuciones de pesos, sesgos, gradientes y valores de activación de cada capa, lo que ayuda a comprender el estado interno del modelo. En particular, pueden ayudarte a detectar temprano si los pesos se saturan en ciertos valores o si los gradientes desaparecen/explotan durante el proceso de aprendizaje, lo cual es muy útil para la depuración del modelo. Puedes registrar histogramas de la siguiente manera.</p>
<div id="cell-79" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, param <span class="kw">in</span> model.named_parameters():</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>    writer.add_histogram(<span class="ss">f'Parameters/</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">'</span>, param.data, global_step)</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> param.grad <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a>        writer.add_histogram(<span class="ss">f'Gradients/</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">'</span>, param.grad, global_step)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="visualización-de-la-estructura-del-modelo" class="level5">
<h5 class="anchored" data-anchor-id="visualización-de-la-estructura-del-modelo">Visualización de la estructura del modelo</h5>
<p>Puede visualizar la estructura del modelo. En particular, puede comprender intuitivamente la estructura de capas y las conexiones de redes neuronales complejas. TensorBoard representa el flujo de datos, la forma de entrada y salida de cada capa, y el orden de operaciones en forma de gráfico, y permite examinar información detallada expandiendo cada nodo. Recientemente, ha sido especialmente útil para visualizar mecanismos de atención complejos como los de los modelos Transformer o Diffusion, capas de atención cruzada, estructuras de ramificación condicional, etc. Esto es muy útil para depurar y optimizar el modelo, y particularmente ayuda a comprender arquitecturas complejas con conexiones residuales o estructuras paralelas. Puede registrar el gráfico del modelo de la siguiente manera.</p>
<div id="cell-81" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>writer.add_graph(model, input_to_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="visualización-de-incrustaciones" class="level5">
<h5 class="anchored" data-anchor-id="visualización-de-incrustaciones">Visualización de incrustaciones</h5>
<p>El Projector de TensorBoard permite proyectar incrustaciones de alta dimensión en espacios 2D o 3D para su visualización. Esto es útil para analizar las relaciones entre incrustaciones de palabras o vectores de características de imágenes. Se utiliza técnicas de reducción de dimensionalidad, como PCA o UMAP, para visualizar datos de alta dimensión complejos mientras se preservan la estructura de clústeres y las distancias relativas. En particular, UMAP permite una visualización rápida que conserva bien tanto la estructura local como la global. A través de esto, se puede verificar cómo los puntos de datos con características similares se agrupan, si se realiza una buena separación entre clases, y cómo cambia el espacio de características durante el proceso de aprendizaje. Se pueden registrar las incrustaciones de la siguiente manera.</p>
<div id="cell-83" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>writer.add_embedding(</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>    features,</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>    metadata<span class="op">=</span>labels,</span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a>    label_img<span class="op">=</span>images,</span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a>    global_step<span class="op">=</span>step</span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="visualización-de-hiperparámetros" class="level5">
<h5 class="anchored" data-anchor-id="visualización-de-hiperparámetros">Visualización de hiperparámetros</h5>
<p>Puede visualizar los resultados del ajuste de hiperparámetros. Además de la tasa de aprendizaje, el tamaño del lote y la tasa de dropout, también puede analizar el impacto de parámetros estructurales como el número de cabezas de atención en modelos Transformer, la longitud del prompt y la dimensión de los embeddings de tokens. Es posible visualizar junto con esto los parámetros de inferencia importantes en LLM modernos o modelos de difusión, como las programaciones de ruido, el número de pasos de muestreo y los pesos CFG (Classifier-Free Guidance). Se pueden representar el rendimiento del modelo según diferentes combinaciones de hiperparámetros mediante gráficos de coordenadas paralelas o diagramas de dispersión para ayudar a encontrar la configuración óptima. En particular, facilita comparar varios resultados experimentales a simple vista y analizar cómo las interacciones entre los hiperparámetros afectan el rendimiento del modelo. Puede registrar hiperparámetros y métricas relacionadas de la siguiente manera.</p>
<div id="cell-85" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>writer.add_hparams(</span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>        <span class="st">'lr'</span>: learning_rate, </span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">'batch_size'</span>: batch_size, </span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">'num_heads'</span>: n_heads,</span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">'cfg_scale'</span>: guidance_scale,</span>
<span id="cb68-7"><a href="#cb68-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">'sampling_steps'</span>: num_steps,</span>
<span id="cb68-8"><a href="#cb68-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">'prompt_length'</span>: max_length</span>
<span id="cb68-9"><a href="#cb68-9" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb68-10"><a href="#cb68-10" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb68-11"><a href="#cb68-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">'accuracy'</span>: accuracy, </span>
<span id="cb68-12"><a href="#cb68-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">'loss'</span>: final_loss,</span>
<span id="cb68-13"><a href="#cb68-13" aria-hidden="true" tabindex="-1"></a>        <span class="st">'fid_score'</span>: fid_score</span>
<span id="cb68-14"><a href="#cb68-14" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb68-15"><a href="#cb68-15" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="visualización-de-imágenes" class="level5">
<h5 class="anchored" data-anchor-id="visualización-de-imágenes">Visualización de imágenes</h5>
<p>Se pueden visualizar las imágenes generadas durante el proceso de aprendizaje o los mapas de características intermedios. Al visualizar los filtros y mapas de activación de las capas convolucionales, se puede comprender intuitivamente qué características está aprendiendo el modelo y en qué partes de la imagen de entrada está prestando atención en cada capa. En particular, es muy útil para rastrear visualmente los cambios en la calidad de las imágenes generadas por modelos generativos modernos como Stable Diffusion o DALL-E. Con el surgimiento de modelos híbridos, se ha vuelto posible generar imágenes más sofisticadas y realistas. Se pueden registrar las imágenes de la siguiente manera.</p>
<div id="cell-87" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 입력 이미지나 생성된 이미지 시각화</span></span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>writer.add_images(<span class="st">'Images/generated'</span>, generated_images, global_step)</span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 디퓨전 모델의 중간 생성 과정 시각화</span></span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a>writer.add_images(<span class="st">'Diffusion/steps'</span>, diffusion_steps, global_step)</span>
<span id="cb69-6"><a href="#cb69-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-7"><a href="#cb69-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 어텐션 맵 시각화</span></span>
<span id="cb69-8"><a href="#cb69-8" aria-hidden="true" tabindex="-1"></a>writer.add_image(<span class="st">'Attention/maps'</span>, attention_visualization, global_step)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>A través de las funciones de visualización de TensorBoard, se puede comprender intuitivamente el proceso de aprendizaje del modelo y detectar rápidamente los problemas. En particular, al poder monitorear en tiempo real el progreso del aprendizaje, es útil para la detención temprana del proceso de aprendizaje o para ajustar los hiperparámetros. La visualización de incrustaciones es especialmente útil para comprender las relaciones de datos de alta dimensión y ayuda a analizar la estructura del espacio de características aprendido por el modelo.</p>
</section>
</section>
<section id="ejemplo-de-tensorboard" class="level3">
<h3 class="anchored" data-anchor-id="ejemplo-de-tensorboard">3.2.3 Ejemplo de TensorBoard</h3>
<p>En esta sección, examinaremos un ejemplo concreto de cómo aplicar las diversas funcionalidades de TensorBoard en el entrenamiento de un modelo de aprendizaje profundo real. Utilizaremos el conjunto de datos MNIST de dígitos manuscritos para entrenar un modelo CNN (Convolutional Neural Network) simple y explicaremos paso a paso cómo visualizar los indicadores y datos clave generados durante el proceso de entrenamiento mediante TensorBoard.</p>
<p><strong>Elementos de visualización clave:</strong></p>
<table class="caption-top table">
<colgroup>
<col style="width: 15%">
<col style="width: 76%">
<col style="width: 8%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Tipo de visualización</th>
<th style="text-align: left;">Contenido de la visualización</th>
<th style="text-align: left;">Pestaña de TensorBoard</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Indicadores escalares</strong></td>
<td style="text-align: left;">Pérdida de entrenamiento/prueba, precisión de entrenamiento/prueba, tasa de aprendizaje, norma del gradiente</td>
<td style="text-align: left;">SCALARS</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Histogramas/distribuciones</strong></td>
<td style="text-align: left;">Distribución de pesos en todas las capas, distribución de gradientes en todas las capas</td>
<td style="text-align: left;">DISTRIBUTIONS, HISTOGRAMS</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Estructura del modelo</strong></td>
<td style="text-align: left;">Grafo computacional del modelo CNN MNIST</td>
<td style="text-align: left;">GRAPHS</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Mapas de características</strong></td>
<td style="text-align: left;">Mapas de características de la capa Conv1, mapas de características de la capa Conv2, cuadrícula de imágenes de entrada, visualización de filtros de Conv1</td>
<td style="text-align: left;">IMAGES</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Embeddings</strong></td>
<td style="text-align: left;">Vectores de características de 32 dimensiones de la capa FC1, visualización en 2D utilizando t-SNE, etiquetas de imágenes MNIST</td>
<td style="text-align: left;">PROJECTOR</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Hiperparámetros</strong></td>
<td style="text-align: left;">Tamaño del lote, tasa de aprendizaje, ratio de dropout, tipo de optimizador, Weight decay, Momentum, pasos/gamma del programador</td>
<td style="text-align: left;">HPARAMS</td>
</tr>
</tbody>
</table>
<p><strong>Frecuencia de visualización:</strong></p>
<ul>
<li>Escalares/histogramas: cada 50 lotes(batch)</li>
<li>Mapas de características/imágenes: cada 50 lotes</li>
<li>Embeddings: al final de cada época(epoch)</li>
<li>Hiperparámetros: al inicio y final del entrenamiento</li>
</ul>
<p><strong>Ejemplo de código</strong></p>
<p>En este ejemplo se utiliza el paquete <code>dld</code>. Se importan los módulos necesarios y se inicia el entrenamiento. La función <code>train()</code> entrena un modelo CNN en el conjunto de datos MNIST utilizando hiperparámetros predeterminados, y registra el proceso de entrenamiento en TensorBoard. Para experimentar con diferentes hiperparámetros, puede pasar el argumento <code>hparams_dict</code> a la función <code>train()</code>.</p>
<div id="cell-91" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="co"># In a notebook cell:</span></span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dldna.chapter_03.train <span class="im">import</span> train</span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Run with default hyperparameters</span></span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a>train()</span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Run with custom hyperparameters</span></span>
<span id="cb70-8"><a href="#cb70-8" aria-hidden="true" tabindex="-1"></a>my_hparams <span class="op">=</span> {</span>
<span id="cb70-9"><a href="#cb70-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'batch_size'</span>: <span class="dv">128</span>,</span>
<span id="cb70-10"><a href="#cb70-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'learning_rate'</span>: <span class="fl">0.01</span>,</span>
<span id="cb70-11"><a href="#cb70-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">'epochs'</span>: <span class="dv">8</span>,</span>
<span id="cb70-12"><a href="#cb70-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb70-13"><a href="#cb70-13" aria-hidden="true" tabindex="-1"></a>train(hparams_dict<span class="op">=</span>my_hparams, log_dir<span class="op">=</span><span class="st">'runs/my_custom_run'</span>)</span>
<span id="cb70-14"><a href="#cb70-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-15"><a href="#cb70-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Start TensorBoard (in a separate cell, or from the command line)</span></span>
<span id="cb70-16"><a href="#cb70-16" aria-hidden="true" tabindex="-1"></a><span class="co"># %load_ext tensorboard</span></span>
<span id="cb70-17"><a href="#cb70-17" aria-hidden="true" tabindex="-1"></a><span class="co"># %tensorboard --logdir runs</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><strong>Ejecución de TensorBoard:</strong></p>
<p>Una vez que el entrenamiento esté completo, use el siguiente comando en la shell para ejecutar TensorBoard.</p>
<div id="cell-93" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>tensorboard <span class="op">--</span>logdir runs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Puede ver el panel de TensorBoard conectándose a <code>http://localhost:6006</code> en su navegador web.</p>
<p>Podrá confirmar que se han creado varias tarjetas para cada elemento. <img src="../../../assets/images/03_01.png" class="img-fluid" alt="TensorBoard"></p>
<p>En cada elemento, puede verificar los cambios individuales de valores e imágenes. <img src="../../../assets/images/03_02.png" class="img-fluid" alt="TensorBoard"></p>
<p><strong>Uso del panel de TensorBoard</strong></p>
<ul>
<li><strong>Pestaña SCALARS:</strong> rastrea los cambios en el tiempo de la pérdida de entrenamiento/prueba, precisión, tasa de aprendizaje, etc. Esto le permite determinar si el modelo está aprendiendo bien y si se produce un ajuste excesivo (overfitting).</li>
<li><strong>Pestaña GRAPHS:</strong> visualiza el grafo de cálculo del modelo para mostrar la flujo de datos y los procesos de cálculo a simple vista. Ayuda a comprender la estructura de modelos complejos.</li>
<li><strong>Pestañas DISTRIBUTIONS/HISTOGRAMS:</strong> visualiza la distribución de pesos y gradientes. Esto le permite diagnosticar si la inicialización de los pesos es adecuada y si se producen problemas de desvanecimiento o explosión de gradientes (vanishing or exploding gradients).</li>
<li><strong>Pestaña IMAGES:</strong> visualiza las imágenes de entrada, mapas de características y filtros en formato de imagen. Esto le permite verificar de manera intuitiva qué partes de la imagen está observando el modelo y si la extracción de características es efectiva.</li>
<li><strong>Pestaña PROJECTOR:</strong> proyecta incrustaciones de alta dimensión a 2D/3D para su visualización. Ayuda a identificar agrupamientos de datos y valores atípicos (outliers).</li>
<li><strong>Pestaña HPARAMS:</strong> compara los resultados de experimentos realizados con diferentes combinaciones de hiperparámetros, ayudándole a encontrar la configuración óptima.</li>
</ul>
<p>En este ejemplo, hemos explorado cómo usar TensorBoard para visualizar el proceso de entrenamiento de un modelo de deep learning. TensorBoard es más que una simple herramienta de visualización; es esencial para comprender el funcionamiento del modelo, diagnosticar problemas y mejorar su rendimiento.</p>
</section>
</section>
<section id="hugging-face-transformers" class="level2">
<h2 class="anchored" data-anchor-id="hugging-face-transformers">3.3 Hugging Face Transformers</h2>
<p>Hugging Face comenzó en 2016 como una aplicación de chatbot para adolescentes fundada por empresarios franceses. Inicialmente, su objetivo era proporcionar un amigo AI que ofreciera apoyo emocional y entretenimiento, pero experimentó un gran punto de inflexión al hacer público el modelo NLP de su chatbot de código abierto. Esto coincidió con un período en el que modelos de lenguaje de alto rendimiento como BERT y GPT estaban emergiendo, aunque era difícil utilizarlos en la práctica, lo que generó una gran resonancia. El lanzamiento de la biblioteca Transformers en 2019 revolucionó el campo del procesamiento de lenguaje natural. Si PyTorch proporciona las operaciones básicas y el marco de aprendizaje profundo, Hugging Face se centra en la implementación y uso práctico de los modelos de lenguaje. En particular, facilitaron la compartición y reutilización de modelos preentrenados, lo que permitió a cualquiera utilizar modelos de lenguaje a gran escala, que hasta entonces eran el dominio exclusivo de un puñado de grandes empresas.</p>
<p>Hugging Face ha construido un ecosistema abierto digno del título “GitHub del AI”. Actualmente se comparten más de un millón de modelos y cientos de miles de conjuntos de datos, convirtiéndose en una plataforma que va más allá de un simple repositorio de código para fomentar el desarrollo ético y responsable de la IA. Especialmente, han implementado un sistema de tarjetas de modelo que detalla las limitaciones y sesgos de cada modelo, y un sistema de retroalimentación basado en la comunidad para verificar continuamente la calidad y la ética del modelo. Estos esfuerzos no solo han democratizado el desarrollo de IA, sino que también han establecido un nuevo paradigma de desarrollo tecnológico responsable. El enfoque de Hugging Face equilibra la innovación técnica con consideraciones éticas, convirtiéndose en un ejemplo a seguir en el desarrollo de AI moderno.</p>
<section id="introducción-a-la-biblioteca-transformers" class="level3">
<h3 class="anchored" data-anchor-id="introducción-a-la-biblioteca-transformers">3.3.1 Introducción a la biblioteca Transformers</h3>
<p>Transformers proporciona una interfaz integrada para descargar y usar modelos preentrenados fácilmente. Funciona sobre marcos como PyTorch o TensorFlow, lo que garantiza su compatibilidad con los ecosistemas de aprendizaje profundo existentes. En particular, también admite nuevos marcos como JAX, ampliando las opciones disponibles para los investigadores. Los componentes principales de Transformers son dos.</p>
<section id="modelo-hub-y-pipelines" class="level5">
<h5 class="anchored" data-anchor-id="modelo-hub-y-pipelines">Modelo Hub y Pipelines</h5>
<p>El Modelo Hub actúa como un repositorio central para modelos preentrenados. Se publican modelos especializados en diversas tareas de procesamiento de lenguaje natural, como generación de texto, clasificación, traducción, resumen y respuestas a preguntas. Cada modelo se proporciona con detallada metadatos, incluyendo métricas de rendimiento, información de licencia, origen de los datos de entrenamiento, etc. En particular, el sistema de tarjetas de modelo (Model Card) también especifica las limitaciones y sesgos del modelo para fomentar el desarrollo responsable de IA.</p>
<p>Las pipelines abstraen procesos complejos de preprocesamiento y postprocesamiento, proporcionándolos a través de una interfaz simple. Esto es especialmente útil en entornos de producción, reduciendo significativamente los costos de integración del modelo. Internamente, las pipelines configuran automáticamente el tokenizador y el modelo, y también realizan optimizaciones como procesamiento por lotes o aceleración GPU de manera automática.</p>
<div id="cell-96" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a>classifier <span class="op">=</span> pipeline(<span class="st">"sentiment-analysis"</span>)</span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> classifier(<span class="st">"I love this book!"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).
Using a pipeline without specifying a model name and revision in production is not recommended.</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c6703892f09b4ade869f16b776740536","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b5210ba6dfe24216ab409ef41d197c2c","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"cc25443102364b8e96035a7c0218e23b","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4e19048c8971437b82f666267ec92f21","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Device set to use cuda:0</code></pre>
</div>
</div>
</section>
<section id="tokenizador-y-clases-de-modelos" class="level5">
<h5 class="anchored" data-anchor-id="tokenizador-y-clases-de-modelos">Tokenizador y clases de modelos</h5>
<p>El tokenizador convierte el texto de entrada en una secuencia numérica que el modelo puede procesar. Cada modelo tiene un tokenizador dedicado, lo cual refleja las características de los datos de entrenamiento. El tokenizador no solo se limita a la división de palabras, sino que también maneja consistentemente preprocesamientos complejos como la tokenización subpalabra, la adición de tokens especiales, el relleno y la truncatura. En particular, integra varios algoritmos de tokenización, como WordPiece, BPE, SentencePiece, lo que permite seleccionar la mejor forma de tokenización adaptada a las características de cada idioma y dominio.</p>
<p>Las clases de modelos implementan las redes neuronales que realizan los cálculos reales. Se admite una variedad de arquitecturas como BERT, GPT, T5, y se puede seleccionar automáticamente la arquitectura del modelo a través de las clases de la serie AutoModel. Cada modelo viene con pesos pre-entrenados y puede ser ajustado para tareas específicas según sea necesario. Además, técnicas de optimización como la paralelización de modelos, cuantización y poda también pueden aplicarse inmediatamente.</p>
<div id="cell-98" class="cell" data-execution_count="43">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoTokenizer, AutoModel</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(<span class="st">"bert-base-uncased"</span>)</span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModel.from_pretrained(<span class="st">"bert-base-uncased"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
</section>
<section id="casos-de-uso-principales" class="level3">
<h3 class="anchored" data-anchor-id="casos-de-uso-principales">3.3.2 Casos de uso principales</h3>
<p>La biblioteca Transformers se utiliza en una variedad de tareas de procesamiento de lenguaje natural. Desde el desarrollo de modelos de la serie GPT a partir de 2020, las capacidades de generación de texto han mejorado enormemente, y para 2024, con la aparición de modelos de código abierto de alto rendimiento como Llama 3, el alcance de uso se ha ampliado aún más. En particular, el modelo de 405B parámetros de Llama 3 muestra un rendimiento comparable al de GPT-4 y ha logrado avances significativos en el procesamiento multilingüe, codificación e inferencia. Este progreso ha permitido diversas aplicaciones en entornos empresariales reales, incluyendo soporte al cliente, generación de contenido, análisis de datos y procesamiento automatizado de tareas. En particular, la mejora significativa en la generación y depuración de código también ha contribuido a aumentar la productividad de los desarrolladores.</p>
<p><strong>Uso del Hugging Face Hub:</strong></p>
<p>El Hugging Face Hub (<a href="https://huggingface.co/models">https://huggingface.co/models</a>) es una plataforma para buscar, filtrar y descargar numerosos modelos y conjuntos de datos.</p>
<ul>
<li><strong>Búsqueda de modelos:</strong> Puede buscar por nombre de modelo (por ejemplo, “bert”, “gpt2”, “t5”) o tarea (por ejemplo, “text-classification”, “question-answering”) en la barra de búsqueda de la esquina superior izquierda.</li>
<li><strong>Filtrado:</strong> Puede filtrar por Tarea, Biblioteca, Idioma, Conjunto de datos y otros criterios en el panel lateral izquierdo.</li>
<li><strong>Páginas de modelos:</strong> Cada página de modelo proporciona información útil como una descripción del modelo, ejemplos de uso, métricas de rendimiento y tarjetas de modelo.</li>
</ul>
<p><strong>Generación y clasificación de texto</strong></p>
<p>La generación de texto es la tarea de crear texto natural basado en un prompt dado. Los modelos más recientes ofrecen las siguientes funciones avanzadas: - Generación multimodal: creación de contenido que combina texto e imágenes - Generación automática de código: escritura de código optimizado para diferentes lenguajes de programación - Agentes conversacionales: implementación de chatbots inteligentes que comprenden el contexto - Texto especializado: generación de documentos en dominios especializados como la medicina y el derecho</p>
<div id="cell-100" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Text generation pipeline (using gpt2 model)</span></span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a>generator <span class="op">=</span> pipeline(<span class="st">'text-generation'</span>, model<span class="op">=</span><span class="st">'gpt2'</span>)  <span class="co"># Smaller model</span></span>
<span id="cb76-5"><a href="#cb76-5" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> generator(<span class="st">"Design a webpage that"</span>, max_length<span class="op">=</span><span class="dv">50</span>, num_return_sequences<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb76-6"><a href="#cb76-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(result[<span class="dv">0</span>][<span class="st">'generated_text'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>Device set to use cuda:0
Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Design a webpage that is compatible with your browser with our FREE SEO Service.

You read that right. By utilizing a web browser's default settings, your webpage should be free from advertisements and other types of spam. The best way to avoid this</code></pre>
</div>
</div>
<p>La clasificación de texto se habrá sofisticado aún más para 2025, ofreciendo las siguientes funciones:</p>
<ul>
<li>Aprendizaje por cero/uno: a través de la biblioteca Transformers de Hugging Face es posible una adaptación inmediata a nuevas categorías. En particular, los modelos de aprendizaje previo basados en inferencia de lenguaje natural pueden lograr una precisión superior al 90% con menos de 8 ejemplos y son aplicables a diversos dominios.</li>
<li>Clasificación multilingüe: los modelos multilingües más recientes, como ModernBERT de Hugging Face, admiten más de 16 idiomas principales. Específicamente, el modelo base de 150M de parámetros logra una puntuación F1 superior al 80% y muestra un rendimiento excelente incluso en idiomas con recursos limitados.</li>
<li>Clasificación jerárquica: el marco HiGen de Hugging Face proporciona funciones especializadas para la clasificación de etiquetas jerárquicas. A través de una función de pérdida basada en niveles, captura eficazmente las relaciones semánticas entre texto y etiquetas, mostrando un alto rendimiento incluso en clases con datos limitados.</li>
<li>Clasificación en tiempo real: a través de las pipelines de Hugging Face es posible el procesamiento en tiempo real de datos de transmisión. Con tecnologías de optimización como Flash Attention integradas por defecto, se pueden manejar secuencias largas de manera eficiente y se ofrece un alto rendimiento en aplicaciones en tiempo real.</li>
</ul>
<section id="ajuste-fino-y-compartición-de-modelos" class="level5">
<h5 class="anchored" data-anchor-id="ajuste-fino-y-compartición-de-modelos">Ajuste fino y compartición de modelos</h5>
<p>Hugging Face proporciona la última tecnología de ajuste fino para apoyar el aprendizaje eficiente de grandes modelos de lenguaje. Estas tecnologías permiten reducir significativamente los costos y tiempos de aprendizaje mientras mantienen el rendimiento del modelo.</p>
<ul>
<li>QLoRA (Quantized Low-Rank Adaptation): proporcionado a través de la biblioteca PEFT de Hugging Face, combina cuantización de 4 bits con adaptación de bajo rango para reducir el uso de memoria en más del 90%. En particular, es posible ajustar modelos de 65B parámetros en una GPU de 48GB.</li>
<li>Spectrum: técnica de optimización selectiva por capa integrada con la biblioteca TRL de Hugging Face. Analiza la relación señal-ruido de cada capa y selecciona para el aprendizaje solo las capas más importantes, mejorando así la eficiencia computacional.</li>
<li>Flash Attention: compatible por defecto desde la versión 2.2 de Transformers de Hugging Face y se puede activar fácilmente con el parámetro attn_implementation=“flash_attention_2”. En particular, mejora significativamente la eficiencia de memoria en el procesamiento de secuencias largas.</li>
<li>DeepSpeed: totalmente integrado a través de la biblioteca Accelerate de Hugging Face y apoya eficientemente el aprendizaje distribuido a gran escala mediante el optimizador ZeRO. También es utilizable durante la inferencia, permitiendo cargar modelos grandes en múltiples GPUs.</li>
</ul>
<div id="cell-102" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer, DataCollatorWithPadding</span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> Dataset</span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb79-5"><a href="#cb79-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-6"><a href="#cb79-6" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 1. Load a pre-trained model and tokenizer ---</span></span>
<span id="cb79-7"><a href="#cb79-7" aria-hidden="true" tabindex="-1"></a>model_name <span class="op">=</span> <span class="st">"distilbert-base-uncased"</span>  <span class="co"># Use a small, fast model</span></span>
<span id="cb79-8"><a href="#cb79-8" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(model_name)</span>
<span id="cb79-9"><a href="#cb79-9" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForSequenceClassification.from_pretrained(model_name, num_labels<span class="op">=</span><span class="dv">2</span>)  <span class="co"># Binary classification</span></span>
<span id="cb79-10"><a href="#cb79-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-11"><a href="#cb79-11" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 2. Create a simple dataset (for demonstration) ---</span></span>
<span id="cb79-12"><a href="#cb79-12" aria-hidden="true" tabindex="-1"></a>raw_data <span class="op">=</span> {</span>
<span id="cb79-13"><a href="#cb79-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">"text"</span>: [</span>
<span id="cb79-14"><a href="#cb79-14" aria-hidden="true" tabindex="-1"></a>        <span class="st">"This is a positive example!"</span>,</span>
<span id="cb79-15"><a href="#cb79-15" aria-hidden="true" tabindex="-1"></a>        <span class="st">"This is a negative example."</span>,</span>
<span id="cb79-16"><a href="#cb79-16" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Another positive one."</span>,</span>
<span id="cb79-17"><a href="#cb79-17" aria-hidden="true" tabindex="-1"></a>        <span class="st">"And a negative one."</span></span>
<span id="cb79-18"><a href="#cb79-18" aria-hidden="true" tabindex="-1"></a>    ],</span>
<span id="cb79-19"><a href="#cb79-19" aria-hidden="true" tabindex="-1"></a>    <span class="st">"label"</span>: [<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>],  <span class="co"># 1 for positive, 0 for negative</span></span>
<span id="cb79-20"><a href="#cb79-20" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb79-21"><a href="#cb79-21" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> Dataset.from_dict(raw_data)</span>
<span id="cb79-22"><a href="#cb79-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-23"><a href="#cb79-23" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 3. Tokenize the dataset ---</span></span>
<span id="cb79-24"><a href="#cb79-24" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tokenize_function(examples):</span>
<span id="cb79-25"><a href="#cb79-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tokenizer(examples[<span class="st">"text"</span>], truncation<span class="op">=</span><span class="va">True</span>) <span class="co">#padding is handled by data collator</span></span>
<span id="cb79-26"><a href="#cb79-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-27"><a href="#cb79-27" aria-hidden="true" tabindex="-1"></a>tokenized_dataset <span class="op">=</span> dataset.<span class="bu">map</span>(tokenize_function, batched<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb79-28"><a href="#cb79-28" aria-hidden="true" tabindex="-1"></a>tokenized_dataset <span class="op">=</span> tokenized_dataset.remove_columns([<span class="st">"text"</span>]) <span class="co"># remove text, keep label</span></span>
<span id="cb79-29"><a href="#cb79-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-30"><a href="#cb79-30" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 4. Data Collator (for dynamic padding) ---</span></span>
<span id="cb79-31"><a href="#cb79-31" aria-hidden="true" tabindex="-1"></a>data_collator <span class="op">=</span> DataCollatorWithPadding(tokenizer<span class="op">=</span>tokenizer)</span>
<span id="cb79-32"><a href="#cb79-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-33"><a href="#cb79-33" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 5. Training Arguments ---</span></span>
<span id="cb79-34"><a href="#cb79-34" aria-hidden="true" tabindex="-1"></a>fp16_enabled <span class="op">=</span> <span class="va">False</span></span>
<span id="cb79-35"><a href="#cb79-35" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> torch.cuda.is_available():</span>
<span id="cb79-36"><a href="#cb79-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb79-37"><a href="#cb79-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> torch.cuda.get_device_capability()[<span class="dv">0</span>] <span class="op">&gt;=</span> <span class="dv">7</span>:</span>
<span id="cb79-38"><a href="#cb79-38" aria-hidden="true" tabindex="-1"></a>            fp16_enabled <span class="op">=</span> <span class="va">True</span></span>
<span id="cb79-39"><a href="#cb79-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span>:</span>
<span id="cb79-40"><a href="#cb79-40" aria-hidden="true" tabindex="-1"></a>        <span class="cf">pass</span></span>
<span id="cb79-41"><a href="#cb79-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-42"><a href="#cb79-42" aria-hidden="true" tabindex="-1"></a>training_args <span class="op">=</span> TrainingArguments(</span>
<span id="cb79-43"><a href="#cb79-43" aria-hidden="true" tabindex="-1"></a>    output_dir<span class="op">=</span><span class="st">"./results"</span>,</span>
<span id="cb79-44"><a href="#cb79-44" aria-hidden="true" tabindex="-1"></a>    num_train_epochs<span class="op">=</span><span class="dv">1</span>,          <span class="co"># Keep it short</span></span>
<span id="cb79-45"><a href="#cb79-45" aria-hidden="true" tabindex="-1"></a>    per_device_train_batch_size<span class="op">=</span><span class="dv">2</span>,  <span class="co"># Small batch size</span></span>
<span id="cb79-46"><a href="#cb79-46" aria-hidden="true" tabindex="-1"></a>    logging_steps<span class="op">=</span><span class="dv">1</span>,           <span class="co"># Log every step</span></span>
<span id="cb79-47"><a href="#cb79-47" aria-hidden="true" tabindex="-1"></a>    save_strategy<span class="op">=</span><span class="st">"no"</span>,         <span class="co"># No saving</span></span>
<span id="cb79-48"><a href="#cb79-48" aria-hidden="true" tabindex="-1"></a>    report_to<span class="op">=</span><span class="st">"none"</span>,          <span class="co"># No reporting</span></span>
<span id="cb79-49"><a href="#cb79-49" aria-hidden="true" tabindex="-1"></a>    fp16<span class="op">=</span>fp16_enabled,  <span class="co"># Use fp16 if avail.</span></span>
<span id="cb79-50"><a href="#cb79-50" aria-hidden="true" tabindex="-1"></a>    <span class="co"># --- Optimization techniques (demonstration) ---</span></span>
<span id="cb79-51"><a href="#cb79-51" aria-hidden="true" tabindex="-1"></a>    <span class="co"># gradient_checkpointing=True,  # Enable gradient checkpointing (if needed for large models)</span></span>
<span id="cb79-52"><a href="#cb79-52" aria-hidden="true" tabindex="-1"></a>    <span class="co"># gradient_accumulation_steps=2, # Increase effective batch size</span></span>
<span id="cb79-53"><a href="#cb79-53" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb79-54"><a href="#cb79-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-55"><a href="#cb79-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-56"><a href="#cb79-56" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 6. Trainer ---</span></span>
<span id="cb79-57"><a href="#cb79-57" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> Trainer(</span>
<span id="cb79-58"><a href="#cb79-58" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model,</span>
<span id="cb79-59"><a href="#cb79-59" aria-hidden="true" tabindex="-1"></a>    args<span class="op">=</span>training_args,</span>
<span id="cb79-60"><a href="#cb79-60" aria-hidden="true" tabindex="-1"></a>    train_dataset<span class="op">=</span>tokenized_dataset,</span>
<span id="cb79-61"><a href="#cb79-61" aria-hidden="true" tabindex="-1"></a>    <span class="co"># eval_dataset=...,  # Add an eval dataset if you have one</span></span>
<span id="cb79-62"><a href="#cb79-62" aria-hidden="true" tabindex="-1"></a>    data_collator<span class="op">=</span>data_collator,  <span class="co"># Use the data collator</span></span>
<span id="cb79-63"><a href="#cb79-63" aria-hidden="true" tabindex="-1"></a>    <span class="co"># optimizers=(optimizer, scheduler) # you could also customize optimizer</span></span>
<span id="cb79-64"><a href="#cb79-64" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb79-65"><a href="#cb79-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-66"><a href="#cb79-66" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 7. Train ---</span></span>
<span id="cb79-67"><a href="#cb79-67" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Starting training..."</span>)</span>
<span id="cb79-68"><a href="#cb79-68" aria-hidden="true" tabindex="-1"></a>trainer.train()</span>
<span id="cb79-69"><a href="#cb79-69" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Training finished!"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ad7aa580feaf4d5fa3abcd96b1bc43e3","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"24731acb95cb4dbea5d194f768b17df3","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ee9456452ccb4910849e2973a1765462","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"688ecbdc102a4cc6b562c911f79851c0","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"62d43521fee04e07a6ce10a5488d2b38","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c2522a9d78974c45beeb8575e3c29e85","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Starting training...</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/sean/anaconda3/envs/DL/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(</code></pre>
</div>
<div class="cell-output cell-output-display">

    <div>
      
      <progress value="1" max="1" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [1/1 00:00, Epoch 1/1]
    </div>
    
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">Step</th>
<th data-quarto-table-cell-role="th">Training Loss</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>0.667500</td>
</tr>
</tbody>
</table>
<p>
</p></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training finished!</code></pre>
</div>
</div>
<p>El ecosistema de compartir modelos actualmente admite las siguientes características más recientes para 2025. - Generación automática de tarjetas de modelo: el sistema automatizado de tarjetas de modelo de Hugging Face analiza y documenta automáticamente los indicadores de rendimiento y sesgo. En particular, se puede describir claramente las características y limitaciones del modelo en un formato estandarizado a través de la Herramienta de Tarjeta de Modelo. - Control de versiones: el sistema de control de versiones basado en Git de Hugging Face Hub permite rastrear el historial de cambios y las variaciones de rendimiento del modelo. Se pueden registrar y comparar automáticamente los métricas de rendimiento y los cambios de parámetros para cada versión. - Herramientas colaborativas: proporciona un entorno colaborativo integrado con Hugging Face Spaces. Los miembros del equipo pueden compartir en tiempo real el proceso de desarrollo, prueba y despliegue de modelos, intercambiar comentarios y también se admite la integración con pipelines CI/CD. - IA ética: a través del marco de IA ética de Hugging Face, se puede verificar y evaluar automáticamente el sesgo del modelo. En particular, se pueden analizar las diferencias en rendimiento entre diversos grupos demográficos y se pueden identificar riesgos potenciales con anticipación.</p>
</section>
</section>
</section>
<section id="ejercicios-de-práctica" class="level2">
<h2 class="anchored" data-anchor-id="ejercicios-de-práctica">Ejercicios de práctica</h2>
<p><strong>1. Problemas básicos</strong></p>
<ul>
<li>Explique las diferencias entre los tensores de PyTorch y los arrays de NumPy, y cómo convertir entre ellos.</li>
<li>Describa el papel de la capa <code>torch.nn.Linear</code> y cómo inicializar sus pesos.</li>
<li>Explique cómo funciona la diferenciación automática (automatic differentiation) en PyTorch y el rol de la propiedad <code>requires_grad</code>.</li>
</ul>
<p><strong>2. Problemas aplicados</strong></p>
<ul>
<li>Escriba un código para dividir un conjunto de datos dado en conjuntos de entrenamiento, validación y prueba utilizando <code>torch.utils.data.Dataset</code> y <code>torch.utils.data.DataLoader</code>, y cargue los datos por lotes.</li>
<li>Implemente un modelo de CNN simple (por ejemplo, LeNet-5) heredando de <code>nn.Module</code> y use <code>torchsummary</code> para verificar la estructura del modelo y el número de parámetros.</li>
<li>Entrene un modelo usando el conjunto de datos MNIST o Fashion-MNIST y visualice el proceso de entrenamiento (pérdida, precisión, etc.) utilizando TensorBoard.</li>
</ul>
<p><strong>3. Problemas avanzados</strong></p>
<ul>
<li>Implemente multiplicación de matrices, transposición, multiplicación de matrices por lotes, transformaciones bilineales, etc., usando <code>torch.einsum</code>. (Proporcione la notación de Einstein para cada operación y implemente el código en PyTorch.)</li>
<li>Escriba un código para crear un conjunto de datos personalizado y aplicar aumentación de datos (data augmentation) utilizando <code>torchvision.transforms</code> (por ejemplo, rotación de imágenes, recorte, transformaciones de color).</li>
<li>Explique cómo calcular derivadas de orden superior usando <code>torch.autograd.grad</code> y escriba un ejemplo de código simple. (Por ejemplo, el cálculo de la matriz Hessiana)</li>
<li>Explique por qué se puede llamar a un objeto de modelo como una función sin necesidad de invocar directamente el método <code>forward()</code> de <code>torch.nn.Module</code>. (Pista: considere la relación con el método <code>__call__</code> y el sistema de diferenciación automática)</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled" title="Haga clic para ver el contenido (solución)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Haga clic para ver el contenido (solución)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<section id="soluciones-a-los-ejercicios-de-práctica" class="level2 callout-body-container callout-body">
<h2 class="anchored" data-anchor-id="soluciones-a-los-ejercicios-de-práctica">Soluciones a los Ejercicios de Práctica</h2>
<section id="soluciones-a-los-problemas-básicos" class="level3">
<h3 class="anchored" data-anchor-id="soluciones-a-los-problemas-básicos">1. Soluciones a los Problemas Básicos</h3>
<ol type="1">
<li><strong>Tensor vs.&nbsp;Array NumPy:</strong>
<ul>
<li><strong>Diferencias:</strong> El tensor admite aceleración GPU y diferenciación automática. NumPy es una operación de matriz genérica basada en CPU.</li>
<li><strong>Conversión:</strong> <code>torch.from_numpy()</code>, <code>.numpy()</code> (sin embargo, para tensores GPU se requiere <code>.cpu()</code> primero).</li>
</ul>
<div class="sourceCode" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Ejemplo</span></span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a>numpy_array <span class="op">=</span> np.array([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>])</span>
<span id="cb84-5"><a href="#cb84-5" aria-hidden="true" tabindex="-1"></a>torch_tensor <span class="op">=</span> torch.from_numpy(numpy_array)  <span class="co"># o torch.tensor()</span></span>
<span id="cb84-6"><a href="#cb84-6" aria-hidden="true" tabindex="-1"></a>numpy_back <span class="op">=</span> torch_tensor.cpu().numpy()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><strong><code>nn.Linear</code>:</strong>
<ul>
<li><strong>Función:</strong> <code>y = xW^T + b</code> (transformación lineal). Multiplica la entrada <code>x</code> por el peso <code>W</code> y suma el sesgo <code>b</code>.</li>
<li><strong>Inicialización:</strong> Por defecto, inicialización Kaiming He (distribución uniforme). Se puede cambiar usando el módulo <code>torch.nn.init</code>.</li>
</ul>
<div class="sourceCode" id="cb85"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Ejemplo</span></span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.init <span class="im">as</span> init</span>
<span id="cb85-4"><a href="#cb85-4" aria-hidden="true" tabindex="-1"></a>linear_layer <span class="op">=</span> nn.Linear(in_features<span class="op">=</span><span class="dv">10</span>, out_features<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb85-5"><a href="#cb85-5" aria-hidden="true" tabindex="-1"></a>init.xavier_uniform_(linear_layer.weight) <span class="co"># Inicialización Xavier</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><strong>Diferenciación Automática (Autograd):</strong>
<ul>
<li><strong>Funcionamiento:</strong> Cuando se realizan operaciones con tensores <code>requires_grad=True</code>, se crea un grafo de cálculo, y al llamar a <code>.backward()</code>, se calcula el gradiente mediante la regla de la cadena.</li>
<li><strong><code>requires_grad</code>:</strong> Establece si se debe calcular y rastrear el gradiente.</li>
</ul>
<div class="sourceCode" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Ejemplo</span></span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="fl">2.0</span>], requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> x<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> <span class="dv">3</span><span class="op">*</span>x <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a>y.backward()</span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.grad)  <span class="co"># Salida: tensor([7.])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ol>
</section>
<section id="soluciones-a-los-problemas-de-aplicación" class="level3">
<h3 class="anchored" data-anchor-id="soluciones-a-los-problemas-de-aplicación">2. Soluciones a los Problemas de Aplicación</h3>
<ol start="4" type="1">
<li><p><strong><code>Dataset</code>, <code>DataLoader</code>:</strong></p>
<div class="sourceCode" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset, DataLoader, random_split</span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.transforms <span class="im">as</span> transforms</span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets</span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-5"><a href="#cb87-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Conjunto de Datos Personalizado (Ejemplo)</span></span>
<span id="cb87-6"><a href="#cb87-6" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> CustomDataset(Dataset):</span>
<span id="cb87-7"><a href="#cb87-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, data, targets, transform<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb87-8"><a href="#cb87-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.data <span class="op">=</span> data</span>
<span id="cb87-9"><a href="#cb87-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.targets <span class="op">=</span> targets</span>
<span id="cb87-10"><a href="#cb87-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.transform <span class="op">=</span> transform</span>
<span id="cb87-11"><a href="#cb87-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb87-12"><a href="#cb87-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.data)</span>
<span id="cb87-13"><a href="#cb87-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, idx):</span>
<span id="cb87-14"><a href="#cb87-14" aria-hidden="true" tabindex="-1"></a>        sample, label <span class="op">=</span> <span class="va">self</span>.data[idx], <span class="va">self</span>.targets[idx]</span>
<span id="cb87-15"><a href="#cb87-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.transform:</span>
<span id="cb87-16"><a href="#cb87-16" aria-hidden="true" tabindex="-1"></a>            sample <span class="op">=</span> <span class="va">self</span>.transform(sample)</span>
<span id="cb87-17"><a href="#cb87-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> sample, label</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<h1 id="mnist-dataloader-ejemplo-utilizando-torchvision">MNIST DataLoader ejemplo (utilizando torchvision)</h1>
<p>transform = transforms.ToTensor() # datos de imagen a tensor mnist_dataset = datasets.MNIST(root=‘./data’, train=True, download=True, transform=transform) train_size = int(0.8 * len(mnist_dataset)) val_size = len(mnist_dataset) - train_size train_dataset, val_dataset = random_split(mnist_dataset, [train_size, val_size]) train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True) val_loader = DataLoader(val_dataset, batch_size=32)</p></li>
</ol>
<pre><code>
5.  **LeNet-5, `torchsummary`, tensorboard:** (código completo ver respuesta anterior, aquí solo la parte clave)

```python
import torch.nn as nn
import torch.nn.functional as F
from torchsummary import summary
from torch.utils.tensorboard import SummaryWriter

# Modelo LeNet-5
class LeNet5(nn.Module):
    def __init__(self):
        super(LeNet5, self).__init__()
        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2)
        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)
        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)
        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = self.pool1(x)
        x = F.relu(self.conv2(x))
        x = self.pool2(x)
        x = x.view(x.size(0), -1)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

model = LeNet5()
summary(model, input_size=(1, 28, 28)) # resumen de la estructura del modelo

# ... (código de entrenamiento, ver respuesta anterior) ...

writer = SummaryWriter() # tensorboard
# ... (durante el entrenamiento usar writer.add_scalar() para registrar) ...
writer.close()</code></pre>
</section>
<section id="solución-a-problemas-avanzados" class="level3">
<h3 class="anchored" data-anchor-id="solución-a-problemas-avanzados">3. Solución a problemas avanzados</h3>
<ol start="6" type="1">
<li><strong><code>torch.einsum</code>:</strong></li>
</ol>
<div class="sourceCode" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>A = torch.randn(3, 4) B = torch.randn(4, 5) C = torch.einsum(“ij,jk-&gt;ik”, A, B) # multiplicación de matrices D = torch.einsum(“ij-&gt;ji”, A) # transposición E = torch.einsum(“bi,bj,ijk-&gt;bk”, A, B, torch.randn(2,3,4)) # transformación bilineal</p>
<pre><code>
7.  **Conjunto de datos personalizado, aumento de datos:**

```python
from torch.utils.data import Dataset
from torchvision import transforms
from PIL import Image
import os

class CustomImageDataset(Dataset): # herencia de Dataset
    def __init__(self, root_dir, transform=None):
        # ... (implementación del constructor) ...
        pass
    def __len__(self):
        # ... (devolver el número de datos) ...
        pass
    def __getitem__(self, idx):
        # ... (devolver la muestra correspondiente a idx) ...
        pass

# aumento de datos
transform = transforms.Compose([
    transforms.RandomResizedCrop(224),  # recorte aleatorio con tamaño y relación de aspecto
    transforms.RandomHorizontalFlip(),     # volteo horizontal aleatorio
    transforms.ToTensor(),              # conversión a tensor
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # normalización
])

# dataset = CustomImageDataset(root_dir='path/to/images', transform=transform)</code></pre>
<ol start="8" type="1">
<li><strong>Funciones de orden superior:</strong></li>
</ol>
<div class="sourceCode" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor(<span class="fl">2.0</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> x<span class="op">**</span><span class="dv">3</span></span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-6"><a href="#cb91-6" aria-hidden="true" tabindex="-1"></a><span class="co"># derivada primera</span></span>
<span id="cb91-7"><a href="#cb91-7" aria-hidden="true" tabindex="-1"></a>first_derivative <span class="op">=</span> torch.autograd.grad(y, x, create_graph<span class="op">=</span><span class="va">True</span>)[<span class="dv">0</span>]  <span class="co"># create_graph=True</span></span>
<span id="cb91-8"><a href="#cb91-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(first_derivative)</span>
<span id="cb91-9"><a href="#cb91-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-10"><a href="#cb91-10" aria-hidden="true" tabindex="-1"></a><span class="co"># derivada segunda (hessiano)</span></span>
<span id="cb91-11"><a href="#cb91-11" aria-hidden="true" tabindex="-1"></a>second_derivative <span class="op">=</span> torch.autograd.grad(first_derivative, x)[<span class="dv">0</span>]</span>
<span id="cb91-12"><a href="#cb91-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(second_derivative)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ol start="9" type="1">
<li><strong>Método <code>__call__</code>:</strong></li>
</ol>
<p>El método <code>__call__</code> de <code>nn.Module</code> realiza tareas adicionales (como registrar hooks, configuraciones relacionadas con la diferenciación automática) <em>antes y después</em> de llamar a <code>forward()</code>. Si se llama directamente a <code>forward()</code>, estas funcionalidades pueden ser omitidas, lo que podría resultar en cálculos incorrectos de gradientes o en mal funcionamiento de otras características del modelo (por ejemplo, la configuración de la propiedad <code>training</code> de <code>nn.Module</code>). Por lo tanto, <em>siempre</em> debe llamarse al objeto de modelo como si fuera una función (<code>model(input)</code>).</p>
</section>
</section>
</div>
</div>
<p><strong>Referencias</strong></p>
<ol type="1">
<li><strong>Tutorial oficial de PyTorch:</strong> <a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://pytorch.org/tutorials/">https://pytorch.org/tutorials/</a></li>
<li><strong>Deep Learning with PyTorch (Stevens, Antiga, Viehmann, 2020):</strong> <a href="https://www.google.com/search?q=https://pytorch.org/deep-learning-with-pytorch">https://pytorch.org/deep-learning-with-pytorch</a></li>
<li><strong>Programming PyTorch for Deep Learning (Delugach, 2023):</strong> <a href="https://www.google.com/search?q=https://www.oreilly.com/library/view/programming-pytorch-for/9781098142481/">https://www.oreilly.com/library/view/programming-pytorch-for/9781098142481/</a></li>
<li><strong>PyTorch Recipes (Kalyan, 2019):</strong> <a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://pytorch.org/tutorials/recipes/recipes_index.html">https://pytorch.org/tutorials/recipes/recipes_index.html</a></li>
<li><strong>Understanding the difficulty of training deep feedforward neural networks (Glorot &amp; Bengio, 2010):</strong> <a href="http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf">http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf</a></li>
<li><strong>Biblioteca Fastai:</strong> <a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://docs.fast.ai/">https://docs.fast.ai/</a></li>
<li><strong>PyTorch Lightning:</strong> <a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://www.pytorchlightning.ai/">https://www.pytorchlightning.ai/</a></li>
<li><strong>Documentación de Hugging Face Transformers:</strong> <a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://huggingface.co/docs/transformers/index">https://huggingface.co/docs/transformers/index</a></li>
<li><strong>Documentación de TensorBoard:</strong> <a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://www.tensorflow.org/tensorboard">https://www.tensorflow.org/tensorboard</a></li>
<li><strong>Documentación de Weights &amp; Biases:</strong> <a href="https://www.google.com/url?sa=E&amp;source=gmail&amp;q=https://docs.wandb.ai/">https://docs.wandb.ai/</a></li>
</ol>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>