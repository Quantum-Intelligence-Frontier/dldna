{"entries":[],"headings":["최적화와-시각화","파라미터-초기화의-발전과-현대적-접근","초기화-방법의-수학적-원리","전통적-초기화","현대적-초기화","최신-초기화-2023년-이후","수학적-원리","심층-신경망-초기화의-수학적-원리와-최신-기법","분산-보존-원리-variance-preservation-principle","이론적-기반","비선형-활성화-함수-확장","확률론적-접근-참고","스펙트럴-제어-spectral-control","특이값-분해와-학습-역학","동적-스펙트럴-정규화","표현력-최적화-expressivity-optimization","유효-랭크-이론","초기화-전략-비교표","emergence-promoting-초기화","초기화와-최적화의-상호작용","ntk-이론-확장","메타-초기화-전략","참고-물리-기반-초기화-기법","실용적-권장-사항","참고-문헌","초기화-방법-실전-비교-분석","실무적-권장사항-및-추가-고려-사항","기본-원칙","모델-규모-및-특성","추가-고려-사항","최적화-알고리즘-딥러닝-학습의-핵심-엔진","최적화-알고리즘의-발전과-구현---계속되는-진화","최적화-알고리즘의-역사","기본-최적화-알고리즘","현대적-최적화-알고리즘-더-빠르고-더-효율적으로-더-큰-모델을-위해","현대-최적화-알고리즘의-심층-분석","lion-evolved-sign-momentum","sophia-second-order-clipped-stochastic-optimization","adafactor","그-외-참고할-만한-최신-최적화-알고리즘","최적화-훈련-비교","기본-태스크-분석","고급-태스크-평가","최적화-과정의-시각화와-분석-딥러닝-학습의-블랙박스-들여다보기","손실-표면loss-landscape의-이해-딥러닝-모델의-지형도","기본-시각화-기법","손실-표면-분석의-심층-기법","위상-기반-손실-표면-분석","다중-스케일-손실-표면-분석","최적화-과정-시각화-가우시안-함수로-엿보는-딥러닝-학습의-비밀","가우시안-함수를-통한-근사적-분석-단순함-속에-숨겨진-통찰","경로-시각화","최적화-과정의-동적-분석-학습-궤적의-탐구","훈련-과정의-특징","학습-안정성-분석-및-제어","안정성-분석-방법론","안정화-기법-stabilization-techniques","최신-연구-동향","맺음말","연습-문제","기본-문제","응용-문제","심화-문제","연습-문제-해답","기본-문제-1","응용-문제-1","심화-문제-1","참고-자료"]}