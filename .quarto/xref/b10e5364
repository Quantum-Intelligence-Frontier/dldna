{"entries":[],"headings":["장-트랜스포머의-진화-효율성과-확장성을-향하여","트랜스포머의-한계와-도전","트랜스포머-아키텍처의-기본-한계-계산-복잡도","트랜스포머-아키텍처의-기본-한계-메모리-효율성","트랜스포머-발전의-시대적-흐름과-본-장의-구성","복잡도-감소-소프트웨어적-어텐션-최적화-2019-2020","초기-접근법-근사화와-희소화","선형-어텐션-performer","희소-어텐션-sparse-transformer-longformer","로컬-글로벌-어텐션-장거리-의존성-문제-해결","reformer-lsh-어텐션","bigbird-로컬-글로벌-랜덤-어텐션의-조합","메모리-효율성-하드웨어와-소프트웨어의-결합-2021-2022","flashattention-gpu-메모리-계층-구조를-활용한-어텐션-최적화","gpu-메모리-구조와-io-최적화","타일링과-블록-처리","flashattention-v2-하드웨어-활용-극대화","쿼리-최적화-어텐션-구조-개선","multi-query-attention-mqa","grouped-query-attention-gqa","mqa-vs.-gqa-vs.-multi-head-attention","kv-캐시-관리와-최적화","pagedattention-vllm-운영체제-페이징-개념에서","연속-배치와-효율적인-캐싱-전략-continuous-batching-efficient-caching","확장성과-특수-목적-아키텍처-2023-2024","long-context-처리-문맥-길이의-확장","계층적-어텐션-recurrent-memory-transformer","claude-2-longlora","윤리적안전-제약-constitutional-ai","규칙-기반-어텐션","강화학습-기반-조정-rlhf-rlaif","특수-목적-어텐션-도메인-및-태스크별-최적화","특수-목적-어텐션의-다양한-예시","멀티모달-어텐션-multimodal-attention","딥-다이브-트랜스포머-모델별-상세-분석-및-기술-연관성","인코더-중심-모델-encoder-only-models","디코더-중심-모델-decoder-only-models","하이브리드-접근-모델-encoder-decoder-models","기술-연관성-심층-분석","미래-전망","효율적인-인코더의-구현과-응용-rope와-flashattention을-중심으로","효율적인-인코더의-설계-철학-속도와-메모리","efficient_encoder.py-코드-상세-분석-rope-미사용","efficient_encoder_rope.py-코드-상세-분석-rope-사용","실험-결과-ag-news-텍스트-분류","mistral-효율적인-디코더-아키텍처-구현-및-분석","simple_mistral-모델-아키텍처-구성-요소-상세-분석","mistralconfig-모델-설정","mistralrmsnorm-rms-정규화","mistralattention-어텐션-메커니즘","mistralrotaryembedding-rope-구현","mistralmlp-feedforward-네트워크","mistraldecoderlayer-디코더-레이어","mistralpretrainedmodel-사전-학습-모델-추상-클래스","mistralmodel-mistral-모델","mistralforcausallm-언어-모델링용-mistral","핵심-기술-요소-분석-효율성과-성능의-비결","gqa-grouped-query-attention-메모리와-계산-효율성을-위한-혁신","swa-sliding-window-attention-긴-시퀀스-처리를-위한-효율적인-전략","rope-rotary-positional-embedding-상대적-위치-정보를-효율적으로-인코딩","kv-캐시-중복-계산을-제거","모델-학습-simple_mistral-훈련-가이드","데이터-전처리-모델이-이해할-수-있는-형태로-변환","모델-학습-최적의-파라미터-찾기","generate-함수를-사용한-텍스트-생성-창의적인-문장-만들기","generate-함수-텍스트-생성의-핵심","생성-과정-단계별-텍스트-생성","숫자-시퀀스-예측-예제-train_seq_num.py-분석","데이터셋-및-데이터-로더-준비-학습-데이터-구성","모델-설정-및-학습-simple_mistral-훈련","텍스트-생성-학습된-모델을-통한-예측","결과-분석-학습-결과-및-생성된-텍스트-평가","사칙-연산-예측-예제-train_math.py-분석","데이터-생성-및-전처리-기호와-숫자의-조화","모델-설정-및-학습","텍스트-생성","결과-분석","자연어-sql-쿼리-생성-예제-train_sql.py-분석","데이터셋-및-전처리-wikisql과-특수-토큰의-조화","모델-설정-및-학습-1","텍스트-생성-generate_sql-질문으로부터-sql-쿼리-추론","결과-분석-1","견고한-트랜스포머-설계-및-디버깅---실용-가이드","단위-테스트의-필수적인-역할","단위-테스트를-넘어-기타-디버깅-전략","gemma-최신-개방형-모델-살펴보기","gemma를-살펴보는-이유","gemma-모델의-특징-mistral과-비교","결론","phi-3-작지만-강력한-언어-모델","simple_phi3-모델","phiminiconfig-모델-설정","phiminirmsnorm-rms-정규화","phiminirotaryembedding-rope-구현-향상된-캐싱","phiminiattention-어텐션-메커니즘-mha-효율적인-rope-적용","헬퍼-함수-rotate_half-apply_rotary_pos_emb-apply_rotary_pos_emb_single","phiminimlp-feedforward-네트워크","phiminidecoderlayer-디코더-레이어","phiminimodel-전체-모델","phiminiforcausallm-언어-모델링을-위한-헤드-추가","simple_phi3-모델-예제-복합-수식-계산","맺음말","moemixture-of-experts-아키텍처의-이론적-진화와-최신-기술-동향","moe의-이론적-기반","기본-구성-요소","sparse-moe와-dense-moe","수학적-형식화와-변분-추론-관점","sparse-moe의-구조적-혁신","계층적-전문가-분할hierarchical-expert-partitioning","동적-토폴로지-어댑테이션","moe-모델의-장점과-최적화","장점","최적화-이론의-혁신","moe-모델의-예시와-한계","예","한계와-과제","물리적-구현의-최전선","스파스-전문가-액티베이션-하드웨어","양자화된-전문가-교환","이론적-확장의-최신-동향","연속-전문가-공간continuous-expert-space","신경-미분-방정식-기반-전문가","도전-과제와-미래-방향","이론적-한계에-대한-심층-분석","차세대-연구-프레임워크","실무적-적용-사례-연구","초대규모-추론-시스템-설계","교차-모달-응용-확장","연습문제","연습문제-해답","기본-문제","응용-문제","심화-문제","참고-자료"]}